{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle-Contradictory, My Dear Watson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "17Wzn2dzvc7gGPKiO1-Y7VVBuQ0aOZqnI",
      "authorship_tag": "ABX9TyPMGLXiXMu3K+u5RWG0pkt5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee850dd8394643f99e962a6abc91fc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ed60d275724435e80cf2a4cf800d35c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84f52b5958a143ae92d526aca93e24a7",
              "IPY_MODEL_f2e80f551da940d3a939385bafebbe10"
            ]
          }
        },
        "8ed60d275724435e80cf2a4cf800d35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84f52b5958a143ae92d526aca93e24a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aae2acc6ea8a45429a7cbf70c46d7c31",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_538fb52e35e84d46a69e52529ba504d5"
          }
        },
        "f2e80f551da940d3a939385bafebbe10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b0619f532f5407c9e39c74a43cfc64b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 373kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75c847356885489e99df11a173856ccd"
          }
        },
        "aae2acc6ea8a45429a7cbf70c46d7c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "538fb52e35e84d46a69e52529ba504d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b0619f532f5407c9e39c74a43cfc64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75c847356885489e99df11a173856ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f0320c05d82470495c399fbba6489cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b27bb311b7cc42198a8a53b3dbe5f7a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_db69db8d111448cf940b6e076aecf6a4",
              "IPY_MODEL_1226f85874454515bd637e37f0a44894"
            ]
          }
        },
        "b27bb311b7cc42198a8a53b3dbe5f7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db69db8d111448cf940b6e076aecf6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4511c6215e71415f966c65e3b068e80a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e547a854aa334b8ea8b454e36a2c3f37"
          }
        },
        "1226f85874454515bd637e37f0a44894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40573685cb7448fea33741063173bf23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 57.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0170880f2ec54b67931e8f6a3db271a5"
          }
        },
        "4511c6215e71415f966c65e3b068e80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e547a854aa334b8ea8b454e36a2c3f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40573685cb7448fea33741063173bf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0170880f2ec54b67931e8f6a3db271a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "941b28a29dcb4584be2e8c7cf6a478d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f6f28fb94494b55b9d334e28f6b49d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9793c4ce08574e258ba3ed94749fc252",
              "IPY_MODEL_e8fb3e2d761a40f4bc2155a350de1729"
            ]
          }
        },
        "1f6f28fb94494b55b9d334e28f6b49d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9793c4ce08574e258ba3ed94749fc252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_247a0d8bf032439bae7cd4260aa04f0f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cd619da2fdc4b708be49b8bbc566e8b"
          }
        },
        "e8fb3e2d761a40f4bc2155a350de1729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e43ec4d299c4daeba05f8c39a0e0d23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 2.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d50bf3a670ba47668d8cb527a576fb46"
          }
        },
        "247a0d8bf032439bae7cd4260aa04f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cd619da2fdc4b708be49b8bbc566e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e43ec4d299c4daeba05f8c39a0e0d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d50bf3a670ba47668d8cb527a576fb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3e9dddd8d3e4c1b899ff7a1999031f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24b0cb3422744d26a1ffde1d6a845589",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2daf5cbffcb748bd9b92976487ecadce",
              "IPY_MODEL_8f518c001cda4560892baa7ef24802bd"
            ]
          }
        },
        "24b0cb3422744d26a1ffde1d6a845589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2daf5cbffcb748bd9b92976487ecadce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb90febb025a4678830c792e85b46641",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d88c42e9ee4c40cdabbffe8ab8f6a119"
          }
        },
        "8f518c001cda4560892baa7ef24802bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76f1ce195b0a44e782a5757a6e24d612",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 19.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e884c4f449734a828bd3889ee8a2ba15"
          }
        },
        "fb90febb025a4678830c792e85b46641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d88c42e9ee4c40cdabbffe8ab8f6a119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76f1ce195b0a44e782a5757a6e24d612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e884c4f449734a828bd3889ee8a2ba15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fb3bb2a31a74b92b8f913d72160ce80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dea44764c93940b3bf176e640fcb3eb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7be9c1967e040eda1a01c6275fa5fd3",
              "IPY_MODEL_ac43314d11064c718fda9ad6b3143ebd"
            ]
          }
        },
        "dea44764c93940b3bf176e640fcb3eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7be9c1967e040eda1a01c6275fa5fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af9f36414038471aa065a0d1aa093646",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dccb47d8b9dc46b1948d59d650b94e41"
          }
        },
        "ac43314d11064c718fda9ad6b3143ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_123d61edf6da4c608de5654748661f86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:22&lt;00:00, 28.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2ae6401f8a04775aea153cab724431c"
          }
        },
        "af9f36414038471aa065a0d1aa093646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dccb47d8b9dc46b1948d59d650b94e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "123d61edf6da4c608de5654748661f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2ae6401f8a04775aea153cab724431c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1a11a6637764448a5827fd8bd677859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3f80a6280dc24b7990586caf9e7f900d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_536f5d16f66b4cffb18ad671a3cf8239",
              "IPY_MODEL_4fe6b82a63bd48bb921a0e0d4ac2d726"
            ]
          }
        },
        "3f80a6280dc24b7990586caf9e7f900d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "536f5d16f66b4cffb18ad671a3cf8239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f519ec3d868c4c04b9ed6207236df785",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 672271273,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 672271273,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c74203a1eab4c9b9ffbca44ce693e71"
          }
        },
        "4fe6b82a63bd48bb921a0e0d4ac2d726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee23ef1abce74a1096825abad919eb6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 672M/672M [00:19&lt;00:00, 34.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1ee7a9f37554ed8a3d0b032f2748d95"
          }
        },
        "f519ec3d868c4c04b9ed6207236df785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c74203a1eab4c9b9ffbca44ce693e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee23ef1abce74a1096825abad919eb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1ee7a9f37554ed8a3d0b032f2748d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "788b778c78034605b9701c2b45f7c2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5dcec3ef30944eaf9f45c11ca3cd7a8f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd69447e90854d668aaa3acfdc47b46e",
              "IPY_MODEL_bae03134d3324bfba3df658b800222b5"
            ]
          }
        },
        "5dcec3ef30944eaf9f45c11ca3cd7a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd69447e90854d668aaa3acfdc47b46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_449bdac3d045491797669793a579d201",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a40b7a1973f74b939f0f87b280a2c7fd"
          }
        },
        "bae03134d3324bfba3df658b800222b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4de106eb2064b96a617f4a6a9c68720",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.07M/5.07M [05:31&lt;00:00, 15.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cd6e99eef9d4dd58844502f1a7605ad"
          }
        },
        "449bdac3d045491797669793a579d201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a40b7a1973f74b939f0f87b280a2c7fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4de106eb2064b96a617f4a6a9c68720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cd6e99eef9d4dd58844502f1a7605ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "996398cbbd2f43e8a47f48fa0508b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97225b7a84694c688a42e51bacd146a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26695cd850424e948893cea4bda173c5",
              "IPY_MODEL_04494c9979814cba97fb2c860db8462e"
            ]
          }
        },
        "97225b7a84694c688a42e51bacd146a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26695cd850424e948893cea4bda173c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73b9c02429434480acecc6a97776a034",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bf6a4008a33480c94beb5c5d3b86583"
          }
        },
        "04494c9979814cba97fb2c860db8462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c78a6a6f9b7f499780a1c156c62262e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9.10M/9.10M [00:21&lt;00:00, 415kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f234d1e6b2004a518f82be422b0c10a9"
          }
        },
        "73b9c02429434480acecc6a97776a034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bf6a4008a33480c94beb5c5d3b86583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c78a6a6f9b7f499780a1c156c62262e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f234d1e6b2004a518f82be422b0c10a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a86e992d8c544a092e64b3aa824a2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8762d12c203146f1a56b5ebabf245865",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2be72b62f3c148349c15f9cbe3c27258",
              "IPY_MODEL_688baec7d74245878e7c455c1eaa713d"
            ]
          }
        },
        "8762d12c203146f1a56b5ebabf245865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2be72b62f3c148349c15f9cbe3c27258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db6392a51eb4408b8c198d1523030273",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 513,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 513,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41c22b69d3834445bb7f798a4620795e"
          }
        },
        "688baec7d74245878e7c455c1eaa713d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8cf14957c89741faa5553570fdc440a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 513/513 [00:21&lt;00:00, 24.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3547e0cf2f442b48692439ac1d332f6"
          }
        },
        "db6392a51eb4408b8c198d1523030273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41c22b69d3834445bb7f798a4620795e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cf14957c89741faa5553570fdc440a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3547e0cf2f442b48692439ac1d332f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Kaggle/blob/main/Kaggle_Contradictory%2C_My_Dear_Watson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uHkwXy_UvfE"
      },
      "source": [
        "# Contradictory, My Dear Watson\n",
        "\n",
        "Detecting contradiction and entailment in multilingual text **using TPUs**\n",
        "\n",
        "- TPU : 구글에서 2016년 5월에 발표한 데이터 분석 및 딥러닝용 하드웨어이다. 벡터/행렬연산의 병렬처리에 특화되어 있으며 넘사벽급의 전성비를 자랑한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gb9u2hdVpol",
        "outputId": "59a97303-d263-45ce-afe0-2a03b082a8cc"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  34567      0 --:--:-- --:--:-- --:--:-- 34567\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Found existing installation: torch 1.9.0+cu102\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.32.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Uninstalling torch-1.9.0+cu102:\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.272 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "  Successfully uninstalled torch-1.9.0+cu102\n",
            "Found existing installation: torchvision 0.10.0+cu102\n",
            "Uninstalling torchvision-0.10.0+cu102:\n",
            "  Successfully uninstalled torchvision-0.10.0+cu102\n",
            "Done updating TPU runtime\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "- [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (326 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 80.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XCGLiU9CtCJ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "torch.manual_seed(555)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "import transformers\n",
        "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "from transformers import XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer\n",
        "from transformers import AdamW\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GPblUf4X91v"
      },
      "source": [
        "# Bert model \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "==> Bidirectional(양방향 모델) : 왼쪽에서 오른쪽으로, 오른쪽에서 왼쪽으로 모두 텍스트를 읽을 수 있음을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "ee850dd8394643f99e962a6abc91fc00",
            "8ed60d275724435e80cf2a4cf800d35c",
            "84f52b5958a143ae92d526aca93e24a7",
            "f2e80f551da940d3a939385bafebbe10",
            "aae2acc6ea8a45429a7cbf70c46d7c31",
            "538fb52e35e84d46a69e52529ba504d5",
            "5b0619f532f5407c9e39c74a43cfc64b",
            "75c847356885489e99df11a173856ccd",
            "9f0320c05d82470495c399fbba6489cf",
            "b27bb311b7cc42198a8a53b3dbe5f7a1",
            "db69db8d111448cf940b6e076aecf6a4",
            "1226f85874454515bd637e37f0a44894",
            "4511c6215e71415f966c65e3b068e80a",
            "e547a854aa334b8ea8b454e36a2c3f37",
            "40573685cb7448fea33741063173bf23",
            "0170880f2ec54b67931e8f6a3db271a5",
            "941b28a29dcb4584be2e8c7cf6a478d9",
            "1f6f28fb94494b55b9d334e28f6b49d5",
            "9793c4ce08574e258ba3ed94749fc252",
            "e8fb3e2d761a40f4bc2155a350de1729",
            "247a0d8bf032439bae7cd4260aa04f0f",
            "2cd619da2fdc4b708be49b8bbc566e8b",
            "7e43ec4d299c4daeba05f8c39a0e0d23",
            "d50bf3a670ba47668d8cb527a576fb46",
            "b3e9dddd8d3e4c1b899ff7a1999031f5",
            "24b0cb3422744d26a1ffde1d6a845589",
            "2daf5cbffcb748bd9b92976487ecadce",
            "8f518c001cda4560892baa7ef24802bd",
            "fb90febb025a4678830c792e85b46641",
            "d88c42e9ee4c40cdabbffe8ab8f6a119",
            "76f1ce195b0a44e782a5757a6e24d612",
            "e884c4f449734a828bd3889ee8a2ba15"
          ]
        },
        "id": "KijHNyJwYEkA",
        "outputId": "ccc83dae-274e-43d5-e8f4-04b9caa6cafa"
      },
      "source": [
        "# Bert Vocabulary\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "len(tokenizer.vocab)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee850dd8394643f99e962a6abc91fc00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f0320c05d82470495c399fbba6489cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "941b28a29dcb4584be2e8c7cf6a478d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3e9dddd8d3e4c1b899ff7a1999031f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B8M44Y6YERQ",
        "outputId": "0914bf68-4c1d-4872-fa2c-2321040627b8"
      },
      "source": [
        "# token의 구성\n",
        "bert_vocab = tokenizer.vocab\n",
        "\n",
        "print(bert_vocab['[CLS]'])\n",
        "print(bert_vocab['[SEP]'])\n",
        "print(bert_vocab['[PAD]']) # padding=0\n",
        "\n",
        "# 문자열 토큰화\n",
        "print(bert_vocab['hello'])\n",
        "print(bert_vocab['world'])\n",
        "\n",
        "bert_keys = []\n",
        "\n",
        "for token in tokenizer.vocab.keys():\n",
        "  bert_keys.append(token)\n",
        "\n",
        "# bert_keys = dict([(j,i) for (i,j) in bert_vocab.items()])\n",
        "\n",
        "print(bert_keys[101])\n",
        "print(bert_keys[102])\n",
        "print(bert_keys[0])\n",
        "\n",
        "print(bert_keys[7592])\n",
        "print(bert_keys[2088])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n",
            "102\n",
            "0\n",
            "7592\n",
            "2088\n",
            "[CLS]\n",
            "[SEP]\n",
            "[PAD]\n",
            "hello\n",
            "world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446,
          "referenced_widgets": [
            "5fb3bb2a31a74b92b8f913d72160ce80",
            "dea44764c93940b3bf176e640fcb3eb6",
            "f7be9c1967e040eda1a01c6275fa5fd3",
            "ac43314d11064c718fda9ad6b3143ebd",
            "af9f36414038471aa065a0d1aa093646",
            "dccb47d8b9dc46b1948d59d650b94e41",
            "123d61edf6da4c608de5654748661f86",
            "c2ae6401f8a04775aea153cab724431c",
            "f1a11a6637764448a5827fd8bd677859",
            "3f80a6280dc24b7990586caf9e7f900d",
            "536f5d16f66b4cffb18ad671a3cf8239",
            "4fe6b82a63bd48bb921a0e0d4ac2d726",
            "f519ec3d868c4c04b9ed6207236df785",
            "9c74203a1eab4c9b9ffbca44ce693e71",
            "ee23ef1abce74a1096825abad919eb6b",
            "d1ee7a9f37554ed8a3d0b032f2748d95"
          ]
        },
        "id": "fdfyy2GFXBY6",
        "outputId": "6323332f-28e2-4886-c32f-c34818a8f53f"
      },
      "source": [
        "# Bert model 구성요소\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased',\n",
        "                                                      num_labels=3,  # 결과 라벨 수\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "outputs = model(input_ids=b_input_ids,\n",
        "                token_type_ids=b_token_type_ids,\n",
        "                attention_mask=b_attention_mask,\n",
        "                labels=b_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fb3bb2a31a74b92b8f913d72160ce80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1a11a6637764448a5827fd8bd677859",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=672271273.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-854a7bd59a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                       output_hidden_states=False)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m outputs = model(input_ids=b_input_ids,\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_token_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b_input_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLPe4fJjbLf4"
      },
      "source": [
        "1. input_ids\n",
        " - 토큰으로 표시되는 문장(토큰)\n",
        " \n",
        " [CLS] : classifier token, vlaue:101\n",
        "\n",
        " [SEP] : separator token, value:102\n",
        "\n",
        " [PAD] : padding token, value:0\n",
        "\n",
        "  For one sentence as input:\n",
        "    - [CLS] ...word tokens... [SEP]\n",
        "\n",
        "  For two sentences as input:\n",
        "    - [CLS] ...sentence1 tokens... [SEP]..sentence2 tokens... [SEP]\n",
        "\n",
        "ex) [101[CLS], 7592, 2045, 1012,  102[SEP],    0,    0,    0,    0,    0]\n",
        "\n",
        "2. token_type_ids\n",
        " - 입력의 일부가 되어야 하는 두 문장이 있을 때 사용\n",
        " - [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        " - 0은 첫번째 sentence 식별\n",
        " - 1은 두번째 sentence 식별\n",
        " - 오른쪽 0은 padding\n",
        "\n",
        "3. attantion_mask\n",
        " - attention_mask의 길이는 input_ids의 길이와 같아야 한다.\n",
        " - 모델에 input_ids의 어떤 토큰이 워드이고 어떤 토큰이 패딩인지 알려준다.\n",
        "\n",
        "ex)\n",
        " - Tokens: [101, 7592, 2045, 1012,  102,    0,    0,    0,    0,    0]\n",
        " - Attention mask: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "4. labels\n",
        " - 각 행의 label(target)\n",
        " - ex) [0, 2, 0, 1, 2, 0, 3, 1]\n",
        "\n",
        "---\n",
        "\n",
        "# how to use tokenizer to auto format input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jtVoqjA_I8SR",
        "outputId": "6dec94e6-67ea-482d-d221-0437b9fe60bf"
      },
      "source": [
        "# encode_plus 실습1\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')  # multilingual tokenizer\n",
        "\n",
        "max_len = 64\n",
        "sentence1 = '나의 살던 고향은 꽃피는 동산'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(sentence1,\n",
        "                                     add_special_tokens=True,\n",
        "                                     max_length=max_len,\n",
        "                                     truncation=True,\n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt')\n",
        "\n",
        "decode = tokenizer.decode(encoded_dict['input_ids'][0],\n",
        "                          skip_special_tokens=False)\n",
        "decode"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] 나의 살던 고향은 꽃피는 동산 [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17UM97J_bJsV",
        "outputId": "6ba4b461-e04f-4fa4-cb44-90a8a7ab84a9"
      },
      "source": [
        "# encode\n",
        "max_length = 10\n",
        "sentence1 = 'hello there.'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "    sentence1,  # text to tokens\n",
        "    add_special_tokens=True,  # [CLS], [SEP]를 추가\n",
        "    max_length=max_length,\n",
        "    truncation=True,  # # Pad or truncate.\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 7592, 2045, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twb11MVleXQx",
        "outputId": "0c0447da-5876-4dd8-db77-137fdbfa253a"
      },
      "source": [
        "input_ids = encoded_dict['input_ids'][0]\n",
        "token_type_ids = encoded_dict['token_type_ids'][0]\n",
        "attention_mask = encoded_dict['attention_mask'][0]\n",
        "\n",
        "print(input_ids)\n",
        "print(token_type_ids)\n",
        "print(attention_mask)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  1165, 25539, 10576,  1172, 82720, 34606, 47468, 75301, 11375,\n",
            "         1164, 29347, 70103, 90341, 11192,  1166, 82890, 22214,   102])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkRekFzkevuT",
        "outputId": "fb495514-4ce0-42df-fb6f-f5e6cc893f38"
      },
      "source": [
        "# decode\n",
        "a = tokenizer.decode(input_ids,\n",
        "                     skip_special_tokens=False)\n",
        "\n",
        "b = tokenizer.decode(input_ids,\n",
        "                     skip_special_tokens=True)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 나의 살던 고향은 꽃피는 동산 [SEP]\n",
            "나의 살던 고향은 꽃피는 동산\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF2k89pjlPNs"
      },
      "source": [
        "# XLM-RoBERTa Vocabulary\n",
        "\n",
        "- XLM은 교차 언어 모델을 의미. \n",
        "\n",
        "- XLM-Roberta(XLM-R)는 다국어 BERT를 능가하는 사전 훈련된 **다국어 모델**이다.\n",
        " - XLM-R이 훨씬 더 많은 데이터를 사용하여 교육을 받았기 때문입니다. (XLM-R은 또한 100개의 언어로 train 되었다.)\n",
        "\n",
        "1. input_ids\n",
        " - BERT의 토큰화와 비슷\n",
        "    - bos_token_id (s) : 0\n",
        "    - eos_token_id (/s) : 2\n",
        "    - sep_token_id (/s) : 2\n",
        "    - pad_token_id (pad) : 1\n",
        "\n",
        " - For one sentence as input:\n",
        "    - (s) ...word tokens... (/s)\n",
        "\n",
        " - For two sentences as input:<br>\n",
        "    - (s) ...sentence1 tokens... (/s)(/s)..sentence2 tokens... (/s)\n",
        "\n",
        " - padding은 1\n",
        "    - ex)[[0, 35378, 2685, 5, 2, 1, 1, 1, 1, 1]]\n",
        "\n",
        "\n",
        "2. token_type_ids\n",
        " - XLM-RoBERTa는 token_type_ids를 사용하지 않는다.\n",
        "\n",
        "3. attention_mask\n",
        " - BERT와 같다.\n",
        "\n",
        "4. labels\n",
        " - target 레이블(BERT와 같다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "q4mXFneuNIbV",
        "outputId": "c275e6e3-895a-42d6-e555-4054a8761886"
      },
      "source": [
        "# xlm-roberta 실습1\n",
        "\n",
        "max_len = 512\n",
        "\n",
        "sentence1 = '코로나19 예방접종 대응 추진단은 3일 오전 10시 20분 기준으로 잠정집계한 결과 코로나19 예방접종을 1회 이상 실시한 사람이 2,000만명을 넘었다고 밝혔다. 3일 10시 20분 현재 누적 1차 접종자는 2,000만4,714명으로 전 국민의 39.0%에 해당되며 이 중 721만6,679명이 접종을 완료했다. 추진단은 “전문가와 정부를 믿고 예방접종에 적극 동참한 국민들과 예방접종을 안전하게 시행해준 전국 위탁의료기관, 예방접종센터, 보건소 의료진과 실무자 덕분”이라고 밝혔다. 추진단은 “백신 수급 관리 등 철저한 준비를 통해 9월 중 3,600만 명 이상 1차 접종 목표 조기달성에 최선을 다할 것”이라고 덧붙였다.'\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "encoded_dict = tokenizer.encode_plus(sentence1,\n",
        "                                     add_special_tokens=True,\n",
        "                                     max_length=max_len,\n",
        "                                     truncation=True,\n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt')\n",
        "a = tokenizer.decode(encoded_dict['input_ids'][0], skip_special_tokens=False)\n",
        "a"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> 코로나19 예방접종 대응 추진단은 3일 오전 10시 20분 기준으로 잠정집계한 결과 코로나19 예방접종을 1회 이상 실시한 사람이 2,000만명을 넘었다고 밝혔다. 3일 10시 20분 현재 누적 1차 접종자는 2,000만4,714명으로 전 국민의 39.0%에 해당되며 이 중 721만6,679명이 접종을 완료했다. 추진단은 “전문가와 정부를 믿고 예방접종에 적극 동참한 국민들과 예방접종을 안전하게 시행해준 전국 위탁의료기관, 예방접종센터, 보건소 의료진과 실무자 덕분”이라고 밝혔다. 추진단은 “백신 수급 관리 등 철저한 준비를 통해 9월 중 3,600만 명 이상 1차 접종 목표 조기달성에 최선을 다할 것”이라고 덧붙였다.</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "788b778c78034605b9701c2b45f7c2b9",
            "5dcec3ef30944eaf9f45c11ca3cd7a8f",
            "fd69447e90854d668aaa3acfdc47b46e",
            "bae03134d3324bfba3df658b800222b5",
            "449bdac3d045491797669793a579d201",
            "a40b7a1973f74b939f0f87b280a2c7fd",
            "c4de106eb2064b96a617f4a6a9c68720",
            "4cd6e99eef9d4dd58844502f1a7605ad",
            "996398cbbd2f43e8a47f48fa0508b2a1",
            "97225b7a84694c688a42e51bacd146a5",
            "26695cd850424e948893cea4bda173c5",
            "04494c9979814cba97fb2c860db8462e",
            "73b9c02429434480acecc6a97776a034",
            "3bf6a4008a33480c94beb5c5d3b86583",
            "c78a6a6f9b7f499780a1c156c62262e9",
            "f234d1e6b2004a518f82be422b0c10a9",
            "8a86e992d8c544a092e64b3aa824a2b1",
            "8762d12c203146f1a56b5ebabf245865",
            "2be72b62f3c148349c15f9cbe3c27258",
            "688baec7d74245878e7c455c1eaa713d",
            "db6392a51eb4408b8c198d1523030273",
            "41c22b69d3834445bb7f798a4620795e",
            "8cf14957c89741faa5553570fdc440a2",
            "c3547e0cf2f442b48692439ac1d332f6"
          ]
        },
        "id": "mn79mpSdlbZI",
        "outputId": "aca69119-5fed-4e7f-a4e1-abe523a4a59c"
      },
      "source": [
        "model_type='xlm-roberta-large'\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_type)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "788b778c78034605b9701c2b45f7c2b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "996398cbbd2f43e8a47f48fa0508b2a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=9096718.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a86e992d8c544a092e64b3aa824a2b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=513.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJvTonuDmpOq",
        "outputId": "03d9a21a-22c4-4aca-b760-a4623257507b"
      },
      "source": [
        "print(tokenizer.vocab_size)  # check vocab size\n",
        "tokenizer.special_tokens_map # what are the special tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bos_token': '<s>',\n",
              " 'cls_token': '<s>',\n",
              " 'eos_token': '</s>',\n",
              " 'mask_token': '<mask>',\n",
              " 'pad_token': '<pad>',\n",
              " 'sep_token': '</s>',\n",
              " 'unk_token': '<unk>'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9sHQctZnYRM"
      },
      "source": [
        "# xlm-roberta-base model\n",
        "\n",
        "model_type = 'xlm-roberta-base'\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(model_type,\n",
        "                                                            num_labels=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TUxQfCED42V",
        "outputId": "513ba718-c34f-4932-dc0b-85898961d3e5"
      },
      "source": [
        "max_len = 10\n",
        "\n",
        "text = '너의 이름은?'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(text,\n",
        "                                     add_special_tokens=True,\n",
        "                                     max_length=max_len,\n",
        "                                     truncation=True,\n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt')\n",
        "encoded_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 70204,   367, 50932,   697,    32,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxyc5leSEUAK",
        "outputId": "1441c680-06e8-4aa2-bf10-2913429688f1"
      },
      "source": [
        "decode = tokenizer.decode(encoded_dict['input_ids'][0],\n",
        "                          skip_special_tokens=False)\n",
        "\n",
        "print(f\"토큰화 된 것:{encoded_dict['input_ids'][0]}\")\n",
        "print(f'토큰화 안된것(디코드 한 것):{decode}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "토큰화 된 것:tensor([    0, 70204,   367, 50932,   697,    32,     2])\n",
            "토큰화 안된것(디코드 한 것):<s> 너의 이름은?</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1WB11nQq9LM",
        "outputId": "35df598b-0732-4ab1-ec77-db91ec0fdc80"
      },
      "source": [
        "# encode\n",
        "max_len = 10\n",
        "\n",
        "sentence1 = 'hello there.'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(sentence1,\n",
        "                                     add_special_tokens=True,\n",
        "                                     max_length=max_len,\n",
        "                                     truncation=True,\n",
        "                                     return_attention_mask=True,\n",
        "                                     return_tensors='pt')\n",
        "\n",
        "encoded_dict\n",
        "# input_ids, attention_mask로 구성 -- Bert는 input_ids, attention_mask, token_type_ids 구성"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 33600,    31,  2685,     5,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s6bSsPbrc8S",
        "outputId": "4e3894fc-b78e-4ccd-d163-38acf0e1836d"
      },
      "source": [
        "input_ids = encoded_dict['input_ids'][0]\n",
        "att_mask = encoded_dict['attention_mask'][0]\n",
        "\n",
        "print(input_ids)\n",
        "print(att_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    0, 33600,    31,  2685,     5,     2])\n",
            "tensor([1, 1, 1, 1, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TvVNJAVrhUO",
        "outputId": "1fa42fc0-c26b-4023-f723-2daa01ff7087"
      },
      "source": [
        "# decode\n",
        "a = tokenizer.decode(input_ids,\n",
        "                     skip_special_tokens=False)  # 'bos_token': '<s>', 'cls_token': '<s>', 'eos_token': '</s>', 'mask_token': '<mask>', 'pad_token': '<pad>', 'sep_token': '</s>', 'unk_token': '<unk>' 등\n",
        "\n",
        "b = tokenizer.decode(input_ids,\n",
        "                     skip_special_tokens=True)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> hello there.</s>\n",
            "hello there.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7UJyLn8r9ST"
      },
      "source": [
        "# Contradictory, My Dear Watson 실습 Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed76pjG1uN-K",
        "outputId": "ef90f206-d4fa-4d00-c2f6-23a03667c54b"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/nlp/contradictory-my-dear-watson/contradictory-my-dear-watson-train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/nlp/contradictory-my-dear-watson/contradictory-my-dear-watson-test.csv')\n",
        "submit = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/nlp/contradictory-my-dear-watson/contradictory-my-dear-watson-sample_submission.csv')\n",
        "train.shape, test.shape, submit.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12120, 6), (5195, 5), (5195, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "LFzcotBVubCE",
        "outputId": "d42ef29c-3571-439c-af17-893db9dee0ce"
      },
      "source": [
        "train.head()\n",
        "# XLM-RoBERTa 쓰기 딱 좋구만..."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-là font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
              "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQu6UdDVUCx",
        "outputId": "3e689ba9-9257-4280-85f6-f0dad82736b5"
      },
      "source": [
        "df = shuffle(train)\n",
        "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "y_train = df['label']\n",
        "\n",
        "fold_list = list(sk.split(df, y_train))\n",
        "\n",
        "train_list = []\n",
        "val_list = []\n",
        "\n",
        "for i, fold in enumerate(fold_list):\n",
        "  df_train = df[df.index.isin(fold[0])]\n",
        "  df_val = df[df.index.isin(fold[1])]\n",
        "\n",
        "  train_list.append(df_train)\n",
        "  val_list.append(df_val)\n",
        "\n",
        "print(f'train length : {len(train_list)}')\n",
        "print(f'val length : {len(val_list)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train length : 5\n",
            "val length : 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72VUx-IOwcyJ"
      },
      "source": [
        "# 위에 하고 같음\n",
        "\n",
        "df = shuffle(train)\n",
        "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "y_train = df['label']\n",
        "\n",
        "fold_list = list(sk.split(df, y_train))\n",
        "\n",
        "list_train = []\n",
        "list_val = []\n",
        "for i, (train_index, val_index) in enumerate(sk.split(df, y_train)):\n",
        "  train_df, val_df = df.iloc[train_index], df.iloc[val_index]\n",
        "\n",
        "  list_train.append(train_df)\n",
        "  list_val.append(val_df)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "xURFuqXtv9M7",
        "outputId": "c7f5f600-d89b-4e5a-a649-a59507caa543"
      },
      "source": [
        "list_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1323</th>\n",
              "      <td>8ec5be35b1</td>\n",
              "      <td>He watched the river flow.</td>\n",
              "      <td>The riverbed was completely dry.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2601</th>\n",
              "      <td>917daf858f</td>\n",
              "      <td>I put it to you that you did do so?</td>\n",
              "      <td>I am guessing that you did stay at the hotel?</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>147267c1a9</td>\n",
              "      <td>although the uh it's uh it we almost one day w...</td>\n",
              "      <td>We painted the house over the duration of one ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>4241535fa7</td>\n",
              "      <td>you know we keep a couple hundred dollars um i...</td>\n",
              "      <td>We have some money on there</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088</th>\n",
              "      <td>865a383c45</td>\n",
              "      <td>Designed by George Meikle Kemp, an unknown dra...</td>\n",
              "      <td>The design was completely original and uncopied.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8033</th>\n",
              "      <td>3cf10465e1</td>\n",
              "      <td>Trại nào đúng là có hậu quả sức khỏe cộng đồng...</td>\n",
              "      <td>Tất cả các trại đều có hậu quả sức khỏe cộng đ...</td>\n",
              "      <td>vi</td>\n",
              "      <td>Vietnamese</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10516</th>\n",
              "      <td>4729fc742c</td>\n",
              "      <td>At Kansas City Power and Light's Hawthorn Powe...</td>\n",
              "      <td>Unit 5 was the only one that was replaced.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>a5484dd197</td>\n",
              "      <td>The finest is the huge conical-roofed Tomb/Pil...</td>\n",
              "      <td>The Tomb/Pillar of Absalom has a large cone-sh...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8612</th>\n",
              "      <td>35305767c9</td>\n",
              "      <td>The fancifully decorated Macau Palace, a float...</td>\n",
              "      <td>Macau Palace is found on the eastern waterfront.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4205</th>\n",
              "      <td>46ccd19eec</td>\n",
              "      <td>If the company makes money on the policy, othe...</td>\n",
              "      <td>If the company loses money on the policy then ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9696 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ... label\n",
              "1323   8ec5be35b1  ...     2\n",
              "2601   917daf858f  ...     1\n",
              "1355   147267c1a9  ...     0\n",
              "270    4241535fa7  ...     0\n",
              "1088   865a383c45  ...     2\n",
              "...           ...  ...   ...\n",
              "8033   3cf10465e1  ...     1\n",
              "10516  4729fc742c  ...     1\n",
              "145    a5484dd197  ...     0\n",
              "8612   35305767c9  ...     2\n",
              "4205   46ccd19eec  ...     2\n",
              "\n",
              "[9696 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "1-0KL4UawCZm",
        "outputId": "c5644730-ead5-44f5-bc65-8df1e9b70ca3"
      },
      "source": [
        "list_val[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2194</th>\n",
              "      <td>41ce3f8a0b</td>\n",
              "      <td>49 Bima ya mshahara inawezesha viparara wa sia...</td>\n",
              "      <td>wadanganyifu hufanya mambo yasiyokubalika na h...</td>\n",
              "      <td>sw</td>\n",
              "      <td>Swahili</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9540</th>\n",
              "      <td>09b4fcf9d0</td>\n",
              "      <td>Хотя я и сейчас не понимаю, как он вообще мог ...</td>\n",
              "      <td>Я не понимаю, почему он думал, что я это доделаю.</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4971</th>\n",
              "      <td>d960aad98e</td>\n",
              "      <td>Bill Clinton has developed a rhetoric and a se...</td>\n",
              "      <td>Bill Clinton is aware of the current divide an...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5008</th>\n",
              "      <td>8395afc7c5</td>\n",
              "      <td>189 и другие затраты оцениваются аналогичною</td>\n",
              "      <td>Они предполагали, что издержки использования с...</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5310</th>\n",
              "      <td>a97a31ea73</td>\n",
              "      <td>Very simply.</td>\n",
              "      <td>In a complicated way.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10146</th>\n",
              "      <td>ec6c1214ca</td>\n",
              "      <td>Inside the Oval  White House Tapes From FDR to...</td>\n",
              "      <td>Many tapes were taken in the white house</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>21abde9983</td>\n",
              "      <td>Off El Hurriya Street you'll find the Neo-Clas...</td>\n",
              "      <td>Interestingly enough, every item is a vampire ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>e7bc15b1b9</td>\n",
              "      <td>that's hilarious to to get that jack off that'...</td>\n",
              "      <td>I will enjoy telling that story.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>3328cdd6d6</td>\n",
              "      <td>The information provided in this guide is curr...</td>\n",
              "      <td>The information in the guide is up-to-date.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11594</th>\n",
              "      <td>5a62d66f86</td>\n",
              "      <td>ان نظاروں سے آگے ناتھانئیل ہاتھورن کے سات کونو...</td>\n",
              "      <td>سیون گیبلز دیکھنے کے لئے بہترین نظارہ ہے</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2424 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ... label\n",
              "2194   41ce3f8a0b  ...     1\n",
              "9540   09b4fcf9d0  ...     0\n",
              "4971   d960aad98e  ...     0\n",
              "5008   8395afc7c5  ...     1\n",
              "5310   a97a31ea73  ...     2\n",
              "...           ...  ...   ...\n",
              "10146  ec6c1214ca  ...     0\n",
              "1426   21abde9983  ...     1\n",
              "140    e7bc15b1b9  ...     1\n",
              "401    3328cdd6d6  ...     0\n",
              "11594  5a62d66f86  ...     1\n",
              "\n",
              "[2424 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUvacqBsxYPV"
      },
      "source": [
        "# 토큰화, Dataset, Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmycFKaxrwR"
      },
      "source": [
        "MODEL_TYPE = 'bert-base-multilingual-uncased'\n",
        "\n",
        "NUM_FOLDS = 5\n",
        "\n",
        "# Saving 5 TPU models will exceed the 4.9GB disk space.\n",
        "# Therefore, will will only train on 3 folds.\n",
        "NUM_FOLDS_TO_TRAIN = 3 \n",
        "\n",
        "L_RATE = 1e-5\n",
        "MAX_LEN = 256\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIWp08_lxVUg",
        "outputId": "94299b57-c945-49f1-dab2-2fe474e4bb42"
      },
      "source": [
        "device = xm.xla_device()\n",
        "print(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5A8yPjoxemz"
      },
      "source": [
        "# bert-base-multilingual-uncased 토큰\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE,\n",
        "                                          do_lower_case=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHwv_qIMtVtu"
      },
      "source": [
        "class CompDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df_data = df\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sentence1 = self.df_data.loc[index, 'premise']\n",
        "    sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "    sentence3 = self.df_data.loc[index, 'language']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus((sentence1, sentence2, sentence3),\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=MAX_LEN,\n",
        "                                             truncation=True,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors='pt')\n",
        "    input_ids = encoded_dict['input_ids'][0]\n",
        "    attention_mask = encoded_dict['attention_mask'][0]\n",
        "    token_type_ids = encoded_dict['token_type_ids'][0]\n",
        "    target = torch.tensor(self.df_data.loc[index, 'label'])\n",
        "\n",
        "    sample = (input_ids, attention_mask, token_type_ids, target)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(df_data)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df_data = df\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sentence1 = self.df_data.loc[index, 'premise']\n",
        "    sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "    sentence3 = self.df_data.loc[index, 'language']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus((sentence1, sentence2, sentence3),\n",
        "                                         add_special_tokens=True,\n",
        "                                         max_length=MAX_LEN,\n",
        "                                         truncation=True,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt')\n",
        "    input_ids = encoded_dict['input_ids'][0]\n",
        "    attention_mask = encoded_dict['attention_mask'][0]\n",
        "    token_type_ids = encoded_dict['token_type_ids'][0]\n",
        "\n",
        "    sample = (input_ids, attention_mask, token_type_ids)\n",
        "    return sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(df_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zprv7N7exuSL"
      },
      "source": [
        "# Dataset으로 tokenizer까지\n",
        "class CompDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df_data = df\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sentence1 = self.df_data.loc[index, 'premise']\n",
        "    sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(sentence1, sentence2,\n",
        "                                         add_special_tokens=True,\n",
        "                                         max_length=MAX_LEN,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         truncation=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt')\n",
        "    \n",
        "    input_ids = encoded_dict['input_ids'][0]\n",
        "    attention_mask = encoded_dict['attention_mask'][0]\n",
        "    token_type_ids = encoded_dict['token_type_ids'][0]\n",
        "\n",
        "    target = torch.tensor(self.df_data.loc[index, 'label'])\n",
        "\n",
        "    sample = (input_ids, attention_mask, token_type_ids, target)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df_data)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sentence1 = self.df_data.loc[index, 'premise']\n",
        "    sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(sentence1, sentence2,\n",
        "                                         add_special_tokens=True,\n",
        "                                         max_length=MAX_LEN,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         truncation=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt')\n",
        "    \n",
        "    input_ids = encoded_dict['input_ids'][0]\n",
        "    attention_mask = encoded_dict['attention_mask'][0]\n",
        "    token_type_ids = encoded_dict['token_type_ids'][0]\n",
        "\n",
        "    sample = (input_ids, attention_mask, tokens_type_ids)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mG1Otd714Be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "5b6f8ac7-ef6a-4674-cc3c-828c2b1740ee"
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d80d8b46d761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByG05cC22tZq",
        "outputId": "3aa6e8e1-95f1-4c15-ed5f-7c5512aca7c8"
      },
      "source": [
        "# num_workers 쓰기 위한 cpu_count()\n",
        "NUM_CORES = os.cpu_count()\n",
        "\n",
        "NUM_CORES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8gOhXfs1_Sj",
        "outputId": "967b6194-02e3-4c75-c37a-9588e2c795ca"
      },
      "source": [
        "train = CompDataset(df_train)\n",
        "valid = CompDataset(df_val)\n",
        "test = TestDataset(test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=4)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(valid,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=False,\n",
        "                                              num_workers=4)\n",
        "\n",
        "len(train_dataloader), len(val_dataloader), len(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303, 76, 163)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZFwa04a6ll5"
      },
      "source": [
        "# Define the Model(BertForSequenceClassification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxA20joo6P3J",
        "outputId": "69e2cd81-b7ee-4396-e4be-1b9a0b747de0"
      },
      "source": [
        "# model 불러오기(BertForSequnceClassification)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_TYPE,\n",
        "                                                      num_labels=3,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y36IFkhK6z5t"
      },
      "source": [
        "# Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95lNKX9A6ryH",
        "outputId": "5660f40a-8734-4360-c566-d0315212d7d8"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train,\n",
        "                                               batch_size=8,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=1)\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "b_input_ids = batch[0].to(device)\n",
        "b_input_mask = batch[1].to(device)\n",
        "b_token_type_ids = batch[2].to(device)\n",
        "b_labels = batch[3].to(device)\n",
        "\n",
        "b_input_ids.size(), b_input_mask.size(), b_token_type_ids.size(), b_labels.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 256]),\n",
              " torch.Size([8, 256]),\n",
              " torch.Size([8, 256]),\n",
              " torch.Size([8]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7qZqnQMAHdB"
      },
      "source": [
        "# 모델의 output 탐구\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl0vADftAMLO"
      },
      "source": [
        "# output 생성\n",
        "outputs = model(b_input_ids, \n",
        "                token_type_ids=b_token_type_ids, \n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHlfsCAvANks",
        "outputId": "0eae0d1d-0e20-44d3-abe0-8faf3783d66f"
      },
      "source": [
        " # 하나의 튜플 안에 (loss, predicts)\n",
        " len(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A5I2XuCAXl1",
        "outputId": "dc0ca15d-37d3-4c5d-9165-d774820e8845"
      },
      "source": [
        "# loss\n",
        "outputs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0701, device='xla:1', grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2X-DTBLAbNx",
        "outputId": "906e3eb5-7d50-4fac-c501-88e9fb6ae667"
      },
      "source": [
        "# predicts\n",
        "outputs[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493],\n",
              "        [ 0.1001, -0.0112,  0.2493]], device='xla:1', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KfiZ5QXAh5h",
        "outputId": "10cbfdf2-66be-4104-dde7-90ea202c470e"
      },
      "source": [
        "preds = outputs[1].detach().cpu().numpy()\n",
        "\n",
        "y_true = b_labels.detach().cpu().numpy()\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 2, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN9Nd8FeA5W_",
        "outputId": "5b53a446-c2b8-417f-cd69-ac320aad5bfc"
      },
      "source": [
        "acc = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74fscdOWAAkl"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4dNwYMOyvS4",
        "outputId": "c28e5224-7ae4-4d75-ae1d-1648d6f6a8d3"
      },
      "source": [
        "import random\n",
        "import gc\n",
        "\n",
        "seed_val = 1024\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "fold_val_acc_list = []\n",
        "for i in range(0, NUM_FOLDS):\n",
        "  fold_val_acc_list.append([])\n",
        "\n",
        "for epoch in range(0, NUM_FOLDS):\n",
        "  print('\\nNum folds used for training', NUM_FOLDS_TO_TRAIN)\n",
        "  print(f'========= Epoch {epoch+1} / {NUM_EPOCHS} =========')\n",
        "\n",
        "  num_folds = len(list_train)\n",
        "\n",
        "  epoch_acc_score_list = []\n",
        "\n",
        "  for fold_index in range(0, NUM_FOLDS_TO_TRAIN):\n",
        "    print('\\n== Fold Model', fold_index)\n",
        "\n",
        "    if epoch == 0:\n",
        "      model = BertForSequenceClassification.from_pretrained(MODEL_TYPE,\n",
        "                                                            num_labels=3,\n",
        "                                                            output_attentions=False,\n",
        "                                                            output_hidden_states=False)\n",
        "      model.to(device)\n",
        "      optimizer = AdamW(model.parameters(), lr=L_RATE)\n",
        "\n",
        "    else:\n",
        "      path_model = 'model_' + str(fold_index) + '.bin'\n",
        "      model.load_state_dict(torch.load(path_model))\n",
        "      model.to(device)\n",
        "    \n",
        "    df_train = list_train[fold_index]\n",
        "    df_val = list_val[fold_index]\n",
        "\n",
        "    df_train = df_train.reset_index(drop=True)\n",
        "    df_val = df_val.reset_index(drop=True)\n",
        "\n",
        "    train_data = CompDataset(df_train)\n",
        "    val_data = CompDataset(df_val)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   shuffle=True,\n",
        "                                                   num_workers=4)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                                 batch_size=BATCH_SIZE,\n",
        "                                                 shuffle=True,\n",
        "                                                 num_workers=4)\n",
        "    \n",
        "    stacked_val_labels = []\n",
        "    targets_list = []\n",
        "\n",
        "    print('Training...')\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for i, (batch) in enumerate(train_dataloader):\n",
        "      input_ids = batch[0].to(device)\n",
        "      attention_mask = batch[1].to(device)\n",
        "      token_type_ids = batch[2].to(device)\n",
        "      target = batch[3].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "      \n",
        "      output = model(input_ids, \n",
        "                      attention_mask=attention_mask,\n",
        "                      token_type_ids=token_type_ids,\n",
        "                      labels=target)\n",
        "      \n",
        "      loss = output[0]\n",
        "      total_train_loss = total_train_loss + loss.item()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      xm.optimizer_step(optimizer=optimizer, barrier=True)\n",
        "\n",
        "    print(f'train loss : {total_train_loss/NUM_FOLDS_TO_TRAIN}')\n",
        "\n",
        "    print('\\nValidation')\n",
        "    model.eval()\n",
        "\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "    total_val_loss=0\n",
        "\n",
        "    for j, val_batch in enumerate(val_dataloader):\n",
        "      input_ids = val_batch[0].to(device)\n",
        "      attention_mask = val_batch[1].to(device)\n",
        "      token_type_ids = val_batch[2].to(device)\n",
        "      target = val_batch[3].to(device)\n",
        "\n",
        "      output = model(input_ids,\n",
        "                     attention_mask=attention_mask,\n",
        "                     token_type_ids=token_type_ids,\n",
        "                     labels=target)\n",
        "      \n",
        "      loss = output[0]\n",
        "      total_val_loss = total_val_loss + loss.item()\n",
        "\n",
        "      preds = output[1]\n",
        "\n",
        "      val_preds = preds.detach().cpu().numpy()\n",
        "      targets_np = target.to('cpu').numpy()\n",
        "\n",
        "      targets_list.extend(targets_np)\n",
        "\n",
        "      if j == 0:\n",
        "        stacked_val_preds = val_preds\n",
        "\n",
        "      else:\n",
        "        stacked_val_preds = np.vstack((stacked_val_preds,\n",
        "                                       val_preds))\n",
        "    \n",
        "    # calculate val acc for this fold\n",
        "    y_true = targets_list\n",
        "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "\n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    epoch_acc_score_list.append(val_acc)\n",
        "\n",
        "    print('Val loss:', total_val_loss)\n",
        "    print('Val Acc:', val_acc)\n",
        "\n",
        "    if epoch == 0:\n",
        "      model_name = 'model_' + str(fold_index) + '.bin'\n",
        "      torch.save(model.state_dict(), model_name)\n",
        "      print('Saved model as', model_name)\n",
        "\n",
        "    if epoch != 0:\n",
        "      val_acc_list = fold_val_acc_list[fold_index]\n",
        "      best_val_acc = max(val_acc_list)\n",
        "\n",
        "      if val_acc > best_val_acc:\n",
        "        model_name = 'model_' + str(fold_index) + '.bin'\n",
        "        torch.save(model.state_dict(), model_name)\n",
        "        print('Val acc improved, saved model...')\n",
        "\n",
        "    fold_val_acc_list[fold_index].append(val_acc)\n",
        "    \n",
        "    gc.collect()\n",
        "\n",
        "  cv_acc = sum(epoch_acc_score_list) / NUM_FOLDS_TO_TRAIN\n",
        "  print('\\nCV Acc:', cv_acc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Num folds used for training 3\n",
            "========= Epoch 1 / 3 =========\n",
            "\n",
            "== Fold Model 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "train loss : 101.10404324531555\n",
            "\n",
            "Validation\n",
            "Val loss: 66.89265096187592\n",
            "Val Acc: 0.5944719471947195\n",
            "Saved model as model_0.bin\n",
            "\n",
            "== Fold Model 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "train loss : 101.80440930525462\n",
            "\n",
            "Validation\n",
            "Val loss: 66.61745792627335\n",
            "Val Acc: 0.6051980198019802\n",
            "Saved model as model_1.bin\n",
            "\n",
            "== Fold Model 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "train loss : 101.5918397307396\n",
            "\n",
            "Validation\n",
            "Val loss: 65.6192399263382\n",
            "Val Acc: 0.6126237623762376\n",
            "Saved model as model_2.bin\n",
            "\n",
            "CV Acc: 0.6040979097909791\n",
            "\n",
            "Num folds used for training 3\n",
            "========= Epoch 2 / 3 =========\n",
            "\n",
            "== Fold Model 0\n",
            "Training...\n",
            "train loss : 81.13626380761464\n",
            "\n",
            "Validation\n",
            "Val loss: 63.00364923477173\n",
            "Val Acc: 0.641914191419142\n",
            "Val acc improved, saved model...\n",
            "\n",
            "== Fold Model 1\n",
            "Training...\n",
            "train loss : 82.57431001464526\n",
            "\n",
            "Validation\n",
            "Val loss: 61.53683412075043\n",
            "Val Acc: 0.6427392739273927\n",
            "Val acc improved, saved model...\n",
            "\n",
            "== Fold Model 2\n",
            "Training...\n",
            "train loss : 81.24642755587895\n",
            "\n",
            "Validation\n",
            "Val loss: 61.14067977666855\n",
            "Val Acc: 0.6373762376237624\n",
            "Val acc improved, saved model...\n",
            "\n",
            "CV Acc: 0.6406765676567657\n",
            "\n",
            "Num folds used for training 3\n",
            "========= Epoch 3 / 3 =========\n",
            "\n",
            "== Fold Model 0\n",
            "Training...\n",
            "train loss : 65.97585199276607\n",
            "\n",
            "Validation\n",
            "Val loss: 63.75871032476425\n",
            "Val Acc: 0.6468646864686468\n",
            "Val acc improved, saved model...\n",
            "\n",
            "== Fold Model 1\n",
            "Training...\n",
            "train loss : 67.83802416920662\n",
            "\n",
            "Validation\n",
            "Val loss: 63.027673840522766\n",
            "Val Acc: 0.6427392739273927\n",
            "\n",
            "== Fold Model 2\n",
            "Training...\n",
            "train loss : 67.32908203204472\n",
            "\n",
            "Validation\n",
            "Val loss: 62.742539048194885\n",
            "Val Acc: 0.6505775577557755\n",
            "Val acc improved, saved model...\n",
            "\n",
            "CV Acc: 0.6467271727172718\n",
            "\n",
            "Num folds used for training 3\n",
            "========= Epoch 4 / 3 =========\n",
            "\n",
            "== Fold Model 0\n",
            "Training...\n",
            "train loss : 51.25152426958084\n",
            "\n",
            "Validation\n",
            "Val loss: 69.63152566552162\n",
            "Val Acc: 0.6563531353135313\n",
            "Val acc improved, saved model...\n",
            "\n",
            "== Fold Model 1\n",
            "Training...\n",
            "train loss : 68.00245346625645\n",
            "\n",
            "Validation\n",
            "Val loss: 62.545603811740875\n",
            "Val Acc: 0.6291254125412541\n",
            "\n",
            "== Fold Model 2\n",
            "Training...\n",
            "train loss : 53.84748722612858\n",
            "\n",
            "Validation\n",
            "Val loss: 68.00508332252502\n",
            "Val Acc: 0.6443894389438944\n",
            "\n",
            "CV Acc: 0.6432893289328933\n",
            "\n",
            "Num folds used for training 3\n",
            "========= Epoch 5 / 3 =========\n",
            "\n",
            "== Fold Model 0\n",
            "Training...\n",
            "train loss : 38.13903167595466\n",
            "\n",
            "Validation\n",
            "Val loss: 76.92087280750275\n",
            "Val Acc: 0.6542904290429042\n",
            "\n",
            "== Fold Model 1\n",
            "Training...\n",
            "train loss : 67.65219762921333\n",
            "\n",
            "Validation\n",
            "Val loss: 62.892207473516464\n",
            "Val Acc: 0.6431518151815182\n",
            "Val acc improved, saved model...\n",
            "\n",
            "== Fold Model 2\n",
            "Training...\n",
            "train loss : 53.74752586086591\n",
            "\n",
            "Validation\n",
            "Val loss: 66.48972034454346\n",
            "Val Acc: 0.6464521452145214\n",
            "\n",
            "CV Acc: 0.647964796479648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGvtz18KTFad"
      },
      "source": [
        "seed_val = 1024\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "\n",
        "# Store the accuracy scores for each fold model in this list.\n",
        "# [[model_0 scores], [model_1 scores], [model_2 scores], [model_3 scores], [model_4 scores]]\n",
        "# [[ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...], [ecpoch 1, epoch 2, ...]]\n",
        "\n",
        "# Create a list of lists to store the val acc results.\n",
        "# The number of items in this list will correspond to\n",
        "# the number of folds that the model is being trained on.\n",
        "fold_val_acc_list = []\n",
        "for i in range(0, NUM_FOLDS):\n",
        "    \n",
        "    # append an empty list\n",
        "    fold_val_acc_list.append([])\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "    \n",
        "    print(\"\\nNum folds used for training:\", NUM_FOLDS_TO_TRAIN)\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n",
        "    \n",
        "    # Get the number of folds\n",
        "    num_folds = len(train_list)\n",
        "\n",
        "    # For this epoch, store the val acc scores for each fold in this list.\n",
        "    # We will use this list to calculate the cv at the end of the epoch.\n",
        "    epoch_acc_scores_list = []\n",
        "    \n",
        "    # For each fold...\n",
        "    for fold_index in range(0, NUM_FOLDS_TO_TRAIN):\n",
        "        \n",
        "        print('\\n== Fold Model', fold_index)\n",
        "        \n",
        "        \n",
        "        # .........................\n",
        "        # Load the fold model\n",
        "        # .........................\n",
        "        \n",
        "        if epoch == 0:\n",
        "            \n",
        "            # define the model\n",
        "            model = BertForSequenceClassification.from_pretrained(\n",
        "            MODEL_TYPE, \n",
        "            num_labels = 3,       \n",
        "            output_attentions = False, \n",
        "            output_hidden_states = False,\n",
        "            )\n",
        "            \n",
        "            # Send the model to the device.\n",
        "            model.to(device)\n",
        "            \n",
        "            optimizer = AdamW(model.parameters(),\n",
        "              lr = L_RATE, \n",
        "              eps = 1e-8\n",
        "            )\n",
        "            \n",
        "        else:\n",
        "        \n",
        "            # Get the fold model\n",
        "            path_model = 'model_' + str(fold_index) + '.bin'\n",
        "            model.load_state_dict(torch.load(path_model))\n",
        "\n",
        "            # Send the model to the device.\n",
        "            model.to(device)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # .....................................\n",
        "        # Set up the train and val dataloaders\n",
        "        # .....................................\n",
        "        \n",
        "        \n",
        "        # Intialize the fold dataframes\n",
        "        df_train = train_list[fold_index]\n",
        "        df_val = val_list[fold_index]\n",
        "        \n",
        "        # Reset the indices or the dataloader won't work.\n",
        "        df_train = df_train.reset_index(drop=True)\n",
        "        df_val = df_val.reset_index(drop=True)\n",
        "    \n",
        "        # Create the dataloaders\n",
        "        train_data = CompDataset(df_train)\n",
        "        val_data = CompDataset(df_val)\n",
        "\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True,\n",
        "                                               num_workers=4)\n",
        "\n",
        "        val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                shuffle=True,\n",
        "                                               num_workers=4)\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "       \n",
        "\n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        stacked_val_labels = []\n",
        "        targets_list = []\n",
        "\n",
        "        print('Training...')\n",
        "\n",
        "        # put the model into train mode\n",
        "        model.train()\n",
        "\n",
        "        # This turns gradient calculations on and off.\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "            train_status = 'Batch ' + str(i+1) + ' of ' + str(len(train_dataloader))\n",
        "\n",
        "            print(train_status, end='\\r')\n",
        "\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_token_type_ids = batch[2].to(device)\n",
        "            b_labels = batch[3].to(device)\n",
        "\n",
        "            model.zero_grad()        \n",
        "\n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                        token_type_ids=b_token_type_ids, \n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "\n",
        "            # Get the loss from the outputs tuple: (loss, logits)\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Convert the loss from a torch tensor to a number.\n",
        "            # Calculate the total loss.\n",
        "            total_train_loss = total_train_loss + loss.item()\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "            \n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Use the optimizer to update Weights\n",
        "            \n",
        "            # Optimizer for GPU\n",
        "            # optimizer.step() \n",
        "            \n",
        "            # Optimizer for TPU\n",
        "            # https://pytorch.org/xla/\n",
        "            xm.optimizer_step(optimizer, barrier=True)\n",
        "            \n",
        "           \n",
        "\n",
        "\n",
        "        print('Train loss:' ,total_train_loss)\n",
        "\n",
        "\n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "\n",
        "        print('\\nValidation...')\n",
        "\n",
        "        # Put the model in evaluation mode.\n",
        "        model.eval()\n",
        "\n",
        "        # Turn off the gradient calculations.\n",
        "        # This tells the model not to compute or store gradients.\n",
        "        # This step saves memory and speeds up validation.\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_val_loss = 0\n",
        "\n",
        "\n",
        "        for j, val_batch in enumerate(val_dataloader):\n",
        "\n",
        "            val_status = 'Batch ' + str(j+1) + ' of ' + str(len(val_dataloader))\n",
        "\n",
        "            print(val_status, end='\\r')\n",
        "\n",
        "            b_input_ids = val_batch[0].to(device)\n",
        "            b_input_mask = val_batch[1].to(device)\n",
        "            b_token_type_ids = val_batch[2].to(device)\n",
        "            b_labels = val_batch[3].to(device)      \n",
        "\n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                    token_type_ids=b_token_type_ids, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "\n",
        "            # Get the loss from the outputs tuple: (loss, logits)\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Convert the loss from a torch tensor to a number.\n",
        "            # Calculate the total loss.\n",
        "            total_val_loss = total_val_loss + loss.item()\n",
        "\n",
        "            # Get the preds\n",
        "            preds = outputs[1]\n",
        "\n",
        "\n",
        "            # Move preds to the CPU\n",
        "            val_preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            # Move the labels to the cpu\n",
        "            targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "            # Append the labels to a numpy list\n",
        "            targets_list.extend(targets_np)\n",
        "\n",
        "            if j == 0:  # first batch\n",
        "                stacked_val_preds = val_preds\n",
        "\n",
        "            else:\n",
        "                stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "                \n",
        "                \n",
        "                \n",
        "        # .........................................\n",
        "        # Calculate the val accuracy for this fold\n",
        "        # .........................................      \n",
        "\n",
        "\n",
        "        # Calculate the validation accuracy\n",
        "        y_true = targets_list\n",
        "        y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "\n",
        "        val_acc = accuracy_score(y_true, y_pred)\n",
        "        \n",
        "        \n",
        "        epoch_acc_scores_list.append(val_acc)\n",
        "\n",
        "\n",
        "        print('Val loss:' ,total_val_loss)\n",
        "        print('Val acc: ', val_acc)\n",
        "        \n",
        "        \n",
        "        # .........................\n",
        "        # Save the best model\n",
        "        # .........................\n",
        "        \n",
        "        if epoch == 0:\n",
        "            \n",
        "            # Save the Model\n",
        "            model_name = 'model_' + str(fold_index) + '.bin'\n",
        "            torch.save(model.state_dict(), model_name)\n",
        "            print('Saved model as ', model_name)\n",
        "            \n",
        "        if epoch != 0:\n",
        "        \n",
        "            val_acc_list = fold_val_acc_list[fold_index]\n",
        "            best_val_acc = max(val_acc_list)\n",
        "            \n",
        "            if val_acc > best_val_acc:\n",
        "                # save the model\n",
        "                model_name = 'model_' + str(fold_index) + '.bin'\n",
        "                torch.save(model.state_dict(), model_name)\n",
        "                print('Val acc improved. Saved model as ', model_name)\n",
        "\n",
        "            \n",
        "                \n",
        "                \n",
        "                \n",
        "        # .....................................\n",
        "        # Save the val_acc for this fold model\n",
        "        # .....................................\n",
        "        \n",
        "        # Note: Don't do this before the above 'Save Model' code or \n",
        "        # the save model code won't work. This is because the best_val_acc will\n",
        "        # become current val accuracy.\n",
        "                \n",
        "        # fold_val_acc_list is a list of lists.\n",
        "        # Each fold model has it's own list corresponding to the fold index.\n",
        "        # Here we choose a list corresponding to the fold number and append the acc score to that list.\n",
        "        fold_val_acc_list[fold_index].append(val_acc)\n",
        "        \n",
        "            \n",
        "\n",
        "        # Use the garbage collector to save memory.\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    \n",
        "        \n",
        "        \n",
        "    # .............................................................\n",
        "    # Calculate the CV accuracy score over all folds in this epoch\n",
        "    # .............................................................   \n",
        "        \n",
        "        \n",
        "    # Print the average val accuracy for all 5 folds\n",
        "    cv_acc = sum(epoch_acc_scores_list)/NUM_FOLDS_TO_TRAIN\n",
        "    print(\"\\nCV Acc:\", cv_acc)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlqX9y1Q5Ekm"
      },
      "source": [
        "# Test Set\n",
        "\n",
        "print('\\nTest Set...')\n",
        "\n",
        "model_preds_list = []\n",
        "\n",
        "print('Total batches:', len(test_dataloader))\n",
        "\n",
        "for fold_index in range(0, NUM_FOLDS_TO_TRAIN):\n",
        "  print('\\nFold Model', fold_index)\n",
        "\n",
        "  # load the fold model\n",
        "  path_model = 'model_' + str(fold_index) + '.bin'\n",
        "  model.load_state_dict(torch.load(path_model))\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  stacked_val_labels = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  torch.set_grad_enabled(False)\n",
        "\n",
        "  total_val_loss = 0\n",
        "\n",
        "  for j, h_batch in enumerate(test_dataloader):\n",
        "    infernce_status = 'Batch' + str(j+1)\n",
        "\n",
        "    print(infernce_status, end='\\r')\n",
        "\n",
        "    b_input_ids = h_batch[0].to(device)\n",
        "    b_input_mask = h_batch[1].to(device)\n",
        "    b_token_type_ids = h_batch[2].to(device)\n",
        "\n",
        "    outputs = model(b_input_ids,\n",
        "                    token_type_ids = b_token_type_ids,\n",
        "                    attention_mask = b_input_mask)\n",
        "    \n",
        "    preds = outputs[0]\n",
        "\n",
        "    val_preds = preds.detach().cpu().numpy()\n",
        "\n",
        "    # Stack the predictions\n",
        "\n",
        "    if j == 0:\n",
        "      stacked_val_preds = val_preds\n",
        "\n",
        "    else:\n",
        "      stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "\n",
        "  model_preds_list.append(stacked_val_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaJ9cnFF9bCl"
      },
      "source": [
        "for i, item in enumerate(model_preds_list):\n",
        "  if i == 0:\n",
        "    preds = item\n",
        "\n",
        "  else:\n",
        "    preds = item+preds\n",
        "\n",
        "avg_preds = preds / len(model_preds_list)\n",
        "\n",
        "test_preds = np.argmax(avg_preds, axis=1)\n",
        "\n",
        "test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuKf3n9F9qtA"
      },
      "source": [
        "# Submission\n",
        "submit['prediction'] = test_preds\n",
        "submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JTpIAuZ9OE0"
      },
      "source": [
        "# XLM-RoBERTa Model 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8f-nuZI9NMX"
      },
      "source": [
        "model_type = 'xlm-roberta-base'\n",
        "\n",
        "L_RATE = 1e-8\n",
        "MAX_LEN = 256\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_tWpE5OALf7",
        "outputId": "09e1d636-abb4-41d2-fa30-2bdecd006ce6"
      },
      "source": [
        "device = xm.xla_device()\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xla:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxoRK3qIBQ5m"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwfJ4BR-AsSG"
      },
      "source": [
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_type)\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TJegKhTBSXI"
      },
      "source": [
        "# Create the DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0iiUykVBHTB"
      },
      "source": [
        "class CompDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df_data = df\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sentence1 = self.df_data.loc[index, 'premise']\n",
        "    sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(sentence1, sentence2,\n",
        "                                         add_special_tokens=True,\n",
        "                                         max_length=MAX_LEN,\n",
        "                                         truncation=True,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt')\n",
        "    \n",
        "    input_ids = encoded_dict['input_ids'][0]\n",
        "    attention_mask = encoded_dict['attention_mask'][0] \n",
        "    target = torch.tensor(self.df_data.loc[index, 'label'])\n",
        "    \n",
        "    sample = (input_ids, attention_mask, target)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df_data)\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df_data = df\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sentence1 = self.df_data.loc[index, 'premise']\n",
        "    sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(sentence1, sentence2,\n",
        "                                         add_special_tokens=True,\n",
        "                                         max_length=MAX_LEN,\n",
        "                                         truncation=True,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt')\n",
        "    input_ids = encoded_dict['input_ids'][0]\n",
        "    attention_mask = encoded_dict['attention_mask'][0]\n",
        "\n",
        "    sample = (input_ids, attention_mask)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df_data)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NWcUwwEDUVn",
        "outputId": "5cdb727d-63dd-4611-b245-f3b0aace87ee"
      },
      "source": [
        "train_data = CompDataset(df_train)\n",
        "val_data = CompDataset(df_val)\n",
        "test_data = TestDataset(test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               num_workers=2)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             shuffle=True,\n",
        "                                             num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=False,\n",
        "                                              num_workers=2)\n",
        "\n",
        "print(len(train_dataloader), len(val_dataloader), len(test_dataloader))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "303 76 163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbWTtE_AkK3E"
      },
      "source": [
        "# Define the Model(xlm-roberta for sequence classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdlKBpDMkKSz",
        "outputId": "f3be09a9-7398-4a6e-a653-4625a16f8ec0"
      },
      "source": [
        "model = XLMRobertaForSequenceClassification.from_pretrained(model_type,\n",
        "                                                            num_labels=3)\n",
        "model.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTL27MroFGOs"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=L_RATE,\n",
        "                  eps=1e-8)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE2BPLFCkppm"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hAZLC1pFMuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c583b42-31c6-493d-a6fe-c040c3499af2"
      },
      "source": [
        "import random\n",
        "import gc\n",
        "\n",
        "seed_val = 1024\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "  print(f'========= Epoch {epoch+1} / {NUM_EPOCHS} =========')\n",
        "    \n",
        "  stacked_val_labels = []\n",
        "  targets_list = []\n",
        "\n",
        "  print('Training...')\n",
        "  model.train()\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  total_train_loss = 0\n",
        "\n",
        "  for i, batch in enumerate(train_dataloader):\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    target = batch[2].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "      \n",
        "    output = model(input_ids, \n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=target)\n",
        "      \n",
        "    loss = output[0]\n",
        "    total_train_loss = total_train_loss + loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    xm.optimizer_step(optimizer=optimizer, barrier=True)\n",
        "\n",
        "  print(f'train loss : {total_train_loss}')\n",
        "\n",
        "  print('\\nValidation')\n",
        "  model.eval()\n",
        "\n",
        "  torch.set_grad_enabled(False)\n",
        "\n",
        "  total_val_loss=0\n",
        "\n",
        "  for j, val_batch in enumerate(val_dataloader):\n",
        "    b_input_ids = val_batch[0].to(device)\n",
        "    b_input_mask  = val_batch[1].to(device)\n",
        "    b_labels  = val_batch[2].to(device)\n",
        "\n",
        "    output = model(b_input_ids,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "      \n",
        "    loss = output[0]\n",
        "    total_val_loss = total_val_loss + loss.item()\n",
        "\n",
        "    preds = output[1]\n",
        "\n",
        "    val_preds = preds.detach().cpu().numpy()\n",
        "    targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "    targets_list.extend(targets_np)\n",
        "\n",
        "    if j == 0:\n",
        "      stacked_val_preds = val_preds\n",
        "\n",
        "    else:\n",
        "        stacked_val_preds = np.vstack((stacked_val_preds,\n",
        "                                       val_preds))\n",
        "    \n",
        "    # calculate val acc for this fold\n",
        "  y_true = targets_list\n",
        "  y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "\n",
        "  val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "  print('Val loss:', total_val_loss)\n",
        "  print('Val Acc:', val_acc)\n",
        "    \n",
        "  torch.save(model.parameters, 'model.pt')\n",
        "  gc.collect()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========= Epoch 1 / 3 =========\n",
            "Training...\n",
            "train loss : 334.8550956249237\n",
            "\n",
            "Validation\n",
            "Val loss: 83.71893048286438\n",
            "Val Acc: 0.327970297029703\n",
            "========= Epoch 2 / 3 =========\n",
            "Training...\n",
            "train loss : 335.2887850999832\n",
            "\n",
            "Validation\n",
            "Val loss: 83.70977783203125\n",
            "Val Acc: 0.327970297029703\n",
            "========= Epoch 3 / 3 =========\n",
            "Training...\n",
            "train loss : 335.32937812805176\n",
            "\n",
            "Validation\n",
            "Val loss: 83.7236179113388\n",
            "Val Acc: 0.327970297029703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPn3cYDhlV9D"
      },
      "source": [
        "for j, batch in enumerate(test_dataloader):\n",
        "  input_ids = batch[0].to(device)\n",
        "  attention_mask = batch[1].to(device)\n",
        "\n",
        "  outputs = model(input_ids,\n",
        "                  attention_mask = attention_mask)\n",
        "  \n",
        "  preds = outputs[0]\n",
        "\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  \n",
        "  if j == 0:\n",
        "    stacked_preds = preds\n",
        "  else:\n",
        "    stacked_preds = np.vstack((stacked_preds, preds))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIlA7reAF36W",
        "outputId": "fefc22b1-e4db-4afb-8e4b-5f1c810cdf2a"
      },
      "source": [
        "preds = np.argmax(stacked_preds, axis=1)\n",
        "preds"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "D-0xMxXPGFXc",
        "outputId": "8d2993f1-d49c-41b9-b40e-d0342e03e1f4"
      },
      "source": [
        "submit['prediction'] = preds\n",
        "submit"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5190</th>\n",
              "      <td>5f90dd59b0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>f357a04e86</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>1f0ea92118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5193</th>\n",
              "      <td>0407b48afb</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5194</th>\n",
              "      <td>16c2f2ab89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5195 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  prediction\n",
              "0     c6d58c3f69           1\n",
              "1     cefcc82292           1\n",
              "2     e98005252c           1\n",
              "3     58518c10ba           1\n",
              "4     c32b0d16df           1\n",
              "...          ...         ...\n",
              "5190  5f90dd59b0           1\n",
              "5191  f357a04e86           1\n",
              "5192  1f0ea92118           1\n",
              "5193  0407b48afb           1\n",
              "5194  16c2f2ab89           1\n",
              "\n",
              "[5195 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_-jsmWbGhgi"
      },
      "source": [
        "# XLM-roBERTa train 필사(필사)\n",
        "# https://www.kaggle.com/vbookshelf/basics-of-bert-and-xlm-roberta-pytorch#Section-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llAND0kRJFwr"
      },
      "source": [
        "# 자연어 처리의 4가지 단계\n",
        "자연어 처리 솔루션을 만들기 위한 방법론은 정말 다양하지만, 대부분의 솔루션은 아래의 4가지 단계로 구성되어 있습니다. 이 포스트에서는 각각의 솔루션에 대해 소개하기보다 각 단계에 활용되는 주요 개념들을 다루어보았습니다.\n",
        "\n",
        "  - Preprocessing : \n",
        "대부분의 자연어 데이터에는 URL과 같은 hypertext 및 특수문자들이 섞여있습니다. 특히 웹크롤링을 통해 데이터를 수집한 경우 각 웹페이지에 있는 텍스트 데이터는 모두 html 태그들과 섞여있을 것입니다. 따라서 자연어 데이터를 머신러닝, 딥러닝과 같은 통계 기법을 이용해 바로 분석하기에 앞서, 우선 분석하고자 하는 데이터에 사람들이 일상적으로 사용하는 언어만 남아있도록 가공해주어야 합니다.\n",
        "\n",
        "   - 이 뿐 아니라 동일한 의미를 가지지만 축약하여 표현하여 그 형태가 달라보이거나(do not = don’t), 실제 문장의 의미 해석에 있어 크게 중요하지 않은 표현들(for, to, the) 또한 처리해주는 편이 좋습니다. 이 밖에도 정말 다양한 형태의 전처리를 수행할 수 있는데요, MBTI classification 관련 포스트에서 구체적인 예시를 찾아보실 수 있습니다.\n",
        "\n",
        "  - Tokenization : \n",
        "데이터의 전처리가 끝나 마침내 자연어 데이터만 남았다면, 이제 문자열(string)을 다차원 벡터(vector)로 변환해주어야 합니다. 이렇게 변환한 벡터들이 위치한 공간을 임베딩(embedding)이라고 부르는데, 각 단어를 벡터로 변환하는 경우 단어 임베딩(word embedding), 각 문장을 벡터로 변환하는 경우 문장 임베딩(sentence embedding) 등으로 벡터화(vectorization)의 단위를 붙여 지칭하기도 합니다.\n",
        "\n",
        "  - 단어 임베딩이란 앞서 말씀드린 바와 같이 말뭉치(corpus)에 포함되어 있는 단어들이 각각 하나의 좌표를 가지도록 형성한 벡터공간을 말합니다. 여기서 단어(word)란 일반적으로 띄어쓰기나 줄바꿈과 같은 공백 문자(whitespace)로 나뉘어져 있는 문자열의 일부분을 지칭합니다.\n",
        "\n",
        "  Lorem ipsum dolor sit amet, …\n",
        "\n",
        "  - 즉 위의 예시에서는 띄어쓰기로 구분되어 있는 Lorem, ipsum, dolor, sit, amet이 각각 하나의 단어가 됩니다. 그러나 띄어쓰기를 활용하지 않는 언어들의 경우, 위와 같은 정의를 통해서는 문자열을 여러 단어로 잘라낼 수 없습니다.\n",
        "\n",
        "  努輸強紙暮革人士績質宿福読相理毎阪釣方新, …\n",
        "\n",
        "  - 이 경우 공백 문자가 아닌 형태소와 같은 의미론적 단위로 문자열을 구분하거나, 여러 말뭉치(corpus)에서 자주 등장하는 글자(character)들의 순서쌍들을 묶어서 벡터공간을 형성하기도 합니다. 이 임베딩의 단위를 토큰(token)이라고 하고, 주어진 문자열을 토큰들로 나누는 과정을 토큰화(tokenization)이라고 부릅니다. 그리고 이러한 토큰들이 위치한 벡터공간을 토큰 임베딩(token embedding)이라고 합니다.\n",
        "\n",
        "  - 참고로 한글 문자열의 자연어 처리에는 아래 예시와 같이 형태소(morpheme)를 이용한 임베딩을 자주 활용하고 있습니다.\n",
        "\n",
        "  대한민국은 민주공화국이다.\n",
        "\n",
        "  대한민국 + -은 + 민주공화국 + -이 + -다\n",
        "\n",
        "  - Token Embedding : \n",
        "문자열을 단어, 형태소 등의 토큰으로 분해하는 데 성공했다면 우선 one-hot encoding을 통해 곧바로 각각의 토큰들을 벡터로 변환할 수 있습니다. One-hot encoding이란 말뭉치에 들어있는 단어들을 중복없이 순서대로 나열한 뒤, 아래 이미지에서와 같이 영벡터(zero-vector)에 해당하는 순서(index)의 요소에만 1의 값을 부여하는 방법을 말합니다. 나열한 단어들에 중복이 없으므로 각각의 단어들은 모두 고유한 벡터값을 가지게 됩니다.\n",
        "   - 그러나 one-hot encoding을 통해 얻은 임베딩에서는 각각의 토큰들이 서로 같은 거리에 위치합니다. 즉 두 토큰이 다르다는 사실만 알려줄 뿐 두 토큰이 서로 어떠한 관계를 가지는지는 알려주지 못하는 것이죠. 토큰화 과정(tokenization)과 one-hot encoding을 통해 토큰의 순서를 정했다면 이제 유사한 의미를 가지는 토큰끼리는 서로 가까이 당기고, 관련 없는 토큰끼리는 밀어냄으로써 보다 유의미한 임베딩을 얻을 수 있습니다.\n",
        "\n",
        "  - Document Embedding\n",
        "말뭉치의 토큰들을 벡터로 만들었다면 이제 머신러닝, 딥러닝 알고리즘을 사용할 준비가 거의 다 끝났습니다. 예를 들어 한 영화에 대한 평론이 전반적으로 긍정적인 내용을 담고 있는지, 부정적인 내용을 담고 있는지 알고 싶다면 해당 평론 안에 포함되어 있는 토큰들의 임베딩을 모두 더해 평균치를 구해볼 수 있겠습니다. 분포가설에 따르면 긍정적 의미를 가진 토큰들은 마찬가지로 긍정적 의미를 가진 토큰들 근처에 위치할 것이고, 부정적 의미를 가진 토큰들은 긍정적 의미를 가진 토큰들과는 멀리 분포할 것이기에 평균치가 이들 중 어느쪽에 더 가까운지 계산해보면 됩니다.\n",
        "\n",
        "   - 그러나 개별 토큰들의 임베딩을 종합하는 것만으로는 해결할 수 없는 문제들도 있습니다. 한가지 예시로는 동음이의어와 다의어가 있습니다.\n",
        "\n",
        "  1) 밥을 많이 먹어 배가 부르다.\n",
        "\n",
        "  2) 사과보다 배가 더 시원하다.\n",
        "\n",
        "  - 1에서의 ‘배’와 2에서의 ‘배’ 모두 동일한 형태를 가지지만 서로 다른 의미를 가지고 있습니다. 1번에서의 ‘배’가 과일이 아닌 신체 부위를 뜻한다는 것을 알기 위해서는 ‘밥’, ‘먹-‘ 등의 형태소가 같은 문장 내에 위치한다는 것을 알아야 합니다.\n",
        "\n",
        "  - 한편 BERT5는 문장의 일부를 다른 단어로 대체하거나 제거한 뒤(mask) 원래의 문장을 복원하는 방식으로 학습합니다. 즉 \n",
        "i\n",
        "번째 토큰이 <MASK>라는 토큰으로 대체되었다고 하면 \n",
        "P\n",
        "(\n",
        "w\n",
        "i\n",
        "|\n",
        "w\n",
        "1\n",
        ",\n",
        "…\n",
        ",\n",
        "w\n",
        "i\n",
        "−\n",
        "1\n",
        ",\n",
        "w\n",
        "i\n",
        "+\n",
        "1\n",
        ",\n",
        "…\n",
        ",\n",
        "w\n",
        "n\n",
        "−\n",
        "1\n",
        ")\n",
        "의 값이 가장 높은 토큰을 찾아 \n",
        "i\n",
        "번째 토큰 자리에 다시 넣어줄 수 있도록 해당 조건부 확률을 학습하는 것입니다.\n",
        "\n",
        "  - 언어모델을 학습시켰다면 이를 분해한 뒤 그 속에 있는 잠재 변수를(latent variable) 꺼내어 문장 또는 문서의 임베딩으로써 활용할 수 있습니다. 만약 학습한 언어모델이 multilayer perceptron과 softmax 함수를 이용해 문자열을 확률공간으로 사영했다면 softmax의 바로 이전 layer(penultimate layer)의 출력값을 임베딩으로 사용할 수 있습니다. 또한 Transformer7와 같이 각 layer별로 latent variable이 특별한 의미를 가지는 경우 (e.g. word pair, trigram) 각 layer의 출력값을 모두 합쳐 하나의 임베딩으로 활용하기도 합니다.\n",
        "\n",
        "  - 이렇게 임베딩을 얻었다면 이제 마침내 풀고자 하는 문제(downstream task)에 맞추어 머신러닝 또는 딥러닝 알고리즘을 적용하면 됩니다. GPT, BERT와 같이 큰 용량의 언어모델을 활용하는 경우 언어모델의 학습 과정에서부터 딥러닝 알고리즘을 사용하므로, 임베딩을 얻은 후에도 동일한 딥러닝 알고리즘을 이용해 downstream task를 학습시키곤 합니다. 이 경우 임베딩을 얻기 위한 학습과정을 pretraining, 임베딩 이후의 추가적인 학습과정을 fine-tuning이라고 부릅니다.\n",
        "\n",
        "  "
      ]
    }
  ]
}