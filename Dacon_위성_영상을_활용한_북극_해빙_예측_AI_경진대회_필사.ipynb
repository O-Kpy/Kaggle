{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon_위성 영상을 활용한 북극 해빙 예측 AI 경진대회_필사.ipynb",
      "provenance": [],
      "mount_file_id": "1gM7wkd7Q0A4UkLsh4QfKdva7TKKsU7ar",
      "authorship_tag": "ABX9TyNMq9iQjHU7e8i3ZWomkU6D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Kaggle/blob/main/Dacon_%EC%9C%84%EC%84%B1_%EC%98%81%EC%83%81%EC%9D%84_%ED%99%9C%EC%9A%A9%ED%95%9C_%EB%B6%81%EA%B7%B9_%ED%95%B4%EB%B9%99_%EC%98%88%EC%B8%A1_AI_%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C_%ED%95%84%EC%82%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8v9fd8-AEPe",
        "outputId": "04bdb38a-cdbd-47cc-9dd0-73cf5fcb462b"
      },
      "source": [
        "import os \n",
        "from glob import glob\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torchvision import transforms, utils\n",
        "from torchsummary import summary\n",
        "\n",
        "device=None\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print('Using PyTorch version:',  torch.__version__, 'and Device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.8.1+cu101 and Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbgO85oKDnPI",
        "outputId": "e2eee1b0-654a-46d2-85c1-14f485d50920"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVaVt6BsGngq"
      },
      "source": [
        "# 데이터 불러오기 주소 (os.path.join())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmL5z1EDFvpK",
        "outputId": "0fd6ada8-13bf-4893-d65d-87fb115b4c16"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/dataset/Dacon/연습/제 2회 컴퓨터비전 학습 경진대회/'\n",
        "train_data_path = os.path.join(data_path, 'train')\n",
        "print(train_data_path)\n",
        "file_list = os.listdir(train_data_path)\n",
        "file_list.sort()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dataset/Dacon/연습/제 2회 컴퓨터비전 학습 경진대회/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaz9R5kCGlvW",
        "outputId": "7e8c5a08-28aa-4f8a-9de8-ddf57f554139"
      },
      "source": [
        "## Custom Dataset which return x_frames, y_frames\n",
        "\n",
        "torch.set_printoptions(threshold=10000) # show all tensor without abbreviation\n",
        "\n",
        "class SeaIceDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform, data_type=\"train\", frame_num=6, predict_num=2, stride=1):\n",
        "        super(SeaIceDataset, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        data_dir                => data folder path\n",
        "        transform               => data to tensor\n",
        "        data_type=\"train\"       => choose train / valid / test\n",
        "        frame_num               => frame nums to use on train \n",
        "        predict_num             => frame nums to predict\n",
        "        stride_num              => stride for frames (if stride=2 => 197811.npy, 198001.npy, 198003.npy ... )\n",
        "                                   만약 8월끼리 비교하고 싶다면 stride = 12 를 넣어준다.\n",
        "        \"\"\"\n",
        "\n",
        "        data_to_path = os.path.join(data_dir, data_type)\n",
        "        filenames = os.listdir(data_to_path)\n",
        "        self.filepaths = [os.path.join(data_to_path, filename) for filename in sorted(filenames)]\n",
        "        \n",
        "        self.transform = transform  # numpy 배열을 tensor 배열로 바꿔주는 함수\n",
        "        self.frame_num = frame_num \n",
        "        self.predict_num = predict_num\n",
        "        self.stride = stride\n",
        "\n",
        "    def __len__(self):\n",
        "        # len = dataset으로 시작가능한 인덱스 번호 \n",
        "        return len(self.filepaths) - (self.frame_num + self.predict_num - 1) * self.stride\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        it will return (x_with_frame_num, y_true_with_predict_num)\n",
        "        if frame_num = 6, predict_num = 2\n",
        "        ((6, 1, 448, 304), (2, 1, 448, 304))\n",
        "        \"\"\"\n",
        "        dataset = []\n",
        "        for id in range(idx, idx + self.frame_num + self.predict_num, self.stride):\n",
        "            cur_npy = np.load(self.filepaths[id])[:,:,0]/250    \n",
        "            # 250을 나눠주어 저장하지 않으면 toTensor했을때 오차값이 크게 생겼습니다\n",
        "            cur_tensor = self.transform(cur_npy)                \n",
        "            # tensor로 저장\n",
        "            dataset.append(cur_tensor)\n",
        "        x = torch.stack(dataset[:self.frame_num])\n",
        "        x = x.transpose(0,1).to(dtype=torch.float)              \n",
        "        # [1, 6, 448, 304] => [channel, frames, height, width]\n",
        "        y = torch.stack(dataset[self.frame_num:])               \n",
        "        y = y.transpose(0,1)                                   \n",
        "        # [1, 2, 448, 304] => [channel, frames, height, width]\n",
        "        return x, y\n",
        "\n",
        "def getTransform():\n",
        "    return transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "\n",
        "\n",
        "transform = getTransform()\n",
        "\n",
        "ice_dataset = SeaIceDataset(data_path, transform, \"train\", 6, 2, 1)\n",
        "\n",
        "a,b = ice_dataset[1]        # sample to see \n",
        "print(len(ice_dataset))     # 데이터셋에 있는 총 데이터의 개수는 8개씩 묶여있는 475개의 데이터가 있습니다\n",
        "print(a.shape, b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "475\n",
            "torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1k1b6h2GrwV",
        "outputId": "76c5f44a-aa36-4f06-fa42-cdea72e8e7fd"
      },
      "source": [
        "# Create splited Dataset to Train and Valid\n",
        "\n",
        "len_ice_dataset = len(ice_dataset)\n",
        "len_ice_train = int(0.8*len_ice_dataset)\n",
        "len_ice_valid = len_ice_dataset - len_ice_train\n",
        "\n",
        "train_dataset, valid_dataset = random_split(ice_dataset, [len_ice_train, len_ice_valid])\n",
        "print('train dataset length:', len(train_dataset))\n",
        "print('valid dataset length:', len(valid_dataset))\n",
        "\n",
        "# show one of train_ds\n",
        "for x,y in train_dataset:\n",
        "  print(x.shape, y.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train dataset length: 380\n",
            "valid dataset length: 95\n",
            "torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naX9xfmgGr1D",
        "outputId": "c6bfd7af-80a7-4eb2-e26c-a62cc2cf2a6c"
      },
      "source": [
        "# Creating DataLoader\n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "# Dataloader 는 데이터셋에서 배치 개수만큼 자동으로 뽑아서 제공해준다\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# train_dataloader length => 32\n",
        "for x, y in train_dataloader:\n",
        "  print(x.shape, y.shape)\n",
        "  break\n",
        "# 12 = > 배치사이즈"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12, 1, 6, 448, 304]) torch.Size([12, 1, 2, 448, 304])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7cCS7ZOoVZ"
      },
      "source": [
        "# Building Model 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auu769iWOfSi"
      },
      "source": [
        "model_params = {'shape':(6,1,448,304),\n",
        "                'init_filters':8,\n",
        "                'dropout_rate':0.5}\n",
        "\n",
        "# Creating Model\n",
        "\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        super(CustomNet, self).__init__()\n",
        "        input_frames, input_channel, input_height, input_width = params[\"shape\"] # input_frames? input_batch?\n",
        "        init_filters = params[\"init_filters\"]\n",
        "        self.dropout_rate = params[\"dropout_rate\"]\n",
        "        self.conv1 = nn.Conv3d(input_channel, init_filters, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(init_filters, init_filters*2, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.ConvTranspose3d(init_filters*2, 1, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool3d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.upsample(x, size=(2, 448, 304))\n",
        "        print(\"input: \", input.shape)\n",
        "        print(\"output: \", x.shape)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAnNrhlbQDID",
        "outputId": "a4319d05-4f84-45b2-a9bd-86e01923617a"
      },
      "source": [
        "my_model = CustomNet(model_params).to(device)\n",
        "print(my_model)\n",
        "summary(my_model, input_size=(1,6,448,304), device=device.type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomNet(\n",
            "  (conv1): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv2): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (conv3): ConvTranspose3d(16, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            ")\n",
            "input:  torch.Size([2, 1, 6, 448, 304])\n",
            "output:  torch.Size([2, 1, 2, 448, 304])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1       [-1, 8, 6, 448, 304]             224\n",
            "            Conv3d-2      [-1, 16, 3, 224, 152]           3,472\n",
            "   ConvTranspose3d-3       [-1, 1, 3, 224, 152]             433\n",
            "================================================================\n",
            "Total params: 4,129\n",
            "Trainable params: 4,129\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 3.12\n",
            "Forward/backward pass size (MB): 63.12\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 66.26\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPgK8fryV6Gq"
      },
      "source": [
        "# Loss Function && etric Function\n",
        "\n",
        "# metrics\n",
        "def mae_score(true, pred):\n",
        "    true, pred = numpy_to_tensor(true, pred)\n",
        "    score = np.mean(np.abs(true-pred))\n",
        "    \n",
        "    return score\n",
        "\n",
        "# metrics\n",
        "def f1_score(true, pred):\n",
        "    true, pred = numpy_to_tensor(true, pred)\n",
        "\n",
        "    target = np.where((true>1*0.05)<1*0.5)\n",
        "    \n",
        "    true = true[target]\n",
        "    pred = pred[target]\n",
        "    true = np.where(true < 1*0.15, 0, 1)\n",
        "    pred = np.where(pred < 1*0.15, 0, 1)\n",
        "    \n",
        "    right = np.sum(true * pred == 1)\n",
        "    precision = right / np.sum(true+1e-8)\n",
        "    recall = right / np.sum(pred+1e-8)\n",
        "    score = 2 * precision*recall/(precision+recall+1e-8)\n",
        "    \n",
        "    return score\n",
        "    \n",
        "# loss function\n",
        "def mae_over_f1(true, pred):\n",
        "    mae = mae_score(true, pred)\n",
        "    f1 = f1_score(true, pred)\n",
        "    score = mae/(f1+1e-8)\n",
        "    \n",
        "    return score\n",
        "\n",
        "def numpy_to_tensor(true, pred):\n",
        "    return true.cpu().detach().numpy(), pred.cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI4DSoTUXQ1t",
        "outputId": "30b6db12-eaa8-4478-eda4-60d50cb99038"
      },
      "source": [
        "# Optimizer\n",
        "\n",
        "# adam optimizer\n",
        "opt_adam = optim.Adam(my_model.parameters(), lr=3e-4)\n",
        "\n",
        "def get_lr(opt):\n",
        "  for param_group in opt.param_groups:\n",
        "    return param_group['lr']\n",
        "\n",
        "# check our learning rate\n",
        "current_lr = get_lr(opt_adam)\n",
        "print('current_lr:', current_lr)\n",
        "\n",
        "# learning rate scheduler\n",
        "lr_scheduler = ReduceLROnPlateau(opt_adam, mode='min', factor=0.5, patience=20, verbose=1)\n",
        "\n",
        "# example\n",
        "for i in range(100):\n",
        "  lr_scheduler.step(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current_lr: 0.0003\n",
            "Epoch    22: reducing learning rate of group 0 to 1.5000e-04.\n",
            "Epoch    43: reducing learning rate of group 0 to 7.5000e-05.\n",
            "Epoch    64: reducing learning rate of group 0 to 3.7500e-05.\n",
            "Epoch    85: reducing learning rate of group 0 to 1.8750e-05.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsUsyvFGYJGx"
      },
      "source": [
        "# Training Setting\n",
        "에폭 한번 할때마다 loss_epoch함수\n",
        "\n",
        "dataloader의 x,y 마다 metric_batch를 통해 metric값을 계산\n",
        "\n",
        "loss_batch를 통해 loss값을 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKDOR6iQYDdz"
      },
      "source": [
        "# Training \n",
        "\n",
        "def metrics_batch(pred, true, metrics):\n",
        "    # if needed add param \"metrics\" to custom\n",
        "    \"\"\"\n",
        "    output will be pred\n",
        "    target will be corrects\n",
        "    \"\"\"\n",
        "    if metrics:\n",
        "        return list(map(lambda x: x(true, pred), metrics))\n",
        "    mae_score = mae_score(true, pred)\n",
        "    f1_score = f1_score(true, pred)\n",
        "    return (mae_score, f1_score)\n",
        "\n",
        "def loss_batch(loss_func, pred, true, opt=None):\n",
        "    \"\"\"\n",
        "    loss_func => mae_over_f1\n",
        "    \"\"\"\n",
        "    loss = loss_func(true, pred)\n",
        "    with torch.no_grad():\n",
        "        metrics = metrics_batch(pred, true, [mae_score, f1_score])\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        # loss.backward()\n",
        "        opt.step()  # 학습이 이뤄지는 곳\n",
        "    return loss, metrics\n",
        "\n",
        "def loss_epoch(model, loss_func, dataset_dataloader, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = [0.0, 0.0]\n",
        "    len_data = len(dataset_dataloader.dataset)\n",
        "\n",
        "    for x, y in dataset_dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # 모델 결과\n",
        "        pred = model(x)\n",
        "        # 손실함수 구하기\n",
        "        loss, metrics = loss_batch(loss_func, pred, y, opt)\n",
        "        # 손실함수 \n",
        "        running_loss += loss\n",
        "        if metrics is not None:\n",
        "            for idx, metric_value in enumerate(metrics):\n",
        "                running_metric[idx] += metric_value\n",
        "        \n",
        "        # 문제 있으면 break, 여기서는 True 일때 바로 break\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "    \n",
        "    loss = running_loss / float(len_data)\n",
        "    metrics = list(map(lambda x: x/float(len_data), metrics))\n",
        "    print(loss, metrics)\n",
        "    return loss, metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BPOsGwHaMpK"
      },
      "source": [
        "loss_func = mae_over_f1\n",
        "opt_adam = optim.Adam(my_model.parameters(), lr=3e-4)\n",
        "lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\n",
        "\n",
        "TRAIN_PARAMS = {\n",
        "    \"num_epochs\" : 10,\n",
        "    \"loss_func\" : loss_func,\n",
        "    \"optimizer\" : opt_adam,\n",
        "    \"train_dataloader\" : train_dataloader,\n",
        "    \"valid_dataloader\" : valid_dataloader,\n",
        "    \"sanity_check\" : True,\n",
        "    \"lr_scheduler\" : lr_scheduler,\n",
        "    \"save_path\" : \"./weights.pt\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMX2QMz_ajNf"
      },
      "source": [
        "def train(model, params):\n",
        "    num_epochs = params['num_epochs']\n",
        "    loss_func = params['loss_func']\n",
        "    opt = params[\"optimizer\"]\n",
        "    train_dataloader = params['train_dataloader']\n",
        "    valid_dataloader = params['valid_dataloader']\n",
        "    sanity_check = params['sanity_check']\n",
        "    lr_scheduler = params['lr_scheduler']\n",
        "    save_path = params['save_path']\n",
        "\n",
        "    # keep history of the loss and metric\n",
        "    loss_hist = {\n",
        "        \"train\" : [],\n",
        "        \"valid\" : []\n",
        "    }\n",
        "\n",
        "    metrics_hist = {\n",
        "        \"train\" : [],\n",
        "        \"valid\" : []\n",
        "    }\n",
        "\n",
        "    # copy best weights\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    # init best loss\n",
        "    best_loss = float(\"inf\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print(f'Epoch:{epoch}/{num_epochs-1}, current lr:{current_lr}')\n",
        "        model.train()\n",
        "        train_loss, train_metrics = loss_epoch(model, loss_func, train_dataloader, sanity_check, opt)\n",
        "\n",
        "        # save history\n",
        "        loss_hist[\"train\"].append(train_loss)\n",
        "        metrics_hist[\"train\"].append(train_metrics)\n",
        "\n",
        "        # model.eval()\n",
        "        # with torch.no_grad():\n",
        "    \n",
        "\n",
        "    return model, loss_hist, metrics_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNtgazcOcF4q",
        "outputId": "d1528b54-66ee-4a94-c13d-4f7fbd9c1699"
      },
      "source": [
        "my_model, loss_hist, metrics_hist = train(my_model, TRAIN_PARAMS)\n",
        "\n",
        "print(loss_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0/9, current lr:0.0003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982581484 [0.0005451104982581484, 0.0]\n",
            "Epoch:1/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982326306 [0.0005451104982326306, 0.0]\n",
            "Epoch:2/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982261523 [0.0005451104982261523, 0.0]\n",
            "Epoch:3/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982874931 [0.0005451104982874931, 0.0]\n",
            "Epoch:4/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04980679474 [0.0005451104980679475, 0.0]\n",
            "Epoch:5/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.049819157684 [0.0005451104981915769, 0.0]\n",
            "Epoch:6/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982395529 [0.0005451104982395529, 0.0]\n",
            "Epoch:7/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.0498211132 [0.000545110498211132, 0.0]\n",
            "Epoch:8/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982437039 [0.0005451104982437039, 0.0]\n",
            "Epoch:9/9, current lr:0.0003\n",
            "input:  torch.Size([12, 1, 6, 448, 304])\n",
            "output:  torch.Size([12, 1, 2, 448, 304])\n",
            "54511.04982532296 [0.0005451104982532296, 0.0]\n",
            "{'train': [54511.04982581484, 54511.04982326306, 54511.04982261523, 54511.04982874931, 54511.04980679474, 54511.049819157684, 54511.04982395529, 54511.0498211132, 54511.04982437039, 54511.04982532296], 'valid': []}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}