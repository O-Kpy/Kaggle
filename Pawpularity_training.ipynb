{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pawpularity training.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOXOZ3UwNIigbQsVRHObWOJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Kaggle/blob/main/Pawpularity_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2hWLPIL_zMl",
        "outputId": "5878c169-a18f-4b0f-9dff-0063a0b988f0"
      },
      "source": [
        "!pip install kaggle --upgrade\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = 'kjohhhhh'\n",
        "os.environ['KAGGLE_KEY'] = '9317f96d3b60d9f8d013f5e394d69311'\n",
        "\n",
        "!kaggle competitions download -c petfinder-pawpularity-score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading 4128bae22183829d2b5fea10effdb0c3.jpg to /content\n",
            "  0% 0.00/10.2k [00:00<?, ?B/s]\n",
            "100% 10.2k/10.2k [00:00<00:00, 13.3MB/s]\n",
            "Downloading b03f7041962238a7c9d6537e22f9b017.jpg to /content\n",
            "  0% 0.00/10.2k [00:00<?, ?B/s]\n",
            "100% 10.2k/10.2k [00:00<00:00, 9.08MB/s]\n",
            "Downloading 80bc3ccafcc51b66303c2c263aa38486.jpg to /content\n",
            "  0% 0.00/10.3k [00:00<?, ?B/s]\n",
            "100% 10.3k/10.3k [00:00<00:00, 3.31MB/s]\n",
            "Downloading 4e429cead1848a298432a0acad014c9d.jpg to /content\n",
            "  0% 0.00/10.3k [00:00<?, ?B/s]\n",
            "100% 10.3k/10.3k [00:00<00:00, 9.40MB/s]\n",
            "Downloading 43a2262d7738e3d420d453815151079e.jpg to /content\n",
            "  0% 0.00/10.2k [00:00<?, ?B/s]\n",
            "100% 10.2k/10.2k [00:00<00:00, 10.7MB/s]\n",
            "Downloading 8f49844c382931444e68dffbe20228f4.jpg to /content\n",
            "  0% 0.00/10.2k [00:00<?, ?B/s]\n",
            "100% 10.2k/10.2k [00:00<00:00, 10.2MB/s]\n",
            "Downloading e0de453c1bffc20c22b072b34b54e50f.jpg to /content\n",
            "  0% 0.00/10.2k [00:00<?, ?B/s]\n",
            "100% 10.2k/10.2k [00:00<00:00, 11.1MB/s]\n",
            "Downloading c978013571258ed6d4637f6e8cc9d6a3.jpg to /content\n",
            "  0% 0.00/10.2k [00:00<?, ?B/s]\n",
            "100% 10.2k/10.2k [00:00<00:00, 10.4MB/s]\n",
            "Downloading 0031d6a9ef7340f898c3e05f92c7bb04.jpg to /content\n",
            "  0% 0.00/299k [00:00<?, ?B/s]\n",
            "100% 299k/299k [00:00<00:00, 41.6MB/s]\n",
            "Downloading 00630b1262efe301cb15a3b2022ba744.jpg to /content\n",
            "  0% 0.00/26.9k [00:00<?, ?B/s]\n",
            "100% 26.9k/26.9k [00:00<00:00, 25.9MB/s]\n",
            "Downloading 001dc955e10590d3ca4673f034feeef2.jpg to /content\n",
            "  0% 0.00/119k [00:00<?, ?B/s]\n",
            "100% 119k/119k [00:00<00:00, 37.6MB/s]\n",
            "Downloading 00655425c10d4c082dd7eeb97fa4fb17.jpg to /content\n",
            "  0% 0.00/47.6k [00:00<?, ?B/s]\n",
            "100% 47.6k/47.6k [00:00<00:00, 48.1MB/s]\n",
            "Downloading 0023b8a3abc93c712edd6120867deb53.jpg to /content\n",
            "  0% 0.00/77.8k [00:00<?, ?B/s]\n",
            "100% 77.8k/77.8k [00:00<00:00, 80.1MB/s]\n",
            "Downloading 001dd4f6fafb890610b1635f967ea081.jpg to /content\n",
            "  0% 0.00/29.2k [00:00<?, ?B/s]\n",
            "100% 29.2k/29.2k [00:00<00:00, 33.2MB/s]\n",
            "Downloading 0042bc5bada6d1cf8951f8f9f0d399fa.jpg to /content\n",
            "  0% 0.00/92.1k [00:00<?, ?B/s]\n",
            "100% 92.1k/92.1k [00:00<00:00, 79.0MB/s]\n",
            "Downloading 0013fd999caf9a3efe1352ca1b0d937e.jpg to /content\n",
            "  0% 0.00/90.9k [00:00<?, ?B/s]\n",
            "100% 90.9k/90.9k [00:00<00:00, 80.8MB/s]\n",
            "Downloading 0067aaaa500b530c76b9c91af34b4cb8.jpg to /content\n",
            "  0% 0.00/144k [00:00<?, ?B/s]\n",
            "100% 144k/144k [00:00<00:00, 45.8MB/s]\n",
            "Downloading 006483b96ca9c09b7afed3e3d3af539d.jpg to /content\n",
            "  0% 0.00/118k [00:00<?, ?B/s]\n",
            "100% 118k/118k [00:00<00:00, 120MB/s]\n",
            "Downloading 006cda7fec46a527f9f627f4722a2304.jpg to /content\n",
            "  0% 0.00/63.1k [00:00<?, ?B/s]\n",
            "100% 63.1k/63.1k [00:00<00:00, 59.1MB/s]\n",
            "Downloading 0049cb81313c94fa007286e9039af910.jpg to /content\n",
            "  0% 0.00/120k [00:00<?, ?B/s]\n",
            "100% 120k/120k [00:00<00:00, 107MB/s]\n",
            "Downloading 0007de18844b0dbbb5e1f607da0606e0.jpg to /content\n",
            "  0% 0.00/81.5k [00:00<?, ?B/s]\n",
            "100% 81.5k/81.5k [00:00<00:00, 87.4MB/s]\n",
            "Downloading 006fe962f5f7e2c5f527b2e27e28ed6d.jpg to /content\n",
            "  0% 0.00/84.4k [00:00<?, ?B/s]\n",
            "100% 84.4k/84.4k [00:00<00:00, 86.8MB/s]\n",
            "Downloading 0075ec6503412f21cf65ac5f43d80440.jpg to /content\n",
            "  0% 0.00/54.2k [00:00<?, ?B/s]\n",
            "100% 54.2k/54.2k [00:00<00:00, 58.1MB/s]\n",
            "Downloading 0009c66b9439883ba2750fb825e1d7db.jpg to /content\n",
            "  0% 0.00/44.8k [00:00<?, ?B/s]\n",
            "100% 44.8k/44.8k [00:00<00:00, 45.9MB/s]\n",
            "Downloading 00768659c1c90409f81dcdecbd270513.jpg to /content\n",
            "  0% 0.00/31.9k [00:00<?, ?B/s]\n",
            "100% 31.9k/31.9k [00:00<00:00, 32.9MB/s]\n",
            "Downloading 0018df346ac9c1d8413cfcc888ca8246.jpg to /content\n",
            "  0% 0.00/34.8k [00:00<?, ?B/s]\n",
            "100% 34.8k/34.8k [00:00<00:00, 33.9MB/s]\n",
            "Downloading 005017716086b8d5e118dd9fe26459b1.jpg to /content\n",
            "  0% 0.00/118k [00:00<?, ?B/s]\n",
            "100% 118k/118k [00:00<00:00, 127MB/s]\n",
            "Downloading 00524dbf2637a80cbc80f70d3ff59616.jpg to /content\n",
            "  0% 0.00/29.3k [00:00<?, ?B/s]\n",
            "100% 29.3k/29.3k [00:00<00:00, 30.1MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/581k [00:00<?, ?B/s]\n",
            "100% 581k/581k [00:00<00:00, 80.8MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/545 [00:00<?, ?B/s]\n",
            "100% 545/545 [00:00<00:00, 545kB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/326 [00:00<?, ?B/s]\n",
            "100% 326/326 [00:00<00:00, 305kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ORflGR_4Qt"
      },
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models\n",
        "!pip install --upgrade wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jAiFDqICwQK",
        "outputId": "71e69f94-00af-45cd-97d4-57364b8f99c1"
      },
      "source": [
        "!pip install colorama"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPr8olMCAOk1"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import copy\n",
        "import time\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# pytorch import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "\n",
        "# utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# sklearn import\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "import timm\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensor\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "c_ = Fore.CYAN\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "# for descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpi_eVGzAlKb",
        "outputId": "d31098b9-5d5f-403e-eb06-766510ca58ec"
      },
      "source": [
        "import wandb\n",
        "\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    api_key = user_secrets.get_secret('wandb_api')\n",
        "    wandb.login(key=api_key)\n",
        "    anony=None\n",
        "except:\n",
        "    anony='must'\n",
        "    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \n",
            "Get your W&B access token from here: https://wandb.ai/authorize\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPU_LXtLDn0c"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SDkroNcCF73"
      },
      "source": [
        "ROOT_DIR = \"/content\"\n",
        "TRAIN_DIR = \"/content/train\"\n",
        "TEST_DIR = \"/content/test\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdxBmtL_CIyv"
      },
      "source": [
        "# Traning Configure\n",
        "CONFIG = dict(\n",
        "seed=42,\n",
        "model_name='tf_efficientnet_b4_ns',\n",
        "train_batch_size=16,\n",
        "valid_batch_size=32,\n",
        "img_size=512,\n",
        "epochs=5,\n",
        "learning_rate=1e-4,\n",
        "scheduler='CosineAnnealingLR',\n",
        "min_lr=1e-6,\n",
        "T_max=20,\n",
        "T_0=25,\n",
        "warmup_epochs=0,\n",
        "weight_decay=1e-6,\n",
        "n_accumulate=1,\n",
        "n_fold=5,\n",
        "num_classes=1,\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "competitions='PetFinder',\n",
        "_wandb_kernel='deb')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20NiBuwsCJJ5"
      },
      "source": [
        "# Set Seed for Reproducibility\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "    torch.backends.cudnn.benchmark=False\n",
        "    os.environ['PYTHONHASHSEED']=str(seed)\n",
        "\n",
        "set_seed(CONFIG['seed'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lbXGeR-CKej"
      },
      "source": [
        "def get_train_file_path(id):\n",
        "    return f'{TRAIN_DIR}/{id}.jpg'\n",
        "\n",
        "\n",
        "df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n",
        "df['file_path'] = df['Id'].apply(get_train_file_path)\n",
        "\n",
        "feature_cols = [col for col in df.columns if col not in ['Id', 'Pawpularity', 'file_path']]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "g-c344UXCL3O",
        "outputId": "1ef6245a-f1e0-447f-9f82-92ce4553293f"
      },
      "source": [
        "# visualize images\n",
        "run = wandb.init(project='Pawpularity',\n",
        "                config=CONFIG,\n",
        "                job_type='Visualization',\n",
        "                anonymous='must')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">glad-terrain-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/anony-mouse-138857/Pawpularity?apiKey=8f0bb63c2839c053c8df8d53b52d415ad6e18112\" target=\"_blank\">https://wandb.ai/anony-mouse-138857/Pawpularity?apiKey=8f0bb63c2839c053c8df8d53b52d415ad6e18112</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/anony-mouse-138857/Pawpularity/runs/3qyfcovp?apiKey=8f0bb63c2839c053c8df8d53b52d415ad6e18112\" target=\"_blank\">https://wandb.ai/anony-mouse-138857/Pawpularity/runs/3qyfcovp?apiKey=8f0bb63c2839c053c8df8d53b52d415ad6e18112</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210928_061904-3qyfcovp</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "P1TDE-PGCS65",
        "outputId": "df5a6120-1e11-480e-b215-16c913759d20"
      },
      "source": [
        "preview_table = wandb.Table(columns=['Id', 'Image', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity'])\n",
        "tmp_df = df.sample(1000, random_state=CONFIG['seed']).reset_index(drop=True)\n",
        "for i in tqdm(range(len(tmp_df))):\n",
        "    row = tmp_df.loc[i]\n",
        "    img=Image.open(row.file_path)\n",
        "    preview_table.add_data(row['Id'],\n",
        "                          wandb.Image(img),\n",
        "                          row['Subject Focus'],\n",
        "                          row['Eyes'],\n",
        "                          row['Face'],\n",
        "                          row['Near'],\n",
        "                          row['Action'],\n",
        "                          row['Accessory'],\n",
        "                          row['Group'],\n",
        "                          row['Collage'],\n",
        "                          row['Human'],\n",
        "                          row['Occlusion'],\n",
        "                          row['Info'],\n",
        "                          row['Blur'],\n",
        "                          row['Pawpularity'])\n",
        "wandb.log({'Visualization':preview_table})\n",
        "run.finish()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-66a5711c6a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     preview_table.add_data(row['Id'],\n\u001b[1;32m      7\u001b[0m                           \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/train.csv/48d53aeabee4f92f77eee3a323343c77.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmWrNQcdCUTk"
      },
      "source": [
        "# Creat Folds\n",
        "def create_folds(df, n_s=5, n_grp=None):\n",
        "    df['kfold'] = -1\n",
        "    if n_grp is None:\n",
        "        skf = KFold(n_splits=n_s, random_state=CONFIG['seed'])\n",
        "        target=df['Pawpularity']\n",
        "    else:\n",
        "        skf=StratifiedKFold(n_splits=n_s, shuffle=True, random_state=CONFIG['seed'])\n",
        "        df['grp']=pd.cut(df['Pawpularity'], n_grp, labels=False)\n",
        "        target = df.grp\n",
        "    for fold_no, (t, v) in enumerate(skf.split(target, target)):\n",
        "        df.loc[v, 'kfold'] = fold_no\n",
        "    \n",
        "    df = df.drop('grp', axis=1)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqSqNKTKCV_9"
      },
      "source": [
        "df = create_folds(df, n_s=CONFIG['n_fold'], n_grp=14)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aHkOaoLCYX4"
      },
      "source": [
        "# Dataset Class\n",
        "\n",
        "class PawpularityDataset(Dataset):\n",
        "    def __init__(self, root_dir, df, transforms=None):\n",
        "        self.root_dir=root_dir  # 먼저 데이터 불러오기\n",
        "        self.df = df\n",
        "        self.file_names = df['file_path'].values\n",
        "        self.targets = df['Pawpularity'].values\n",
        "        self.meta = df[feature_cols].values\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_names[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        meta = self.meta[index, :]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)['image']\n",
        "        \n",
        "        return img, meta, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxkowdTfCZeU"
      },
      "source": [
        "# Augmentations\n",
        "\n",
        "data_transforms = {\n",
        "    'train' : A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                   std=[0.229, 0.224, 0.225],\n",
        "                   max_pixel_value=255.0,\n",
        "                   p=1.0),\n",
        "        ToTensorV2()\n",
        "    ], p=1.0),\n",
        "    \n",
        "    'valid' : A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                   std=[0.229, 0.224, 0.225],\n",
        "                   max_pixel_value=255.0,\n",
        "                   p=1.0),\n",
        "        ToTensorV2()\n",
        "    ], p=1.0)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noNMBGOFCafJ"
      },
      "source": [
        "class PawpularityModel(nn.Module):\n",
        "    def __init__(self, model_name, pretrained=True):\n",
        "        super(PawpularityModel, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        self.n_features = self.model.classifier.in_features\n",
        "        self.model.reset_classifier(0)\n",
        "        self.fc = nn.Linear(self.n_features + 12, CONFIG['num_classes'])\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def forward(self, images, meta):\n",
        "        features = self.model(images)  # features = (bs, embedding_size)\n",
        "        features = self.dropout(features)  \n",
        "        features = torch.cat([features, meta], dim=1)  # features = (bs, embedding_size + 12)\n",
        "        output = self.fc(features)  # outputs  = (bs, num_classes)\n",
        "        return output\n",
        "\n",
        "    \n",
        "model = PawpularityModel(CONFIG['model_name'])\n",
        "model.to(CONFIG['device'])\n",
        "\n",
        "# 모델 설명 ↓↓"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RU9TC3JCbfW"
      },
      "source": [
        "# Loss Function\n",
        "def criterion(outputs, targets):\n",
        "    return torch.sqrt(nn.MSELoss()(outputs.view(-1), targets.view(-1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJvqgtRrCdVt"
      },
      "source": [
        "# Training Function\n",
        "\n",
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    scaler=amp.GradScaler()\n",
        "    \n",
        "    dataset_size=0\n",
        "    running_losss=0.0\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, (images, meta, targets) in bar:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        meta = meta.to(device, dtype=torch.float)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        \n",
        "        batch_size = images.size(0)\n",
        "        \n",
        "        with amp.autocast(enabled=True):\n",
        "            outputs = model(images, meta)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss = loss / CONFIG['n_accumulate']\n",
        "            \n",
        "        scaler.scale(loss).backward()\n",
        "        \n",
        "        if (step + 1) % CONFIG['n_accumulate'] == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf9C_xeKCeMo"
      },
      "source": [
        "# Validation function\n",
        "\n",
        "@torch.no_grad()\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    dataset_size=0\n",
        "    running_loss=0.00\n",
        "    \n",
        "    TARGETS = []\n",
        "    PREDS = []\n",
        "    \n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, (images, meta, targets) in bar:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        meta = meta.to(device, dtype=torch.float)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "        \n",
        "        batch_size = images.size(0)\n",
        "        \n",
        "        outputs = model(images, meta)\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "        \n",
        "        epoch_loss = running_loss / dataset_size\n",
        "        \n",
        "        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n",
        "        TARGETS.append(targets.view(-1).cpu().detach().numpy())\n",
        "        \n",
        "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n",
        "    \n",
        "    TARGETS = np.concatenate(TARGETS)\n",
        "    PREDS = np.concatenate(PREDS)\n",
        "    val_rmse = mean_squared_error(TARGETS, PREDS, squared=False)\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    return epoch_loss, val_rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfFoFWGhCfZN"
      },
      "source": [
        "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
        "    \n",
        "    # To automatically log gradients\n",
        "    wandb.watch(model, log_freq=100)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print('[INFO] USING GPU: {}\\n'.format(torch.cuda.get_device_name()))\n",
        "        \n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_rmse = np.inf\n",
        "    history = defaultdict(list)\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        gc.collect()\n",
        "        \n",
        "        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, dataloader=train_loader, device=CONFIG['device'], epoch=epoch)\n",
        "        val_epoch_loss, val_epoch_rmse = valid_one_epoch(model, valid_loader, device=CONFIG['device'], epoch=epoch)\n",
        "        \n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "        history['Valid RMSE'].append(val_epoch_rmse)\n",
        "        \n",
        "        # Log the metrics\n",
        "        wandb.log({'Train Loss':train_epoch_loss})\n",
        "        wandb.log({'Valid Loss':val_epoch_loss})\n",
        "        wandb.log({'Valid RMSE':val_epoch_rmse})\n",
        "        \n",
        "        # deep copy the model\n",
        "        if val_epoch_rmse <= best_epoch_rmse:\n",
        "            print(f\"{c_}Validation Loos Improved ({best_epoch_rmse} --> {val_epoch_rmse})\")\n",
        "            best_epoch_rmse = val_epoch_rmse\n",
        "            run.summary['Best RMSE'] = best_epoch_rmse\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = 'RMSE{:.4f}_epoch{:.04}.bin'.format(best_epoch_rmse, epoch)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            wandb.save(PATH)\n",
        "            print(f'Model Saved{sr_}')\n",
        "            \n",
        "        print()\n",
        "    \n",
        "    end=time.time()\n",
        "    time_elapsed = end - start\n",
        "    \n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print('Best RMSE:{:.4f}'.format(best_epoch_rmse))\n",
        "    \n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ6HU8cFCgUe"
      },
      "source": [
        "def prepare_loader(fold):\n",
        "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    train_dataset = PawpularityDataset(TRAIN_DIR, df_train, transforms=data_transforms['train'])\n",
        "    valid_dataset = PawpularityDataset(TRAIN_DIR, df_valid, transforms=data_transforms['valid'])\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], num_workers=4, shuffle=True, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], num_workers=4, shuffle=False, pin_memory=True)\n",
        "    \n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUFN9h8eChWK"
      },
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr'])\n",
        "    \n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=CONFIG['T_0'], eta_min=CONFIG['min_lr'])\n",
        "    \n",
        "    elif CONFIG['scheduler'] == None:\n",
        "        return None\n",
        "    \n",
        "    return scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELkec1e3CiQH"
      },
      "source": [
        "# create Dataloader\n",
        "train_loader, valid_loader = prepare_loader(fold=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LXEhOnGCjnc"
      },
      "source": [
        "# define optimizer and scheduler\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
        "scheduler = fetch_scheduler(optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWPApv4zCktw"
      },
      "source": [
        "run = wandb.init(project='Pawpularity',\n",
        "                config=CONFIG,\n",
        "                job_type='Train',\n",
        "                anonymous='must')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noR6p6nKClrd"
      },
      "source": [
        "model, history = run_training(model, optimizer, scheduler, device=CONFIG['device'], num_epochs=CONFIG['epochs'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUXPlgfVcJ6O"
      },
      "source": [
        "run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}