{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport random\nimport collections\nimport cv2\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torchvision.transforms import ToPILImage\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n\nfrom PIL import Image, ImageFile\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport torchvision.transforms as T","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-21T12:49:31.783381Z","iopub.execute_input":"2021-10-21T12:49:31.784036Z","iopub.status.idle":"2021-10-21T12:49:31.792008Z","shell.execute_reply.started":"2021-10-21T12:49:31.783993Z","shell.execute_reply":"2021-10-21T12:49:31.790931Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# seed\ndef Seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nSeed(2021)    ","metadata":{"execution":{"iopub.status.busy":"2021-10-21T12:16:56.762806Z","iopub.execute_input":"2021-10-21T12:16:56.763137Z","iopub.status.idle":"2021-10-21T12:16:56.770271Z","shell.execute_reply.started":"2021-10-21T12:16:56.763099Z","shell.execute_reply":"2021-10-21T12:16:56.769370Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# DIR\nsubmit_dir = '../input/sartorius-cell-instance-segmentation/sample_submission.csv'\ntrain_dir = '../input/sartorius-cell-instance-segmentation/train'\ntest_dir = '../input/sartorius-cell-instance-segmentation/test'\ntrain_csv_dir = '../input/sartorius-cell-instance-segmentation/train.csv'\n\n# 모델 정의\nNUM_EPOCHS = 12\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-10-21T12:22:12.198699Z","iopub.execute_input":"2021-10-21T12:22:12.199031Z","iopub.status.idle":"2021-10-21T12:22:12.205354Z","shell.execute_reply.started":"2021-10-21T12:22:12.198986Z","shell.execute_reply":"2021-10-21T12:22:12.204364Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Dataset 정의","metadata":{}},{"cell_type":"code","source":"# utilities\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle : run-length a string formated(start length)\n    shape : (height, width) of array to return\n    Returns numpy array, 1-mask, 0-background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\ndef get_transforms(train):\n    transforms = []\n    transforms.append(ToTensorV2())\n    if train:\n        transforms.append(T.RandomHorizontalFlip(0.5))\n    return T.Compose(transforms)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T12:38:02.175906Z","iopub.execute_input":"2021-10-21T12:38:02.176544Z","iopub.status.idle":"2021-10-21T12:38:02.186058Z","shell.execute_reply.started":"2021-10-21T12:38:02.176503Z","shell.execute_reply":"2021-10-21T12:38:02.185055Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class CellDataset(Dataset):\n    def __init__(self, image_dir, df_path, height, width, transforms=None):\n        self.image_dir = image_dir\n        self.df = pd.read_csv(df_path)\n        self.height = height\n        self.width = width\n        self.image_info = collections.defaultdict(dict)\n        self.transforms = transforms\n        temp_df = self.df.groupby('id')['annotation'].agg(lambda x: list(x)).reset_index()\n        for index, row in temp_df.iterrows():  # image id, annotation 붙이기\n            self.image_info[index] = {\n                'image_id' : row['id'],\n                'image_path' : os.path.join(self.image_dir, row['id'] + '.png'),\n                'annotations' : row['annotation']\n            }\n    \n    def __getitem__(self, idx):\n        img_path = self.image_info[idx]['image_path']\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #img = Image.open(img_path).convert('RGB')\n        #img = img.resize((self.width, self.height), resample=Image.BILINEAR)\n        \n        info = self.image_info[idx]\n        \n        mask = np.zeros((len(info['annotations']), self.width, self.height), dtype=np.uint8)\n        labels = []\n        \n        for m, annotation in enumerate(info['annotations']):\n            sub_mask = rle_decode(annotation, (520, 704))\n            sub_mask = Image.fromarray(sub_mask)\n            #sub_mask = sub_mask.resize((self.width, self.height), resample=Image.BILINEAR)\n            sub_mask = np.array(sub_mask) > 0\n            mask[m, :, :] = sub_mask\n            labels.append(1)\n        \n        num_objs = len(labels)\n        boxes = []\n        new_labels = []\n        new_masks = []\n        \n        for i in range(num_objs):  # obj box\n            try:\n                \n        ","metadata":{},"execution_count":null,"outputs":[]}]}