{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cocera Kaggle 공부 영상.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZNArH9bJOqh0p+p40wLB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Kaggle/blob/main/Cocera_Kaggle_%EA%B3%B5%EB%B6%80_%EC%98%81%EC%83%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LSXcZ0pDqj3"
      },
      "source": [
        "# 1주차\n",
        "\n",
        "ML을 할때 진행해야하는 process\n",
        "\n",
        "1. 비즈니스 관점으로 보기(ex 사용자에게 무엇을 제공할수있을지, 무엇을 할까...)\n",
        "2. 작업을 공식화 ==> 무엇을 예측해야하는가?, 어떤 데이터를 사용해야하는가?...\n",
        "3. 데이터 수집\n",
        "4. 데이터 처리(전,후처리)\n",
        "5. 데이터 저장\n",
        "6. 모델링\n",
        "7. 실제 시나리오에서 모델의 효과를 입증\n",
        "8. 모델 성능 모니터링, 새 데이터를 재교육하기\n",
        "\n",
        "\n",
        "\n",
        "> KNN은 신경망과 앙상블하면 안된다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Feature Preprocessing, Feature Generating\n",
        "\n",
        "1. 데이터 결측값 채우기, (데이터 전처리...)\n",
        "2. Feature Preprocessing은 반드시 필요\n",
        "3. Feature Generating은 반드시 필요하진 않지만 데이터에 따라서 강력한 Tool이 될수있다.\n",
        "4. Feature Generation ==> 새 기능을 만드는 프로세스, 패턴을 발견해 새로운 컬럼을 추가 할 수 있다.\n",
        "\n",
        "> Numeric Features\n",
        "1. 스케일링(Scaling)(특히 KNN) - 데이터 분포를 고르게해주진 않는다.\n",
        "2. 이상치(Outlier)\n",
        "3. 순위(Rank)\n",
        "4. Numeric Features는 트리기반(스케일링에 의존하지 않는다.) 모델과 Non트리기반 모델과 다른 preprocessing 효과를 가진다.\n",
        "5. 로그(np.log(1+x))와 제곱근(np.sqrt(1+x)) 데이터 분포 변환\n",
        "\n",
        "\n",
        "> Categorical Features\n",
        "1. 레이블 인코딩(원핫인코딩, 라벨인코딩, pandas.factorize(나오는 순서대로 인코딩)\n",
        "2. 피쳐 생성의 유용한 것 ==> 여러 분류 피쳐간의 피쳐 상호작용을 따라 피쳐를 생성\n",
        "3. 원핫 인코딩은 트리모델에서 시간이 너무 많이 걸림\n",
        "4. 두 개 이상의 고유 범주의 경우 원핫 인코딩이 안전 옵션이다. \n",
        "\n",
        "\n",
        " > Date and Time\n",
        " 1. 시계열데이터\n",
        " 2. 반복되는 패턴을 발견 할 수 있음 그리고 예측 할 수 있음\n",
        " 3. 주기 적용, 특정 이벤트 이후 전달된 시간 계산\n",
        "\n",
        "\n",
        " > Coordinates(좌표)\n",
        " 1. 거리(거리측정) 활용\n",
        " 2. 회전\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Missing Null (결측치 처리)\n",
        "너무 큰값, 음수(-)값(데이터에 따라), Nan, 999등...\n",
        "\n",
        "> 그냥 두기(무시) ==> 성능이 떨어질수있음, 중위수를 하기도 어려운 상황에서(상황마다 다르다)\n",
        "\n",
        "> 중위수(mean, median, mode)로 대체하기 ==> 선형, 신경망에서는 좋은 효과 but 트리모형에서는 안좋음\n",
        "\n",
        "> 예측값 집어넣기 ==> 일반화 오류가 생길수있음 \n",
        "\n",
        "> 피쳐 생성 전에 누락값을 채우지 말자 ==> 생성된 피쳐의 유용성이 안좋아진다.\n",
        "1. 먼저 피쳐 엔지니어링\n",
        "2. 그 다음 누락 값 채우기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcDcc95g3gvU"
      },
      "source": [
        "# 'Will Koehrsen'의 일반적인 데이터분석 순서\n",
        "\n",
        "1. Understand the problem (we're almost there already) - 데이터 이해하기\n",
        "2. Exploratory Data Analysis - EDA(with corr)\n",
        "3. Feature engineering to create a dataset for machine learning - 피쳐 엔지니어링과 모델링\n",
        "4. Compare several baseline machine learning models - 모델 비교\n",
        "5. Try more complex machine learning models - 더 많은 모델\n",
        "6. Optimize the selected model - 모델 최적화\n",
        "7. Investigate model predictions in context of problem - 모델 검증\n",
        "8. Draw conclusions and lay out next steps"
      ]
    }
  ]
}