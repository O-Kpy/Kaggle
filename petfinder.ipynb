{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-30T08:00:19.601007Z","iopub.execute_input":"2021-10-30T08:00:19.601563Z","iopub.status.idle":"2021-10-30T08:00:29.099910Z","shell.execute_reply.started":"2021-10-30T08:00:19.601473Z","shell.execute_reply":"2021-10-30T08:00:29.099104Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport random\nimport copy\nimport time\nimport cv2\nfrom PIL import Image\n\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\nimport albumentations as A\nimport torchvision.transforms as T\nfrom albumentations.pytorch import ToTensorV2\n\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nimport timm\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nfrom colorama import Fore, Back, Style\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:03:42.127963Z","iopub.execute_input":"2021-10-30T08:03:42.128357Z","iopub.status.idle":"2021-10-30T08:03:42.137621Z","shell.execute_reply.started":"2021-10-30T08:03:42.128321Z","shell.execute_reply":"2021-10-30T08:03:42.135842Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret('wandb_api')  # api 얻어오기\n    wandb.login(key=api_key)  # wandb 로그인\n    anony = None\nexcept:\n    anony = 'must'","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:09:29.856179Z","iopub.execute_input":"2021-10-30T08:09:29.856797Z","iopub.status.idle":"2021-10-30T08:09:30.119571Z","shell.execute_reply.started":"2021-10-30T08:09:29.856757Z","shell.execute_reply":"2021-10-30T08:09:30.118830Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/petfinder-pawpularity-score'\nTRAIN_DIR = '../input/petfinder-pawpularity-score/train'\nTEST_DIR = '../input/petfinder-pawpularity-score/test'","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:09:31.623516Z","iopub.execute_input":"2021-10-30T08:09:31.624307Z","iopub.status.idle":"2021-10-30T08:09:31.629498Z","shell.execute_reply.started":"2021-10-30T08:09:31.624267Z","shell.execute_reply":"2021-10-30T08:09:31.627527Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42,\n    model_name = 'tf_efficientnet_b4_ns',\n    train_batch_size = 16,\n    valid_batch_size = 32,\n    img_size = 256,\n    epochs = 10,\n    learning_rate = 1e-5,\n    min_lr = 1e-4,\n    T_max = 100,\n    T_0 = 25,\n    warmup_epochs = 0,\n    weight_decay = 1e-6,\n    n_accumulate = 1,\n    n_fold = 5,\n    num_classes = 1,\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n    competition = 'PetFinder',\n    wandb_kernel = 'deb'\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:11:58.415764Z","iopub.execute_input":"2021-10-30T08:11:58.416676Z","iopub.status.idle":"2021-10-30T08:11:58.465262Z","shell.execute_reply.started":"2021-10-30T08:11:58.416633Z","shell.execute_reply":"2021-10-30T08:11:58.464492Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:14:10.267945Z","iopub.execute_input":"2021-10-30T08:14:10.268266Z","iopub.status.idle":"2021-10-30T08:14:10.275788Z","shell.execute_reply.started":"2021-10-30T08:14:10.268234Z","shell.execute_reply":"2021-10-30T08:14:10.275056Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(id):\n    return f'{TRAIN_DIR}/{id}.jpg'\n\ndf = pd.read_csv(f'{ROOT_DIR}/train.csv')\ndf['file_path'] = df['Id'].apply(get_train_file_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:15:06.303703Z","iopub.execute_input":"2021-10-30T08:15:06.303975Z","iopub.status.idle":"2021-10-30T08:15:06.350751Z","shell.execute_reply.started":"2021-10-30T08:15:06.303946Z","shell.execute_reply":"2021-10-30T08:15:06.349884Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# KFOLD","metadata":{}},{"cell_type":"code","source":"def create_folds(df, n_s, n_grp=None):\n    df['kfold'] = -1\n    \n    if n_grp is None:\n        skf = KFold(n_splits=n_s, random_state=CONFIG['seed'])\n        target = df['Pawpularity']\n    else:\n        skf = StratifiedKFold(n_splits=n_s, shuffle=True, random_state=CONFIG['seed'])\n        df['grp'] = pd.cut(df['Pawpularity'], bins=n_grp, labels=False)\n        target = df['grp']\n        \n    for fold_no, (t,v) in enumerate(skf.split(target, target)):\n        df.loc[v, 'kfold'] = fold_no\n        \n    df = df.drop(columns=['grp'])\n    return df\n    \ndf = create_folds(df, n_s=CONFIG['n_fold'], n_grp=14)\n\nfeature_cols = [cols for cols in df.columns if cols not in ['Id', 'Pawpularity', 'kfold', 'file_path']]","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:31:25.145196Z","iopub.execute_input":"2021-10-30T08:31:25.145893Z","iopub.status.idle":"2021-10-30T08:31:25.173817Z","shell.execute_reply.started":"2021-10-30T08:31:25.145855Z","shell.execute_reply":"2021-10-30T08:31:25.173072Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:31:27.063250Z","iopub.execute_input":"2021-10-30T08:31:27.063906Z","iopub.status.idle":"2021-10-30T08:31:27.086080Z","shell.execute_reply.started":"2021-10-30T08:31:27.063867Z","shell.execute_reply":"2021-10-30T08:31:27.085393Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class PawpularityDataset(Dataset):\n    def __init__(self, root_dir, df, transforms):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_name = df['file_path'].values\n        self.meta = df[feature_cols].values\n        self.targets = df['Pawpularity'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_name[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        meta = self.meta[index, :]\n        targets = self.targets[index]\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        return img, meta, targets","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:34:54.578254Z","iopub.execute_input":"2021-10-30T08:34:54.578813Z","iopub.status.idle":"2021-10-30T08:34:54.587184Z","shell.execute_reply.started":"2021-10-30T08:34:54.578774Z","shell.execute_reply":"2021-10-30T08:34:54.585530Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class PawpularityDataset(Dataset):\n    def __init__(self, root_dir, df, transforms=None):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_name = df['file_path'].values\n        self.targets = df['Pawpularity'].values\n        self.meta = df[feature_cols].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_name[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        meta = self.meta[index, :]\n        targets = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n            \n        return img, meta, targets","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:12:17.288485Z","iopub.execute_input":"2021-10-27T09:12:17.289199Z","iopub.status.idle":"2021-10-27T09:12:17.298903Z","shell.execute_reply.started":"2021-10-27T09:12:17.28916Z","shell.execute_reply":"2021-10-27T09:12:17.298046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\n\ndata_transforms = {\n    'train' : A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0, p=1.0),\n        ToTensorV2()\n    ], p=1.0),\n    \n    'valid' : A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0, p=1.0),\n        ToTensorV2()\n    ], p=1.0)\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-30T08:50:21.033016Z","iopub.execute_input":"2021-10-30T08:50:21.033277Z","iopub.status.idle":"2021-10-30T08:50:21.039807Z","shell.execute_reply.started":"2021-10-30T08:50:21.033248Z","shell.execute_reply":"2021-10-30T08:50:21.039071Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# model 불러오기","metadata":{}},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super(PawpularityModel, self).__init__()\n        self.model = timm.create_model(model_name=model_name, pretrained=pretrained)\n        self.in_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.in_features+len(feature_cols), CONFIG['num_classes'])\n        self.dropout = nn.Dropout(p=0.6)\n        \n    def forward(self, images, meta):\n        features = self.model(images)\n        features = self.dropout(features)\n        features = torch.cat([features, meta], dim=1)\n        output = self.fc(features)\n        return output\n    \nmodel = PawpularityModel(CONFIG['model_name'])\nmodel.to(CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2021-10-30T09:00:22.875787Z","iopub.execute_input":"2021-10-30T09:00:22.876581Z","iopub.status.idle":"2021-10-30T09:00:30.831801Z","shell.execute_reply.started":"2021-10-30T09:00:22.876532Z","shell.execute_reply":"2021-10-30T09:00:30.831125Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class PawpularityModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super(PawpularityModel, self).__init__()\n        self.model = timm.create_model(model_name=model_name, pretrained=pretrained)\n        self.n_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.n_features+12, CONFIG['num_classes'])\n        # self.fc2 = nn.Linear(512, CONFIG['num_classes'])\n        self.dropout = nn.Dropout(p=0.6)\n        \n    def forward(self, images, meta):\n        features = self.model(images)\n        features = self.dropout(features)\n        features = torch.cat([features, meta], dim=1)\n        output = self.fc(features)\n        return output\n    \nmodel = PawpularityModel(CONFIG['model_name'])\nmodel.to(CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2021-10-19T08:32:54.127246Z","iopub.execute_input":"2021-10-19T08:32:54.127694Z","iopub.status.idle":"2021-10-19T08:33:02.532989Z","shell.execute_reply.started":"2021-10-19T08:32:54.127661Z","shell.execute_reply":"2021-10-19T08:33:02.532236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# criterion\ndef criterion(outputs, targets):\n    return torch.sqrt(nn.MSELoss()(outputs.view(-1), targets.view(-1)))","metadata":{"execution":{"iopub.status.busy":"2021-10-30T09:05:21.163398Z","iopub.execute_input":"2021-10-30T09:05:21.163997Z","iopub.status.idle":"2021-10-30T09:05:21.168223Z","shell.execute_reply.started":"2021-10-30T09:05:21.163962Z","shell.execute_reply":"2021-10-30T09:05:21.167540Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, meta, targets) in bar:         \n        images = images.to(device, dtype=torch.float)\n        meta = meta.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        \n        with amp.autocast(enabled=True):\n            outputs = model(images, meta)\n            loss = criterion(outputs, targets)\n            loss = loss / CONFIG['n_accumulate']\n            \n        scaler.scale(loss).backward()  # .backward() == 기울기 계산\n    \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            scaler.step(optimizer)  # .step() == parameter를 업데이트\n            scaler.update()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()  # .zero_grad() == 기울기 초기화 \n\n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-30T09:28:55.546990Z","iopub.execute_input":"2021-10-30T09:28:55.547285Z","iopub.status.idle":"2021-10-30T09:28:55.557748Z","shell.execute_reply.started":"2021-10-30T09:28:55.547255Z","shell.execute_reply":"2021-10-30T09:28:55.556992Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, meta, targets) in bar:\n        images = images.to(device, dtype=torch.float)\n        meta = meta.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images, meta)\n        loss = criterion(outputs, targets)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        PREDS.append(outputs.view(-1).cpu().detach().numpy())\n        TARGETS.append(targets.view(-1).cpu().detach().numpy())\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n        \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_rmse = mean_squared_error(TARGETS, PREDS, squared=False)\n    \n    gc.collect()\n    \n    return epoch_loss, val_rmse","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:13:03.435321Z","iopub.execute_input":"2021-10-27T09:13:03.435576Z","iopub.status.idle":"2021-10-27T09:13:03.445281Z","shell.execute_reply.started":"2021-10-27T09:13:03.435547Z","shell.execute_reply":"2021-10-27T09:13:03.444597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    wandb.watch(model, log_freq=100)\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_rmse = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        gc.collect()\n        \n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device=CONFIG['device'], epoch=epoch)\n        valid_epoch_loss, valid_epoch_rmse = valid_one_epoch(model, valid_loader, device=CONFIG['device'], epoch=epoch)\n        \n        history['Train_Loss'].append(train_epoch_loss)\n        history['Valid_Loss'].append(valid_epoch_loss)\n        history['Valid_RMSE'].append(valid_epoch_rmse)\n        \n        wandb.log({'Train Loss' : train_epoch_loss})\n        wandb.log({'Valid Loss' : valid_epoch_loss})\n        wandb.log({'Valid RMSE' : valid_epoch_rmse})\n        \n        print(f'Valid RMSE : {valid_epoch_rmse}')\n        \n        if valid_epoch_rmse <= best_epoch_rmse:\n            print(f'{c_}Validation Loss Improved ({best_epoch_rmse} --> {valid_epoch_rmse}')\n            best_epoch_rmse = valid_epoch_rmse\n            run.summary['Best RMSE'] = best_epoch_rmse\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f'epoch{epoch}.bin'\n            torch.save(model.state_dict(), PATH)\n            wandb.save(PATH)\n            print(f'Model Saved{sr_}')\n            \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best RMSE: {:.4f}\".format(best_epoch_rmse))\n    \n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:13:05.914039Z","iopub.execute_input":"2021-10-27T09:13:05.914427Z","iopub.status.idle":"2021-10-27T09:13:05.926389Z","shell.execute_reply.started":"2021-10-27T09:13:05.914392Z","shell.execute_reply":"2021-10-27T09:13:05.92546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    wandb.watch(model, log_freq=100)\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_rmse = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device=CONFIG['device'], epoch=epoch)\n        valid_epoch_loss, valid_epoch_rmse = valid_one_epoch(model, valid_loader, device=CONFIG['device'], epoch=epoch)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        history['Valid RMSE'].append(valid_epoch_rmse)\n        \n        wandb.log({'Train Loss' : train_epoch_loss})\n        wandb.log({'Valid Loss' : valid_epoch_loss})\n        wandb.log({'Valid RMSE' : valid_epoch_rmse})\n        \n        print(f'Valid RMSE : {valid_epoch_rmse}')\n        \n        if valid_epoch_rmse <= best_epoch_rmse:\n            print(f'{c_}Validation Loss Improved ({best_epoch_rmse} --> {valid_epoch_rmse})')\n            best_epoch_rmse = valid_epoch_rmse\n            run.summary['Best RMSE'] = best_epoch_rmse\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f'epoch{epoch}.bin'\n            torch.save(model.state_dict(), PATH)\n            wandb.save(PATH)\n            print(f'Model Saved{sr_}')\n            \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best RMSE: {:.4f}\".format(best_epoch_rmse))\n        \n    model.load_state_dict(best_model_wts)\n        \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-25T09:02:43.272373Z","iopub.execute_input":"2021-10-25T09:02:43.273129Z","iopub.status.idle":"2021-10-25T09:02:43.285681Z","shell.execute_reply.started":"2021-10-25T09:02:43.273081Z","shell.execute_reply":"2021-10-25T09:02:43.284904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:13:08.748802Z","iopub.execute_input":"2021-10-27T09:13:08.74958Z","iopub.status.idle":"2021-10-27T09:13:08.760986Z","shell.execute_reply.started":"2021-10-27T09:13:08.749544Z","shell.execute_reply":"2021-10-27T09:13:08.760162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer, scheduler 선언\noptimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\nscheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], eta_min=CONFIG['min_lr'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T08:06:47.899344Z","iopub.execute_input":"2021-10-27T08:06:47.900019Z","iopub.status.idle":"2021-10-27T08:06:47.914291Z","shell.execute_reply.started":"2021-10-27T08:06:47.899983Z","shell.execute_reply":"2021-10-27T08:06:47.913531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 데이터 로더 준비","metadata":{}},{"cell_type":"code","source":"def prepare_loader(fold):\n    df_train = df[df['kfold'] != fold].reset_index(drop=True)\n    df_valid = df[df['kfold'] == fold].reset_index(drop=True)\n    \n    train_dataset = PawpularityDataset(TRAIN_DIR, df_train, transforms=data_transforms['train'])\n    valid_dataset = PawpularityDataset(TRAIN_DIR, df_valid, transforms=data_transforms['valid'])\n    \n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], pin_memory=True, shuffle=True, drop_last=True, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], pin_memory=True, shuffle=False, num_workers=4)\n    \n    return train_loader, valid_loader\n\ntrain_loader, valid_loader = prepare_loader(fold=0)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:13:12.129807Z","iopub.execute_input":"2021-10-27T09:13:12.130605Z","iopub.status.idle":"2021-10-27T09:13:12.159821Z","shell.execute_reply.started":"2021-10-27T09:13:12.130542Z","shell.execute_reply":"2021-10-27T09:13:12.158957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run = wandb.init(project='Pawpularity',\n                 config=CONFIG,\n                 job_type='Train',\n                 anonymous='must')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:13:14.093426Z","iopub.execute_input":"2021-10-27T09:13:14.094206Z","iopub.status.idle":"2021-10-27T09:13:24.018198Z","shell.execute_reply.started":"2021-10-27T09:13:14.09416Z","shell.execute_reply":"2021-10-27T09:13:24.017381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = run_training(model, optimizer, scheduler, device=CONFIG['device'], num_epochs=CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T09:13:49.206393Z","iopub.execute_input":"2021-10-27T09:13:49.206675Z","iopub.status.idle":"2021-10-27T10:23:09.19443Z","shell.execute_reply.started":"2021-10-27T09:13:49.206638Z","shell.execute_reply":"2021-10-27T10:23:09.193707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_file_path(id):\n    return f'{TEST_DIR}/{id}.jpg'\n\ntest_df = pd.read_csv(f'{ROOT_DIR}/test.csv')\ntest_df['file_path'] = test_df['Id'].apply(get_test_file_path)\n\nfeature_cols = [cols for cols test_df.columns if cols not in ['Id', 'file_path', 'Pawpularity']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityTestDataset(Dataset):\n    def __init__(self, root_dir, df, transforms=None):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_name = df['file_path'].values\n        self.meta = df[feature_cols].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_name[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        meta = self.meta[index, :]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return img, meta","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}