{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tabular-playground-series/2021-aug/tabular-playground-series-aug-2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jPxX8yPI5M-ht0FHW3esyqlTeqc_R6Hw",
      "authorship_tag": "ABX9TyMyLGfGpPytmGRg9F6u4Pt6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Kaggle/blob/main/tabular_playground_series_2021_aug_tabular_playground_series_aug_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxPUpwmsufDV",
        "outputId": "060d38c9-ba4b-4503-e753-c46d7cac8d39"
      },
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 23326, done.\u001b[K\n",
            "remote: Counting objects: 100% (1003/1003), done.\u001b[K\n",
            "remote: Compressing objects: 100% (549/549), done.\u001b[K\n",
            "remote: Total 23326 (delta 619), reused 743 (delta 434), pack-reused 22323\u001b[K\n",
            "Receiving objects: 100% (23326/23326), 18.10 MiB | 21.30 MiB/s, done.\n",
            "Resolving deltas: 100% (17012/17012), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
            "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
            "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
            "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
            "Cloning into '/content/LightGBM/external_libs/compute'...\n",
            "remote: Enumerating objects: 21731, done.        \n",
            "remote: Counting objects: 100% (3/3), done.        \n",
            "remote: Compressing objects: 100% (3/3), done.        \n",
            "remote: Total 21731 (delta 0), reused 1 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21731/21731), 8.51 MiB | 23.49 MiB/s, done.\n",
            "Resolving deltas: 100% (17566/17566), done.\n",
            "Cloning into '/content/LightGBM/external_libs/eigen'...\n",
            "remote: Enumerating objects: 111147, done.        \n",
            "remote: Counting objects: 100% (771/771), done.        \n",
            "remote: Compressing objects: 100% (453/453), done.        \n",
            "remote: Total 111147 (delta 414), reused 638 (delta 309), pack-reused 110376        \n",
            "Receiving objects: 100% (111147/111147), 102.34 MiB | 22.92 MiB/s, done.\n",
            "Resolving deltas: 100% (91207/91207), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser'...\n",
            "remote: Enumerating objects: 689, done.        \n",
            "remote: Counting objects: 100% (189/189), done.        \n",
            "remote: Compressing objects: 100% (121/121), done.        \n",
            "remote: Total 689 (delta 93), reused 99 (delta 41), pack-reused 500        \n",
            "Receiving objects: 100% (689/689), 802.19 KiB | 10.03 MiB/s, done.\n",
            "Resolving deltas: 100% (347/347), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fmt'...\n",
            "remote: Enumerating objects: 27156, done.        \n",
            "remote: Counting objects: 100% (864/864), done.        \n",
            "remote: Compressing objects: 100% (343/343), done.        \n",
            "remote: Total 27156 (delta 520), reused 705 (delta 423), pack-reused 26292        \n",
            "Receiving objects: 100% (27156/27156), 13.45 MiB | 9.54 MiB/s, done.\n",
            "Resolving deltas: 100% (18319/18319), done.\n",
            "Submodule path 'external_libs/compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
            "Submodule path 'external_libs/eigen': checked out '8ba1b0f41a7950dc3e1d4ed75859e36c73311235'\n",
            "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
            "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
            "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
            "remote: Enumerating objects: 15092, done.        \n",
            "remote: Counting objects: 100% (1027/1027), done.        \n",
            "remote: Compressing objects: 100% (530/530), done.        \n",
            "remote: Total 15092 (delta 667), reused 795 (delta 496), pack-reused 14065        \n",
            "Receiving objects: 100% (15092/15092), 10.21 MiB | 19.48 MiB/s, done.\n",
            "Resolving deltas: 100% (11408/11408), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
            "remote: Enumerating objects: 1235, done.        \n",
            "remote: Counting objects: 100% (79/79), done.        \n",
            "remote: Compressing objects: 100% (61/61), done.        \n",
            "remote: Total 1235 (delta 45), reused 38 (delta 18), pack-reused 1156        \n",
            "Receiving objects: 100% (1235/1235), 7.09 MiB | 19.11 MiB/s, done.\n",
            "Resolving deltas: 100% (817/817), done.\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
            "Submodule path 'external_libs/fmt': checked out 'cc09f1a6798c085c325569ef466bcdcffdc266d4'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2nWgx0vup8n",
        "outputId": "67e84701-27ec-446c-dd5c-d75c7c88ccc8"
      },
      "source": [
        "%cd /content/LightGBM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LightGBM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgOjbW7iuquk",
        "outputId": "84906216-a88e-4c29-a557-7f30592bdd02"
      },
      "source": [
        "\n",
        "!mkdir build\n",
        "!cmake -DUSE_GPU=1\n",
        "!make -j$(nproc)\n",
        "!sudo apt-get -y install python-pip\n",
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
        "%cd /content/LightGBM/python-package/\n",
        "!sudo python setup.py install --precompile"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
            "[ 98%] Built target lightgbm\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
            "[100%] Built target _lightgbm\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-setuptools python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 3,430 kB of archives.\n",
            "After this operation, 10.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1.18.04.5 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-xdg all 0.25-4ubuntu1.1 [31.2 kB]\n",
            "Fetched 3,430 kB in 2s (1,983 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 148489 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 330 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 53 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: numpy, threadpoolctl, scipy, scikit-learn, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.2 pandas-1.3.2 scikit-learn-0.24.2 scipy-1.7.1 threadpoolctl-2.2.0\n",
            "/content/LightGBM/python-package\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/lightgbm\n",
            "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
            "copying lightgbm/dask.py -> build/lib/lightgbm\n",
            "copying lightgbm/compat.py -> build/lib/lightgbm\n",
            "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
            "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
            "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
            "copying lightgbm/callback.py -> build/lib/lightgbm\n",
            "copying lightgbm/basic.py -> build/lib/lightgbm\n",
            "copying lightgbm/engine.py -> build/lib/lightgbm\n",
            "running egg_info\n",
            "creating lightgbm.egg-info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching 'compile/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/include'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\n",
            "warning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
            "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
            "running install_lib\n",
            "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/dask.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['/content/LightGBM/lib_lightgbm.so']\n",
            "copying /content/LightGBM/lib_lightgbm.so -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/dask.py to dask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/compat.py to compat.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/callback.py to callback.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/basic.py to basic.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py to engine.cpython-37.pyc\n",
            "running install_egg_info\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-3.2.1.99-py3.7.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEBAjbJ7UkPH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from scipy.stats import skew\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a1qRF-QVgSq",
        "outputId": "5e1c1038-bff5-4d98-8baa-9d104528c087"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/tabular-playground-series/2021-aug/tabular-playground-series-aug-2021_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/tabular-playground-series/2021-aug/tabular-playground-series-aug-2021_test.csv')\n",
        "submit = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/tabular-playground-series/2021-aug/tabular-playground-series-aug-2021_sample_submission.csv')\n",
        "train.shape, test.shape, submit.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((250000, 102), (150000, 101), (150000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEP635LtVsHJ",
        "outputId": "729b4c52-bd55-4549-e6ad-1fc33741783d"
      },
      "source": [
        "train['loss'].skew()  # target 라벨에 log1p씌울까 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.4653191365369271"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "JHafe73qXiKH",
        "outputId": "4e5bab98-a133-4a73-ba11-5e38602fc056"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "train.skew().sort_values().plot()\n",
        "plt.title('Train set Skew', fontsize=20, fontweight='bold', pad=20)\n",
        "# noramlize를 적용 할까 고민"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Train set Skew')"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAaP4UlNsOz1"
      },
      "source": [
        "# cluster DBSCAN기법\n",
        "\n",
        "- DBSCAN(density-based spatial clustering of application with noise)은 클러스터의 갯수를 미리 지정하지 않는 군집 알고리즘\n",
        "\n",
        "\n",
        "- DBSCAN은 병합 군집이나 k-평균보다는 다소 느리지만 비교적 큰 데이터셋에도 적용\n",
        "\n",
        "\n",
        "\n",
        "- 데이터의 밀집지역이 한 클러스터를 구성하며 비교적 비어있는 지역을 경계로 다른 클러스터와 구분함\n",
        "\n",
        "\n",
        "\n",
        "- DBSCAN은 특성 공간에서 가까이 있는 데이터가 많아 붐비는 지역의 포인트를 찾음\n",
        "\n",
        "- 이런 지역을 밀집 지역dense region이라 함\n",
        "\n",
        "- 밀집 지역에 있는 포인트를 핵심 포인트core point라고함\n",
        "\n",
        "\n",
        "\n",
        "- 핵심 포인트: min_samples, epsepsilon\n",
        "\n",
        "  - 한 데이터 포인트에서 eps 거리 안에 데이터가 min_samples 갯수만큼 들어 있으면 이 데이터 포인트를 핵심 포인트로 분류\n",
        "\n",
        "  - eps(거리)보다 가까운 핵심 샘플은 동일한 클러스터로 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmVVxeJZx26U"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "data = pd.concat([train.drop(columns=['id']), test.drop(columns=['id'])], axis=0)\n",
        "data_columns = data.columns\n",
        "\n",
        "for i in data.columns:\n",
        "  if i == 'loss':\n",
        "    continue\n",
        "  data[i] = MinMaxScaler().fit_transform(data[[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "QZmixSiSy5uy",
        "outputId": "2c85d0f4-fb57-4ef6-83f0-64164e42c49e"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "data['cluster'] = DBSCAN(n_jobs=-1).fit_predict(data.drop(columns=['loss']))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-938e90b76fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mCluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNoisy\u001b[0m \u001b[0msamples\u001b[0m \u001b[0mare\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \"\"\"\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_dbscan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# This has worst case O(n^2) memory complexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         neighborhoods = neighbors_model.radius_neighbors(X,\n\u001b[0;32m--> 335\u001b[0;31m                                                          return_distance=False)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[0;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[1;32m    969\u001b[0m                               sort_results=sort_results)\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m             )\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9JOhkaLZkNq"
      },
      "source": [
        "# Clustering 적용하자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHOZOVN3ZW3z",
        "outputId": "bc95cab8-34ff-48ab-f8d7-17ce2e306a76"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install optuna"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-0.26.1-cp37-none-manylinux1_x86_64.whl (67.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 67.4 MB 81 kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.26.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.9.1-py3-none-any.whl (302 kB)\n",
            "\u001b[K     |████████████████████████████████| 302 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.2)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 53.9 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.4.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.4)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.2)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=19291b9419c0a219883d44fdbad45c8a503ebb469e788a35f626784a6294aaa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, python-editor, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.5 alembic-1.6.5 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-6.4.1 optuna-2.9.1 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLlP0cqcZ6vD"
      },
      "source": [
        "import catboost\n",
        "import optuna\n",
        "import optuna.integration.lightgbm as lgbo\n",
        "import lightgbm\n",
        "import xgboost\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneGroupOut, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Y-LxF9aRWi",
        "outputId": "56001efd-611b-43f7-ac0e-7c989c49d38d"
      },
      "source": [
        "# 데이터 나누기\n",
        "x_train = train.drop(columns=['id', 'loss'])\n",
        "y_train = train['loss']\n",
        "x_test = test.drop(columns=['id'])\n",
        "x_train_columns = x_train.columns\n",
        "x_test_columns = x_test.columns\n",
        "x_train.shape, y_train.shape, x_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((250000, 100), (250000,), (150000, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQF7A77Fe5EI"
      },
      "source": [
        "mm = MinMaxScaler().fit(x_train)\n",
        "x_train = mm.transform(x_train)\n",
        "x_test = mm.transform(x_test)\n",
        "\n",
        "x_train = pd.DataFrame(x_train, columns=x_train_columns)\n",
        "x_test = pd.DataFrame(x_test, columns=x_test_columns)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "SzyHuK_Rf6Vx",
        "outputId": "4e5f0d68-9f84-4525-afa1-2e57b56eb81e"
      },
      "source": [
        "# Clustering\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vstack = np.vstack((x_train,\n",
        "                    x_test))\n",
        "\n",
        "sse = {}\n",
        "for i in range(1,20, 1):\n",
        "  km = KMeans(n_clusters=i, max_iter=1000, random_state=0, n_jobs=-1).fit(vstack)\n",
        "  sse[i] = km.inertia_\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.lineplot(pd.Series(sse).index, pd.Series(sse), marker='o')\n",
        "plt.xticks(pd.Series(sse).index)\n",
        "plt.title('elbow method', fontsize=20, fontweight='bold', pad=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'elbow method')"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR5YSCDNmaYZ"
      },
      "source": [
        "km = KMeans(n_splits=, max_iter=1000, n_jobs=-1).fit(vstack)\n",
        "\n",
        "x_train['cluster'] = km.predict(x_train)\n",
        "x_test['cluster'] = km.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye_vs_epatCG",
        "outputId": "e1ff0b20-eb07-4488-a699-aa941fa77b1d"
      },
      "source": [
        "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "preds = np.zeros((x_test.shape[0],))\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(x_train, y_train)):\n",
        "  X_train, X_valid = x_train.iloc[train_index], x_train.iloc[valid_index]\n",
        "  Y_train, Y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
        "\n",
        "  model_cat = catboost.CatBoostRegressor(iterations=3000, learning_rate=0.022, loss_function='RMSE', eval_metric='RMSE', task_type='GPU')\n",
        "  model_cat.fit(X_train, Y_train, eval_set=(X_valid, Y_valid), verbose=100, early_stopping_rounds=70)\n",
        "\n",
        "  preds += np.expm1(model_cat.predict(x_test)) / kf.n_splits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 1.1039045\ttest: 1.1063753\tbest: 1.1063753 (0)\ttotal: 10.3ms\tremaining: 30.9s\n",
            "100:\tlearn: 1.0945647\ttest: 1.0977858\tbest: 1.0977858 (100)\ttotal: 1.8s\tremaining: 51.6s\n",
            "200:\tlearn: 1.0901819\ttest: 1.0942911\tbest: 1.0942911 (200)\ttotal: 2.91s\tremaining: 40.6s\n",
            "300:\tlearn: 1.0869794\ttest: 1.0920953\tbest: 1.0920953 (300)\ttotal: 4.21s\tremaining: 37.7s\n",
            "400:\tlearn: 1.0843921\ttest: 1.0905177\tbest: 1.0905177 (400)\ttotal: 5.58s\tremaining: 36.2s\n",
            "500:\tlearn: 1.0821666\ttest: 1.0893155\tbest: 1.0893155 (500)\ttotal: 7.41s\tremaining: 37s\n",
            "600:\tlearn: 1.0800835\ttest: 1.0882926\tbest: 1.0882926 (600)\ttotal: 9.82s\tremaining: 39.2s\n",
            "700:\tlearn: 1.0781490\ttest: 1.0874149\tbest: 1.0874149 (700)\ttotal: 12.1s\tremaining: 39.7s\n",
            "800:\tlearn: 1.0763697\ttest: 1.0866818\tbest: 1.0866818 (800)\ttotal: 14.4s\tremaining: 39.6s\n",
            "900:\tlearn: 1.0746677\ttest: 1.0860741\tbest: 1.0860741 (900)\ttotal: 16.9s\tremaining: 39.3s\n",
            "1000:\tlearn: 1.0730308\ttest: 1.0855342\tbest: 1.0855342 (1000)\ttotal: 18.9s\tremaining: 37.8s\n",
            "1100:\tlearn: 1.0714150\ttest: 1.0850424\tbest: 1.0850424 (1100)\ttotal: 21.2s\tremaining: 36.6s\n",
            "1200:\tlearn: 1.0698821\ttest: 1.0846505\tbest: 1.0846505 (1200)\ttotal: 23.7s\tremaining: 35.5s\n",
            "1300:\tlearn: 1.0683260\ttest: 1.0842475\tbest: 1.0842465 (1299)\ttotal: 26.1s\tremaining: 34.1s\n",
            "1400:\tlearn: 1.0668515\ttest: 1.0838828\tbest: 1.0838828 (1400)\ttotal: 27.5s\tremaining: 31.4s\n",
            "1500:\tlearn: 1.0653633\ttest: 1.0836128\tbest: 1.0836126 (1499)\ttotal: 28.8s\tremaining: 28.8s\n",
            "1600:\tlearn: 1.0639787\ttest: 1.0833106\tbest: 1.0833106 (1600)\ttotal: 30s\tremaining: 26.2s\n",
            "1700:\tlearn: 1.0625681\ttest: 1.0830857\tbest: 1.0830857 (1700)\ttotal: 32.5s\tremaining: 24.8s\n",
            "1800:\tlearn: 1.0611735\ttest: 1.0828337\tbest: 1.0828337 (1800)\ttotal: 34.9s\tremaining: 23.3s\n",
            "1900:\tlearn: 1.0597726\ttest: 1.0826380\tbest: 1.0826380 (1900)\ttotal: 37.3s\tremaining: 21.6s\n",
            "2000:\tlearn: 1.0584389\ttest: 1.0824363\tbest: 1.0824332 (1994)\ttotal: 39.8s\tremaining: 19.9s\n",
            "2100:\tlearn: 1.0571054\ttest: 1.0822507\tbest: 1.0822499 (2099)\ttotal: 42.2s\tremaining: 18.1s\n",
            "2200:\tlearn: 1.0557804\ttest: 1.0821156\tbest: 1.0821124 (2196)\ttotal: 44s\tremaining: 16s\n",
            "2300:\tlearn: 1.0544493\ttest: 1.0819591\tbest: 1.0819591 (2300)\ttotal: 45.6s\tremaining: 13.8s\n",
            "2400:\tlearn: 1.0531320\ttest: 1.0818264\tbest: 1.0818219 (2399)\ttotal: 46.9s\tremaining: 11.7s\n",
            "2500:\tlearn: 1.0518649\ttest: 1.0816928\tbest: 1.0816928 (2500)\ttotal: 48.2s\tremaining: 9.61s\n",
            "2600:\tlearn: 1.0505918\ttest: 1.0815349\tbest: 1.0815347 (2599)\ttotal: 49.3s\tremaining: 7.57s\n",
            "2700:\tlearn: 1.0492934\ttest: 1.0814109\tbest: 1.0814109 (2700)\ttotal: 50.4s\tremaining: 5.58s\n",
            "2800:\tlearn: 1.0480326\ttest: 1.0813022\tbest: 1.0813000 (2787)\ttotal: 52.4s\tremaining: 3.72s\n",
            "2900:\tlearn: 1.0467668\ttest: 1.0811932\tbest: 1.0811932 (2900)\ttotal: 54.5s\tremaining: 1.86s\n",
            "2999:\tlearn: 1.0455514\ttest: 1.0810936\tbest: 1.0810932 (2987)\ttotal: 56.2s\tremaining: 0us\n",
            "bestTest = 1.081093161\n",
            "bestIteration = 2987\n",
            "Shrink model to first 2988 iterations.\n",
            "0:\tlearn: 1.1044649\ttest: 1.1040989\tbest: 1.1040989 (0)\ttotal: 18.1ms\tremaining: 54.3s\n",
            "100:\tlearn: 1.0949868\ttest: 1.0959699\tbest: 1.0959699 (100)\ttotal: 1.2s\tremaining: 34.5s\n",
            "200:\tlearn: 1.0905697\ttest: 1.0928548\tbest: 1.0928548 (200)\ttotal: 2.29s\tremaining: 31.9s\n",
            "300:\tlearn: 1.0873358\ttest: 1.0907929\tbest: 1.0907929 (300)\ttotal: 3.46s\tremaining: 31s\n",
            "400:\tlearn: 1.0846803\ttest: 1.0892726\tbest: 1.0892726 (400)\ttotal: 5.38s\tremaining: 34.9s\n",
            "500:\tlearn: 1.0824005\ttest: 1.0881087\tbest: 1.0881087 (500)\ttotal: 7.39s\tremaining: 36.9s\n",
            "600:\tlearn: 1.0803119\ttest: 1.0871455\tbest: 1.0871455 (600)\ttotal: 8.51s\tremaining: 34s\n",
            "700:\tlearn: 1.0783302\ttest: 1.0864048\tbest: 1.0864048 (700)\ttotal: 9.64s\tremaining: 31.6s\n",
            "800:\tlearn: 1.0764583\ttest: 1.0857012\tbest: 1.0857012 (800)\ttotal: 10.8s\tremaining: 29.6s\n",
            "900:\tlearn: 1.0747186\ttest: 1.0851662\tbest: 1.0851662 (900)\ttotal: 11.9s\tremaining: 27.7s\n",
            "1000:\tlearn: 1.0730927\ttest: 1.0847154\tbest: 1.0847154 (1000)\ttotal: 13s\tremaining: 25.9s\n",
            "1100:\tlearn: 1.0714434\ttest: 1.0842594\tbest: 1.0842585 (1099)\ttotal: 14.1s\tremaining: 24.3s\n",
            "1200:\tlearn: 1.0698469\ttest: 1.0839155\tbest: 1.0839155 (1200)\ttotal: 15.3s\tremaining: 22.8s\n",
            "1300:\tlearn: 1.0682957\ttest: 1.0835978\tbest: 1.0835978 (1300)\ttotal: 16.4s\tremaining: 21.4s\n",
            "1400:\tlearn: 1.0667727\ttest: 1.0832844\tbest: 1.0832843 (1399)\ttotal: 17.6s\tremaining: 20.1s\n",
            "1500:\tlearn: 1.0653106\ttest: 1.0830181\tbest: 1.0830181 (1500)\ttotal: 18.7s\tremaining: 18.7s\n",
            "1600:\tlearn: 1.0639018\ttest: 1.0827778\tbest: 1.0827778 (1600)\ttotal: 19.8s\tremaining: 17.3s\n",
            "1700:\tlearn: 1.0625020\ttest: 1.0825785\tbest: 1.0825785 (1700)\ttotal: 21s\tremaining: 16s\n",
            "1800:\tlearn: 1.0610969\ttest: 1.0823383\tbest: 1.0823349 (1799)\ttotal: 22.1s\tremaining: 14.7s\n",
            "1900:\tlearn: 1.0597379\ttest: 1.0821661\tbest: 1.0821639 (1898)\ttotal: 23.2s\tremaining: 13.4s\n",
            "2000:\tlearn: 1.0583402\ttest: 1.0820170\tbest: 1.0820170 (2000)\ttotal: 24.3s\tremaining: 12.1s\n",
            "2100:\tlearn: 1.0570234\ttest: 1.0818561\tbest: 1.0818561 (2100)\ttotal: 25.4s\tremaining: 10.9s\n",
            "2200:\tlearn: 1.0557233\ttest: 1.0816966\tbest: 1.0816959 (2196)\ttotal: 26.5s\tremaining: 9.61s\n",
            "2300:\tlearn: 1.0544256\ttest: 1.0815937\tbest: 1.0815937 (2300)\ttotal: 27.6s\tremaining: 8.37s\n",
            "2400:\tlearn: 1.0530978\ttest: 1.0814849\tbest: 1.0814778 (2398)\ttotal: 28.7s\tremaining: 7.16s\n",
            "2500:\tlearn: 1.0518130\ttest: 1.0813679\tbest: 1.0813612 (2496)\ttotal: 29.8s\tremaining: 5.95s\n",
            "2600:\tlearn: 1.0505029\ttest: 1.0812040\tbest: 1.0812040 (2600)\ttotal: 31.1s\tremaining: 4.78s\n",
            "2700:\tlearn: 1.0492377\ttest: 1.0810894\tbest: 1.0810894 (2700)\ttotal: 33.5s\tremaining: 3.71s\n",
            "2800:\tlearn: 1.0479710\ttest: 1.0809939\tbest: 1.0809939 (2800)\ttotal: 35.2s\tremaining: 2.5s\n",
            "2900:\tlearn: 1.0467395\ttest: 1.0808998\tbest: 1.0808998 (2900)\ttotal: 36.5s\tremaining: 1.25s\n",
            "2999:\tlearn: 1.0454753\ttest: 1.0808057\tbest: 1.0808036 (2998)\ttotal: 38.9s\tremaining: 0us\n",
            "bestTest = 1.080803593\n",
            "bestIteration = 2998\n",
            "Shrink model to first 2999 iterations.\n",
            "0:\tlearn: 1.1043364\ttest: 1.1046365\tbest: 1.1046365 (0)\ttotal: 16.8ms\tremaining: 50.3s\n",
            "100:\tlearn: 1.0951551\ttest: 1.0959988\tbest: 1.0959988 (100)\ttotal: 1.21s\tremaining: 34.8s\n",
            "200:\tlearn: 1.0907616\ttest: 1.0923131\tbest: 1.0923131 (200)\ttotal: 2.57s\tremaining: 35.7s\n",
            "300:\tlearn: 1.0876000\ttest: 1.0899917\tbest: 1.0899917 (300)\ttotal: 3.96s\tremaining: 35.5s\n",
            "400:\tlearn: 1.0849994\ttest: 1.0884217\tbest: 1.0884217 (400)\ttotal: 5.11s\tremaining: 33.1s\n",
            "500:\tlearn: 1.0827736\ttest: 1.0872028\tbest: 1.0872028 (500)\ttotal: 6.15s\tremaining: 30.7s\n",
            "600:\tlearn: 1.0807277\ttest: 1.0861478\tbest: 1.0861478 (600)\ttotal: 7.19s\tremaining: 28.7s\n",
            "700:\tlearn: 1.0787555\ttest: 1.0852493\tbest: 1.0852493 (700)\ttotal: 8.24s\tremaining: 27s\n",
            "800:\tlearn: 1.0769298\ttest: 1.0844928\tbest: 1.0844928 (800)\ttotal: 9.32s\tremaining: 25.6s\n",
            "900:\tlearn: 1.0751642\ttest: 1.0837819\tbest: 1.0837819 (900)\ttotal: 10.4s\tremaining: 24.2s\n",
            "1000:\tlearn: 1.0735155\ttest: 1.0832363\tbest: 1.0832363 (1000)\ttotal: 11.5s\tremaining: 23.1s\n",
            "1100:\tlearn: 1.0719398\ttest: 1.0827809\tbest: 1.0827809 (1100)\ttotal: 12.7s\tremaining: 21.9s\n",
            "1200:\tlearn: 1.0703779\ttest: 1.0823821\tbest: 1.0823821 (1200)\ttotal: 14.3s\tremaining: 21.5s\n",
            "1300:\tlearn: 1.0688606\ttest: 1.0819637\tbest: 1.0819631 (1299)\ttotal: 16.3s\tremaining: 21.3s\n",
            "1400:\tlearn: 1.0674074\ttest: 1.0816368\tbest: 1.0816368 (1400)\ttotal: 18.8s\tremaining: 21.4s\n",
            "1500:\tlearn: 1.0659707\ttest: 1.0812870\tbest: 1.0812870 (1500)\ttotal: 21.1s\tremaining: 21.1s\n",
            "1600:\tlearn: 1.0645424\ttest: 1.0810012\tbest: 1.0810012 (1600)\ttotal: 22.8s\tremaining: 19.9s\n",
            "1700:\tlearn: 1.0631301\ttest: 1.0807146\tbest: 1.0807145 (1698)\ttotal: 24.1s\tremaining: 18.4s\n",
            "1800:\tlearn: 1.0617530\ttest: 1.0804705\tbest: 1.0804705 (1800)\ttotal: 26.6s\tremaining: 17.7s\n",
            "1900:\tlearn: 1.0604199\ttest: 1.0802916\tbest: 1.0802916 (1900)\ttotal: 28.7s\tremaining: 16.6s\n",
            "2000:\tlearn: 1.0590658\ttest: 1.0801167\tbest: 1.0801167 (2000)\ttotal: 30.9s\tremaining: 15.4s\n",
            "2100:\tlearn: 1.0577407\ttest: 1.0798941\tbest: 1.0798941 (2100)\ttotal: 33.3s\tremaining: 14.3s\n",
            "2200:\tlearn: 1.0564280\ttest: 1.0797223\tbest: 1.0797223 (2200)\ttotal: 35.7s\tremaining: 13s\n",
            "2300:\tlearn: 1.0551496\ttest: 1.0796212\tbest: 1.0796212 (2300)\ttotal: 38.2s\tremaining: 11.6s\n",
            "2400:\tlearn: 1.0538422\ttest: 1.0794974\tbest: 1.0794974 (2400)\ttotal: 40.6s\tremaining: 10.1s\n",
            "2500:\tlearn: 1.0525076\ttest: 1.0793624\tbest: 1.0793624 (2500)\ttotal: 42.6s\tremaining: 8.5s\n",
            "2600:\tlearn: 1.0512346\ttest: 1.0792140\tbest: 1.0792118 (2599)\ttotal: 43.7s\tremaining: 6.7s\n",
            "2700:\tlearn: 1.0499682\ttest: 1.0790912\tbest: 1.0790818 (2690)\ttotal: 44.8s\tremaining: 4.96s\n",
            "2800:\tlearn: 1.0487082\ttest: 1.0789863\tbest: 1.0789863 (2800)\ttotal: 46s\tremaining: 3.27s\n",
            "2900:\tlearn: 1.0474607\ttest: 1.0788419\tbest: 1.0788419 (2900)\ttotal: 47.2s\tremaining: 1.61s\n",
            "2999:\tlearn: 1.0462245\ttest: 1.0787354\tbest: 1.0787354 (2999)\ttotal: 48.4s\tremaining: 0us\n",
            "bestTest = 1.078735407\n",
            "bestIteration = 2999\n",
            "0:\tlearn: 1.1046693\ttest: 1.1032981\tbest: 1.1032981 (0)\ttotal: 6.4ms\tremaining: 19.2s\n",
            "100:\tlearn: 1.0952729\ttest: 1.0948783\tbest: 1.0948783 (100)\ttotal: 1.32s\tremaining: 37.9s\n",
            "200:\tlearn: 1.0909207\ttest: 1.0916262\tbest: 1.0916262 (200)\ttotal: 3.77s\tremaining: 52.4s\n",
            "300:\tlearn: 1.0876895\ttest: 1.0895470\tbest: 1.0895470 (300)\ttotal: 5.92s\tremaining: 53.1s\n",
            "400:\tlearn: 1.0850554\ttest: 1.0880001\tbest: 1.0880001 (400)\ttotal: 8.35s\tremaining: 54.1s\n",
            "500:\tlearn: 1.0827696\ttest: 1.0868355\tbest: 1.0868355 (500)\ttotal: 10.7s\tremaining: 53.2s\n",
            "600:\tlearn: 1.0806568\ttest: 1.0859213\tbest: 1.0859213 (600)\ttotal: 12.5s\tremaining: 49.9s\n",
            "700:\tlearn: 1.0786979\ttest: 1.0851148\tbest: 1.0851148 (700)\ttotal: 14.9s\tremaining: 48.9s\n",
            "800:\tlearn: 1.0768434\ttest: 1.0844396\tbest: 1.0844396 (800)\ttotal: 16.6s\tremaining: 45.7s\n",
            "900:\tlearn: 1.0751011\ttest: 1.0838771\tbest: 1.0838771 (900)\ttotal: 17.7s\tremaining: 41.2s\n",
            "1000:\tlearn: 1.0734114\ttest: 1.0833684\tbest: 1.0833684 (1000)\ttotal: 18.8s\tremaining: 37.5s\n",
            "1100:\tlearn: 1.0718222\ttest: 1.0829429\tbest: 1.0829429 (1100)\ttotal: 19.9s\tremaining: 34.2s\n",
            "1200:\tlearn: 1.0702567\ttest: 1.0826086\tbest: 1.0826086 (1200)\ttotal: 21s\tremaining: 31.5s\n",
            "1300:\tlearn: 1.0686840\ttest: 1.0823112\tbest: 1.0823112 (1300)\ttotal: 22.1s\tremaining: 28.9s\n",
            "1400:\tlearn: 1.0671978\ttest: 1.0819663\tbest: 1.0819663 (1400)\ttotal: 23.2s\tremaining: 26.5s\n",
            "1500:\tlearn: 1.0657685\ttest: 1.0816630\tbest: 1.0816629 (1499)\ttotal: 24.4s\tremaining: 24.4s\n",
            "1600:\tlearn: 1.0642780\ttest: 1.0814067\tbest: 1.0814050 (1598)\ttotal: 25.7s\tremaining: 22.5s\n",
            "1700:\tlearn: 1.0628801\ttest: 1.0811574\tbest: 1.0811574 (1700)\ttotal: 27.9s\tremaining: 21.3s\n",
            "1800:\tlearn: 1.0615133\ttest: 1.0809694\tbest: 1.0809694 (1800)\ttotal: 30.2s\tremaining: 20.1s\n",
            "1900:\tlearn: 1.0601648\ttest: 1.0807605\tbest: 1.0807583 (1899)\ttotal: 32.7s\tremaining: 18.9s\n",
            "2000:\tlearn: 1.0587644\ttest: 1.0806205\tbest: 1.0806171 (1999)\ttotal: 35.2s\tremaining: 17.6s\n",
            "2100:\tlearn: 1.0574156\ttest: 1.0804483\tbest: 1.0804480 (2099)\ttotal: 36.9s\tremaining: 15.8s\n",
            "2200:\tlearn: 1.0560762\ttest: 1.0802641\tbest: 1.0802641 (2200)\ttotal: 38s\tremaining: 13.8s\n",
            "2300:\tlearn: 1.0547519\ttest: 1.0801293\tbest: 1.0801254 (2298)\ttotal: 40.2s\tremaining: 12.2s\n",
            "2400:\tlearn: 1.0534229\ttest: 1.0800333\tbest: 1.0800316 (2399)\ttotal: 41.9s\tremaining: 10.5s\n",
            "2500:\tlearn: 1.0520842\ttest: 1.0799071\tbest: 1.0799070 (2494)\ttotal: 43s\tremaining: 8.58s\n",
            "2600:\tlearn: 1.0508228\ttest: 1.0797646\tbest: 1.0797646 (2600)\ttotal: 44.2s\tremaining: 6.78s\n",
            "2700:\tlearn: 1.0495656\ttest: 1.0796465\tbest: 1.0796465 (2700)\ttotal: 45.3s\tremaining: 5.01s\n",
            "2800:\tlearn: 1.0482951\ttest: 1.0795261\tbest: 1.0795258 (2799)\ttotal: 46.5s\tremaining: 3.3s\n",
            "2900:\tlearn: 1.0470255\ttest: 1.0794058\tbest: 1.0794058 (2900)\ttotal: 47.6s\tremaining: 1.62s\n",
            "2999:\tlearn: 1.0457698\ttest: 1.0792825\tbest: 1.0792791 (2998)\ttotal: 50.1s\tremaining: 0us\n",
            "bestTest = 1.079279129\n",
            "bestIteration = 2998\n",
            "Shrink model to first 2999 iterations.\n",
            "0:\tlearn: 1.1045939\ttest: 1.1036272\tbest: 1.1036272 (0)\ttotal: 16.5ms\tremaining: 49.5s\n",
            "100:\tlearn: 1.0952264\ttest: 1.0951645\tbest: 1.0951645 (100)\ttotal: 2.58s\tremaining: 1m 14s\n",
            "200:\tlearn: 1.0907438\ttest: 1.0919422\tbest: 1.0919422 (200)\ttotal: 4.88s\tremaining: 1m 8s\n",
            "300:\tlearn: 1.0875038\ttest: 1.0898594\tbest: 1.0898594 (300)\ttotal: 6.96s\tremaining: 1m 2s\n",
            "400:\tlearn: 1.0848840\ttest: 1.0884204\tbest: 1.0884204 (400)\ttotal: 9.06s\tremaining: 58.7s\n",
            "500:\tlearn: 1.0825648\ttest: 1.0872621\tbest: 1.0872621 (500)\ttotal: 11.5s\tremaining: 57.3s\n",
            "600:\tlearn: 1.0804561\ttest: 1.0862248\tbest: 1.0862248 (600)\ttotal: 14s\tremaining: 56s\n",
            "700:\tlearn: 1.0784642\ttest: 1.0854515\tbest: 1.0854515 (700)\ttotal: 16.1s\tremaining: 52.8s\n",
            "800:\tlearn: 1.0766058\ttest: 1.0848253\tbest: 1.0848253 (800)\ttotal: 18.6s\tremaining: 51s\n",
            "900:\tlearn: 1.0748467\ttest: 1.0842278\tbest: 1.0842278 (900)\ttotal: 20.1s\tremaining: 46.8s\n",
            "1000:\tlearn: 1.0731724\ttest: 1.0837211\tbest: 1.0837211 (1000)\ttotal: 22.6s\tremaining: 45s\n",
            "1100:\tlearn: 1.0715640\ttest: 1.0832451\tbest: 1.0832451 (1100)\ttotal: 25s\tremaining: 43.1s\n",
            "1200:\tlearn: 1.0700144\ttest: 1.0829242\tbest: 1.0829242 (1200)\ttotal: 27.4s\tremaining: 41s\n",
            "1300:\tlearn: 1.0684526\ttest: 1.0825897\tbest: 1.0825885 (1299)\ttotal: 29.8s\tremaining: 38.9s\n",
            "1400:\tlearn: 1.0669769\ttest: 1.0822851\tbest: 1.0822851 (1400)\ttotal: 32.2s\tremaining: 36.8s\n",
            "1500:\tlearn: 1.0655330\ttest: 1.0820148\tbest: 1.0820148 (1500)\ttotal: 34.1s\tremaining: 34s\n",
            "1600:\tlearn: 1.0641151\ttest: 1.0817907\tbest: 1.0817888 (1599)\ttotal: 36.2s\tremaining: 31.6s\n",
            "1700:\tlearn: 1.0626952\ttest: 1.0815271\tbest: 1.0815262 (1699)\ttotal: 38.6s\tremaining: 29.5s\n",
            "1800:\tlearn: 1.0613044\ttest: 1.0813151\tbest: 1.0813140 (1799)\ttotal: 41.1s\tremaining: 27.4s\n",
            "1900:\tlearn: 1.0599200\ttest: 1.0811788\tbest: 1.0811708 (1895)\ttotal: 43.2s\tremaining: 25s\n",
            "2000:\tlearn: 1.0585464\ttest: 1.0809923\tbest: 1.0809923 (2000)\ttotal: 45s\tremaining: 22.5s\n",
            "2100:\tlearn: 1.0571921\ttest: 1.0808418\tbest: 1.0808416 (2099)\ttotal: 47.5s\tremaining: 20.3s\n",
            "2200:\tlearn: 1.0559011\ttest: 1.0806903\tbest: 1.0806903 (2200)\ttotal: 49.9s\tremaining: 18.1s\n",
            "2300:\tlearn: 1.0545456\ttest: 1.0805497\tbest: 1.0805497 (2300)\ttotal: 52.4s\tremaining: 15.9s\n",
            "2400:\tlearn: 1.0532480\ttest: 1.0803966\tbest: 1.0803966 (2400)\ttotal: 54.1s\tremaining: 13.5s\n",
            "2500:\tlearn: 1.0519436\ttest: 1.0802798\tbest: 1.0802798 (2500)\ttotal: 55.3s\tremaining: 11s\n",
            "2600:\tlearn: 1.0506378\ttest: 1.0801431\tbest: 1.0801431 (2600)\ttotal: 56.8s\tremaining: 8.71s\n",
            "2700:\tlearn: 1.0493185\ttest: 1.0800106\tbest: 1.0800086 (2698)\ttotal: 58.6s\tremaining: 6.48s\n",
            "2800:\tlearn: 1.0480501\ttest: 1.0798877\tbest: 1.0798818 (2798)\ttotal: 59.9s\tremaining: 4.26s\n",
            "2900:\tlearn: 1.0467496\ttest: 1.0797381\tbest: 1.0797281 (2895)\ttotal: 1m 1s\tremaining: 2.08s\n",
            "2999:\tlearn: 1.0455093\ttest: 1.0796131\tbest: 1.0796080 (2996)\ttotal: 1m 2s\tremaining: 0us\n",
            "bestTest = 1.079608002\n",
            "bestIteration = 2996\n",
            "Shrink model to first 2997 iterations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK9c34jfsjxX"
      },
      "source": [
        "# LGBM LB: 7.90478"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLbpI3PrY-Lo",
        "outputId": "7145ea91-ea68-4192-ab7d-d9b2014b2032"
      },
      "source": [
        "params = {'objective':'poisson', 'metric': 'rmse', 'device':'gpu'} #'objective': 'mean_squared_error',\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
        "lgb_train = lightgbm.Dataset(X_train, Y_train)\n",
        "lgb_valid = lightgbm.Dataset(X_test, Y_test)\n",
        "model = lgbo.train(params, lgb_train, valid_sets=[lgb_valid], verbose_eval=False, num_boost_round=100, early_stopping_rounds=5) \n",
        "model.params"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:09:19,813]\u001b[0m A new study created in memory with name: no-name-d8e4cf57-8121-4e60-986d-565df11c5f89\u001b[0m\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021824 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535:  14%|#4        | 1/7 [00:07<00:46,  7.79s/it]\u001b[32m[I 2021-08-30 07:09:27,627]\u001b[0m Trial 0 finished with value: 7.87853516693168 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535:  14%|#4        | 1/7 [00:07<00:46,  7.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022657 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535:  29%|##8       | 2/7 [00:15<00:38,  7.70s/it]\u001b[32m[I 2021-08-30 07:09:35,253]\u001b[0m Trial 1 finished with value: 7.878767098869623 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535:  29%|##8       | 2/7 [00:15<00:38,  7.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022921 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535:  43%|####2     | 3/7 [00:23<00:31,  7.78s/it]\u001b[32m[I 2021-08-30 07:09:43,125]\u001b[0m Trial 2 finished with value: 7.878836623917205 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535:  43%|####2     | 3/7 [00:23<00:31,  7.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.027307 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535:  57%|#####7    | 4/7 [00:30<00:22,  7.66s/it]\u001b[32m[I 2021-08-30 07:09:50,607]\u001b[0m Trial 3 finished with value: 7.879584833574512 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535:  57%|#####7    | 4/7 [00:30<00:22,  7.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022743 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535:  71%|#######1  | 5/7 [00:38<00:15,  7.64s/it]\u001b[32m[I 2021-08-30 07:09:58,208]\u001b[0m Trial 4 finished with value: 7.879205299650378 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535:  71%|#######1  | 5/7 [00:38<00:15,  7.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022742 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535:  86%|########5 | 6/7 [00:45<00:07,  7.53s/it]\u001b[32m[I 2021-08-30 07:10:05,534]\u001b[0m Trial 5 finished with value: 7.880467512927149 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535:  86%|########5 | 6/7 [00:45<00:07,  7.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024170 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 7.878535: 100%|##########| 7/7 [00:53<00:00,  7.73s/it]\u001b[32m[I 2021-08-30 07:10:13,663]\u001b[0m Trial 6 finished with value: 7.8786790713956165 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 7.87853516693168.\u001b[0m\n",
            "feature_fraction, val_score: 7.878535: 100%|##########| 7/7 [00:53<00:00,  7.69s/it]\n",
            "num_leaves, val_score: 7.878535:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023230 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:   5%|5         | 1/20 [00:10<03:13, 10.21s/it]\u001b[32m[I 2021-08-30 07:10:23,894]\u001b[0m Trial 7 finished with value: 7.87488969547243 and parameters: {'num_leaves': 67}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:   5%|5         | 1/20 [00:10<03:13, 10.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023926 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  10%|#         | 2/20 [00:18<02:47,  9.28s/it]\u001b[32m[I 2021-08-30 07:10:32,520]\u001b[0m Trial 8 finished with value: 7.877064663736373 and parameters: {'num_leaves': 38}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  10%|#         | 2/20 [00:18<02:47,  9.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024329 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  15%|#5        | 3/20 [00:30<02:57, 10.44s/it]\u001b[32m[I 2021-08-30 07:10:44,351]\u001b[0m Trial 9 finished with value: 7.875750767789008 and parameters: {'num_leaves': 103}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  15%|#5        | 3/20 [00:30<02:57, 10.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024425 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  20%|##        | 4/20 [00:45<03:16, 12.26s/it]\u001b[32m[I 2021-08-30 07:10:59,393]\u001b[0m Trial 10 finished with value: 7.876197826113815 and parameters: {'num_leaves': 175}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  20%|##        | 4/20 [00:45<03:16, 12.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024377 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  25%|##5       | 5/20 [01:02<03:29, 13.94s/it]\u001b[32m[I 2021-08-30 07:11:16,299]\u001b[0m Trial 11 finished with value: 7.878857937969654 and parameters: {'num_leaves': 224}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  25%|##5       | 5/20 [01:02<03:29, 13.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023753 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  30%|###       | 6/20 [01:16<03:16, 14.05s/it]\u001b[32m[I 2021-08-30 07:11:30,576]\u001b[0m Trial 12 finished with value: 7.876673710417436 and parameters: {'num_leaves': 165}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  30%|###       | 6/20 [01:16<03:16, 14.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022462 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  35%|###5      | 7/20 [01:29<02:57, 13.63s/it]\u001b[32m[I 2021-08-30 07:11:43,331]\u001b[0m Trial 13 finished with value: 7.875659658596096 and parameters: {'num_leaves': 123}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  35%|###5      | 7/20 [01:29<02:57, 13.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023340 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874890:  40%|####      | 8/20 [01:35<02:14, 11.19s/it]\u001b[32m[I 2021-08-30 07:11:49,311]\u001b[0m Trial 14 finished with value: 7.924021487685716 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 7.87488969547243.\u001b[0m\n",
            "num_leaves, val_score: 7.874890:  40%|####      | 8/20 [01:35<02:14, 11.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.025250 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.874494:  45%|####5     | 9/20 [01:48<02:08, 11.73s/it]\u001b[32m[I 2021-08-30 07:12:02,211]\u001b[0m Trial 15 finished with value: 7.87449439792581 and parameters: {'num_leaves': 124}. Best is trial 15 with value: 7.87449439792581.\u001b[0m\n",
            "num_leaves, val_score: 7.874494:  45%|####5     | 9/20 [01:48<02:08, 11.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022750 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  50%|#####     | 10/20 [01:59<01:54, 11.44s/it]\u001b[32m[I 2021-08-30 07:12:13,024]\u001b[0m Trial 16 finished with value: 7.872876739348606 and parameters: {'num_leaves': 84}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  50%|#####     | 10/20 [01:59<01:54, 11.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023556 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  55%|#####5    | 11/20 [02:17<02:02, 13.62s/it]\u001b[32m[I 2021-08-30 07:12:31,583]\u001b[0m Trial 17 finished with value: 7.880870169231547 and parameters: {'num_leaves': 254}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  55%|#####5    | 11/20 [02:17<02:02, 13.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024124 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  60%|######    | 12/20 [02:28<01:42, 12.76s/it]\u001b[32m[I 2021-08-30 07:12:42,356]\u001b[0m Trial 18 finished with value: 7.8731646245669396 and parameters: {'num_leaves': 79}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  60%|######    | 12/20 [02:28<01:42, 12.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023106 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  65%|######5   | 13/20 [02:39<01:24, 12.05s/it]\u001b[32m[I 2021-08-30 07:12:52,788]\u001b[0m Trial 19 finished with value: 7.874549146428764 and parameters: {'num_leaves': 71}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  65%|######5   | 13/20 [02:39<01:24, 12.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023986 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  70%|#######   | 14/20 [02:49<01:09, 11.57s/it]\u001b[32m[I 2021-08-30 07:13:03,233]\u001b[0m Trial 20 finished with value: 7.875104152997295 and parameters: {'num_leaves': 75}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  70%|#######   | 14/20 [02:49<01:09, 11.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021226 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  75%|#######5  | 15/20 [02:57<00:52, 10.52s/it]\u001b[32m[I 2021-08-30 07:13:11,322]\u001b[0m Trial 21 finished with value: 7.877443030568458 and parameters: {'num_leaves': 33}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  75%|#######5  | 15/20 [02:57<00:52, 10.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023486 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  80%|########  | 16/20 [03:12<00:46, 11.69s/it]\u001b[32m[I 2021-08-30 07:13:25,745]\u001b[0m Trial 22 finished with value: 7.880413092571202 and parameters: {'num_leaves': 166}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  80%|########  | 16/20 [03:12<00:46, 11.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.028651 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  85%|########5 | 17/20 [03:23<00:35, 11.69s/it]\u001b[32m[I 2021-08-30 07:13:37,441]\u001b[0m Trial 23 finished with value: 7.875451508973036 and parameters: {'num_leaves': 97}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  85%|########5 | 17/20 [03:23<00:35, 11.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022981 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  90%|######### | 18/20 [03:33<00:21, 10.99s/it]\u001b[32m[I 2021-08-30 07:13:46,780]\u001b[0m Trial 24 finished with value: 7.876755623629727 and parameters: {'num_leaves': 49}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  90%|######### | 18/20 [03:33<00:21, 10.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023408 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877:  95%|#########5| 19/20 [03:40<00:09,  9.97s/it]\u001b[32m[I 2021-08-30 07:13:54,380]\u001b[0m Trial 25 finished with value: 7.881418747873098 and parameters: {'num_leaves': 19}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877:  95%|#########5| 19/20 [03:40<00:09,  9.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023846 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 7.872877: 100%|##########| 20/20 [03:52<00:00, 10.42s/it]\u001b[32m[I 2021-08-30 07:14:05,848]\u001b[0m Trial 26 finished with value: 7.876080516938785 and parameters: {'num_leaves': 93}. Best is trial 16 with value: 7.872876739348606.\u001b[0m\n",
            "num_leaves, val_score: 7.872877: 100%|##########| 20/20 [03:52<00:00, 11.61s/it]\n",
            "bagging, val_score: 7.872877:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023866 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  10%|#         | 1/10 [00:11<01:40, 11.17s/it]\u001b[32m[I 2021-08-30 07:14:17,052]\u001b[0m Trial 27 finished with value: 7.874392953556041 and parameters: {'bagging_fraction': 0.9759801803851128, 'bagging_freq': 2}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  10%|#         | 1/10 [00:11<01:40, 11.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022546 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  20%|##        | 2/10 [00:22<01:27, 10.99s/it]\u001b[32m[I 2021-08-30 07:14:27,905]\u001b[0m Trial 28 finished with value: 7.8820459028846335 and parameters: {'bagging_fraction': 0.4872426711375109, 'bagging_freq': 4}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  20%|##        | 2/10 [00:22<01:27, 10.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023865 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  30%|###       | 3/10 [00:33<01:16, 10.99s/it]\u001b[32m[I 2021-08-30 07:14:38,895]\u001b[0m Trial 29 finished with value: 7.874417126241428 and parameters: {'bagging_fraction': 0.9753720906947116, 'bagging_freq': 1}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  30%|###       | 3/10 [00:33<01:16, 10.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023853 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  40%|####      | 4/10 [00:43<01:05, 10.97s/it]\u001b[32m[I 2021-08-30 07:14:49,849]\u001b[0m Trial 30 finished with value: 7.8750784871835195 and parameters: {'bagging_fraction': 0.9052916847753665, 'bagging_freq': 2}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  40%|####      | 4/10 [00:43<01:05, 10.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.029370 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  50%|#####     | 5/10 [00:54<00:54, 10.92s/it]\u001b[32m[I 2021-08-30 07:15:00,674]\u001b[0m Trial 31 finished with value: 7.882925519645139 and parameters: {'bagging_fraction': 0.4465209438483266, 'bagging_freq': 1}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  50%|#####     | 5/10 [00:54<00:54, 10.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023742 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  60%|######    | 6/10 [01:05<00:43, 10.94s/it]\u001b[32m[I 2021-08-30 07:15:11,663]\u001b[0m Trial 32 finished with value: 7.880365216850319 and parameters: {'bagging_fraction': 0.5897071276330124, 'bagging_freq': 3}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  60%|######    | 6/10 [01:05<00:43, 10.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021467 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  70%|#######   | 7/10 [01:16<00:32, 10.76s/it]\u001b[32m[I 2021-08-30 07:15:22,033]\u001b[0m Trial 33 finished with value: 7.880659244447222 and parameters: {'bagging_fraction': 0.5494282537670009, 'bagging_freq': 2}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  70%|#######   | 7/10 [01:16<00:32, 10.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022372 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  80%|########  | 8/10 [01:27<00:21, 10.79s/it]\u001b[32m[I 2021-08-30 07:15:32,903]\u001b[0m Trial 34 finished with value: 7.884434250942655 and parameters: {'bagging_fraction': 0.4726377520130172, 'bagging_freq': 4}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  80%|########  | 8/10 [01:27<00:21, 10.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023666 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877:  90%|######### | 9/10 [01:38<00:10, 10.86s/it]\u001b[32m[I 2021-08-30 07:15:43,928]\u001b[0m Trial 35 finished with value: 7.875346337327372 and parameters: {'bagging_fraction': 0.7138655440150281, 'bagging_freq': 3}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877:  90%|######### | 9/10 [01:38<00:10, 10.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024121 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 7.872877: 100%|##########| 10/10 [01:48<00:00, 10.85s/it]\u001b[32m[I 2021-08-30 07:15:54,736]\u001b[0m Trial 36 finished with value: 7.884378243338531 and parameters: {'bagging_fraction': 0.4468366857977264, 'bagging_freq': 3}. Best is trial 27 with value: 7.874392953556041.\u001b[0m\n",
            "bagging, val_score: 7.872877: 100%|##########| 10/10 [01:48<00:00, 10.89s/it]\n",
            "feature_fraction_stage2, val_score: 7.872877:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021988 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 7.872877:  33%|###3      | 1/3 [00:10<00:21, 10.61s/it]\u001b[32m[I 2021-08-30 07:16:05,372]\u001b[0m Trial 37 finished with value: 7.875895274726896 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 7.875895274726896.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 7.872877:  33%|###3      | 1/3 [00:10<00:21, 10.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024410 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 7.872877:  67%|######6   | 2/3 [00:21<00:10, 10.79s/it]\u001b[32m[I 2021-08-30 07:16:16,282]\u001b[0m Trial 38 finished with value: 7.874308993484097 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 38 with value: 7.874308993484097.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 7.872877:  67%|######6   | 2/3 [00:21<00:10, 10.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021977 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 7.872877: 100%|##########| 3/3 [00:32<00:00, 10.65s/it]\u001b[32m[I 2021-08-30 07:16:26,767]\u001b[0m Trial 39 finished with value: 7.876361886779303 and parameters: {'feature_fraction': 0.92}. Best is trial 38 with value: 7.874308993484097.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 7.872877: 100%|##########| 3/3 [00:32<00:00, 10.67s/it]\n",
            "regularization_factors, val_score: 7.872877:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022728 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872874:   5%|5         | 1/20 [00:11<03:46, 11.91s/it]\u001b[32m[I 2021-08-30 07:16:38,705]\u001b[0m Trial 40 finished with value: 7.8728739693253305 and parameters: {'lambda_l1': 2.101335265162669e-06, 'lambda_l2': 0.0026747664863179064}. Best is trial 40 with value: 7.8728739693253305.\u001b[0m\n",
            "regularization_factors, val_score: 7.872874:   5%|5         | 1/20 [00:11<03:46, 11.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022739 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872874:  10%|#         | 2/20 [00:24<03:36, 12.02s/it]\u001b[32m[I 2021-08-30 07:16:50,797]\u001b[0m Trial 41 finished with value: 7.875414111833475 and parameters: {'lambda_l1': 5.525470930987033e-05, 'lambda_l2': 1.9054140746240704}. Best is trial 40 with value: 7.8728739693253305.\u001b[0m\n",
            "regularization_factors, val_score: 7.872874:  10%|#         | 2/20 [00:24<03:36, 12.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022228 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  15%|#5        | 3/20 [00:35<03:23, 12.00s/it]\u001b[32m[I 2021-08-30 07:17:02,781]\u001b[0m Trial 42 finished with value: 7.872859008111081 and parameters: {'lambda_l1': 0.0011783096876516164, 'lambda_l2': 1.8847177685137956e-05}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  15%|#5        | 3/20 [00:35<03:23, 12.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023287 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  20%|##        | 4/20 [00:48<03:12, 12.04s/it]\u001b[32m[I 2021-08-30 07:17:14,873]\u001b[0m Trial 43 finished with value: 7.872867781539736 and parameters: {'lambda_l1': 7.711564346964976e-06, 'lambda_l2': 0.005526498496338368}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  20%|##        | 4/20 [00:48<03:12, 12.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023883 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  25%|##5       | 5/20 [01:00<03:02, 12.14s/it]\u001b[32m[I 2021-08-30 07:17:27,197]\u001b[0m Trial 44 finished with value: 7.872888830220381 and parameters: {'lambda_l1': 0.7616737058349371, 'lambda_l2': 0.0007713362900750304}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  25%|##5       | 5/20 [01:00<03:02, 12.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022459 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  30%|###       | 6/20 [01:12<02:49, 12.08s/it]\u001b[32m[I 2021-08-30 07:17:39,158]\u001b[0m Trial 45 finished with value: 7.872880500210388 and parameters: {'lambda_l1': 4.704717112083642e-06, 'lambda_l2': 4.2714631613135786e-07}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  30%|###       | 6/20 [01:12<02:49, 12.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024124 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  35%|###5      | 7/20 [01:24<02:37, 12.11s/it]\u001b[32m[I 2021-08-30 07:17:51,333]\u001b[0m Trial 46 finished with value: 7.874518785606408 and parameters: {'lambda_l1': 0.004503067864788707, 'lambda_l2': 1.4252194000522284e-07}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  35%|###5      | 7/20 [01:24<02:37, 12.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023576 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  40%|####      | 8/20 [01:36<02:24, 12.08s/it]\u001b[32m[I 2021-08-30 07:18:03,331]\u001b[0m Trial 47 finished with value: 7.873793262507416 and parameters: {'lambda_l1': 3.673484355873453e-08, 'lambda_l2': 0.4000786664243761}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  40%|####      | 8/20 [01:36<02:24, 12.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.028046 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  45%|####5     | 9/20 [01:48<02:13, 12.11s/it]\u001b[32m[I 2021-08-30 07:18:15,507]\u001b[0m Trial 48 finished with value: 7.873817225301568 and parameters: {'lambda_l1': 0.3659148845771167, 'lambda_l2': 1.0747193781572308e-07}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  45%|####5     | 9/20 [01:48<02:13, 12.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023655 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  50%|#####     | 10/20 [02:00<02:01, 12.11s/it]\u001b[32m[I 2021-08-30 07:18:27,629]\u001b[0m Trial 49 finished with value: 7.873985920972084 and parameters: {'lambda_l1': 1.026149263027506e-05, 'lambda_l2': 0.6872599643287822}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  50%|#####     | 10/20 [02:00<02:01, 12.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.033865 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  55%|#####5    | 11/20 [02:12<01:48, 12.08s/it]\u001b[32m[I 2021-08-30 07:18:39,655]\u001b[0m Trial 50 finished with value: 7.8745151880000135 and parameters: {'lambda_l1': 0.008988735085611573, 'lambda_l2': 1.0828378762473639e-05}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  55%|#####5    | 11/20 [02:12<01:48, 12.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023423 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  60%|######    | 12/20 [02:24<01:36, 12.07s/it]\u001b[32m[I 2021-08-30 07:18:51,682]\u001b[0m Trial 51 finished with value: 7.874529701273957 and parameters: {'lambda_l1': 0.001202505549103544, 'lambda_l2': 0.008770505770849072}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  60%|######    | 12/20 [02:24<01:36, 12.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023628 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  65%|######5   | 13/20 [02:37<01:24, 12.10s/it]\u001b[32m[I 2021-08-30 07:19:03,854]\u001b[0m Trial 52 finished with value: 7.8728767435265015 and parameters: {'lambda_l1': 9.014588912538843e-08, 'lambda_l2': 8.981881828227946e-06}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  65%|######5   | 13/20 [02:37<01:24, 12.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023267 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  70%|#######   | 14/20 [02:49<01:12, 12.10s/it]\u001b[32m[I 2021-08-30 07:19:15,954]\u001b[0m Trial 53 finished with value: 7.872881038362327 and parameters: {'lambda_l1': 0.00018818426993810023, 'lambda_l2': 1.885424972400101e-05}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  70%|#######   | 14/20 [02:49<01:12, 12.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024451 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.872859:  75%|#######5  | 15/20 [03:01<01:00, 12.08s/it]\u001b[32m[I 2021-08-30 07:19:27,997]\u001b[0m Trial 54 finished with value: 7.874518305174736 and parameters: {'lambda_l1': 7.124419939933934e-07, 'lambda_l2': 0.023798701632138927}. Best is trial 42 with value: 7.872859008111081.\u001b[0m\n",
            "regularization_factors, val_score: 7.872859:  75%|#######5  | 15/20 [03:01<01:00, 12.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024373 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.871942:  80%|########  | 16/20 [03:13<00:48, 12.13s/it]\u001b[32m[I 2021-08-30 07:19:40,223]\u001b[0m Trial 55 finished with value: 7.871942109726842 and parameters: {'lambda_l1': 0.060424084726140616, 'lambda_l2': 0.0001258070491589518}. Best is trial 55 with value: 7.871942109726842.\u001b[0m\n",
            "regularization_factors, val_score: 7.871942:  80%|########  | 16/20 [03:13<00:48, 12.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022744 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.871942:  85%|########5 | 17/20 [03:25<00:36, 12.12s/it]\u001b[32m[I 2021-08-30 07:19:52,318]\u001b[0m Trial 56 finished with value: 7.876532011399399 and parameters: {'lambda_l1': 0.03922314728352458, 'lambda_l2': 5.418363487199309e-05}. Best is trial 55 with value: 7.871942109726842.\u001b[0m\n",
            "regularization_factors, val_score: 7.871942:  85%|########5 | 17/20 [03:25<00:36, 12.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022447 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.871942:  90%|######### | 18/20 [03:38<00:24, 12.23s/it]\u001b[32m[I 2021-08-30 07:20:04,798]\u001b[0m Trial 57 finished with value: 7.87308772916945 and parameters: {'lambda_l1': 7.111190772340779, 'lambda_l2': 1.6014025391481857e-06}. Best is trial 55 with value: 7.871942109726842.\u001b[0m\n",
            "regularization_factors, val_score: 7.871942:  90%|######### | 18/20 [03:38<00:24, 12.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023333 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.871710:  95%|#########5| 19/20 [03:50<00:12, 12.18s/it]\u001b[32m[I 2021-08-30 07:20:16,857]\u001b[0m Trial 58 finished with value: 7.871709951737301 and parameters: {'lambda_l1': 0.06439204656539935, 'lambda_l2': 0.00018079588095795137}. Best is trial 58 with value: 7.871709951737301.\u001b[0m\n",
            "regularization_factors, val_score: 7.871710:  95%|#########5| 19/20 [03:50<00:12, 12.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022002 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 7.871710: 100%|##########| 20/20 [04:01<00:00, 12.09s/it]\u001b[32m[I 2021-08-30 07:20:28,737]\u001b[0m Trial 59 finished with value: 7.8732549483260605 and parameters: {'lambda_l1': 0.2275567660782366, 'lambda_l2': 0.0001419561827285696}. Best is trial 58 with value: 7.871709951737301.\u001b[0m\n",
            "regularization_factors, val_score: 7.871710: 100%|##########| 20/20 [04:01<00:00, 12.10s/it]\n",
            "min_data_in_leaf, val_score: 7.871710:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.023811 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 7.871710:  20%|##        | 1/5 [00:12<00:49, 12.32s/it]\u001b[32m[I 2021-08-30 07:20:41,083]\u001b[0m Trial 60 finished with value: 7.876733931928839 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 7.876733931928839.\u001b[0m\n",
            "min_data_in_leaf, val_score: 7.871710:  20%|##        | 1/5 [00:12<00:49, 12.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.024265 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 7.870852:  40%|####      | 2/5 [00:24<00:36, 12.09s/it]\u001b[32m[I 2021-08-30 07:20:53,006]\u001b[0m Trial 61 finished with value: 7.870852254995209 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 7.870852254995209.\u001b[0m\n",
            "min_data_in_leaf, val_score: 7.870852:  40%|####      | 2/5 [00:24<00:36, 12.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021457 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 7.870852:  60%|######    | 3/5 [00:36<00:24, 12.04s/it]\u001b[32m[I 2021-08-30 07:21:05,002]\u001b[0m Trial 62 finished with value: 7.875462188256313 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 7.870852254995209.\u001b[0m\n",
            "min_data_in_leaf, val_score: 7.870852:  60%|######    | 3/5 [00:36<00:24, 12.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.022486 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 7.870852:  80%|########  | 4/5 [00:48<00:12, 12.07s/it]\u001b[32m[I 2021-08-30 07:21:17,098]\u001b[0m Trial 63 finished with value: 7.875349843679355 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 7.870852254995209.\u001b[0m\n",
            "min_data_in_leaf, val_score: 7.870852:  80%|########  | 4/5 [00:48<00:12, 12.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 25500\n",
            "[LightGBM] [Info] Number of data points in the train set: 175000, number of used features: 100\n",
            "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 100 dense feature groups (16.69 MB) transferred to GPU in 0.021921 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score 1.920970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 7.870852: 100%|##########| 5/5 [01:00<00:00, 12.03s/it]\u001b[32m[I 2021-08-30 07:21:29,082]\u001b[0m Trial 64 finished with value: 7.872094827131643 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 7.870852254995209.\u001b[0m\n",
            "min_data_in_leaf, val_score: 7.870852: 100%|##########| 5/5 [01:00<00:00, 12.07s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 1.0,\n",
              " 'bagging_freq': 0,\n",
              " 'device': 'gpu',\n",
              " 'early_stopping_round': 5,\n",
              " 'feature_fraction': 1.0,\n",
              " 'feature_pre_filter': False,\n",
              " 'lambda_l1': 0.06439204656539935,\n",
              " 'lambda_l2': 0.00018079588095795137,\n",
              " 'metric': 'rmse',\n",
              " 'min_child_samples': 100,\n",
              " 'num_iterations': 100,\n",
              " 'num_leaves': 84,\n",
              " 'objective': 'poisson'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdm9c8VWJ8wd"
      },
      "source": [
        "del best_lgb_params['early_stopping_round']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGAUKm04h5ux",
        "outputId": "c2cfd6a8-c29a-4d8d-bea3-2f2aec83e84d"
      },
      "source": [
        "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "preds = np.zeros((x_test.shape[0],))\n",
        "best_lgb_params = model.params\n",
        "best_lgb_params[\"learning_rate\"] = 0.006\n",
        "best_lgb_params[\"num_iterations\"] = 10000\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(kf.split(x_train, y_train)):\n",
        "  X_train, X_valid = x_train.iloc[train_index], x_train.iloc[valid_index]\n",
        "  Y_train, Y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
        "\n",
        "  model_lgb = lightgbm.LGBMRegressor(**best_lgb_params)\n",
        "  model_lgb.fit(X_train, Y_train, eval_set=[(X_train, Y_train), (X_valid, Y_valid)], verbose=100, early_stopping_rounds=70)\n",
        "\n",
        "  preds += model_lgb.predict(x_test) / kf.n_splits\n",
        "  val_preds = model_lgb.predict(X_valid)\n",
        "  RMSE = np.sqrt(mean_squared_error(val_preds, Y_valid))\n",
        "  print(f'{i+1}번째 RMSE:{RMSE}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00018079588095795137, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018079588095795137\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06439204656539935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06439204656539935\n",
            "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[100]\ttraining's rmse: 7.91777\tvalid_1's rmse: 7.90504\n",
            "[200]\ttraining's rmse: 7.89409\tvalid_1's rmse: 7.89531\n",
            "[300]\ttraining's rmse: 7.8717\tvalid_1's rmse: 7.88732\n",
            "[400]\ttraining's rmse: 7.85089\tvalid_1's rmse: 7.88064\n",
            "[500]\ttraining's rmse: 7.83098\tvalid_1's rmse: 7.87468\n",
            "[600]\ttraining's rmse: 7.81161\tvalid_1's rmse: 7.86959\n",
            "[700]\ttraining's rmse: 7.7928\tvalid_1's rmse: 7.86498\n",
            "[800]\ttraining's rmse: 7.77451\tvalid_1's rmse: 7.86111\n",
            "[900]\ttraining's rmse: 7.75656\tvalid_1's rmse: 7.85779\n",
            "[1000]\ttraining's rmse: 7.73898\tvalid_1's rmse: 7.85468\n",
            "[1100]\ttraining's rmse: 7.72182\tvalid_1's rmse: 7.85174\n",
            "[1200]\ttraining's rmse: 7.7051\tvalid_1's rmse: 7.84928\n",
            "[1300]\ttraining's rmse: 7.68856\tvalid_1's rmse: 7.84684\n",
            "[1400]\ttraining's rmse: 7.67219\tvalid_1's rmse: 7.8445\n",
            "[1500]\ttraining's rmse: 7.6561\tvalid_1's rmse: 7.84247\n",
            "[1600]\ttraining's rmse: 7.64031\tvalid_1's rmse: 7.84068\n",
            "[1700]\ttraining's rmse: 7.62456\tvalid_1's rmse: 7.83902\n",
            "[1800]\ttraining's rmse: 7.60903\tvalid_1's rmse: 7.83749\n",
            "[1900]\ttraining's rmse: 7.59363\tvalid_1's rmse: 7.83587\n",
            "[2000]\ttraining's rmse: 7.57871\tvalid_1's rmse: 7.83441\n",
            "[2100]\ttraining's rmse: 7.56393\tvalid_1's rmse: 7.83327\n",
            "[2200]\ttraining's rmse: 7.54941\tvalid_1's rmse: 7.83242\n",
            "[2300]\ttraining's rmse: 7.53503\tvalid_1's rmse: 7.83156\n",
            "[2400]\ttraining's rmse: 7.52103\tvalid_1's rmse: 7.83082\n",
            "Early stopping, best iteration is:\n",
            "[2431]\ttraining's rmse: 7.51676\tvalid_1's rmse: 7.8306\n",
            "1번째 RMSE:7.830596523518704\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00018079588095795137, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018079588095795137\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06439204656539935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06439204656539935\n",
            "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[100]\ttraining's rmse: 7.90529\tvalid_1's rmse: 7.95149\n",
            "[200]\ttraining's rmse: 7.8814\tvalid_1's rmse: 7.94242\n",
            "[300]\ttraining's rmse: 7.85924\tvalid_1's rmse: 7.93527\n",
            "[400]\ttraining's rmse: 7.83818\tvalid_1's rmse: 7.92926\n",
            "[500]\ttraining's rmse: 7.81807\tvalid_1's rmse: 7.92436\n",
            "[600]\ttraining's rmse: 7.79871\tvalid_1's rmse: 7.91976\n",
            "[700]\ttraining's rmse: 7.77986\tvalid_1's rmse: 7.9157\n",
            "[800]\ttraining's rmse: 7.76132\tvalid_1's rmse: 7.91198\n",
            "[900]\ttraining's rmse: 7.74344\tvalid_1's rmse: 7.90906\n",
            "[1000]\ttraining's rmse: 7.72582\tvalid_1's rmse: 7.90625\n",
            "[1100]\ttraining's rmse: 7.70847\tvalid_1's rmse: 7.90359\n",
            "[1200]\ttraining's rmse: 7.6915\tvalid_1's rmse: 7.90142\n",
            "[1300]\ttraining's rmse: 7.67485\tvalid_1's rmse: 7.89939\n",
            "[1400]\ttraining's rmse: 7.65849\tvalid_1's rmse: 7.89755\n",
            "[1500]\ttraining's rmse: 7.64233\tvalid_1's rmse: 7.8958\n",
            "[1600]\ttraining's rmse: 7.6264\tvalid_1's rmse: 7.89445\n",
            "[1700]\ttraining's rmse: 7.61058\tvalid_1's rmse: 7.8929\n",
            "[1800]\ttraining's rmse: 7.59494\tvalid_1's rmse: 7.89152\n",
            "[1900]\ttraining's rmse: 7.57946\tvalid_1's rmse: 7.89029\n",
            "[2000]\ttraining's rmse: 7.56428\tvalid_1's rmse: 7.88923\n",
            "[2100]\ttraining's rmse: 7.54913\tvalid_1's rmse: 7.88824\n",
            "[2200]\ttraining's rmse: 7.53429\tvalid_1's rmse: 7.88737\n",
            "[2300]\ttraining's rmse: 7.51979\tvalid_1's rmse: 7.88672\n",
            "Early stopping, best iteration is:\n",
            "[2328]\ttraining's rmse: 7.51574\tvalid_1's rmse: 7.88651\n",
            "2번째 RMSE:7.886508294669092\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00018079588095795137, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018079588095795137\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06439204656539935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06439204656539935\n",
            "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[100]\ttraining's rmse: 7.90871\tvalid_1's rmse: 7.94122\n",
            "[200]\ttraining's rmse: 7.88484\tvalid_1's rmse: 7.93118\n",
            "[300]\ttraining's rmse: 7.86275\tvalid_1's rmse: 7.92317\n",
            "[400]\ttraining's rmse: 7.84247\tvalid_1's rmse: 7.91691\n",
            "[500]\ttraining's rmse: 7.82267\tvalid_1's rmse: 7.91138\n",
            "[600]\ttraining's rmse: 7.80385\tvalid_1's rmse: 7.90666\n",
            "[700]\ttraining's rmse: 7.78546\tvalid_1's rmse: 7.90238\n",
            "[800]\ttraining's rmse: 7.76746\tvalid_1's rmse: 7.89854\n",
            "[900]\ttraining's rmse: 7.74979\tvalid_1's rmse: 7.89471\n",
            "[1000]\ttraining's rmse: 7.73251\tvalid_1's rmse: 7.89111\n",
            "[1100]\ttraining's rmse: 7.71563\tvalid_1's rmse: 7.88815\n",
            "[1200]\ttraining's rmse: 7.69891\tvalid_1's rmse: 7.88532\n",
            "[1300]\ttraining's rmse: 7.68244\tvalid_1's rmse: 7.88276\n",
            "[1400]\ttraining's rmse: 7.66628\tvalid_1's rmse: 7.88023\n",
            "[1500]\ttraining's rmse: 7.65026\tvalid_1's rmse: 7.87774\n",
            "[1600]\ttraining's rmse: 7.6345\tvalid_1's rmse: 7.87532\n",
            "[1700]\ttraining's rmse: 7.61878\tvalid_1's rmse: 7.87324\n",
            "[1800]\ttraining's rmse: 7.6033\tvalid_1's rmse: 7.87149\n",
            "[1900]\ttraining's rmse: 7.58795\tvalid_1's rmse: 7.87003\n",
            "[2000]\ttraining's rmse: 7.57291\tvalid_1's rmse: 7.86878\n",
            "[2100]\ttraining's rmse: 7.55813\tvalid_1's rmse: 7.86768\n",
            "[2200]\ttraining's rmse: 7.54352\tvalid_1's rmse: 7.86672\n",
            "[2300]\ttraining's rmse: 7.52908\tvalid_1's rmse: 7.86563\n",
            "[2400]\ttraining's rmse: 7.51489\tvalid_1's rmse: 7.86464\n",
            "[2500]\ttraining's rmse: 7.50079\tvalid_1's rmse: 7.86382\n",
            "Early stopping, best iteration is:\n",
            "[2568]\ttraining's rmse: 7.49144\tvalid_1's rmse: 7.86336\n",
            "3번째 RMSE:7.863361170829678\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00018079588095795137, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018079588095795137\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06439204656539935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06439204656539935\n",
            "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[100]\ttraining's rmse: 7.91445\tvalid_1's rmse: 7.91689\n",
            "[200]\ttraining's rmse: 7.8903\tvalid_1's rmse: 7.9067\n",
            "[300]\ttraining's rmse: 7.86818\tvalid_1's rmse: 7.89876\n",
            "[400]\ttraining's rmse: 7.84718\tvalid_1's rmse: 7.89231\n",
            "[500]\ttraining's rmse: 7.82711\tvalid_1's rmse: 7.88709\n",
            "[600]\ttraining's rmse: 7.80775\tvalid_1's rmse: 7.8825\n",
            "[700]\ttraining's rmse: 7.78893\tvalid_1's rmse: 7.87818\n",
            "[800]\ttraining's rmse: 7.77066\tvalid_1's rmse: 7.87454\n",
            "[900]\ttraining's rmse: 7.75281\tvalid_1's rmse: 7.87121\n",
            "[1000]\ttraining's rmse: 7.73533\tvalid_1's rmse: 7.86828\n",
            "[1100]\ttraining's rmse: 7.71799\tvalid_1's rmse: 7.86544\n",
            "[1200]\ttraining's rmse: 7.70099\tvalid_1's rmse: 7.86284\n",
            "[1300]\ttraining's rmse: 7.68428\tvalid_1's rmse: 7.86051\n",
            "[1400]\ttraining's rmse: 7.66798\tvalid_1's rmse: 7.85861\n",
            "[1500]\ttraining's rmse: 7.65182\tvalid_1's rmse: 7.85692\n",
            "[1600]\ttraining's rmse: 7.63577\tvalid_1's rmse: 7.85523\n",
            "[1700]\ttraining's rmse: 7.61987\tvalid_1's rmse: 7.85379\n",
            "[1800]\ttraining's rmse: 7.60418\tvalid_1's rmse: 7.85218\n",
            "[1900]\ttraining's rmse: 7.58868\tvalid_1's rmse: 7.85071\n",
            "[2000]\ttraining's rmse: 7.57347\tvalid_1's rmse: 7.84961\n",
            "[2100]\ttraining's rmse: 7.55858\tvalid_1's rmse: 7.84864\n",
            "Early stopping, best iteration is:\n",
            "[2106]\ttraining's rmse: 7.55768\tvalid_1's rmse: 7.84858\n",
            "4번째 RMSE:7.8485760318890545\n",
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00018079588095795137, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018079588095795137\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06439204656539935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06439204656539935\n",
            "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
            "Training until validation scores don't improve for 5 rounds\n",
            "[100]\ttraining's rmse: 7.91459\tvalid_1's rmse: 7.91512\n",
            "[200]\ttraining's rmse: 7.88988\tvalid_1's rmse: 7.90494\n",
            "[300]\ttraining's rmse: 7.86762\tvalid_1's rmse: 7.8973\n",
            "[400]\ttraining's rmse: 7.84673\tvalid_1's rmse: 7.89119\n",
            "[500]\ttraining's rmse: 7.82674\tvalid_1's rmse: 7.88595\n",
            "[600]\ttraining's rmse: 7.80727\tvalid_1's rmse: 7.8816\n",
            "[700]\ttraining's rmse: 7.78819\tvalid_1's rmse: 7.87764\n",
            "[800]\ttraining's rmse: 7.76972\tvalid_1's rmse: 7.87414\n",
            "[900]\ttraining's rmse: 7.7518\tvalid_1's rmse: 7.87111\n",
            "[1000]\ttraining's rmse: 7.73438\tvalid_1's rmse: 7.86809\n",
            "[1100]\ttraining's rmse: 7.71728\tvalid_1's rmse: 7.86567\n",
            "[1200]\ttraining's rmse: 7.70044\tvalid_1's rmse: 7.86345\n",
            "[1300]\ttraining's rmse: 7.68389\tvalid_1's rmse: 7.86108\n",
            "[1400]\ttraining's rmse: 7.66757\tvalid_1's rmse: 7.85903\n",
            "[1500]\ttraining's rmse: 7.65141\tvalid_1's rmse: 7.85723\n",
            "[1600]\ttraining's rmse: 7.63545\tvalid_1's rmse: 7.85551\n",
            "[1700]\ttraining's rmse: 7.61961\tvalid_1's rmse: 7.85393\n",
            "[1800]\ttraining's rmse: 7.60395\tvalid_1's rmse: 7.85233\n",
            "[1900]\ttraining's rmse: 7.58842\tvalid_1's rmse: 7.85077\n",
            "[2000]\ttraining's rmse: 7.57325\tvalid_1's rmse: 7.84967\n",
            "[2100]\ttraining's rmse: 7.55827\tvalid_1's rmse: 7.84847\n",
            "Early stopping, best iteration is:\n",
            "[2112]\ttraining's rmse: 7.5565\tvalid_1's rmse: 7.84839\n",
            "5번째 RMSE:7.84838627451115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr1xPaaLssBB"
      },
      "source": [
        "# XGBoost LB: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd_RfzHxsiEJ"
      },
      "source": [
        "def objective(trial,data=x_train,target=y_train):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2,random_state=42)\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_int('max_depth', 4, 12), # Extremely prone to overfitting!\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 400, 4000, 400), # Extremely prone to overfitting!\n",
        "        'eta': trial.suggest_float('eta', 0.007, 0.013), # Most important parameter.\n",
        "        'subsample': trial.suggest_discrete_uniform('subsample', 0.2, 0.9, 0.1),\n",
        "        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.2, 0.9, 0.1),\n",
        "        'colsample_bylevel': trial.suggest_discrete_uniform('colsample_bylevel', 0.2, 0.9, 0.1),\n",
        "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-4, 1e4), # I've had trouble with LB score until tuning this.\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 1e4), # L2 regularization\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 1e4), # L1 regularization\n",
        "        'gamma': trial.suggest_loguniform('gamma', 1e-4, 1e4),\n",
        "        'tree_method' : 'gpu_hist',\n",
        "        'booster' : 'gbtree',\n",
        "        'loss_function':'rmse',\n",
        "        'eval_metric':'rmse'\n",
        "     }\n",
        "\n",
        "    model = xgboost.XGBRegressor(**params)  \n",
        "    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n",
        "        \n",
        "    y_preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "    RMSE = np.sqrt(mean_squared_error(y_test, y_preds))\n",
        "    \n",
        "    return RMSE"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES6aUfkStH0-",
        "outputId": "4381891a-0a31-41da-bd44-ba7ec9bb353e"
      },
      "source": [
        "OPTUNA_OPTIMIZATION = True\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:04,566]\u001b[0m A new study created in memory with name: no-name-7be1021d-a6fb-45d8-a26e-06d762e797a8\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:08,499]\u001b[0m Trial 0 finished with value: 7.837774140819902 and parameters: {'max_depth': 5, 'n_estimators': 1200, 'eta': 0.010112365412387515, 'subsample': 0.5, 'colsample_bytree': 0.30000000000000004, 'colsample_bylevel': 0.8, 'min_child_weight': 0.05489829497396655, 'reg_lambda': 8.289436004178185, 'reg_alpha': 0.004197360343344479, 'gamma': 838.6877942321752}. Best is trial 0 with value: 7.837774140819902.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:19,421]\u001b[0m Trial 1 finished with value: 7.8254563700209925 and parameters: {'max_depth': 9, 'n_estimators': 2000, 'eta': 0.007455517722596376, 'subsample': 0.8, 'colsample_bytree': 0.6000000000000001, 'colsample_bylevel': 0.8, 'min_child_weight': 14.50947401035363, 'reg_lambda': 2949.8672845513756, 'reg_alpha': 4184.314438594567, 'gamma': 0.3874729714882345}. Best is trial 1 with value: 7.8254563700209925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:27,806]\u001b[0m Trial 2 finished with value: 7.833601874298859 and parameters: {'max_depth': 9, 'n_estimators': 400, 'eta': 0.007079137046147311, 'subsample': 0.9, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.9, 'min_child_weight': 0.8761333000345538, 'reg_lambda': 304.3833529406082, 'reg_alpha': 0.016218050979251757, 'gamma': 966.627954367564}. Best is trial 1 with value: 7.8254563700209925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:30,872]\u001b[0m Trial 3 finished with value: 7.825758326985845 and parameters: {'max_depth': 4, 'n_estimators': 400, 'eta': 0.00924217848702799, 'subsample': 0.5, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 0.3994400597278731, 'reg_lambda': 0.1738649755056939, 'reg_alpha': 497.87976027559233, 'gamma': 0.000548226289948492}. Best is trial 1 with value: 7.8254563700209925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:37,144]\u001b[0m Trial 4 finished with value: 7.844406466026922 and parameters: {'max_depth': 12, 'n_estimators': 1600, 'eta': 0.007406066760473974, 'subsample': 0.5, 'colsample_bytree': 0.4, 'colsample_bylevel': 0.9, 'min_child_weight': 0.9675739936480781, 'reg_lambda': 0.0006045373974757064, 'reg_alpha': 1071.9410113530678, 'gamma': 0.006126484518747736}. Best is trial 1 with value: 7.8254563700209925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:44,041]\u001b[0m Trial 5 finished with value: 7.837343979156359 and parameters: {'max_depth': 4, 'n_estimators': 1200, 'eta': 0.007008509587545676, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7, 'min_child_weight': 0.00013871532413805947, 'reg_lambda': 0.00014641718481119787, 'reg_alpha': 3458.0038029625703, 'gamma': 80.3112945188303}. Best is trial 1 with value: 7.8254563700209925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:48,177]\u001b[0m Trial 6 finished with value: 7.835598094991509 and parameters: {'max_depth': 11, 'n_estimators': 2000, 'eta': 0.010866632013531196, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 1241.3622164311764, 'reg_lambda': 0.9002018875496928, 'reg_alpha': 9.433187721870326, 'gamma': 0.00039505497203580606}. Best is trial 1 with value: 7.8254563700209925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:40:56,695]\u001b[0m Trial 7 finished with value: 7.8211433097749925 and parameters: {'max_depth': 7, 'n_estimators': 1200, 'eta': 0.007965047922711608, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.5, 'min_child_weight': 0.0054922795113115, 'reg_lambda': 7262.8195903941605, 'reg_alpha': 0.3455750291232227, 'gamma': 417.9515967142502}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:40:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:01,255]\u001b[0m Trial 8 finished with value: 7.84056386162631 and parameters: {'max_depth': 5, 'n_estimators': 1600, 'eta': 0.00826854735280328, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.9, 'min_child_weight': 5456.276674200663, 'reg_lambda': 58.662613113286874, 'reg_alpha': 730.2908514323032, 'gamma': 3577.5024420978775}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:03,833]\u001b[0m Trial 9 finished with value: 7.870921324549151 and parameters: {'max_depth': 7, 'n_estimators': 3600, 'eta': 0.011213484949005427, 'subsample': 0.4, 'colsample_bytree': 0.4, 'colsample_bylevel': 0.4, 'min_child_weight': 0.01296073648192281, 'reg_lambda': 0.0003671356715407041, 'reg_alpha': 0.5200963878806427, 'gamma': 24.625029290872476}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:10,854]\u001b[0m Trial 10 finished with value: 7.82359458097919 and parameters: {'max_depth': 7, 'n_estimators': 3200, 'eta': 0.012765670437176493, 'subsample': 0.7, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.5, 'min_child_weight': 0.000107016481992925, 'reg_lambda': 5717.430264857367, 'reg_alpha': 0.00011359627016769402, 'gamma': 1.0337833763336255}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:16,868]\u001b[0m Trial 11 finished with value: 7.826907942926643 and parameters: {'max_depth': 7, 'n_estimators': 3200, 'eta': 0.012792835564099722, 'subsample': 0.7, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.5, 'min_child_weight': 0.0001293537009487626, 'reg_lambda': 2715.9977972865277, 'reg_alpha': 0.00018336017304742145, 'gamma': 0.46050899366036957}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:25,777]\u001b[0m Trial 12 finished with value: 7.821267678728174 and parameters: {'max_depth': 7, 'n_estimators': 3200, 'eta': 0.012430652898099703, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.6000000000000001, 'min_child_weight': 0.0032907662001371474, 'reg_lambda': 8251.353220532777, 'reg_alpha': 0.00017288701647606513, 'gamma': 10.794758158363281}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:29,671]\u001b[0m Trial 13 finished with value: 7.859605719250738 and parameters: {'max_depth': 8, 'n_estimators': 2800, 'eta': 0.011715150737504025, 'subsample': 0.9, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.6000000000000001, 'min_child_weight': 0.0040225108800788735, 'reg_lambda': 0.02505557723437028, 'reg_alpha': 1.4021985621272983, 'gamma': 25.3824957940245}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:33,216]\u001b[0m Trial 14 finished with value: 7.832952011816253 and parameters: {'max_depth': 6, 'n_estimators': 4000, 'eta': 0.008932569981657463, 'subsample': 0.8, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.6000000000000001, 'min_child_weight': 0.003920511124046001, 'reg_lambda': 135.52198544853957, 'reg_alpha': 0.009655803741591674, 'gamma': 4.089103015678289}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:50,117]\u001b[0m Trial 15 finished with value: 7.821736165691084 and parameters: {'max_depth': 9, 'n_estimators': 2800, 'eta': 0.01014345233612709, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.2, 'min_child_weight': 20.229859792329616, 'reg_lambda': 8591.761472990598, 'reg_alpha': 36.08804496908274, 'gamma': 158.75044533750267}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:41:57,879]\u001b[0m Trial 16 finished with value: 7.869540230337356 and parameters: {'max_depth': 10, 'n_estimators': 2400, 'eta': 0.01191487608347462, 'subsample': 0.7, 'colsample_bytree': 0.2, 'colsample_bylevel': 0.4, 'min_child_weight': 0.0018075580393583529, 'reg_lambda': 11.906540130656365, 'reg_alpha': 0.10779249866902993, 'gamma': 0.045060932430794155}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:41:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:01,964]\u001b[0m Trial 17 finished with value: 7.827864035979797 and parameters: {'max_depth': 6, 'n_estimators': 800, 'eta': 0.008325647388714217, 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.7, 'min_child_weight': 0.058222209381963874, 'reg_lambda': 296.9405629838186, 'reg_alpha': 0.0012198240930563825, 'gamma': 7196.522482003467}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:07,351]\u001b[0m Trial 18 finished with value: 7.850895282420119 and parameters: {'max_depth': 8, 'n_estimators': 4000, 'eta': 0.009533423463103362, 'subsample': 0.2, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.4, 'min_child_weight': 0.0010288361338542003, 'reg_lambda': 819.0877131907679, 'reg_alpha': 0.10948402435378635, 'gamma': 6.0189980699709675}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:11,002]\u001b[0m Trial 19 finished with value: 7.837482233670346 and parameters: {'max_depth': 6, 'n_estimators': 2400, 'eta': 0.008238130013356267, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.7, 'min_child_weight': 10.463504700008443, 'reg_lambda': 11.074642613106496, 'reg_alpha': 26.137971192292248, 'gamma': 318.2402634870291}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:16,791]\u001b[0m Trial 20 finished with value: 7.886507364941946 and parameters: {'max_depth': 10, 'n_estimators': 3200, 'eta': 0.012139873860970218, 'subsample': 0.8, 'colsample_bytree': 0.6000000000000001, 'colsample_bylevel': 0.5, 'min_child_weight': 0.073767952082077, 'reg_lambda': 0.003270804673346498, 'reg_alpha': 0.0006911156236602134, 'gamma': 0.014157270051850579}. Best is trial 7 with value: 7.8211433097749925.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:30,313]\u001b[0m Trial 21 finished with value: 7.819594810556224 and parameters: {'max_depth': 9, 'n_estimators': 2800, 'eta': 0.010120483400057632, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.2, 'min_child_weight': 34.94469782321918, 'reg_lambda': 9398.459605171662, 'reg_alpha': 65.04671128783795, 'gamma': 85.1499839381993}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:35,984]\u001b[0m Trial 22 finished with value: 7.821612058515445 and parameters: {'max_depth': 8, 'n_estimators': 2800, 'eta': 0.010618172814977338, 'subsample': 0.9, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.2, 'min_child_weight': 259.7935007107936, 'reg_lambda': 1426.3818189035896, 'reg_alpha': 124.96397030828552, 'gamma': 29.61767673229419}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:43,891]\u001b[0m Trial 23 finished with value: 7.822024440221737 and parameters: {'max_depth': 7, 'n_estimators': 3600, 'eta': 0.009581545809031113, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 139.66494097294193, 'reg_lambda': 9210.579401193312, 'reg_alpha': 3.2606382674669545, 'gamma': 5.921158363532394}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:42:52,250]\u001b[0m Trial 24 finished with value: 7.859333402169732 and parameters: {'max_depth': 10, 'n_estimators': 2400, 'eta': 0.008838437602034495, 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.6000000000000001, 'min_child_weight': 0.2147101575455458, 'reg_lambda': 59.21396600208734, 'reg_alpha': 0.18276461300117344, 'gamma': 1171.4643993358468}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:42:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:01,419]\u001b[0m Trial 25 finished with value: 7.829909917040766 and parameters: {'max_depth': 9, 'n_estimators': 3600, 'eta': 0.011354190017065694, 'subsample': 0.7, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.2, 'min_child_weight': 3.7456878119436046, 'reg_lambda': 906.3958774602138, 'reg_alpha': 91.84513404532228, 'gamma': 56.19627146918884}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:07,638]\u001b[0m Trial 26 finished with value: 7.83162304859636 and parameters: {'max_depth': 8, 'n_estimators': 1600, 'eta': 0.007813865916123293, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.4, 'min_child_weight': 0.0006916948756426843, 'reg_lambda': 583.5814143000052, 'reg_alpha': 0.031146691214540227, 'gamma': 282.4956309177828}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:10,965]\u001b[0m Trial 27 finished with value: 7.832704202969254 and parameters: {'max_depth': 5, 'n_estimators': 2800, 'eta': 0.012316314160842222, 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.5, 'min_child_weight': 0.014037884404604802, 'reg_lambda': 1.8601705542297167, 'reg_alpha': 5.992679309362577, 'gamma': 1.8553547897839249}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:14,877]\u001b[0m Trial 28 finished with value: 7.830365267653832 and parameters: {'max_depth': 6, 'n_estimators': 2000, 'eta': 0.01052337860873798, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.6000000000000001, 'min_child_weight': 0.0005789914551574655, 'reg_lambda': 73.85187167332035, 'reg_alpha': 0.5585921454177571, 'gamma': 12.64059667448325}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:25,618]\u001b[0m Trial 29 finished with value: 7.832180538181351 and parameters: {'max_depth': 11, 'n_estimators': 800, 'eta': 0.010039884428400533, 'subsample': 0.7, 'colsample_bytree': 0.6000000000000001, 'colsample_bylevel': 0.8, 'min_child_weight': 82.66744192686171, 'reg_lambda': 2447.3066650626843, 'reg_alpha': 0.0010804364252920988, 'gamma': 1090.883248524967}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:29,642]\u001b[0m Trial 30 finished with value: 7.836884455786306 and parameters: {'max_depth': 7, 'n_estimators': 3200, 'eta': 0.00873319093324535, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.2, 'colsample_bylevel': 0.7, 'min_child_weight': 0.018429065719534368, 'reg_lambda': 22.607570511080056, 'reg_alpha': 136.0401954892209, 'gamma': 0.09035880180265776}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:34,541]\u001b[0m Trial 31 finished with value: 7.826311287308488 and parameters: {'max_depth': 8, 'n_estimators': 2800, 'eta': 0.010491591675829644, 'subsample': 0.9, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.2, 'min_child_weight': 680.161304738183, 'reg_lambda': 1792.1682732018621, 'reg_alpha': 91.20630344403911, 'gamma': 58.742511639733095}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:43,160]\u001b[0m Trial 32 finished with value: 7.824717388497833 and parameters: {'max_depth': 8, 'n_estimators': 2400, 'eta': 0.010705871083261638, 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 361.41257869454034, 'reg_lambda': 8456.425805887824, 'reg_alpha': 256.81524980857955, 'gamma': 286.39352765799947}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:51,836]\u001b[0m Trial 33 finished with value: 7.827214945483959 and parameters: {'max_depth': 9, 'n_estimators': 2800, 'eta': 0.011203701197732162, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.2, 'min_child_weight': 4.196033254089937, 'reg_lambda': 1536.1974400507092, 'reg_alpha': 18.168403889034696, 'gamma': 18.280604853887624}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:43:58,273]\u001b[0m Trial 34 finished with value: 7.820190697720467 and parameters: {'max_depth': 7, 'n_estimators': 2000, 'eta': 0.009543772641575863, 'subsample': 0.8, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 34.193603065889896, 'reg_lambda': 361.94834914190704, 'reg_alpha': 1812.136499150273, 'gamma': 1694.8086897772607}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:43:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:03,862]\u001b[0m Trial 35 finished with value: 7.85669274506414 and parameters: {'max_depth': 7, 'n_estimators': 1200, 'eta': 0.007735221852886281, 'subsample': 0.8, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 66.19003072150917, 'reg_lambda': 203.17725941258857, 'reg_alpha': 8490.24588510042, 'gamma': 2287.7394795496048}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:10,859]\u001b[0m Trial 36 finished with value: 7.822036747022882 and parameters: {'max_depth': 6, 'n_estimators': 800, 'eta': 0.009732555050377772, 'subsample': 0.9, 'colsample_bytree': 0.6000000000000001, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 0.23361054093911904, 'reg_lambda': 412.0083189652274, 'reg_alpha': 906.200862005442, 'gamma': 9413.34664657595}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:21,488]\u001b[0m Trial 37 finished with value: 7.82186536528835 and parameters: {'max_depth': 5, 'n_estimators': 1600, 'eta': 0.009344756071789657, 'subsample': 0.8, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.4, 'min_child_weight': 29.200524004852543, 'reg_lambda': 3411.0760110808656, 'reg_alpha': 2969.1582413157153, 'gamma': 398.39749069502136}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:28,823]\u001b[0m Trial 38 finished with value: 7.825303748687234 and parameters: {'max_depth': 9, 'n_estimators': 2000, 'eta': 0.00791137561762423, 'subsample': 0.9, 'colsample_bytree': 0.4, 'colsample_bylevel': 0.5, 'min_child_weight': 2.1202517859592986, 'reg_lambda': 1.7518762437972908, 'reg_alpha': 2151.15413773158, 'gamma': 113.54277750861581}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:36,318]\u001b[0m Trial 39 finished with value: 7.824936927572468 and parameters: {'max_depth': 7, 'n_estimators': 1200, 'eta': 0.007309958255719823, 'subsample': 0.8, 'colsample_bytree': 0.30000000000000004, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 0.695289703536684, 'reg_lambda': 3223.2969003323274, 'reg_alpha': 0.004284493248449653, 'gamma': 2575.2093269432294}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:39,341]\u001b[0m Trial 40 finished with value: 7.835893702444216 and parameters: {'max_depth': 4, 'n_estimators': 400, 'eta': 0.01029071573717482, 'subsample': 0.4, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.8, 'min_child_weight': 1965.8380216366259, 'reg_lambda': 0.4656412140431169, 'reg_alpha': 323.98251091527936, 'gamma': 740.0702076055244}. Best is trial 21 with value: 7.819594810556224.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:47,039]\u001b[0m Trial 41 finished with value: 7.819479327884982 and parameters: {'max_depth': 8, 'n_estimators': 3200, 'eta': 0.00986130660739818, 'subsample': 0.9, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.2, 'min_child_weight': 175.57994362299922, 'reg_lambda': 796.0069231962208, 'reg_alpha': 1633.033080754412, 'gamma': 39.75742087100033}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:44:51,761]\u001b[0m Trial 42 finished with value: 7.84822915870636 and parameters: {'max_depth': 8, 'n_estimators': 3200, 'eta': 0.009187872076483106, 'subsample': 0.9, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.2, 'min_child_weight': 57.9454841657648, 'reg_lambda': 583.7246326426256, 'reg_alpha': 6932.768642884749, 'gamma': 124.95855914296375}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:44:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:04,652]\u001b[0m Trial 43 finished with value: 7.824683610708985 and parameters: {'max_depth': 9, 'n_estimators': 3600, 'eta': 0.008514579368581653, 'subsample': 0.9, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.2, 'min_child_weight': 9840.878162576419, 'reg_lambda': 4000.8424611835744, 'reg_alpha': 1951.45973329346, 'gamma': 681.534512119507}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:45:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:09,272]\u001b[0m Trial 44 finished with value: 7.829338864701422 and parameters: {'max_depth': 7, 'n_estimators': 2000, 'eta': 0.009792407103517338, 'subsample': 0.9, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.30000000000000004, 'min_child_weight': 8.78245772406876, 'reg_lambda': 152.88954123612754, 'reg_alpha': 284.0480042583468, 'gamma': 1.939852857953971}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:45:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:21,921]\u001b[0m Trial 45 finished with value: 7.826192087417109 and parameters: {'max_depth': 6, 'n_estimators': 3200, 'eta': 0.00908961425709653, 'subsample': 0.7, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.2, 'min_child_weight': 2566.6344188817607, 'reg_lambda': 9386.956311801008, 'reg_alpha': 1254.120645846412, 'gamma': 0.00018779511015714227}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:45:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:25,317]\u001b[0m Trial 46 finished with value: 7.830800822536753 and parameters: {'max_depth': 8, 'n_estimators': 3600, 'eta': 0.012511157834590435, 'subsample': 0.8, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.4, 'min_child_weight': 599.6166399764777, 'reg_lambda': 0.11153362444472373, 'reg_alpha': 1.2923796083590016, 'gamma': 0.4856617311122036}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:45:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:30,031]\u001b[0m Trial 47 finished with value: 7.825238885212012 and parameters: {'max_depth': 7, 'n_estimators': 2400, 'eta': 0.010999656464983272, 'subsample': 0.9, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.6000000000000001, 'min_child_weight': 0.00024135387019889876, 'reg_lambda': 1179.9214831894146, 'reg_alpha': 0.0003657738041709762, 'gamma': 10.124380214750364}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:45:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:38,421]\u001b[0m Trial 48 finished with value: 7.855115779634775 and parameters: {'max_depth': 10, 'n_estimators': 3200, 'eta': 0.011400719531948624, 'subsample': 0.8, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.7, 'min_child_weight': 0.0043076236526734335, 'reg_lambda': 29.24306094525249, 'reg_alpha': 0.037533852696940054, 'gamma': 3934.225703720897}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[07:45:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:45:48,225]\u001b[0m Trial 49 finished with value: 7.837438721666108 and parameters: {'max_depth': 11, 'n_estimators': 1600, 'eta': 0.011595728799084895, 'subsample': 0.4, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.2, 'min_child_weight': 137.53801445631248, 'reg_lambda': 4384.697542073255, 'reg_alpha': 3.883835940757644, 'gamma': 56.72522870118311}. Best is trial 41 with value: 7.819479327884982.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of finished trials: 50\n",
            "Best trial: score 7.819479327884982, params {'max_depth': 8, 'n_estimators': 3200, 'eta': 0.00986130660739818, 'subsample': 0.9, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.2, 'min_child_weight': 175.57994362299922, 'reg_lambda': 796.0069231962208, 'reg_alpha': 1633.033080754412, 'gamma': 39.75742087100033}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKd3TTTRzgxo",
        "outputId": "4141b3c7-87f0-43bb-cde4-2f9fe917c748"
      },
      "source": [
        "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "preds = np.zeros((x_test.shape[0],))\n",
        "params_xgb = {'booster' : 'gbtree',\n",
        "              'tree_method' : 'gpu_hist',\n",
        "              'loss_function':'rmse',\n",
        "              'eval_metric':'rmse',\n",
        "              'max_depth': study.best_params['max_depth'],\n",
        "              'n_estimators': study.best_params['n_estimators'],\n",
        "              'eta': study.best_params['eta'],\n",
        "              'colsample_bytree': study.best_params['colsample_bytree'],\n",
        "              'colsample_bylevel': study.best_params['colsample_bylevel'],\n",
        "              'min_child_weight': study.best_params['min_child_weight'],\n",
        "              'reg_lambda': study.best_params['reg_lambda'],\n",
        "              'reg_alpha': study.best_params['reg_alpha'],\n",
        "              'gamma': study.best_params['gamma'],\n",
        "              'subsample': study.best_params['subsample']\n",
        "          }\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(sk.split(x_train, y_train)):\n",
        "  X_train, X_valid = x_train.iloc[train_index], x_train.iloc[valid_index]\n",
        "  Y_train, Y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
        "\n",
        "  model_xgb = xgboost.XGBRegressor(**params_xgb)\n",
        "  model_xgb.fit(X_train, Y_train, eval_set=((X_train, Y_train), (X_valid, Y_valid)), verbose=100, early_stopping_rounds=70)\n",
        "\n",
        "  preds += model_xgb.predict(x_test) / sk.n_splits\n",
        "  val_preds = model_xgb.predict(X_valid)\n",
        "  RMSE = np.sqrt(mean_squared_error(Y_valid, val_preds))\n",
        "  print(f'{i+1}번째 RMSE:{RMSE}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[07:45:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:9.76624\tvalidation_1-rmse:9.76507\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 70 rounds.\n",
            "[100]\tvalidation_0-rmse:7.80781\tvalidation_1-rmse:7.87263\n",
            "[200]\tvalidation_0-rmse:7.73606\tvalidation_1-rmse:7.85822\n",
            "[300]\tvalidation_0-rmse:7.67817\tvalidation_1-rmse:7.85199\n",
            "[400]\tvalidation_0-rmse:7.62485\tvalidation_1-rmse:7.84875\n",
            "[500]\tvalidation_0-rmse:7.57371\tvalidation_1-rmse:7.84694\n",
            "[600]\tvalidation_0-rmse:7.52577\tvalidation_1-rmse:7.84642\n",
            "[700]\tvalidation_0-rmse:7.47944\tvalidation_1-rmse:7.84568\n",
            "[800]\tvalidation_0-rmse:7.43561\tvalidation_1-rmse:7.8463\n",
            "Stopping. Best iteration:\n",
            "[761]\tvalidation_0-rmse:7.45268\tvalidation_1-rmse:7.84558\n",
            "\n",
            "1번째 RMSE:7.845584578339821\n",
            "[07:46:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:9.7657\tvalidation_1-rmse:9.7673\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 70 rounds.\n",
            "[100]\tvalidation_0-rmse:7.80936\tvalidation_1-rmse:7.87285\n",
            "[200]\tvalidation_0-rmse:7.73723\tvalidation_1-rmse:7.85506\n",
            "[300]\tvalidation_0-rmse:7.67893\tvalidation_1-rmse:7.84883\n",
            "[400]\tvalidation_0-rmse:7.6259\tvalidation_1-rmse:7.84542\n",
            "[500]\tvalidation_0-rmse:7.57617\tvalidation_1-rmse:7.84456\n",
            "Stopping. Best iteration:\n",
            "[470]\tvalidation_0-rmse:7.59074\tvalidation_1-rmse:7.84435\n",
            "\n",
            "2번째 RMSE:7.8443516894880245\n",
            "[07:46:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:9.76574\tvalidation_1-rmse:9.76712\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 70 rounds.\n",
            "[100]\tvalidation_0-rmse:7.80609\tvalidation_1-rmse:7.87591\n",
            "[200]\tvalidation_0-rmse:7.73518\tvalidation_1-rmse:7.86072\n",
            "[300]\tvalidation_0-rmse:7.67788\tvalidation_1-rmse:7.85491\n",
            "[400]\tvalidation_0-rmse:7.62676\tvalidation_1-rmse:7.85301\n",
            "[500]\tvalidation_0-rmse:7.57595\tvalidation_1-rmse:7.85197\n",
            "Stopping. Best iteration:\n",
            "[460]\tvalidation_0-rmse:7.5965\tvalidation_1-rmse:7.85134\n",
            "\n",
            "3번째 RMSE:7.851343693459015\n",
            "[07:46:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:9.76619\tvalidation_1-rmse:9.7653\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 70 rounds.\n",
            "[100]\tvalidation_0-rmse:7.80749\tvalidation_1-rmse:7.8746\n",
            "[200]\tvalidation_0-rmse:7.73427\tvalidation_1-rmse:7.86048\n",
            "[300]\tvalidation_0-rmse:7.67567\tvalidation_1-rmse:7.85651\n",
            "[400]\tvalidation_0-rmse:7.62239\tvalidation_1-rmse:7.85388\n",
            "[500]\tvalidation_0-rmse:7.5729\tvalidation_1-rmse:7.85335\n",
            "Stopping. Best iteration:\n",
            "[440]\tvalidation_0-rmse:7.60189\tvalidation_1-rmse:7.85297\n",
            "\n",
            "4번째 RMSE:7.852967513477892\n",
            "[07:46:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:9.76619\tvalidation_1-rmse:9.76528\n",
            "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-rmse hasn't improved in 70 rounds.\n",
            "[100]\tvalidation_0-rmse:7.80614\tvalidation_1-rmse:7.87352\n",
            "[200]\tvalidation_0-rmse:7.73417\tvalidation_1-rmse:7.85832\n",
            "[300]\tvalidation_0-rmse:7.67732\tvalidation_1-rmse:7.85184\n",
            "[400]\tvalidation_0-rmse:7.62608\tvalidation_1-rmse:7.84868\n",
            "[500]\tvalidation_0-rmse:7.57707\tvalidation_1-rmse:7.84668\n",
            "[600]\tvalidation_0-rmse:7.52862\tvalidation_1-rmse:7.84554\n",
            "[700]\tvalidation_0-rmse:7.48329\tvalidation_1-rmse:7.84526\n",
            "Stopping. Best iteration:\n",
            "[640]\tvalidation_0-rmse:7.50929\tvalidation_1-rmse:7.84506\n",
            "\n",
            "5번째 RMSE:7.845062046362339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxEiw9UUtIcx"
      },
      "source": [
        "# Catboost LB : 7.87727"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A72VesFU8WFi"
      },
      "source": [
        "cat_features = x_train.select_dtypes('object').columns\n",
        "def objective(trial,data=x_train,target=y_train):\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2,random_state=42)\n",
        "    params = {'iterations':trial.suggest_int(\"iterations\", 2000, 25000),\n",
        "             'loss_function':'RMSE',\n",
        "              'task_type':\"GPU\",\n",
        "              'eval_metric':'RMSE',\n",
        "              'leaf_estimation_method':'Newton',\n",
        "              'bootstrap_type': 'Bernoulli',\n",
        "              'learning_rate' : trial.suggest_uniform('learning_rate',0.01,0.5),\n",
        "              'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n",
        "              'subsample': trial.suggest_uniform('subsample',0,1),\n",
        "              'random_strength': trial.suggest_uniform('random_strength',10,50),\n",
        "              'depth': trial.suggest_int('depth',1,13),\n",
        "              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,50),\n",
        "              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n",
        "              'grow_policy' : 'Depthwise',\n",
        "              'objective' : 'Poisson'\n",
        "               }\n",
        "    model = catboost.CatBoostRegressor(**params)  \n",
        "    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n",
        "        \n",
        "    y_preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "    RMSE = np.sqrt(mean_squared_error(y_test, y_preds))\n",
        "    \n",
        "    return RMSE"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Z5YVXw8eMd",
        "outputId": "ce777527-ed30-4907-d825-62dd209dfded"
      },
      "source": [
        "OPTUNA_OPTIMIZATION = True\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-30 07:46:37,576]\u001b[0m A new study created in memory with name: no-name-46c16416-a79f-4d26-8a90-3dbdf3523acc\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:47:57,864]\u001b[0m Trial 0 finished with value: 7.9491715649253525 and parameters: {'iterations': 13972, 'learning_rate': 0.4943793871380891, 'reg_lambda': 48.861884497795685, 'subsample': 0.78287677590438, 'random_strength': 14.980489166167605, 'depth': 8, 'min_data_in_leaf': 50, 'leaf_estimation_iterations': 10}. Best is trial 0 with value: 7.9491715649253525.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:48:02,043]\u001b[0m Trial 1 finished with value: 7.8930120265698385 and parameters: {'iterations': 23406, 'learning_rate': 0.46138468500478563, 'reg_lambda': 49.247677414049654, 'subsample': 0.7777856949743465, 'random_strength': 19.049486254794864, 'depth': 5, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 2}. Best is trial 1 with value: 7.8930120265698385.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:48:08,742]\u001b[0m Trial 2 finished with value: 7.849363090188717 and parameters: {'iterations': 21368, 'learning_rate': 0.14190976349790288, 'reg_lambda': 94.97518788257898, 'subsample': 0.2690227286048986, 'random_strength': 11.272851287330937, 'depth': 7, 'min_data_in_leaf': 16, 'leaf_estimation_iterations': 8}. Best is trial 2 with value: 7.849363090188717.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:48:14,582]\u001b[0m Trial 3 finished with value: 7.898860094124201 and parameters: {'iterations': 10257, 'learning_rate': 0.2459502811903671, 'reg_lambda': 98.76674381730004, 'subsample': 0.5327860817189388, 'random_strength': 18.371675163306904, 'depth': 9, 'min_data_in_leaf': 22, 'leaf_estimation_iterations': 4}. Best is trial 2 with value: 7.849363090188717.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:48:20,297]\u001b[0m Trial 4 finished with value: 7.913440519215653 and parameters: {'iterations': 22214, 'learning_rate': 0.36566293025829155, 'reg_lambda': 68.14968472665278, 'subsample': 0.45610768704711724, 'random_strength': 29.65301788985571, 'depth': 9, 'min_data_in_leaf': 38, 'leaf_estimation_iterations': 7}. Best is trial 2 with value: 7.849363090188717.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:48:31,577]\u001b[0m Trial 5 finished with value: 7.84017326547252 and parameters: {'iterations': 5113, 'learning_rate': 0.48436010746880176, 'reg_lambda': 68.83288012268557, 'subsample': 0.01838272755598125, 'random_strength': 35.5307312749854, 'depth': 1, 'min_data_in_leaf': 21, 'leaf_estimation_iterations': 4}. Best is trial 5 with value: 7.84017326547252.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:48:45,096]\u001b[0m Trial 6 finished with value: 7.825373322989577 and parameters: {'iterations': 13467, 'learning_rate': 0.08240058094233475, 'reg_lambda': 38.51225391352252, 'subsample': 0.5195592910663204, 'random_strength': 11.506094115468514, 'depth': 4, 'min_data_in_leaf': 38, 'leaf_estimation_iterations': 8}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:49:01,747]\u001b[0m Trial 7 finished with value: 7.855116030157488 and parameters: {'iterations': 11844, 'learning_rate': 0.04729430904687648, 'reg_lambda': 95.75591004792854, 'subsample': 0.4573802604205218, 'random_strength': 10.605434975399039, 'depth': 12, 'min_data_in_leaf': 41, 'leaf_estimation_iterations': 11}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:49:08,627]\u001b[0m Trial 8 finished with value: 7.8480395166107355 and parameters: {'iterations': 16633, 'learning_rate': 0.12022418089386615, 'reg_lambda': 10.089753454519318, 'subsample': 0.8010160067098212, 'random_strength': 35.894176342539055, 'depth': 7, 'min_data_in_leaf': 25, 'leaf_estimation_iterations': 8}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:49:15,630]\u001b[0m Trial 9 finished with value: 7.850281566609205 and parameters: {'iterations': 7448, 'learning_rate': 0.4592124976404814, 'reg_lambda': 66.69813586425119, 'subsample': 0.13693269088551985, 'random_strength': 39.44557178851559, 'depth': 3, 'min_data_in_leaf': 2, 'leaf_estimation_iterations': 12}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:52:28,603]\u001b[0m Trial 10 finished with value: 7.8351570618344395 and parameters: {'iterations': 17413, 'learning_rate': 0.011060175581191364, 'reg_lambda': 19.46819355714788, 'subsample': 0.5854274982892963, 'random_strength': 48.650131654415404, 'depth': 1, 'min_data_in_leaf': 35, 'leaf_estimation_iterations': 15}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:55:03,338]\u001b[0m Trial 11 finished with value: 7.830188880382899 and parameters: {'iterations': 16656, 'learning_rate': 0.02541655132631382, 'reg_lambda': 17.06897458780161, 'subsample': 0.59694001940924, 'random_strength': 48.8438747679559, 'depth': 1, 'min_data_in_leaf': 36, 'leaf_estimation_iterations': 15}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:55:13,519]\u001b[0m Trial 12 finished with value: 7.831694133455514 and parameters: {'iterations': 17454, 'learning_rate': 0.1207857106788515, 'reg_lambda': 27.482078802130985, 'subsample': 0.9351220231365451, 'random_strength': 25.532577340177646, 'depth': 4, 'min_data_in_leaf': 32, 'leaf_estimation_iterations': 15}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:55:27,667]\u001b[0m Trial 13 finished with value: 7.834981712336313 and parameters: {'iterations': 14301, 'learning_rate': 0.22294477758578274, 'reg_lambda': 0.006648663890480577, 'subsample': 0.32989796253649056, 'random_strength': 47.22572025921846, 'depth': 3, 'min_data_in_leaf': 47, 'leaf_estimation_iterations': 13}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:55:48,849]\u001b[0m Trial 14 finished with value: 7.832440153299854 and parameters: {'iterations': 2527, 'learning_rate': 0.09433516556745485, 'reg_lambda': 33.117478097455034, 'subsample': 0.666160941623678, 'random_strength': 42.08701050063156, 'depth': 1, 'min_data_in_leaf': 43, 'leaf_estimation_iterations': 6}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:55:57,188]\u001b[0m Trial 15 finished with value: 7.846545337399312 and parameters: {'iterations': 9709, 'learning_rate': 0.19876817448801662, 'reg_lambda': 36.88630986549427, 'subsample': 0.3160632978500023, 'random_strength': 24.773479808874782, 'depth': 5, 'min_data_in_leaf': 31, 'leaf_estimation_iterations': 10}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:56:03,905]\u001b[0m Trial 16 finished with value: 7.8365466582254495 and parameters: {'iterations': 19722, 'learning_rate': 0.3404450836956535, 'reg_lambda': 13.97386315188809, 'subsample': 0.6428162408560144, 'random_strength': 29.809737601595586, 'depth': 3, 'min_data_in_leaf': 30, 'leaf_estimation_iterations': 13}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:56:14,413]\u001b[0m Trial 17 finished with value: 7.828162505698021 and parameters: {'iterations': 15239, 'learning_rate': 0.060403758807905605, 'reg_lambda': 38.34297413169108, 'subsample': 0.9623820245680252, 'random_strength': 44.0994612650383, 'depth': 5, 'min_data_in_leaf': 44, 'leaf_estimation_iterations': 5}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:56:18,877]\u001b[0m Trial 18 finished with value: 7.890533072356692 and parameters: {'iterations': 12434, 'learning_rate': 0.3014540596312155, 'reg_lambda': 58.45097962660075, 'subsample': 0.9611700019071203, 'random_strength': 42.21139085931898, 'depth': 5, 'min_data_in_leaf': 44, 'leaf_estimation_iterations': 1}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:56:33,235]\u001b[0m Trial 19 finished with value: 7.964498658087161 and parameters: {'iterations': 7604, 'learning_rate': 0.17385729594839922, 'reg_lambda': 41.99096861860334, 'subsample': 0.9842365690607687, 'random_strength': 23.60130487959185, 'depth': 12, 'min_data_in_leaf': 3, 'leaf_estimation_iterations': 4}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:56:41,545]\u001b[0m Trial 20 finished with value: 7.836180100588593 and parameters: {'iterations': 20045, 'learning_rate': 0.07693222240208626, 'reg_lambda': 77.52725194276017, 'subsample': 0.8663537284242968, 'random_strength': 34.560838871938856, 'depth': 6, 'min_data_in_leaf': 50, 'leaf_estimation_iterations': 6}. Best is trial 6 with value: 7.825373322989577.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:57:44,367]\u001b[0m Trial 21 finished with value: 7.823537836153379 and parameters: {'iterations': 16819, 'learning_rate': 0.028130111308547714, 'reg_lambda': 24.793502001879578, 'subsample': 0.6738398464211142, 'random_strength': 49.944175816425535, 'depth': 2, 'min_data_in_leaf': 38, 'leaf_estimation_iterations': 9}. Best is trial 21 with value: 7.823537836153379.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:58:06,391]\u001b[0m Trial 22 finished with value: 7.822535218740207 and parameters: {'iterations': 14798, 'learning_rate': 0.06103990019044714, 'reg_lambda': 24.87950973039213, 'subsample': 0.40206291058928617, 'random_strength': 43.02076578831086, 'depth': 3, 'min_data_in_leaf': 40, 'leaf_estimation_iterations': 9}. Best is trial 22 with value: 7.822535218740207.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:58:24,726]\u001b[0m Trial 23 finished with value: 7.82703023182876 and parameters: {'iterations': 19355, 'learning_rate': 0.17127458415317032, 'reg_lambda': 22.46168226089066, 'subsample': 0.38883917978132754, 'random_strength': 44.639740270812034, 'depth': 2, 'min_data_in_leaf': 38, 'leaf_estimation_iterations': 9}. Best is trial 22 with value: 7.822535218740207.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:58:41,272]\u001b[0m Trial 24 finished with value: 7.821941073689446 and parameters: {'iterations': 11809, 'learning_rate': 0.09052033903341576, 'reg_lambda': 27.76601024534907, 'subsample': 0.704331077026563, 'random_strength': 38.004044361375435, 'depth': 3, 'min_data_in_leaf': 27, 'leaf_estimation_iterations': 9}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:59:26,400]\u001b[0m Trial 25 finished with value: 7.82308558824088 and parameters: {'iterations': 10574, 'learning_rate': 0.039158817694271035, 'reg_lambda': 4.767683100290942, 'subsample': 0.7198425544636439, 'random_strength': 39.937663615150306, 'depth': 2, 'min_data_in_leaf': 27, 'leaf_estimation_iterations': 10}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 07:59:42,787]\u001b[0m Trial 26 finished with value: 7.825912109645202 and parameters: {'iterations': 10583, 'learning_rate': 0.13955632876524762, 'reg_lambda': 3.7627486395521963, 'subsample': 0.7137006408339274, 'random_strength': 38.94309474506298, 'depth': 2, 'min_data_in_leaf': 27, 'leaf_estimation_iterations': 11}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:00:03,236]\u001b[0m Trial 27 finished with value: 7.825144985313953 and parameters: {'iterations': 8001, 'learning_rate': 0.0748937097527774, 'reg_lambda': 9.13753374845531, 'subsample': 0.2455362756425552, 'random_strength': 33.102234991159165, 'depth': 4, 'min_data_in_leaf': 19, 'leaf_estimation_iterations': 10}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:00:18,011]\u001b[0m Trial 28 finished with value: 7.825588738373292 and parameters: {'iterations': 5855, 'learning_rate': 0.10953761937639825, 'reg_lambda': 29.533745852668968, 'subsample': 0.7471269010762558, 'random_strength': 39.199377202315496, 'depth': 3, 'min_data_in_leaf': 8, 'leaf_estimation_iterations': 12}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:00:28,410]\u001b[0m Trial 29 finished with value: 7.8346436111865625 and parameters: {'iterations': 11599, 'learning_rate': 0.04490759587141126, 'reg_lambda': 7.091025656943536, 'subsample': 0.8487437703308572, 'random_strength': 32.179636695284366, 'depth': 8, 'min_data_in_leaf': 26, 'leaf_estimation_iterations': 10}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:00:33,836]\u001b[0m Trial 30 finished with value: 7.861663188377168 and parameters: {'iterations': 15164, 'learning_rate': 0.2795596322604882, 'reg_lambda': 54.80635419051497, 'subsample': 0.39435959514660723, 'random_strength': 37.33862243690493, 'depth': 6, 'min_data_in_leaf': 13, 'leaf_estimation_iterations': 9}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:01:33,294]\u001b[0m Trial 31 finished with value: 7.823020399144664 and parameters: {'iterations': 13376, 'learning_rate': 0.02462003318703094, 'reg_lambda': 24.420627776772108, 'subsample': 0.6889375302547152, 'random_strength': 46.373844617824496, 'depth': 2, 'min_data_in_leaf': 29, 'leaf_estimation_iterations': 9}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:02:09,162]\u001b[0m Trial 32 finished with value: 7.823746921466853 and parameters: {'iterations': 13601, 'learning_rate': 0.047454173199103555, 'reg_lambda': 46.600349556744504, 'subsample': 0.5787415706260386, 'random_strength': 44.524200812196234, 'depth': 2, 'min_data_in_leaf': 30, 'leaf_estimation_iterations': 7}. Best is trial 24 with value: 7.821941073689446.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:03:05,507]\u001b[0m Trial 33 finished with value: 7.8189224071220105 and parameters: {'iterations': 24853, 'learning_rate': 0.015130496691778246, 'reg_lambda': 15.698334668378212, 'subsample': 0.8050170108728548, 'random_strength': 42.09044009303539, 'depth': 4, 'min_data_in_leaf': 33, 'leaf_estimation_iterations': 11}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:04:15,518]\u001b[0m Trial 34 finished with value: 7.819240604637936 and parameters: {'iterations': 24090, 'learning_rate': 0.01220562183047786, 'reg_lambda': 14.950784574450712, 'subsample': 0.803861444545215, 'random_strength': 46.31653360421638, 'depth': 4, 'min_data_in_leaf': 33, 'leaf_estimation_iterations': 11}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:04:21,917]\u001b[0m Trial 35 finished with value: 7.841504798963651 and parameters: {'iterations': 24964, 'learning_rate': 0.15867282481302597, 'reg_lambda': 14.452514585468537, 'subsample': 0.8777325001422334, 'random_strength': 42.172660830881654, 'depth': 6, 'min_data_in_leaf': 34, 'leaf_estimation_iterations': 13}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:05:24,837]\u001b[0m Trial 36 finished with value: 7.819369917586703 and parameters: {'iterations': 24628, 'learning_rate': 0.0127524940737863, 'reg_lambda': 30.307659472046012, 'subsample': 0.7997752353507737, 'random_strength': 46.293012214096244, 'depth': 4, 'min_data_in_leaf': 33, 'leaf_estimation_iterations': 11}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:06:11,740]\u001b[0m Trial 37 finished with value: 7.81974615660641 and parameters: {'iterations': 23606, 'learning_rate': 0.017402336565364423, 'reg_lambda': 19.52360243318889, 'subsample': 0.8524345241270035, 'random_strength': 46.09047029081352, 'depth': 4, 'min_data_in_leaf': 24, 'leaf_estimation_iterations': 12}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:06:39,252]\u001b[0m Trial 38 finished with value: 7.828227476150706 and parameters: {'iterations': 23451, 'learning_rate': 0.01323374313447075, 'reg_lambda': 18.39057528110495, 'subsample': 0.7896824203345962, 'random_strength': 46.72853406316238, 'depth': 8, 'min_data_in_leaf': 23, 'leaf_estimation_iterations': 14}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:06:44,114]\u001b[0m Trial 39 finished with value: 7.8603853493787925 and parameters: {'iterations': 24112, 'learning_rate': 0.4050325491330997, 'reg_lambda': 32.71256749730935, 'subsample': 0.9073445547185471, 'random_strength': 47.810686074844114, 'depth': 4, 'min_data_in_leaf': 17, 'leaf_estimation_iterations': 12}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:06:52,901]\u001b[0m Trial 40 finished with value: 7.86776592372787 and parameters: {'iterations': 21594, 'learning_rate': 0.10182360225617682, 'reg_lambda': 13.855479163636113, 'subsample': 0.81528322422137, 'random_strength': 45.59086790799829, 'depth': 10, 'min_data_in_leaf': 34, 'leaf_estimation_iterations': 11}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:07:05,582]\u001b[0m Trial 41 finished with value: 7.823763490659347 and parameters: {'iterations': 22328, 'learning_rate': 0.061486324514015284, 'reg_lambda': 31.741069067584682, 'subsample': 0.7524341765436567, 'random_strength': 40.707681152006394, 'depth': 5, 'min_data_in_leaf': 22, 'leaf_estimation_iterations': 11}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:07:20,287]\u001b[0m Trial 42 finished with value: 7.828591728560435 and parameters: {'iterations': 24724, 'learning_rate': 0.08396292749740616, 'reg_lambda': 20.15364170728049, 'subsample': 0.8308436855579527, 'random_strength': 37.53657028733111, 'depth': 4, 'min_data_in_leaf': 25, 'leaf_estimation_iterations': 12}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:08:00,224]\u001b[0m Trial 43 finished with value: 7.820295116995142 and parameters: {'iterations': 22838, 'learning_rate': 0.012636197204605466, 'reg_lambda': 9.943210534836107, 'subsample': 0.8934363851221648, 'random_strength': 44.59494782312951, 'depth': 6, 'min_data_in_leaf': 33, 'leaf_estimation_iterations': 14}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:08:31,178]\u001b[0m Trial 44 finished with value: 7.826807389656933 and parameters: {'iterations': 22741, 'learning_rate': 0.012527139886367484, 'reg_lambda': 11.096196225698314, 'subsample': 0.9036174576142538, 'random_strength': 49.83718820446248, 'depth': 7, 'min_data_in_leaf': 32, 'leaf_estimation_iterations': 14}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:08:46,364]\u001b[0m Trial 45 finished with value: 7.823444008437318 and parameters: {'iterations': 20696, 'learning_rate': 0.041028581259005506, 'reg_lambda': 16.66414532012014, 'subsample': 0.7696843554247421, 'random_strength': 45.58455504592564, 'depth': 6, 'min_data_in_leaf': 36, 'leaf_estimation_iterations': 14}. Best is trial 33 with value: 7.8189224071220105.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:09:34,184]\u001b[0m Trial 46 finished with value: 7.81816022153966 and parameters: {'iterations': 23712, 'learning_rate': 0.014513866466145036, 'reg_lambda': 0.514610922391622, 'subsample': 0.9326523243591447, 'random_strength': 43.40453068733296, 'depth': 5, 'min_data_in_leaf': 34, 'leaf_estimation_iterations': 13}. Best is trial 46 with value: 7.81816022153966.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:09:43,167]\u001b[0m Trial 47 finished with value: 7.832232089517489 and parameters: {'iterations': 23773, 'learning_rate': 0.12963956571146493, 'reg_lambda': 3.6819254311461656, 'subsample': 0.9228357214628892, 'random_strength': 15.279631133063084, 'depth': 4, 'min_data_in_leaf': 40, 'leaf_estimation_iterations': 13}. Best is trial 46 with value: 7.81816022153966.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:09:54,964]\u001b[0m Trial 48 finished with value: 7.824663574847787 and parameters: {'iterations': 21296, 'learning_rate': 0.06425664083130177, 'reg_lambda': 5.975569505149675, 'subsample': 0.8357882784807638, 'random_strength': 41.08086243488101, 'depth': 5, 'min_data_in_leaf': 29, 'leaf_estimation_iterations': 11}. Best is trial 46 with value: 7.81816022153966.\u001b[0m\n",
            "\u001b[32m[I 2021-08-30 08:10:06,403]\u001b[0m Trial 49 finished with value: 7.835381217464921 and parameters: {'iterations': 18846, 'learning_rate': 0.04679943951332917, 'reg_lambda': 2.113983571642642, 'subsample': 0.9954091170079136, 'random_strength': 48.245207993322346, 'depth': 7, 'min_data_in_leaf': 36, 'leaf_estimation_iterations': 12}. Best is trial 46 with value: 7.81816022153966.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of finished trials: 50\n",
            "Best trial: score 7.81816022153966, params {'iterations': 23712, 'learning_rate': 0.014513866466145036, 'reg_lambda': 0.514610922391622, 'subsample': 0.9326523243591447, 'random_strength': 43.40453068733296, 'depth': 5, 'min_data_in_leaf': 34, 'leaf_estimation_iterations': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPSwdl-Sdzhq",
        "outputId": "43c774fa-466f-442c-91de-a4aee604c1e0"
      },
      "source": [
        "sk = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "preds = np.zeros((x_test.shape[0],))\n",
        "params_cat = {'iterations':study.best_params['iterations'],\n",
        "         'loss_function':'RMSE',\n",
        "         'task_type':\"GPU\",\n",
        "         'eval_metric':'RMSE',\n",
        "         'leaf_estimation_method':'Newton',\n",
        "         'bootstrap_type': 'Bernoulli',\n",
        "         'learning_rate' : study.best_params['learning_rate'],\n",
        "         'reg_lambda': study.best_params['reg_lambda'],\n",
        "         'subsample': study.best_params['subsample'],\n",
        "         'random_strength': study.best_params['random_strength'],\n",
        "         'depth': study.best_params['depth'],\n",
        "         'min_data_in_leaf': study.best_params['min_data_in_leaf'],\n",
        "         'leaf_estimation_iterations': study.best_params['leaf_estimation_iterations'],\n",
        "         'grow_policy' : 'Depthwise',  \n",
        "}\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(sk.split(x_train, y_train)):\n",
        "  X_train, X_valid = x_train.iloc[train_index], x_train.iloc[valid_index]\n",
        "  Y_train, Y_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
        "\n",
        "  model_cat = catboost.CatBoostRegressor(**params_cat)\n",
        "  model_cat.fit(X_train, Y_train, eval_set=(X_valid, Y_valid), verbose=100, early_stopping_rounds=70)\n",
        "\n",
        "  preds += model_cat.predict(x_test) / sk.n_splits\n",
        "  val_preds = model_cat.predict(X_valid)\n",
        "  RMSE = np.sqrt(mean_squared_error(val_preds, Y_valid))\n",
        "  print(f'{i+1}번째 RMSE:{RMSE}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 7.9396218\ttest: 7.9387181\tbest: 7.9387181 (0)\ttotal: 16ms\tremaining: 6m 19s\n",
            "100:\tlearn: 7.8923048\ttest: 7.9125470\tbest: 7.9125470 (100)\ttotal: 1.54s\tremaining: 5m 59s\n",
            "200:\tlearn: 7.8582084\ttest: 7.8994234\tbest: 7.8994234 (200)\ttotal: 3.01s\tremaining: 5m 52s\n",
            "300:\tlearn: 7.8282597\ttest: 7.8892655\tbest: 7.8892655 (300)\ttotal: 4.47s\tremaining: 5m 48s\n",
            "400:\tlearn: 7.8012868\ttest: 7.8810336\tbest: 7.8810336 (400)\ttotal: 5.89s\tremaining: 5m 42s\n",
            "500:\tlearn: 7.7758829\ttest: 7.8741111\tbest: 7.8741111 (500)\ttotal: 7.36s\tremaining: 5m 40s\n",
            "600:\tlearn: 7.7520062\ttest: 7.8688716\tbest: 7.8688500 (599)\ttotal: 8.81s\tremaining: 5m 38s\n",
            "700:\tlearn: 7.7295744\ttest: 7.8643611\tbest: 7.8643611 (700)\ttotal: 10.3s\tremaining: 5m 36s\n",
            "800:\tlearn: 7.7084214\ttest: 7.8609999\tbest: 7.8609999 (800)\ttotal: 11.7s\tremaining: 5m 34s\n",
            "900:\tlearn: 7.6876388\ttest: 7.8584642\tbest: 7.8584324 (899)\ttotal: 13.1s\tremaining: 5m 32s\n",
            "1000:\tlearn: 7.6676277\ttest: 7.8559780\tbest: 7.8559780 (1000)\ttotal: 14.6s\tremaining: 5m 32s\n",
            "1100:\tlearn: 7.6484874\ttest: 7.8534021\tbest: 7.8534021 (1100)\ttotal: 16.1s\tremaining: 5m 30s\n",
            "1200:\tlearn: 7.6299590\ttest: 7.8512996\tbest: 7.8512996 (1200)\ttotal: 17.5s\tremaining: 5m 28s\n",
            "1300:\tlearn: 7.6118099\ttest: 7.8496516\tbest: 7.8496127 (1297)\ttotal: 18.9s\tremaining: 5m 26s\n",
            "1400:\tlearn: 7.5938669\ttest: 7.8482807\tbest: 7.8482785 (1399)\ttotal: 20.4s\tremaining: 5m 25s\n",
            "1500:\tlearn: 7.5760712\ttest: 7.8471692\tbest: 7.8471606 (1492)\ttotal: 21.9s\tremaining: 5m 23s\n",
            "1600:\tlearn: 7.5588868\ttest: 7.8463625\tbest: 7.8463625 (1600)\ttotal: 23.3s\tremaining: 5m 21s\n",
            "1700:\tlearn: 7.5419192\ttest: 7.8455535\tbest: 7.8455433 (1699)\ttotal: 24.7s\tremaining: 5m 19s\n",
            "1800:\tlearn: 7.5251076\ttest: 7.8447903\tbest: 7.8447157 (1794)\ttotal: 26.1s\tremaining: 5m 17s\n",
            "1900:\tlearn: 7.5081459\ttest: 7.8441172\tbest: 7.8441172 (1900)\ttotal: 27.6s\tremaining: 5m 16s\n",
            "2000:\tlearn: 7.4917258\ttest: 7.8436984\tbest: 7.8436608 (1974)\ttotal: 29s\tremaining: 5m 15s\n",
            "2100:\tlearn: 7.4756087\ttest: 7.8430718\tbest: 7.8430045 (2090)\ttotal: 30.6s\tremaining: 5m 14s\n",
            "bestTest = 7.84300102\n",
            "bestIteration = 2112\n",
            "Shrink model to first 2113 iterations.\n",
            "1번째 RMSE:7.843001254202245\n",
            "0:\tlearn: 7.9391227\ttest: 7.9406933\tbest: 7.9406933 (0)\ttotal: 15ms\tremaining: 5m 55s\n",
            "100:\tlearn: 7.8939600\ttest: 7.9136758\tbest: 7.9136758 (100)\ttotal: 1.36s\tremaining: 5m 17s\n",
            "200:\tlearn: 7.8597083\ttest: 7.9004117\tbest: 7.9004117 (200)\ttotal: 2.75s\tremaining: 5m 21s\n",
            "300:\tlearn: 7.8290581\ttest: 7.8899918\tbest: 7.8899918 (300)\ttotal: 4.19s\tremaining: 5m 26s\n",
            "400:\tlearn: 7.8022577\ttest: 7.8820080\tbest: 7.8820080 (400)\ttotal: 5.66s\tremaining: 5m 29s\n",
            "500:\tlearn: 7.7770431\ttest: 7.8751543\tbest: 7.8751543 (500)\ttotal: 7.14s\tremaining: 5m 30s\n",
            "600:\tlearn: 7.7531310\ttest: 7.8698583\tbest: 7.8698583 (600)\ttotal: 8.64s\tremaining: 5m 32s\n",
            "700:\tlearn: 7.7309847\ttest: 7.8655562\tbest: 7.8655562 (700)\ttotal: 10.1s\tremaining: 5m 32s\n",
            "800:\tlearn: 7.7091180\ttest: 7.8614693\tbest: 7.8614693 (800)\ttotal: 11.6s\tremaining: 5m 31s\n",
            "900:\tlearn: 7.6882872\ttest: 7.8581283\tbest: 7.8581283 (900)\ttotal: 13.1s\tremaining: 5m 32s\n",
            "1000:\tlearn: 7.6686677\ttest: 7.8551426\tbest: 7.8551426 (1000)\ttotal: 14.6s\tremaining: 5m 31s\n",
            "1100:\tlearn: 7.6497225\ttest: 7.8524926\tbest: 7.8524926 (1100)\ttotal: 16.1s\tremaining: 5m 29s\n",
            "1200:\tlearn: 7.6309328\ttest: 7.8508767\tbest: 7.8508710 (1198)\ttotal: 17.5s\tremaining: 5m 27s\n",
            "1300:\tlearn: 7.6129873\ttest: 7.8495025\tbest: 7.8495025 (1300)\ttotal: 18.9s\tremaining: 5m 25s\n",
            "1400:\tlearn: 7.5953749\ttest: 7.8484412\tbest: 7.8484412 (1400)\ttotal: 20.3s\tremaining: 5m 23s\n",
            "1500:\tlearn: 7.5779499\ttest: 7.8471549\tbest: 7.8471549 (1500)\ttotal: 21.7s\tremaining: 5m 21s\n",
            "1600:\tlearn: 7.5603538\ttest: 7.8460790\tbest: 7.8460739 (1598)\ttotal: 23.1s\tremaining: 5m 19s\n",
            "1700:\tlearn: 7.5435240\ttest: 7.8455930\tbest: 7.8455456 (1694)\ttotal: 24.6s\tremaining: 5m 17s\n",
            "1800:\tlearn: 7.5262411\ttest: 7.8449031\tbest: 7.8449031 (1800)\ttotal: 26s\tremaining: 5m 15s\n",
            "1900:\tlearn: 7.5094580\ttest: 7.8440203\tbest: 7.8440203 (1900)\ttotal: 27.4s\tremaining: 5m 14s\n",
            "2000:\tlearn: 7.4928302\ttest: 7.8437705\tbest: 7.8437185 (1975)\ttotal: 28.8s\tremaining: 5m 12s\n",
            "2100:\tlearn: 7.4764069\ttest: 7.8430447\tbest: 7.8430447 (2100)\ttotal: 30.3s\tremaining: 5m 11s\n",
            "2200:\tlearn: 7.4600395\ttest: 7.8429044\tbest: 7.8428828 (2199)\ttotal: 31.8s\tremaining: 5m 10s\n",
            "2300:\tlearn: 7.4436261\ttest: 7.8426686\tbest: 7.8426686 (2300)\ttotal: 33.2s\tremaining: 5m 9s\n",
            "2400:\tlearn: 7.4271044\ttest: 7.8420645\tbest: 7.8420590 (2398)\ttotal: 34.7s\tremaining: 5m 8s\n",
            "2500:\tlearn: 7.4106073\ttest: 7.8418132\tbest: 7.8418059 (2499)\ttotal: 36.2s\tremaining: 5m 6s\n",
            "2600:\tlearn: 7.3947265\ttest: 7.8416143\tbest: 7.8415643 (2589)\ttotal: 37.7s\tremaining: 5m 5s\n",
            "bestTest = 7.841564257\n",
            "bestIteration = 2589\n",
            "Shrink model to first 2590 iterations.\n",
            "2번째 RMSE:7.8415642815186475\n",
            "0:\tlearn: 7.9391278\ttest: 7.9407503\tbest: 7.9407503 (0)\ttotal: 16.7ms\tremaining: 6m 37s\n",
            "100:\tlearn: 7.8926957\ttest: 7.9147224\tbest: 7.9147224 (100)\ttotal: 1.5s\tremaining: 5m 50s\n",
            "200:\tlearn: 7.8583643\ttest: 7.9012198\tbest: 7.9012198 (200)\ttotal: 3.01s\tremaining: 5m 52s\n",
            "300:\tlearn: 7.8277098\ttest: 7.8909084\tbest: 7.8909084 (300)\ttotal: 4.53s\tremaining: 5m 52s\n",
            "400:\tlearn: 7.8001731\ttest: 7.8825402\tbest: 7.8825402 (400)\ttotal: 6.06s\tremaining: 5m 52s\n",
            "500:\tlearn: 7.7747833\ttest: 7.8759796\tbest: 7.8759796 (500)\ttotal: 7.59s\tremaining: 5m 51s\n",
            "600:\tlearn: 7.7509064\ttest: 7.8704336\tbest: 7.8704314 (599)\ttotal: 9.09s\tremaining: 5m 49s\n",
            "700:\tlearn: 7.7286341\ttest: 7.8659612\tbest: 7.8659612 (700)\ttotal: 10.5s\tremaining: 5m 46s\n",
            "800:\tlearn: 7.7070104\ttest: 7.8624207\tbest: 7.8624204 (799)\ttotal: 12s\tremaining: 5m 43s\n",
            "900:\tlearn: 7.6867265\ttest: 7.8593629\tbest: 7.8593591 (899)\ttotal: 13.4s\tremaining: 5m 40s\n",
            "1000:\tlearn: 7.6670385\ttest: 7.8568031\tbest: 7.8568031 (1000)\ttotal: 14.9s\tremaining: 5m 37s\n",
            "1100:\tlearn: 7.6475682\ttest: 7.8544249\tbest: 7.8544249 (1100)\ttotal: 16.3s\tremaining: 5m 34s\n",
            "1200:\tlearn: 7.6286322\ttest: 7.8530446\tbest: 7.8530446 (1200)\ttotal: 17.8s\tremaining: 5m 33s\n",
            "1300:\tlearn: 7.6108235\ttest: 7.8520497\tbest: 7.8520093 (1297)\ttotal: 19.2s\tremaining: 5m 30s\n",
            "1400:\tlearn: 7.5932598\ttest: 7.8509353\tbest: 7.8509229 (1399)\ttotal: 20.6s\tremaining: 5m 28s\n",
            "1500:\tlearn: 7.5753637\ttest: 7.8500752\tbest: 7.8500710 (1494)\ttotal: 22.1s\tremaining: 5m 27s\n",
            "1600:\tlearn: 7.5581870\ttest: 7.8490136\tbest: 7.8490136 (1600)\ttotal: 23.6s\tremaining: 5m 25s\n",
            "1700:\tlearn: 7.5411906\ttest: 7.8480431\tbest: 7.8480402 (1695)\ttotal: 25s\tremaining: 5m 24s\n",
            "1800:\tlearn: 7.5239843\ttest: 7.8476232\tbest: 7.8476108 (1799)\ttotal: 26.5s\tremaining: 5m 22s\n",
            "1900:\tlearn: 7.5072808\ttest: 7.8470803\tbest: 7.8470784 (1892)\ttotal: 27.9s\tremaining: 5m 20s\n",
            "2000:\tlearn: 7.4905180\ttest: 7.8465792\tbest: 7.8465792 (2000)\ttotal: 29.3s\tremaining: 5m 18s\n",
            "2100:\tlearn: 7.4741689\ttest: 7.8457074\tbest: 7.8457074 (2100)\ttotal: 30.8s\tremaining: 5m 16s\n",
            "2200:\tlearn: 7.4577574\ttest: 7.8455774\tbest: 7.8455181 (2193)\ttotal: 32.2s\tremaining: 5m 14s\n",
            "2300:\tlearn: 7.4416362\ttest: 7.8452696\tbest: 7.8452135 (2296)\ttotal: 33.6s\tremaining: 5m 12s\n",
            "2400:\tlearn: 7.4253057\ttest: 7.8450650\tbest: 7.8450421 (2389)\ttotal: 35s\tremaining: 5m 11s\n",
            "bestTest = 7.844811024\n",
            "bestIteration = 2426\n",
            "Shrink model to first 2427 iterations.\n",
            "3번째 RMSE:7.844811556087188\n",
            "0:\tlearn: 7.9395601\ttest: 7.9389096\tbest: 7.9389096 (0)\ttotal: 16.6ms\tremaining: 6m 34s\n",
            "100:\tlearn: 7.8931318\ttest: 7.9128023\tbest: 7.9128023 (100)\ttotal: 1.47s\tremaining: 5m 44s\n",
            "200:\tlearn: 7.8587671\ttest: 7.9000019\tbest: 7.9000019 (200)\ttotal: 2.92s\tremaining: 5m 41s\n",
            "300:\tlearn: 7.8278420\ttest: 7.8906033\tbest: 7.8906033 (300)\ttotal: 4.38s\tremaining: 5m 41s\n",
            "400:\tlearn: 7.7999285\ttest: 7.8830261\tbest: 7.8830261 (400)\ttotal: 5.81s\tremaining: 5m 37s\n",
            "500:\tlearn: 7.7741646\ttest: 7.8767922\tbest: 7.8767922 (500)\ttotal: 7.25s\tremaining: 5m 35s\n",
            "600:\tlearn: 7.7500877\ttest: 7.8720071\tbest: 7.8720071 (600)\ttotal: 8.67s\tremaining: 5m 33s\n",
            "700:\tlearn: 7.7277603\ttest: 7.8680010\tbest: 7.8680010 (700)\ttotal: 10.1s\tremaining: 5m 31s\n",
            "800:\tlearn: 7.7058608\ttest: 7.8648020\tbest: 7.8648020 (800)\ttotal: 11.6s\tremaining: 5m 30s\n",
            "900:\tlearn: 7.6847570\ttest: 7.8614881\tbest: 7.8614881 (900)\ttotal: 13s\tremaining: 5m 29s\n",
            "1000:\tlearn: 7.6650144\ttest: 7.8596924\tbest: 7.8596867 (996)\ttotal: 14.5s\tremaining: 5m 28s\n",
            "1100:\tlearn: 7.6460699\ttest: 7.8580061\tbest: 7.8580061 (1100)\ttotal: 15.9s\tremaining: 5m 26s\n",
            "1200:\tlearn: 7.6272000\ttest: 7.8564404\tbest: 7.8564404 (1200)\ttotal: 17.3s\tremaining: 5m 24s\n",
            "1300:\tlearn: 7.6086461\ttest: 7.8550977\tbest: 7.8550853 (1295)\ttotal: 18.7s\tremaining: 5m 22s\n",
            "1400:\tlearn: 7.5903999\ttest: 7.8535584\tbest: 7.8535584 (1400)\ttotal: 20.1s\tremaining: 5m 20s\n",
            "1500:\tlearn: 7.5730638\ttest: 7.8524764\tbest: 7.8524764 (1500)\ttotal: 21.5s\tremaining: 5m 18s\n",
            "1600:\tlearn: 7.5556892\ttest: 7.8515030\tbest: 7.8514938 (1594)\ttotal: 22.9s\tremaining: 5m 16s\n",
            "1700:\tlearn: 7.5385383\ttest: 7.8505334\tbest: 7.8504758 (1698)\ttotal: 24.3s\tremaining: 5m 15s\n",
            "1800:\tlearn: 7.5217225\ttest: 7.8497392\tbest: 7.8497392 (1800)\ttotal: 25.8s\tremaining: 5m 13s\n",
            "1900:\tlearn: 7.5051962\ttest: 7.8492694\tbest: 7.8491410 (1885)\ttotal: 27.1s\tremaining: 5m 11s\n",
            "bestTest = 7.849141036\n",
            "bestIteration = 1885\n",
            "Shrink model to first 1886 iterations.\n",
            "4번째 RMSE:7.849142110082292\n",
            "0:\tlearn: 7.9395771\ttest: 7.9388866\tbest: 7.9388866 (0)\ttotal: 15.6ms\tremaining: 6m 9s\n",
            "100:\tlearn: 7.8937086\ttest: 7.9120519\tbest: 7.9120519 (100)\ttotal: 1.42s\tremaining: 5m 31s\n",
            "200:\tlearn: 7.8595922\ttest: 7.8978377\tbest: 7.8978377 (200)\ttotal: 2.82s\tremaining: 5m 29s\n",
            "300:\tlearn: 7.8288326\ttest: 7.8868856\tbest: 7.8868856 (300)\ttotal: 4.21s\tremaining: 5m 27s\n",
            "400:\tlearn: 7.8015066\ttest: 7.8789793\tbest: 7.8789793 (400)\ttotal: 5.61s\tremaining: 5m 26s\n",
            "500:\tlearn: 7.7759536\ttest: 7.8727146\tbest: 7.8727146 (500)\ttotal: 7.04s\tremaining: 5m 26s\n",
            "600:\tlearn: 7.7519304\ttest: 7.8674481\tbest: 7.8674481 (600)\ttotal: 8.47s\tremaining: 5m 25s\n",
            "700:\tlearn: 7.7294243\ttest: 7.8635517\tbest: 7.8635517 (700)\ttotal: 9.9s\tremaining: 5m 24s\n",
            "800:\tlearn: 7.7079693\ttest: 7.8601406\tbest: 7.8601406 (800)\ttotal: 11.3s\tremaining: 5m 24s\n",
            "900:\tlearn: 7.6874193\ttest: 7.8575308\tbest: 7.8575174 (897)\ttotal: 12.8s\tremaining: 5m 23s\n",
            "1000:\tlearn: 7.6673095\ttest: 7.8551801\tbest: 7.8551801 (1000)\ttotal: 14.2s\tremaining: 5m 21s\n",
            "1100:\tlearn: 7.6483018\ttest: 7.8532267\tbest: 7.8532267 (1100)\ttotal: 15.6s\tremaining: 5m 20s\n",
            "1200:\tlearn: 7.6293483\ttest: 7.8512913\tbest: 7.8512913 (1200)\ttotal: 17s\tremaining: 5m 19s\n",
            "1300:\tlearn: 7.6111119\ttest: 7.8496631\tbest: 7.8496580 (1299)\ttotal: 18.5s\tremaining: 5m 18s\n",
            "1400:\tlearn: 7.5934195\ttest: 7.8485008\tbest: 7.8485008 (1400)\ttotal: 19.9s\tremaining: 5m 16s\n",
            "1500:\tlearn: 7.5760679\ttest: 7.8473237\tbest: 7.8473190 (1499)\ttotal: 21.3s\tremaining: 5m 15s\n",
            "1600:\tlearn: 7.5590757\ttest: 7.8460136\tbest: 7.8460136 (1600)\ttotal: 22.7s\tremaining: 5m 13s\n",
            "1700:\tlearn: 7.5424366\ttest: 7.8450497\tbest: 7.8450494 (1699)\ttotal: 24.1s\tremaining: 5m 11s\n",
            "1800:\tlearn: 7.5257897\ttest: 7.8444732\tbest: 7.8444732 (1800)\ttotal: 25.5s\tremaining: 5m 10s\n",
            "1900:\tlearn: 7.5086467\ttest: 7.8436911\tbest: 7.8436911 (1900)\ttotal: 27s\tremaining: 5m 9s\n",
            "2000:\tlearn: 7.4918623\ttest: 7.8427712\tbest: 7.8427712 (2000)\ttotal: 28.4s\tremaining: 5m 7s\n",
            "2100:\tlearn: 7.4758879\ttest: 7.8426073\tbest: 7.8425149 (2094)\ttotal: 29.8s\tremaining: 5m 6s\n",
            "2200:\tlearn: 7.4597624\ttest: 7.8420504\tbest: 7.8420504 (2200)\ttotal: 31.2s\tremaining: 5m 4s\n",
            "2300:\tlearn: 7.4437632\ttest: 7.8414705\tbest: 7.8414705 (2300)\ttotal: 32.7s\tremaining: 5m 4s\n",
            "bestTest = 7.8414667\n",
            "bestIteration = 2301\n",
            "Shrink model to first 2302 iterations.\n",
            "5번째 RMSE:7.841467077682003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgIJ08Lf6yq2"
      },
      "source": [
        "# voting regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6lYeqixdEIW"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z7sPGwW64N2"
      },
      "source": [
        "cat = catboost.CatBoostRegressor(**params_cat)\n",
        "lgb = lightgbm.LGBMRegressor(**best_lgb_params)\n",
        "xgb = xgboost.XGBRegressor(**params_xgb)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4BWRfMA6x4V",
        "outputId": "2edf3b06-2617-4f15-ba42-a84ced5db3f5"
      },
      "source": [
        "from sklearn.ensemble import VotingRegressor\n",
        "folds = KFold(n_splits = 10, random_state = 42, shuffle = True)\n",
        "\n",
        "predictions = np.zeros((len(x_test),))\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(folds.split(x_train)):\n",
        "    print(f\"Fold: {fold}\")\n",
        "    X_train, X_val = x_train.values[trn_idx], x_train.values[val_idx]\n",
        "    Y_train, Y_val = y_train.values[trn_idx], y_train.values[val_idx]\n",
        "\n",
        "    model = VotingRegressor(\n",
        "            estimators = [\n",
        "                ('xgb', xgb),\n",
        "                ('cat', cat),\n",
        "                ('lgb', lgb)\n",
        "            ],\n",
        "            weights = [0.25, 0.5, 0.25]\n",
        "        )\n",
        "   \n",
        "    model.fit(X_train, Y_train)\n",
        "    pred = model.predict(X_val)\n",
        "    error = mean_squared_error(Y_val, pred,squared = False)\n",
        "    print(f\" mean_squared_error: {error}\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    predictions += model.predict(x_test) / folds.n_splits "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "7183:\tlearn: 7.7301637\ttotal: 42.7s\tremaining: 29.7s\n",
            "7184:\tlearn: 7.7301482\ttotal: 42.7s\tremaining: 29.7s\n",
            "7185:\tlearn: 7.7301358\ttotal: 42.7s\tremaining: 29.7s\n",
            "7186:\tlearn: 7.7301134\ttotal: 42.7s\tremaining: 29.7s\n",
            "7187:\tlearn: 7.7301010\ttotal: 42.7s\tremaining: 29.7s\n",
            "7188:\tlearn: 7.7300898\ttotal: 42.7s\tremaining: 29.7s\n",
            "7189:\tlearn: 7.7300717\ttotal: 42.8s\tremaining: 29.7s\n",
            "7190:\tlearn: 7.7300381\ttotal: 42.8s\tremaining: 29.7s\n",
            "7191:\tlearn: 7.7300286\ttotal: 42.8s\tremaining: 29.7s\n",
            "7192:\tlearn: 7.7300122\ttotal: 42.8s\tremaining: 29.7s\n",
            "7193:\tlearn: 7.7300016\ttotal: 42.8s\tremaining: 29.7s\n",
            "7194:\tlearn: 7.7299800\ttotal: 42.8s\tremaining: 29.6s\n",
            "7195:\tlearn: 7.7299564\ttotal: 42.8s\tremaining: 29.6s\n",
            "7196:\tlearn: 7.7299415\ttotal: 42.8s\tremaining: 29.6s\n",
            "7197:\tlearn: 7.7299375\ttotal: 42.8s\tremaining: 29.6s\n",
            "7198:\tlearn: 7.7299274\ttotal: 42.8s\tremaining: 29.6s\n",
            "7199:\tlearn: 7.7299176\ttotal: 42.8s\tremaining: 29.6s\n",
            "7200:\tlearn: 7.7299076\ttotal: 42.8s\tremaining: 29.6s\n",
            "7201:\tlearn: 7.7298852\ttotal: 42.8s\tremaining: 29.6s\n",
            "7202:\tlearn: 7.7298731\ttotal: 42.8s\tremaining: 29.6s\n",
            "7203:\tlearn: 7.7298466\ttotal: 42.8s\tremaining: 29.6s\n",
            "7204:\tlearn: 7.7298383\ttotal: 42.8s\tremaining: 29.6s\n",
            "7205:\tlearn: 7.7298262\ttotal: 42.8s\tremaining: 29.6s\n",
            "7206:\tlearn: 7.7298254\ttotal: 42.9s\tremaining: 29.6s\n",
            "7207:\tlearn: 7.7298061\ttotal: 42.9s\tremaining: 29.6s\n",
            "7208:\tlearn: 7.7297937\ttotal: 42.9s\tremaining: 29.6s\n",
            "7209:\tlearn: 7.7297722\ttotal: 42.9s\tremaining: 29.6s\n",
            "7210:\tlearn: 7.7297592\ttotal: 42.9s\tremaining: 29.6s\n",
            "7211:\tlearn: 7.7297543\ttotal: 42.9s\tremaining: 29.5s\n",
            "7212:\tlearn: 7.7297417\ttotal: 42.9s\tremaining: 29.5s\n",
            "7213:\tlearn: 7.7297351\ttotal: 42.9s\tremaining: 29.5s\n",
            "7214:\tlearn: 7.7297288\ttotal: 42.9s\tremaining: 29.5s\n",
            "7215:\tlearn: 7.7297161\ttotal: 42.9s\tremaining: 29.5s\n",
            "7216:\tlearn: 7.7296848\ttotal: 42.9s\tremaining: 29.5s\n",
            "7217:\tlearn: 7.7296805\ttotal: 42.9s\tremaining: 29.5s\n",
            "7218:\tlearn: 7.7296727\ttotal: 42.9s\tremaining: 29.5s\n",
            "7219:\tlearn: 7.7296638\ttotal: 42.9s\tremaining: 29.5s\n",
            "7220:\tlearn: 7.7296500\ttotal: 42.9s\tremaining: 29.5s\n",
            "7221:\tlearn: 7.7296250\ttotal: 42.9s\tremaining: 29.5s\n",
            "7222:\tlearn: 7.7296063\ttotal: 43s\tremaining: 29.5s\n",
            "7223:\tlearn: 7.7295974\ttotal: 43s\tremaining: 29.5s\n",
            "7224:\tlearn: 7.7295916\ttotal: 43s\tremaining: 29.5s\n",
            "7225:\tlearn: 7.7295873\ttotal: 43s\tremaining: 29.5s\n",
            "7226:\tlearn: 7.7295836\ttotal: 43s\tremaining: 29.5s\n",
            "7227:\tlearn: 7.7295824\ttotal: 43s\tremaining: 29.5s\n",
            "7228:\tlearn: 7.7295611\ttotal: 43s\tremaining: 29.5s\n",
            "7229:\tlearn: 7.7295427\ttotal: 43s\tremaining: 29.4s\n",
            "7230:\tlearn: 7.7295356\ttotal: 43s\tremaining: 29.4s\n",
            "7231:\tlearn: 7.7295151\ttotal: 43s\tremaining: 29.4s\n",
            "7232:\tlearn: 7.7295025\ttotal: 43s\tremaining: 29.4s\n",
            "7233:\tlearn: 7.7294947\ttotal: 43s\tremaining: 29.4s\n",
            "7234:\tlearn: 7.7294855\ttotal: 43s\tremaining: 29.4s\n",
            "7235:\tlearn: 7.7294620\ttotal: 43s\tremaining: 29.4s\n",
            "7236:\tlearn: 7.7294441\ttotal: 43s\tremaining: 29.4s\n",
            "7237:\tlearn: 7.7294272\ttotal: 43s\tremaining: 29.4s\n",
            "7238:\tlearn: 7.7294070\ttotal: 43.1s\tremaining: 29.4s\n",
            "7239:\tlearn: 7.7293907\ttotal: 43.1s\tremaining: 29.4s\n",
            "7240:\tlearn: 7.7293751\ttotal: 43.1s\tremaining: 29.4s\n",
            "7241:\tlearn: 7.7293639\ttotal: 43.1s\tremaining: 29.4s\n",
            "7242:\tlearn: 7.7293553\ttotal: 43.1s\tremaining: 29.4s\n",
            "7243:\tlearn: 7.7293441\ttotal: 43.1s\tremaining: 29.4s\n",
            "7244:\tlearn: 7.7293283\ttotal: 43.1s\tremaining: 29.4s\n",
            "7245:\tlearn: 7.7293056\ttotal: 43.1s\tremaining: 29.3s\n",
            "7246:\tlearn: 7.7292926\ttotal: 43.1s\tremaining: 29.3s\n",
            "7247:\tlearn: 7.7292834\ttotal: 43.1s\tremaining: 29.3s\n",
            "7248:\tlearn: 7.7292682\ttotal: 43.1s\tremaining: 29.3s\n",
            "7249:\tlearn: 7.7292466\ttotal: 43.1s\tremaining: 29.3s\n",
            "7250:\tlearn: 7.7292455\ttotal: 43.1s\tremaining: 29.3s\n",
            "7251:\tlearn: 7.7292380\ttotal: 43.1s\tremaining: 29.3s\n",
            "7252:\tlearn: 7.7292219\ttotal: 43.1s\tremaining: 29.3s\n",
            "7253:\tlearn: 7.7292044\ttotal: 43.1s\tremaining: 29.3s\n",
            "7254:\tlearn: 7.7291908\ttotal: 43.1s\tremaining: 29.3s\n",
            "7255:\tlearn: 7.7291788\ttotal: 43.1s\tremaining: 29.3s\n",
            "7256:\tlearn: 7.7291687\ttotal: 43.2s\tremaining: 29.3s\n",
            "7257:\tlearn: 7.7291572\ttotal: 43.2s\tremaining: 29.3s\n",
            "7258:\tlearn: 7.7291417\ttotal: 43.2s\tremaining: 29.3s\n",
            "7259:\tlearn: 7.7291259\ttotal: 43.2s\tremaining: 29.3s\n",
            "7260:\tlearn: 7.7291152\ttotal: 43.2s\tremaining: 29.3s\n",
            "7261:\tlearn: 7.7290974\ttotal: 43.2s\tremaining: 29.2s\n",
            "7262:\tlearn: 7.7290830\ttotal: 43.2s\tremaining: 29.2s\n",
            "7263:\tlearn: 7.7290652\ttotal: 43.2s\tremaining: 29.2s\n",
            "7264:\tlearn: 7.7290336\ttotal: 43.2s\tremaining: 29.2s\n",
            "7265:\tlearn: 7.7290195\ttotal: 43.2s\tremaining: 29.2s\n",
            "7266:\tlearn: 7.7290169\ttotal: 43.2s\tremaining: 29.2s\n",
            "7267:\tlearn: 7.7290091\ttotal: 43.2s\tremaining: 29.2s\n",
            "7268:\tlearn: 7.7290002\ttotal: 43.2s\tremaining: 29.2s\n",
            "7269:\tlearn: 7.7289902\ttotal: 43.2s\tremaining: 29.2s\n",
            "7270:\tlearn: 7.7289755\ttotal: 43.2s\tremaining: 29.2s\n",
            "7271:\tlearn: 7.7289551\ttotal: 43.2s\tremaining: 29.2s\n",
            "7272:\tlearn: 7.7289519\ttotal: 43.2s\tremaining: 29.2s\n",
            "7273:\tlearn: 7.7289447\ttotal: 43.3s\tremaining: 29.2s\n",
            "7274:\tlearn: 7.7289404\ttotal: 43.3s\tremaining: 29.2s\n",
            "7275:\tlearn: 7.7289286\ttotal: 43.3s\tremaining: 29.2s\n",
            "7276:\tlearn: 7.7289148\ttotal: 43.3s\tremaining: 29.2s\n",
            "7277:\tlearn: 7.7289088\ttotal: 43.3s\tremaining: 29.2s\n",
            "7278:\tlearn: 7.7288970\ttotal: 43.3s\tremaining: 29.1s\n",
            "7279:\tlearn: 7.7288907\ttotal: 43.3s\tremaining: 29.1s\n",
            "7280:\tlearn: 7.7288867\ttotal: 43.3s\tremaining: 29.1s\n",
            "7281:\tlearn: 7.7288812\ttotal: 43.3s\tremaining: 29.1s\n",
            "7282:\tlearn: 7.7288766\ttotal: 43.3s\tremaining: 29.1s\n",
            "7283:\tlearn: 7.7288579\ttotal: 43.3s\tremaining: 29.1s\n",
            "7284:\tlearn: 7.7288475\ttotal: 43.3s\tremaining: 29.1s\n",
            "7285:\tlearn: 7.7288309\ttotal: 43.3s\tremaining: 29.1s\n",
            "7286:\tlearn: 7.7288208\ttotal: 43.3s\tremaining: 29.1s\n",
            "7287:\tlearn: 7.7287995\ttotal: 43.3s\tremaining: 29.1s\n",
            "7288:\tlearn: 7.7287987\ttotal: 43.3s\tremaining: 29.1s\n",
            "7289:\tlearn: 7.7287941\ttotal: 43.3s\tremaining: 29.1s\n",
            "7290:\tlearn: 7.7287872\ttotal: 43.3s\tremaining: 29.1s\n",
            "7291:\tlearn: 7.7287806\ttotal: 43.4s\tremaining: 29.1s\n",
            "7292:\tlearn: 7.7287711\ttotal: 43.4s\tremaining: 29.1s\n",
            "7293:\tlearn: 7.7287475\ttotal: 43.4s\tremaining: 29.1s\n",
            "7294:\tlearn: 7.7287420\ttotal: 43.4s\tremaining: 29s\n",
            "7295:\tlearn: 7.7287320\ttotal: 43.4s\tremaining: 29s\n",
            "7296:\tlearn: 7.7287219\ttotal: 43.4s\tremaining: 29s\n",
            "7297:\tlearn: 7.7287127\ttotal: 43.4s\tremaining: 29s\n",
            "7298:\tlearn: 7.7286917\ttotal: 43.4s\tremaining: 29s\n",
            "7299:\tlearn: 7.7286845\ttotal: 43.4s\tremaining: 29s\n",
            "7300:\tlearn: 7.7286765\ttotal: 43.4s\tremaining: 29s\n",
            "7301:\tlearn: 7.7286604\ttotal: 43.4s\tremaining: 29s\n",
            "7302:\tlearn: 7.7286480\ttotal: 43.4s\tremaining: 29s\n",
            "7303:\tlearn: 7.7286336\ttotal: 43.4s\tremaining: 29s\n",
            "7304:\tlearn: 7.7286170\ttotal: 43.4s\tremaining: 29s\n",
            "7305:\tlearn: 7.7285957\ttotal: 43.4s\tremaining: 29s\n",
            "7306:\tlearn: 7.7285896\ttotal: 43.4s\tremaining: 29s\n",
            "7307:\tlearn: 7.7285761\ttotal: 43.5s\tremaining: 29s\n",
            "7308:\tlearn: 7.7285571\ttotal: 43.5s\tremaining: 29s\n",
            "7309:\tlearn: 7.7285387\ttotal: 43.5s\tremaining: 29s\n",
            "7310:\tlearn: 7.7285341\ttotal: 43.5s\tremaining: 29s\n",
            "7311:\tlearn: 7.7285284\ttotal: 43.5s\tremaining: 28.9s\n",
            "7312:\tlearn: 7.7285063\ttotal: 43.5s\tremaining: 28.9s\n",
            "7313:\tlearn: 7.7285040\ttotal: 43.5s\tremaining: 28.9s\n",
            "7314:\tlearn: 7.7284913\ttotal: 43.5s\tremaining: 28.9s\n",
            "7315:\tlearn: 7.7284827\ttotal: 43.5s\tremaining: 28.9s\n",
            "7316:\tlearn: 7.7284597\ttotal: 43.5s\tremaining: 28.9s\n",
            "7317:\tlearn: 7.7284416\ttotal: 43.5s\tremaining: 28.9s\n",
            "7318:\tlearn: 7.7284355\ttotal: 43.5s\tremaining: 28.9s\n",
            "7319:\tlearn: 7.7284243\ttotal: 43.5s\tremaining: 28.9s\n",
            "7320:\tlearn: 7.7284108\ttotal: 43.5s\tremaining: 28.9s\n",
            "7321:\tlearn: 7.7284033\ttotal: 43.5s\tremaining: 28.9s\n",
            "7322:\tlearn: 7.7283950\ttotal: 43.5s\tremaining: 28.9s\n",
            "7323:\tlearn: 7.7283863\ttotal: 43.5s\tremaining: 28.9s\n",
            "7324:\tlearn: 7.7283760\ttotal: 43.5s\tremaining: 28.9s\n",
            "7325:\tlearn: 7.7283708\ttotal: 43.5s\tremaining: 28.9s\n",
            "7326:\tlearn: 7.7283633\ttotal: 43.5s\tremaining: 28.9s\n",
            "7327:\tlearn: 7.7283398\ttotal: 43.6s\tremaining: 28.8s\n",
            "7328:\tlearn: 7.7283271\ttotal: 43.6s\tremaining: 28.8s\n",
            "7329:\tlearn: 7.7283142\ttotal: 43.6s\tremaining: 28.8s\n",
            "7330:\tlearn: 7.7282989\ttotal: 43.6s\tremaining: 28.8s\n",
            "7331:\tlearn: 7.7282762\ttotal: 43.6s\tremaining: 28.8s\n",
            "7332:\tlearn: 7.7282716\ttotal: 43.6s\tremaining: 28.8s\n",
            "7333:\tlearn: 7.7282532\ttotal: 43.6s\tremaining: 28.8s\n",
            "7334:\tlearn: 7.7282432\ttotal: 43.6s\tremaining: 28.8s\n",
            "7335:\tlearn: 7.7282322\ttotal: 43.6s\tremaining: 28.8s\n",
            "7336:\tlearn: 7.7282259\ttotal: 43.6s\tremaining: 28.8s\n",
            "7337:\tlearn: 7.7282150\ttotal: 43.6s\tremaining: 28.8s\n",
            "7338:\tlearn: 7.7282063\ttotal: 43.6s\tremaining: 28.8s\n",
            "7339:\tlearn: 7.7281874\ttotal: 43.6s\tremaining: 28.8s\n",
            "7340:\tlearn: 7.7281690\ttotal: 43.6s\tremaining: 28.8s\n",
            "7341:\tlearn: 7.7281598\ttotal: 43.6s\tremaining: 28.8s\n",
            "7342:\tlearn: 7.7281555\ttotal: 43.6s\tremaining: 28.8s\n",
            "7343:\tlearn: 7.7281391\ttotal: 43.7s\tremaining: 28.8s\n",
            "7344:\tlearn: 7.7281336\ttotal: 43.7s\tremaining: 28.7s\n",
            "7345:\tlearn: 7.7281212\ttotal: 43.7s\tremaining: 28.7s\n",
            "7346:\tlearn: 7.7281074\ttotal: 43.7s\tremaining: 28.7s\n",
            "7347:\tlearn: 7.7281028\ttotal: 43.7s\tremaining: 28.7s\n",
            "7348:\tlearn: 7.7280816\ttotal: 43.7s\tremaining: 28.7s\n",
            "7349:\tlearn: 7.7280686\ttotal: 43.7s\tremaining: 28.7s\n",
            "7350:\tlearn: 7.7280623\ttotal: 43.7s\tremaining: 28.7s\n",
            "7351:\tlearn: 7.7280525\ttotal: 43.7s\tremaining: 28.7s\n",
            "7352:\tlearn: 7.7280416\ttotal: 43.7s\tremaining: 28.7s\n",
            "7353:\tlearn: 7.7280307\ttotal: 43.7s\tremaining: 28.7s\n",
            "7354:\tlearn: 7.7280235\ttotal: 43.7s\tremaining: 28.7s\n",
            "7355:\tlearn: 7.7280203\ttotal: 43.7s\tremaining: 28.7s\n",
            "7356:\tlearn: 7.7280097\ttotal: 43.7s\tremaining: 28.7s\n",
            "7357:\tlearn: 7.7280002\ttotal: 43.7s\tremaining: 28.7s\n",
            "7358:\tlearn: 7.7279987\ttotal: 43.7s\tremaining: 28.7s\n",
            "7359:\tlearn: 7.7279812\ttotal: 43.7s\tremaining: 28.7s\n",
            "7360:\tlearn: 7.7279691\ttotal: 43.8s\tremaining: 28.6s\n",
            "7361:\tlearn: 7.7279605\ttotal: 43.8s\tremaining: 28.6s\n",
            "7362:\tlearn: 7.7279527\ttotal: 43.8s\tremaining: 28.6s\n",
            "7363:\tlearn: 7.7279349\ttotal: 43.8s\tremaining: 28.6s\n",
            "7364:\tlearn: 7.7279320\ttotal: 43.8s\tremaining: 28.6s\n",
            "7365:\tlearn: 7.7279199\ttotal: 43.8s\tremaining: 28.6s\n",
            "7366:\tlearn: 7.7279059\ttotal: 43.8s\tremaining: 28.6s\n",
            "7367:\tlearn: 7.7278903\ttotal: 43.8s\tremaining: 28.6s\n",
            "7368:\tlearn: 7.7278800\ttotal: 43.8s\tremaining: 28.6s\n",
            "7369:\tlearn: 7.7278604\ttotal: 43.8s\tremaining: 28.6s\n",
            "7370:\tlearn: 7.7278541\ttotal: 43.8s\tremaining: 28.6s\n",
            "7371:\tlearn: 7.7278452\ttotal: 43.8s\tremaining: 28.6s\n",
            "7372:\tlearn: 7.7278297\ttotal: 43.8s\tremaining: 28.6s\n",
            "7373:\tlearn: 7.7278112\ttotal: 43.8s\tremaining: 28.6s\n",
            "7374:\tlearn: 7.7278052\ttotal: 43.8s\tremaining: 28.6s\n",
            "7375:\tlearn: 7.7277891\ttotal: 43.8s\tremaining: 28.6s\n",
            "7376:\tlearn: 7.7277681\ttotal: 43.9s\tremaining: 28.6s\n",
            "7377:\tlearn: 7.7277488\ttotal: 43.9s\tremaining: 28.6s\n",
            "7378:\tlearn: 7.7277350\ttotal: 43.9s\tremaining: 28.5s\n",
            "7379:\tlearn: 7.7277250\ttotal: 43.9s\tremaining: 28.5s\n",
            "7380:\tlearn: 7.7277100\ttotal: 43.9s\tremaining: 28.5s\n",
            "7381:\tlearn: 7.7277023\ttotal: 43.9s\tremaining: 28.5s\n",
            "7382:\tlearn: 7.7276804\ttotal: 43.9s\tremaining: 28.5s\n",
            "7383:\tlearn: 7.7276775\ttotal: 43.9s\tremaining: 28.5s\n",
            "7384:\tlearn: 7.7276652\ttotal: 43.9s\tremaining: 28.5s\n",
            "7385:\tlearn: 7.7276537\ttotal: 43.9s\tremaining: 28.5s\n",
            "7386:\tlearn: 7.7276419\ttotal: 43.9s\tremaining: 28.5s\n",
            "7387:\tlearn: 7.7276238\ttotal: 43.9s\tremaining: 28.5s\n",
            "7388:\tlearn: 7.7275996\ttotal: 43.9s\tremaining: 28.5s\n",
            "7389:\tlearn: 7.7275881\ttotal: 43.9s\tremaining: 28.5s\n",
            "7390:\tlearn: 7.7275763\ttotal: 43.9s\tremaining: 28.5s\n",
            "7391:\tlearn: 7.7275545\ttotal: 44s\tremaining: 28.5s\n",
            "7392:\tlearn: 7.7275481\ttotal: 44s\tremaining: 28.5s\n",
            "7393:\tlearn: 7.7275369\ttotal: 44s\tremaining: 28.5s\n",
            "7394:\tlearn: 7.7275297\ttotal: 44s\tremaining: 28.5s\n",
            "7395:\tlearn: 7.7275199\ttotal: 44s\tremaining: 28.4s\n",
            "7396:\tlearn: 7.7275096\ttotal: 44s\tremaining: 28.4s\n",
            "7397:\tlearn: 7.7274958\ttotal: 44s\tremaining: 28.4s\n",
            "7398:\tlearn: 7.7274869\ttotal: 44s\tremaining: 28.4s\n",
            "7399:\tlearn: 7.7274765\ttotal: 44s\tremaining: 28.4s\n",
            "7400:\tlearn: 7.7274688\ttotal: 44s\tremaining: 28.4s\n",
            "7401:\tlearn: 7.7274636\ttotal: 44s\tremaining: 28.4s\n",
            "7402:\tlearn: 7.7274509\ttotal: 44s\tremaining: 28.4s\n",
            "7403:\tlearn: 7.7274397\ttotal: 44s\tremaining: 28.4s\n",
            "7404:\tlearn: 7.7274288\ttotal: 44s\tremaining: 28.4s\n",
            "7405:\tlearn: 7.7274158\ttotal: 44s\tremaining: 28.4s\n",
            "7406:\tlearn: 7.7274020\ttotal: 44s\tremaining: 28.4s\n",
            "7407:\tlearn: 7.7273951\ttotal: 44s\tremaining: 28.4s\n",
            "7408:\tlearn: 7.7273856\ttotal: 44.1s\tremaining: 28.4s\n",
            "7409:\tlearn: 7.7273747\ttotal: 44.1s\tremaining: 28.4s\n",
            "7410:\tlearn: 7.7273572\ttotal: 44.1s\tremaining: 28.4s\n",
            "7411:\tlearn: 7.7273471\ttotal: 44.1s\tremaining: 28.4s\n",
            "7412:\tlearn: 7.7273336\ttotal: 44.1s\tremaining: 28.4s\n",
            "7413:\tlearn: 7.7273342\ttotal: 44.1s\tremaining: 28.3s\n",
            "7414:\tlearn: 7.7273253\ttotal: 44.1s\tremaining: 28.3s\n",
            "7415:\tlearn: 7.7273071\ttotal: 44.1s\tremaining: 28.3s\n",
            "7416:\tlearn: 7.7272864\ttotal: 44.1s\tremaining: 28.3s\n",
            "7417:\tlearn: 7.7272703\ttotal: 44.1s\tremaining: 28.3s\n",
            "7418:\tlearn: 7.7272649\ttotal: 44.1s\tremaining: 28.3s\n",
            "7419:\tlearn: 7.7272577\ttotal: 44.1s\tremaining: 28.3s\n",
            "7420:\tlearn: 7.7272407\ttotal: 44.1s\tremaining: 28.3s\n",
            "7421:\tlearn: 7.7272306\ttotal: 44.1s\tremaining: 28.3s\n",
            "7422:\tlearn: 7.7272082\ttotal: 44.1s\tremaining: 28.3s\n",
            "7423:\tlearn: 7.7271944\ttotal: 44.1s\tremaining: 28.3s\n",
            "7424:\tlearn: 7.7271806\ttotal: 44.1s\tremaining: 28.3s\n",
            "7425:\tlearn: 7.7271754\ttotal: 44.1s\tremaining: 28.3s\n",
            "7426:\tlearn: 7.7271656\ttotal: 44.2s\tremaining: 28.3s\n",
            "7427:\tlearn: 7.7271579\ttotal: 44.2s\tremaining: 28.3s\n",
            "7428:\tlearn: 7.7271455\ttotal: 44.2s\tremaining: 28.3s\n",
            "7429:\tlearn: 7.7271320\ttotal: 44.2s\tremaining: 28.2s\n",
            "7430:\tlearn: 7.7271274\ttotal: 44.2s\tremaining: 28.2s\n",
            "7431:\tlearn: 7.7271208\ttotal: 44.2s\tremaining: 28.2s\n",
            "7432:\tlearn: 7.7270983\ttotal: 44.2s\tremaining: 28.2s\n",
            "7433:\tlearn: 7.7270874\ttotal: 44.2s\tremaining: 28.2s\n",
            "7434:\tlearn: 7.7270745\ttotal: 44.2s\tremaining: 28.2s\n",
            "7435:\tlearn: 7.7270569\ttotal: 44.2s\tremaining: 28.2s\n",
            "7436:\tlearn: 7.7270437\ttotal: 44.2s\tremaining: 28.2s\n",
            "7437:\tlearn: 7.7270368\ttotal: 44.2s\tremaining: 28.2s\n",
            "7438:\tlearn: 7.7270221\ttotal: 44.2s\tremaining: 28.2s\n",
            "7439:\tlearn: 7.7270069\ttotal: 44.2s\tremaining: 28.2s\n",
            "7440:\tlearn: 7.7269876\ttotal: 44.2s\tremaining: 28.2s\n",
            "7441:\tlearn: 7.7269767\ttotal: 44.3s\tremaining: 28.2s\n",
            "7442:\tlearn: 7.7269606\ttotal: 44.3s\tremaining: 28.2s\n",
            "7443:\tlearn: 7.7269465\ttotal: 44.3s\tremaining: 28.2s\n",
            "7444:\tlearn: 7.7269258\ttotal: 44.3s\tremaining: 28.2s\n",
            "7445:\tlearn: 7.7269149\ttotal: 44.3s\tremaining: 28.2s\n",
            "7446:\tlearn: 7.7269045\ttotal: 44.3s\tremaining: 28.1s\n",
            "7447:\tlearn: 7.7268804\ttotal: 44.3s\tremaining: 28.1s\n",
            "7448:\tlearn: 7.7268729\ttotal: 44.3s\tremaining: 28.1s\n",
            "7449:\tlearn: 7.7268585\ttotal: 44.3s\tremaining: 28.1s\n",
            "7450:\tlearn: 7.7268352\ttotal: 44.3s\tremaining: 28.1s\n",
            "7451:\tlearn: 7.7268297\ttotal: 44.3s\tremaining: 28.1s\n",
            "7452:\tlearn: 7.7268194\ttotal: 44.3s\tremaining: 28.1s\n",
            "7453:\tlearn: 7.7268079\ttotal: 44.3s\tremaining: 28.1s\n",
            "7454:\tlearn: 7.7267932\ttotal: 44.3s\tremaining: 28.1s\n",
            "7455:\tlearn: 7.7267808\ttotal: 44.3s\tremaining: 28.1s\n",
            "7456:\tlearn: 7.7267604\ttotal: 44.3s\tremaining: 28.1s\n",
            "7457:\tlearn: 7.7267590\ttotal: 44.3s\tremaining: 28.1s\n",
            "7458:\tlearn: 7.7267366\ttotal: 44.3s\tremaining: 28.1s\n",
            "7459:\tlearn: 7.7267236\ttotal: 44.3s\tremaining: 28.1s\n",
            "7460:\tlearn: 7.7267101\ttotal: 44.3s\tremaining: 28.1s\n",
            "7461:\tlearn: 7.7266957\ttotal: 44.4s\tremaining: 28s\n",
            "7462:\tlearn: 7.7266905\ttotal: 44.4s\tremaining: 28s\n",
            "7463:\tlearn: 7.7266805\ttotal: 44.4s\tremaining: 28s\n",
            "7464:\tlearn: 7.7266583\ttotal: 44.4s\tremaining: 28s\n",
            "7465:\tlearn: 7.7266460\ttotal: 44.4s\tremaining: 28s\n",
            "7466:\tlearn: 7.7266345\ttotal: 44.4s\tremaining: 28s\n",
            "7467:\tlearn: 7.7266100\ttotal: 44.4s\tremaining: 28s\n",
            "7468:\tlearn: 7.7265997\ttotal: 44.4s\tremaining: 28s\n",
            "7469:\tlearn: 7.7265838\ttotal: 44.4s\tremaining: 28s\n",
            "7470:\tlearn: 7.7265778\ttotal: 44.4s\tremaining: 28s\n",
            "7471:\tlearn: 7.7265634\ttotal: 44.4s\tremaining: 28s\n",
            "7472:\tlearn: 7.7265539\ttotal: 44.4s\tremaining: 28s\n",
            "7473:\tlearn: 7.7265479\ttotal: 44.4s\tremaining: 28s\n",
            "7474:\tlearn: 7.7265283\ttotal: 44.4s\tremaining: 28s\n",
            "7475:\tlearn: 7.7265128\ttotal: 44.4s\tremaining: 28s\n",
            "7476:\tlearn: 7.7264999\ttotal: 44.4s\tremaining: 28s\n",
            "7477:\tlearn: 7.7264932\ttotal: 44.5s\tremaining: 28s\n",
            "7478:\tlearn: 7.7264826\ttotal: 44.5s\tremaining: 28s\n",
            "7479:\tlearn: 7.7264803\ttotal: 44.5s\tremaining: 27.9s\n",
            "7480:\tlearn: 7.7264665\ttotal: 44.5s\tremaining: 27.9s\n",
            "7481:\tlearn: 7.7264584\ttotal: 44.5s\tremaining: 27.9s\n",
            "7482:\tlearn: 7.7264395\ttotal: 44.5s\tremaining: 27.9s\n",
            "7483:\tlearn: 7.7264311\ttotal: 44.5s\tremaining: 27.9s\n",
            "7484:\tlearn: 7.7264285\ttotal: 44.5s\tremaining: 27.9s\n",
            "7485:\tlearn: 7.7264236\ttotal: 44.5s\tremaining: 27.9s\n",
            "7486:\tlearn: 7.7264124\ttotal: 44.5s\tremaining: 27.9s\n",
            "7487:\tlearn: 7.7263989\ttotal: 44.5s\tremaining: 27.9s\n",
            "7488:\tlearn: 7.7263955\ttotal: 44.5s\tremaining: 27.9s\n",
            "7489:\tlearn: 7.7263825\ttotal: 44.5s\tremaining: 27.9s\n",
            "7490:\tlearn: 7.7263759\ttotal: 44.5s\tremaining: 27.9s\n",
            "7491:\tlearn: 7.7263581\ttotal: 44.5s\tremaining: 27.9s\n",
            "7492:\tlearn: 7.7263535\ttotal: 44.5s\tremaining: 27.9s\n",
            "7493:\tlearn: 7.7263345\ttotal: 44.5s\tremaining: 27.9s\n",
            "7494:\tlearn: 7.7263316\ttotal: 44.6s\tremaining: 27.9s\n",
            "7495:\tlearn: 7.7263126\ttotal: 44.6s\tremaining: 27.8s\n",
            "7496:\tlearn: 7.7263008\ttotal: 44.6s\tremaining: 27.8s\n",
            "7497:\tlearn: 7.7262856\ttotal: 44.6s\tremaining: 27.8s\n",
            "7498:\tlearn: 7.7262732\ttotal: 44.6s\tremaining: 27.8s\n",
            "7499:\tlearn: 7.7262620\ttotal: 44.6s\tremaining: 27.8s\n",
            "7500:\tlearn: 7.7262485\ttotal: 44.6s\tremaining: 27.8s\n",
            "7501:\tlearn: 7.7262393\ttotal: 44.6s\tremaining: 27.8s\n",
            "7502:\tlearn: 7.7262324\ttotal: 44.6s\tremaining: 27.8s\n",
            "7503:\tlearn: 7.7262186\ttotal: 44.6s\tremaining: 27.8s\n",
            "7504:\tlearn: 7.7262048\ttotal: 44.6s\tremaining: 27.8s\n",
            "7505:\tlearn: 7.7261901\ttotal: 44.6s\tremaining: 27.8s\n",
            "7506:\tlearn: 7.7261780\ttotal: 44.6s\tremaining: 27.8s\n",
            "7507:\tlearn: 7.7261723\ttotal: 44.6s\tremaining: 27.8s\n",
            "7508:\tlearn: 7.7261659\ttotal: 44.6s\tremaining: 27.8s\n",
            "7509:\tlearn: 7.7261475\ttotal: 44.6s\tremaining: 27.8s\n",
            "7510:\tlearn: 7.7261452\ttotal: 44.7s\tremaining: 27.8s\n",
            "7511:\tlearn: 7.7261311\ttotal: 44.7s\tremaining: 27.8s\n",
            "7512:\tlearn: 7.7261188\ttotal: 44.7s\tremaining: 27.8s\n",
            "7513:\tlearn: 7.7261107\ttotal: 44.7s\tremaining: 27.7s\n",
            "7514:\tlearn: 7.7261024\ttotal: 44.7s\tremaining: 27.7s\n",
            "7515:\tlearn: 7.7260837\ttotal: 44.7s\tremaining: 27.7s\n",
            "7516:\tlearn: 7.7260771\ttotal: 44.7s\tremaining: 27.7s\n",
            "7517:\tlearn: 7.7260690\ttotal: 44.7s\tremaining: 27.7s\n",
            "7518:\tlearn: 7.7260607\ttotal: 44.7s\tremaining: 27.7s\n",
            "7519:\tlearn: 7.7260489\ttotal: 44.7s\tremaining: 27.7s\n",
            "7520:\tlearn: 7.7260351\ttotal: 44.7s\tremaining: 27.7s\n",
            "7521:\tlearn: 7.7260227\ttotal: 44.7s\tremaining: 27.7s\n",
            "7522:\tlearn: 7.7260069\ttotal: 44.7s\tremaining: 27.7s\n",
            "7523:\tlearn: 7.7259925\ttotal: 44.7s\tremaining: 27.7s\n",
            "7524:\tlearn: 7.7259847\ttotal: 44.7s\tremaining: 27.7s\n",
            "7525:\tlearn: 7.7259752\ttotal: 44.7s\tremaining: 27.7s\n",
            "7526:\tlearn: 7.7259600\ttotal: 44.7s\tremaining: 27.7s\n",
            "7527:\tlearn: 7.7259476\ttotal: 44.7s\tremaining: 27.7s\n",
            "7528:\tlearn: 7.7259289\ttotal: 44.8s\tremaining: 27.7s\n",
            "7529:\tlearn: 7.7259191\ttotal: 44.8s\tremaining: 27.6s\n",
            "7530:\tlearn: 7.7259088\ttotal: 44.8s\tremaining: 27.6s\n",
            "7531:\tlearn: 7.7259042\ttotal: 44.8s\tremaining: 27.6s\n",
            "7532:\tlearn: 7.7258887\ttotal: 44.8s\tremaining: 27.6s\n",
            "7533:\tlearn: 7.7258769\ttotal: 44.8s\tremaining: 27.6s\n",
            "7534:\tlearn: 7.7258679\ttotal: 44.8s\tremaining: 27.6s\n",
            "7535:\tlearn: 7.7258587\ttotal: 44.8s\tremaining: 27.6s\n",
            "7536:\tlearn: 7.7258386\ttotal: 44.8s\tremaining: 27.6s\n",
            "7537:\tlearn: 7.7258113\ttotal: 44.8s\tremaining: 27.6s\n",
            "7538:\tlearn: 7.7257995\ttotal: 44.8s\tremaining: 27.6s\n",
            "7539:\tlearn: 7.7257917\ttotal: 44.8s\tremaining: 27.6s\n",
            "7540:\tlearn: 7.7257868\ttotal: 44.8s\tremaining: 27.6s\n",
            "7541:\tlearn: 7.7257753\ttotal: 44.8s\tremaining: 27.6s\n",
            "7542:\tlearn: 7.7257538\ttotal: 44.8s\tremaining: 27.6s\n",
            "7543:\tlearn: 7.7257460\ttotal: 44.8s\tremaining: 27.6s\n",
            "7544:\tlearn: 7.7257325\ttotal: 44.9s\tremaining: 27.6s\n",
            "7545:\tlearn: 7.7257195\ttotal: 44.9s\tremaining: 27.6s\n",
            "7546:\tlearn: 7.7257017\ttotal: 44.9s\tremaining: 27.5s\n",
            "7547:\tlearn: 7.7256888\ttotal: 44.9s\tremaining: 27.5s\n",
            "7548:\tlearn: 7.7256847\ttotal: 44.9s\tremaining: 27.5s\n",
            "7549:\tlearn: 7.7256632\ttotal: 44.9s\tremaining: 27.5s\n",
            "7550:\tlearn: 7.7256522\ttotal: 44.9s\tremaining: 27.5s\n",
            "7551:\tlearn: 7.7256381\ttotal: 44.9s\tremaining: 27.5s\n",
            "7552:\tlearn: 7.7256309\ttotal: 44.9s\tremaining: 27.5s\n",
            "7553:\tlearn: 7.7256160\ttotal: 44.9s\tremaining: 27.5s\n",
            "7554:\tlearn: 7.7256013\ttotal: 44.9s\tremaining: 27.5s\n",
            "7555:\tlearn: 7.7255826\ttotal: 44.9s\tremaining: 27.5s\n",
            "7556:\tlearn: 7.7255711\ttotal: 44.9s\tremaining: 27.5s\n",
            "7557:\tlearn: 7.7255605\ttotal: 44.9s\tremaining: 27.5s\n",
            "7558:\tlearn: 7.7255501\ttotal: 44.9s\tremaining: 27.5s\n",
            "7559:\tlearn: 7.7255282\ttotal: 44.9s\tremaining: 27.5s\n",
            "7560:\tlearn: 7.7255124\ttotal: 45s\tremaining: 27.5s\n",
            "7561:\tlearn: 7.7254900\ttotal: 45s\tremaining: 27.5s\n",
            "7562:\tlearn: 7.7254816\ttotal: 45s\tremaining: 27.5s\n",
            "7563:\tlearn: 7.7254710\ttotal: 45s\tremaining: 27.4s\n",
            "7564:\tlearn: 7.7254598\ttotal: 45s\tremaining: 27.4s\n",
            "7565:\tlearn: 7.7254540\ttotal: 45s\tremaining: 27.4s\n",
            "7566:\tlearn: 7.7254497\ttotal: 45s\tremaining: 27.4s\n",
            "7567:\tlearn: 7.7254330\ttotal: 45s\tremaining: 27.4s\n",
            "7568:\tlearn: 7.7254241\ttotal: 45s\tremaining: 27.4s\n",
            "7569:\tlearn: 7.7254140\ttotal: 45s\tremaining: 27.4s\n",
            "7570:\tlearn: 7.7254054\ttotal: 45s\tremaining: 27.4s\n",
            "7571:\tlearn: 7.7253925\ttotal: 45s\tremaining: 27.4s\n",
            "7572:\tlearn: 7.7253879\ttotal: 45s\tremaining: 27.4s\n",
            "7573:\tlearn: 7.7253818\ttotal: 45s\tremaining: 27.4s\n",
            "7574:\tlearn: 7.7253637\ttotal: 45s\tremaining: 27.4s\n",
            "7575:\tlearn: 7.7253588\ttotal: 45s\tremaining: 27.4s\n",
            "7576:\tlearn: 7.7253390\ttotal: 45s\tremaining: 27.4s\n",
            "7577:\tlearn: 7.7253301\ttotal: 45s\tremaining: 27.4s\n",
            "7578:\tlearn: 7.7253171\ttotal: 45s\tremaining: 27.4s\n",
            "7579:\tlearn: 7.7253076\ttotal: 45.1s\tremaining: 27.3s\n",
            "7580:\tlearn: 7.7253027\ttotal: 45.1s\tremaining: 27.3s\n",
            "7581:\tlearn: 7.7252973\ttotal: 45.1s\tremaining: 27.3s\n",
            "7582:\tlearn: 7.7252832\ttotal: 45.1s\tremaining: 27.3s\n",
            "7583:\tlearn: 7.7252731\ttotal: 45.1s\tremaining: 27.3s\n",
            "7584:\tlearn: 7.7252648\ttotal: 45.1s\tremaining: 27.3s\n",
            "7585:\tlearn: 7.7252466\ttotal: 45.1s\tremaining: 27.3s\n",
            "7586:\tlearn: 7.7252432\ttotal: 45.1s\tremaining: 27.3s\n",
            "7587:\tlearn: 7.7252374\ttotal: 45.1s\tremaining: 27.3s\n",
            "7588:\tlearn: 7.7252302\ttotal: 45.1s\tremaining: 27.3s\n",
            "7589:\tlearn: 7.7252207\ttotal: 45.1s\tremaining: 27.3s\n",
            "7590:\tlearn: 7.7251969\ttotal: 45.1s\tremaining: 27.3s\n",
            "7591:\tlearn: 7.7251877\ttotal: 45.1s\tremaining: 27.3s\n",
            "7592:\tlearn: 7.7251851\ttotal: 45.1s\tremaining: 27.3s\n",
            "7593:\tlearn: 7.7251733\ttotal: 45.1s\tremaining: 27.3s\n",
            "7594:\tlearn: 7.7251612\ttotal: 45.1s\tremaining: 27.3s\n",
            "7595:\tlearn: 7.7251500\ttotal: 45.1s\tremaining: 27.2s\n",
            "7596:\tlearn: 7.7251379\ttotal: 45.1s\tremaining: 27.2s\n",
            "7597:\tlearn: 7.7251264\ttotal: 45.2s\tremaining: 27.2s\n",
            "7598:\tlearn: 7.7251209\ttotal: 45.2s\tremaining: 27.2s\n",
            "7599:\tlearn: 7.7251034\ttotal: 45.2s\tremaining: 27.2s\n",
            "7600:\tlearn: 7.7250876\ttotal: 45.2s\tremaining: 27.2s\n",
            "7601:\tlearn: 7.7250832\ttotal: 45.2s\tremaining: 27.2s\n",
            "7602:\tlearn: 7.7250755\ttotal: 45.2s\tremaining: 27.2s\n",
            "7603:\tlearn: 7.7250717\ttotal: 45.2s\tremaining: 27.2s\n",
            "7604:\tlearn: 7.7250553\ttotal: 45.2s\tremaining: 27.2s\n",
            "7605:\tlearn: 7.7250487\ttotal: 45.2s\tremaining: 27.2s\n",
            "7606:\tlearn: 7.7250326\ttotal: 45.2s\tremaining: 27.2s\n",
            "7607:\tlearn: 7.7250197\ttotal: 45.2s\tremaining: 27.2s\n",
            "7608:\tlearn: 7.7250053\ttotal: 45.2s\tremaining: 27.2s\n",
            "7609:\tlearn: 7.7249987\ttotal: 45.2s\tremaining: 27.2s\n",
            "7610:\tlearn: 7.7249759\ttotal: 45.2s\tremaining: 27.2s\n",
            "7611:\tlearn: 7.7249688\ttotal: 45.2s\tremaining: 27.2s\n",
            "7612:\tlearn: 7.7249316\ttotal: 45.2s\tremaining: 27.1s\n",
            "7613:\tlearn: 7.7249181\ttotal: 45.2s\tremaining: 27.1s\n",
            "7614:\tlearn: 7.7249092\ttotal: 45.3s\tremaining: 27.1s\n",
            "7615:\tlearn: 7.7248934\ttotal: 45.3s\tremaining: 27.1s\n",
            "7616:\tlearn: 7.7248865\ttotal: 45.3s\tremaining: 27.1s\n",
            "7617:\tlearn: 7.7248744\ttotal: 45.3s\tremaining: 27.1s\n",
            "7618:\tlearn: 7.7248632\ttotal: 45.3s\tremaining: 27.1s\n",
            "7619:\tlearn: 7.7248508\ttotal: 45.3s\tremaining: 27.1s\n",
            "7620:\tlearn: 7.7248396\ttotal: 45.3s\tremaining: 27.1s\n",
            "7621:\tlearn: 7.7248284\ttotal: 45.3s\tremaining: 27.1s\n",
            "7622:\tlearn: 7.7248180\ttotal: 45.3s\tremaining: 27.1s\n",
            "7623:\tlearn: 7.7248077\ttotal: 45.3s\tremaining: 27.1s\n",
            "7624:\tlearn: 7.7247904\ttotal: 45.3s\tremaining: 27.1s\n",
            "7625:\tlearn: 7.7247723\ttotal: 45.3s\tremaining: 27.1s\n",
            "7626:\tlearn: 7.7247645\ttotal: 45.3s\tremaining: 27.1s\n",
            "7627:\tlearn: 7.7247461\ttotal: 45.3s\tremaining: 27.1s\n",
            "7628:\tlearn: 7.7247288\ttotal: 45.3s\tremaining: 27.1s\n",
            "7629:\tlearn: 7.7247219\ttotal: 45.3s\tremaining: 27s\n",
            "7630:\tlearn: 7.7247055\ttotal: 45.3s\tremaining: 27s\n",
            "7631:\tlearn: 7.7246782\ttotal: 45.4s\tremaining: 27s\n",
            "7632:\tlearn: 7.7246724\ttotal: 45.4s\tremaining: 27s\n",
            "7633:\tlearn: 7.7246647\ttotal: 45.4s\tremaining: 27s\n",
            "7634:\tlearn: 7.7246471\ttotal: 45.4s\tremaining: 27s\n",
            "7635:\tlearn: 7.7246425\ttotal: 45.4s\tremaining: 27s\n",
            "7636:\tlearn: 7.7246330\ttotal: 45.4s\tremaining: 27s\n",
            "7637:\tlearn: 7.7246227\ttotal: 45.4s\tremaining: 27s\n",
            "7638:\tlearn: 7.7246169\ttotal: 45.4s\tremaining: 27s\n",
            "7639:\tlearn: 7.7245948\ttotal: 45.4s\tremaining: 27s\n",
            "7640:\tlearn: 7.7245896\ttotal: 45.4s\tremaining: 27s\n",
            "7641:\tlearn: 7.7245861\ttotal: 45.4s\tremaining: 27s\n",
            "7642:\tlearn: 7.7245746\ttotal: 45.4s\tremaining: 27s\n",
            "7643:\tlearn: 7.7245637\ttotal: 45.4s\tremaining: 27s\n",
            "7644:\tlearn: 7.7245539\ttotal: 45.4s\tremaining: 27s\n",
            "7645:\tlearn: 7.7245433\ttotal: 45.4s\tremaining: 26.9s\n",
            "7646:\tlearn: 7.7245214\ttotal: 45.4s\tremaining: 26.9s\n",
            "7647:\tlearn: 7.7245188\ttotal: 45.4s\tremaining: 26.9s\n",
            "7648:\tlearn: 7.7245050\ttotal: 45.5s\tremaining: 26.9s\n",
            "7649:\tlearn: 7.7244955\ttotal: 45.5s\tremaining: 26.9s\n",
            "7650:\tlearn: 7.7244875\ttotal: 45.5s\tremaining: 26.9s\n",
            "7651:\tlearn: 7.7244797\ttotal: 45.5s\tremaining: 26.9s\n",
            "7652:\tlearn: 7.7244702\ttotal: 45.5s\tremaining: 26.9s\n",
            "7653:\tlearn: 7.7244691\ttotal: 45.5s\tremaining: 26.9s\n",
            "7654:\tlearn: 7.7244567\ttotal: 45.5s\tremaining: 26.9s\n",
            "7655:\tlearn: 7.7244389\ttotal: 45.5s\tremaining: 26.9s\n",
            "7656:\tlearn: 7.7244357\ttotal: 45.5s\tremaining: 26.9s\n",
            "7657:\tlearn: 7.7244345\ttotal: 45.5s\tremaining: 26.9s\n",
            "7658:\tlearn: 7.7244225\ttotal: 45.5s\tremaining: 26.9s\n",
            "7659:\tlearn: 7.7244118\ttotal: 45.5s\tremaining: 26.9s\n",
            "7660:\tlearn: 7.7244015\ttotal: 45.5s\tremaining: 26.9s\n",
            "7661:\tlearn: 7.7243781\ttotal: 45.5s\tremaining: 26.8s\n",
            "7662:\tlearn: 7.7243666\ttotal: 45.5s\tremaining: 26.8s\n",
            "7663:\tlearn: 7.7243554\ttotal: 45.5s\tremaining: 26.8s\n",
            "7664:\tlearn: 7.7243384\ttotal: 45.5s\tremaining: 26.8s\n",
            "7665:\tlearn: 7.7243255\ttotal: 45.5s\tremaining: 26.8s\n",
            "7666:\tlearn: 7.7243120\ttotal: 45.5s\tremaining: 26.8s\n",
            "7667:\tlearn: 7.7242947\ttotal: 45.6s\tremaining: 26.8s\n",
            "7668:\tlearn: 7.7242884\ttotal: 45.6s\tremaining: 26.8s\n",
            "7669:\tlearn: 7.7242685\ttotal: 45.6s\tremaining: 26.8s\n",
            "7670:\tlearn: 7.7242668\ttotal: 45.6s\tremaining: 26.8s\n",
            "7671:\tlearn: 7.7242527\ttotal: 45.6s\tremaining: 26.8s\n",
            "7672:\tlearn: 7.7242464\ttotal: 45.6s\tremaining: 26.8s\n",
            "7673:\tlearn: 7.7242401\ttotal: 45.6s\tremaining: 26.8s\n",
            "7674:\tlearn: 7.7242271\ttotal: 45.6s\tremaining: 26.8s\n",
            "7675:\tlearn: 7.7242064\ttotal: 45.6s\tremaining: 26.8s\n",
            "7676:\tlearn: 7.7241958\ttotal: 45.6s\tremaining: 26.8s\n",
            "7677:\tlearn: 7.7241860\ttotal: 45.6s\tremaining: 26.8s\n",
            "7678:\tlearn: 7.7241825\ttotal: 45.6s\tremaining: 26.7s\n",
            "7679:\tlearn: 7.7241788\ttotal: 45.6s\tremaining: 26.7s\n",
            "7680:\tlearn: 7.7241699\ttotal: 45.6s\tremaining: 26.7s\n",
            "7681:\tlearn: 7.7241517\ttotal: 45.6s\tremaining: 26.7s\n",
            "7682:\tlearn: 7.7241371\ttotal: 45.6s\tremaining: 26.7s\n",
            "7683:\tlearn: 7.7241195\ttotal: 45.7s\tremaining: 26.7s\n",
            "7684:\tlearn: 7.7241083\ttotal: 45.7s\tremaining: 26.7s\n",
            "7685:\tlearn: 7.7241060\ttotal: 45.7s\tremaining: 26.7s\n",
            "7686:\tlearn: 7.7240994\ttotal: 45.7s\tremaining: 26.7s\n",
            "7687:\tlearn: 7.7240815\ttotal: 45.7s\tremaining: 26.7s\n",
            "7688:\tlearn: 7.7240700\ttotal: 45.7s\tremaining: 26.7s\n",
            "7689:\tlearn: 7.7240614\ttotal: 45.7s\tremaining: 26.7s\n",
            "7690:\tlearn: 7.7240528\ttotal: 45.7s\tremaining: 26.7s\n",
            "7691:\tlearn: 7.7240392\ttotal: 45.7s\tremaining: 26.7s\n",
            "7692:\tlearn: 7.7240355\ttotal: 45.7s\tremaining: 26.7s\n",
            "7693:\tlearn: 7.7240300\ttotal: 45.7s\tremaining: 26.7s\n",
            "7694:\tlearn: 7.7240148\ttotal: 45.7s\tremaining: 26.7s\n",
            "7695:\tlearn: 7.7240021\ttotal: 45.7s\tremaining: 26.6s\n",
            "7696:\tlearn: 7.7239921\ttotal: 45.7s\tremaining: 26.6s\n",
            "7697:\tlearn: 7.7239800\ttotal: 45.7s\tremaining: 26.6s\n",
            "7698:\tlearn: 7.7239621\ttotal: 45.7s\tremaining: 26.6s\n",
            "7699:\tlearn: 7.7239544\ttotal: 45.7s\tremaining: 26.6s\n",
            "7700:\tlearn: 7.7239457\ttotal: 45.8s\tremaining: 26.6s\n",
            "7701:\tlearn: 7.7239270\ttotal: 45.8s\tremaining: 26.6s\n",
            "7702:\tlearn: 7.7239210\ttotal: 45.8s\tremaining: 26.6s\n",
            "7703:\tlearn: 7.7238937\ttotal: 45.8s\tremaining: 26.6s\n",
            "7704:\tlearn: 7.7238787\ttotal: 45.8s\tremaining: 26.6s\n",
            "7705:\tlearn: 7.7238738\ttotal: 45.8s\tremaining: 26.6s\n",
            "7706:\tlearn: 7.7238678\ttotal: 45.8s\tremaining: 26.6s\n",
            "7707:\tlearn: 7.7238629\ttotal: 45.8s\tremaining: 26.6s\n",
            "7708:\tlearn: 7.7238502\ttotal: 45.8s\tremaining: 26.6s\n",
            "7709:\tlearn: 7.7238479\ttotal: 45.8s\tremaining: 26.6s\n",
            "7710:\tlearn: 7.7238307\ttotal: 45.8s\tremaining: 26.6s\n",
            "7711:\tlearn: 7.7238160\ttotal: 45.8s\tremaining: 26.5s\n",
            "7712:\tlearn: 7.7237973\ttotal: 45.8s\tremaining: 26.5s\n",
            "7713:\tlearn: 7.7237679\ttotal: 45.8s\tremaining: 26.5s\n",
            "7714:\tlearn: 7.7237481\ttotal: 45.8s\tremaining: 26.5s\n",
            "7715:\tlearn: 7.7237377\ttotal: 45.8s\tremaining: 26.5s\n",
            "7716:\tlearn: 7.7237262\ttotal: 45.9s\tremaining: 26.5s\n",
            "7717:\tlearn: 7.7237173\ttotal: 45.9s\tremaining: 26.5s\n",
            "7718:\tlearn: 7.7236949\ttotal: 45.9s\tremaining: 26.5s\n",
            "7719:\tlearn: 7.7236831\ttotal: 45.9s\tremaining: 26.5s\n",
            "7720:\tlearn: 7.7236799\ttotal: 45.9s\tremaining: 26.5s\n",
            "7721:\tlearn: 7.7236681\ttotal: 45.9s\tremaining: 26.5s\n",
            "7722:\tlearn: 7.7236589\ttotal: 45.9s\tremaining: 26.5s\n",
            "7723:\tlearn: 7.7236528\ttotal: 45.9s\tremaining: 26.5s\n",
            "7724:\tlearn: 7.7236457\ttotal: 45.9s\tremaining: 26.5s\n",
            "7725:\tlearn: 7.7236313\ttotal: 45.9s\tremaining: 26.5s\n",
            "7726:\tlearn: 7.7236221\ttotal: 45.9s\tremaining: 26.5s\n",
            "7727:\tlearn: 7.7236114\ttotal: 45.9s\tremaining: 26.5s\n",
            "7728:\tlearn: 7.7235881\ttotal: 45.9s\tremaining: 26.4s\n",
            "7729:\tlearn: 7.7235755\ttotal: 45.9s\tremaining: 26.4s\n",
            "7730:\tlearn: 7.7235611\ttotal: 45.9s\tremaining: 26.4s\n",
            "7731:\tlearn: 7.7235501\ttotal: 45.9s\tremaining: 26.4s\n",
            "7732:\tlearn: 7.7235271\ttotal: 45.9s\tremaining: 26.4s\n",
            "7733:\tlearn: 7.7235214\ttotal: 45.9s\tremaining: 26.4s\n",
            "7734:\tlearn: 7.7235041\ttotal: 46s\tremaining: 26.4s\n",
            "7735:\tlearn: 7.7234794\ttotal: 46s\tremaining: 26.4s\n",
            "7736:\tlearn: 7.7234739\ttotal: 46s\tremaining: 26.4s\n",
            "7737:\tlearn: 7.7234653\ttotal: 46s\tremaining: 26.4s\n",
            "7738:\tlearn: 7.7234575\ttotal: 46s\tremaining: 26.4s\n",
            "7739:\tlearn: 7.7234497\ttotal: 46s\tremaining: 26.4s\n",
            "7740:\tlearn: 7.7234327\ttotal: 46s\tremaining: 26.4s\n",
            "7741:\tlearn: 7.7234224\ttotal: 46s\tremaining: 26.4s\n",
            "7742:\tlearn: 7.7234163\ttotal: 46s\tremaining: 26.4s\n",
            "7743:\tlearn: 7.7234086\ttotal: 46s\tremaining: 26.4s\n",
            "7744:\tlearn: 7.7233959\ttotal: 46s\tremaining: 26.3s\n",
            "7745:\tlearn: 7.7233833\ttotal: 46s\tremaining: 26.3s\n",
            "7746:\tlearn: 7.7233715\ttotal: 46s\tremaining: 26.3s\n",
            "7747:\tlearn: 7.7233660\ttotal: 46s\tremaining: 26.3s\n",
            "7748:\tlearn: 7.7233433\ttotal: 46s\tremaining: 26.3s\n",
            "7749:\tlearn: 7.7233338\ttotal: 46s\tremaining: 26.3s\n",
            "7750:\tlearn: 7.7233237\ttotal: 46.1s\tremaining: 26.3s\n",
            "7751:\tlearn: 7.7233142\ttotal: 46.1s\tremaining: 26.3s\n",
            "7752:\tlearn: 7.7233073\ttotal: 46.1s\tremaining: 26.3s\n",
            "7753:\tlearn: 7.7232998\ttotal: 46.1s\tremaining: 26.3s\n",
            "7754:\tlearn: 7.7232964\ttotal: 46.1s\tremaining: 26.3s\n",
            "7755:\tlearn: 7.7232762\ttotal: 46.1s\tremaining: 26.3s\n",
            "7756:\tlearn: 7.7232716\ttotal: 46.1s\tremaining: 26.3s\n",
            "7757:\tlearn: 7.7232572\ttotal: 46.1s\tremaining: 26.3s\n",
            "7758:\tlearn: 7.7232486\ttotal: 46.1s\tremaining: 26.3s\n",
            "7759:\tlearn: 7.7232279\ttotal: 46.1s\tremaining: 26.3s\n",
            "7760:\tlearn: 7.7232195\ttotal: 46.1s\tremaining: 26.3s\n",
            "7761:\tlearn: 7.7232011\ttotal: 46.1s\tremaining: 26.3s\n",
            "7762:\tlearn: 7.7231836\ttotal: 46.1s\tremaining: 26.2s\n",
            "7763:\tlearn: 7.7231611\ttotal: 46.1s\tremaining: 26.2s\n",
            "7764:\tlearn: 7.7231372\ttotal: 46.1s\tremaining: 26.2s\n",
            "7765:\tlearn: 7.7231249\ttotal: 46.1s\tremaining: 26.2s\n",
            "7766:\tlearn: 7.7231111\ttotal: 46.1s\tremaining: 26.2s\n",
            "7767:\tlearn: 7.7230993\ttotal: 46.1s\tremaining: 26.2s\n",
            "7768:\tlearn: 7.7230895\ttotal: 46.2s\tremaining: 26.2s\n",
            "7769:\tlearn: 7.7230745\ttotal: 46.2s\tremaining: 26.2s\n",
            "7770:\tlearn: 7.7230627\ttotal: 46.2s\tremaining: 26.2s\n",
            "7771:\tlearn: 7.7230573\ttotal: 46.2s\tremaining: 26.2s\n",
            "7772:\tlearn: 7.7230524\ttotal: 46.2s\tremaining: 26.2s\n",
            "7773:\tlearn: 7.7230296\ttotal: 46.2s\tremaining: 26.2s\n",
            "7774:\tlearn: 7.7230138\ttotal: 46.2s\tremaining: 26.2s\n",
            "7775:\tlearn: 7.7230098\ttotal: 46.2s\tremaining: 26.2s\n",
            "7776:\tlearn: 7.7229891\ttotal: 46.2s\tremaining: 26.2s\n",
            "7777:\tlearn: 7.7229767\ttotal: 46.2s\tremaining: 26.2s\n",
            "7778:\tlearn: 7.7229643\ttotal: 46.2s\tremaining: 26.1s\n",
            "7779:\tlearn: 7.7229465\ttotal: 46.2s\tremaining: 26.1s\n",
            "7780:\tlearn: 7.7229378\ttotal: 46.2s\tremaining: 26.1s\n",
            "7781:\tlearn: 7.7229289\ttotal: 46.2s\tremaining: 26.1s\n",
            "7782:\tlearn: 7.7229188\ttotal: 46.2s\tremaining: 26.1s\n",
            "7783:\tlearn: 7.7229151\ttotal: 46.2s\tremaining: 26.1s\n",
            "7784:\tlearn: 7.7229082\ttotal: 46.2s\tremaining: 26.1s\n",
            "7785:\tlearn: 7.7229013\ttotal: 46.3s\tremaining: 26.1s\n",
            "7786:\tlearn: 7.7228918\ttotal: 46.3s\tremaining: 26.1s\n",
            "7787:\tlearn: 7.7228806\ttotal: 46.3s\tremaining: 26.1s\n",
            "7788:\tlearn: 7.7228745\ttotal: 46.3s\tremaining: 26.1s\n",
            "7789:\tlearn: 7.7228682\ttotal: 46.3s\tremaining: 26.1s\n",
            "7790:\tlearn: 7.7228578\ttotal: 46.3s\tremaining: 26.1s\n",
            "7791:\tlearn: 7.7228489\ttotal: 46.3s\tremaining: 26.1s\n",
            "7792:\tlearn: 7.7228363\ttotal: 46.3s\tremaining: 26.1s\n",
            "7793:\tlearn: 7.7228233\ttotal: 46.3s\tremaining: 26.1s\n",
            "7794:\tlearn: 7.7228204\ttotal: 46.3s\tremaining: 26.1s\n",
            "7795:\tlearn: 7.7228020\ttotal: 46.3s\tremaining: 26.1s\n",
            "7796:\tlearn: 7.7227905\ttotal: 46.3s\tremaining: 26s\n",
            "7797:\tlearn: 7.7227698\ttotal: 46.3s\tremaining: 26s\n",
            "7798:\tlearn: 7.7227494\ttotal: 46.3s\tremaining: 26s\n",
            "7799:\tlearn: 7.7227298\ttotal: 46.3s\tremaining: 26s\n",
            "7800:\tlearn: 7.7227145\ttotal: 46.4s\tremaining: 26s\n",
            "7801:\tlearn: 7.7226981\ttotal: 46.4s\tremaining: 26s\n",
            "7802:\tlearn: 7.7226887\ttotal: 46.4s\tremaining: 26s\n",
            "7803:\tlearn: 7.7226803\ttotal: 46.4s\tremaining: 26s\n",
            "7804:\tlearn: 7.7226699\ttotal: 46.4s\tremaining: 26s\n",
            "7805:\tlearn: 7.7226561\ttotal: 46.4s\tremaining: 26s\n",
            "7806:\tlearn: 7.7226484\ttotal: 46.4s\tremaining: 26s\n",
            "7807:\tlearn: 7.7226366\ttotal: 46.4s\tremaining: 26s\n",
            "7808:\tlearn: 7.7226337\ttotal: 46.4s\tremaining: 26s\n",
            "7809:\tlearn: 7.7226210\ttotal: 46.4s\tremaining: 26s\n",
            "7810:\tlearn: 7.7226107\ttotal: 46.4s\tremaining: 26s\n",
            "7811:\tlearn: 7.7226015\ttotal: 46.4s\tremaining: 26s\n",
            "7812:\tlearn: 7.7225911\ttotal: 46.4s\tremaining: 25.9s\n",
            "7813:\tlearn: 7.7225842\ttotal: 46.4s\tremaining: 25.9s\n",
            "7814:\tlearn: 7.7225724\ttotal: 46.4s\tremaining: 25.9s\n",
            "7815:\tlearn: 7.7225689\ttotal: 46.4s\tremaining: 25.9s\n",
            "7816:\tlearn: 7.7225583\ttotal: 46.4s\tremaining: 25.9s\n",
            "7817:\tlearn: 7.7225433\ttotal: 46.4s\tremaining: 25.9s\n",
            "7818:\tlearn: 7.7225238\ttotal: 46.4s\tremaining: 25.9s\n",
            "7819:\tlearn: 7.7225059\ttotal: 46.5s\tremaining: 25.9s\n",
            "7820:\tlearn: 7.7224924\ttotal: 46.5s\tremaining: 25.9s\n",
            "7821:\tlearn: 7.7224783\ttotal: 46.5s\tremaining: 25.9s\n",
            "7822:\tlearn: 7.7224705\ttotal: 46.5s\tremaining: 25.9s\n",
            "7823:\tlearn: 7.7224561\ttotal: 46.5s\tremaining: 25.9s\n",
            "7824:\tlearn: 7.7224541\ttotal: 46.5s\tremaining: 25.9s\n",
            "7825:\tlearn: 7.7224277\ttotal: 46.5s\tremaining: 25.9s\n",
            "7826:\tlearn: 7.7224245\ttotal: 46.5s\tremaining: 25.9s\n",
            "7827:\tlearn: 7.7224127\ttotal: 46.5s\tremaining: 25.9s\n",
            "7828:\tlearn: 7.7223997\ttotal: 46.5s\tremaining: 25.9s\n",
            "7829:\tlearn: 7.7223937\ttotal: 46.5s\tremaining: 25.9s\n",
            "7830:\tlearn: 7.7223865\ttotal: 46.5s\tremaining: 25.8s\n",
            "7831:\tlearn: 7.7223747\ttotal: 46.5s\tremaining: 25.8s\n",
            "7832:\tlearn: 7.7223534\ttotal: 46.5s\tremaining: 25.8s\n",
            "7833:\tlearn: 7.7223359\ttotal: 46.5s\tremaining: 25.8s\n",
            "7834:\tlearn: 7.7223212\ttotal: 46.6s\tremaining: 25.8s\n",
            "7835:\tlearn: 7.7223045\ttotal: 46.6s\tremaining: 25.8s\n",
            "7836:\tlearn: 7.7222915\ttotal: 46.6s\tremaining: 25.8s\n",
            "7837:\tlearn: 7.7222820\ttotal: 46.6s\tremaining: 25.8s\n",
            "7838:\tlearn: 7.7222714\ttotal: 46.6s\tremaining: 25.8s\n",
            "7839:\tlearn: 7.7222487\ttotal: 46.6s\tremaining: 25.8s\n",
            "7840:\tlearn: 7.7222400\ttotal: 46.6s\tremaining: 25.8s\n",
            "7841:\tlearn: 7.7222282\ttotal: 46.6s\tremaining: 25.8s\n",
            "7842:\tlearn: 7.7222069\ttotal: 46.6s\tremaining: 25.8s\n",
            "7843:\tlearn: 7.7221931\ttotal: 46.6s\tremaining: 25.8s\n",
            "7844:\tlearn: 7.7221767\ttotal: 46.6s\tremaining: 25.8s\n",
            "7845:\tlearn: 7.7221727\ttotal: 46.6s\tremaining: 25.8s\n",
            "7846:\tlearn: 7.7221638\ttotal: 46.6s\tremaining: 25.7s\n",
            "7847:\tlearn: 7.7221577\ttotal: 46.6s\tremaining: 25.7s\n",
            "7848:\tlearn: 7.7221448\ttotal: 46.6s\tremaining: 25.7s\n",
            "7849:\tlearn: 7.7221399\ttotal: 46.6s\tremaining: 25.7s\n",
            "7850:\tlearn: 7.7221292\ttotal: 46.6s\tremaining: 25.7s\n",
            "7851:\tlearn: 7.7221189\ttotal: 46.6s\tremaining: 25.7s\n",
            "7852:\tlearn: 7.7220910\ttotal: 46.6s\tremaining: 25.7s\n",
            "7853:\tlearn: 7.7220849\ttotal: 46.7s\tremaining: 25.7s\n",
            "7854:\tlearn: 7.7220766\ttotal: 46.7s\tremaining: 25.7s\n",
            "7855:\tlearn: 7.7220645\ttotal: 46.7s\tremaining: 25.7s\n",
            "7856:\tlearn: 7.7220464\ttotal: 46.7s\tremaining: 25.7s\n",
            "7857:\tlearn: 7.7220383\ttotal: 46.7s\tremaining: 25.7s\n",
            "7858:\tlearn: 7.7220219\ttotal: 46.7s\tremaining: 25.7s\n",
            "7859:\tlearn: 7.7220087\ttotal: 46.7s\tremaining: 25.7s\n",
            "7860:\tlearn: 7.7219957\ttotal: 46.7s\tremaining: 25.7s\n",
            "7861:\tlearn: 7.7219782\ttotal: 46.7s\tremaining: 25.7s\n",
            "7862:\tlearn: 7.7219675\ttotal: 46.7s\tremaining: 25.7s\n",
            "7863:\tlearn: 7.7219626\ttotal: 46.7s\tremaining: 25.6s\n",
            "7864:\tlearn: 7.7219563\ttotal: 46.7s\tremaining: 25.6s\n",
            "7865:\tlearn: 7.7219540\ttotal: 46.7s\tremaining: 25.6s\n",
            "7866:\tlearn: 7.7219477\ttotal: 46.7s\tremaining: 25.6s\n",
            "7867:\tlearn: 7.7219373\ttotal: 46.7s\tremaining: 25.6s\n",
            "7868:\tlearn: 7.7219192\ttotal: 46.8s\tremaining: 25.6s\n",
            "7869:\tlearn: 7.7219065\ttotal: 46.8s\tremaining: 25.6s\n",
            "7870:\tlearn: 7.7218979\ttotal: 46.8s\tremaining: 25.6s\n",
            "7871:\tlearn: 7.7218869\ttotal: 46.8s\tremaining: 25.6s\n",
            "7872:\tlearn: 7.7218774\ttotal: 46.8s\tremaining: 25.6s\n",
            "7873:\tlearn: 7.7218702\ttotal: 46.8s\tremaining: 25.6s\n",
            "7874:\tlearn: 7.7218653\ttotal: 46.8s\tremaining: 25.6s\n",
            "7875:\tlearn: 7.7218510\ttotal: 46.8s\tremaining: 25.6s\n",
            "7876:\tlearn: 7.7218357\ttotal: 46.8s\tremaining: 25.6s\n",
            "7877:\tlearn: 7.7218337\ttotal: 46.8s\tremaining: 25.6s\n",
            "7878:\tlearn: 7.7218253\ttotal: 46.8s\tremaining: 25.6s\n",
            "7879:\tlearn: 7.7218141\ttotal: 46.8s\tremaining: 25.6s\n",
            "7880:\tlearn: 7.7217983\ttotal: 46.8s\tremaining: 25.6s\n",
            "7881:\tlearn: 7.7217948\ttotal: 46.8s\tremaining: 25.5s\n",
            "7882:\tlearn: 7.7217836\ttotal: 46.8s\tremaining: 25.5s\n",
            "7883:\tlearn: 7.7217617\ttotal: 46.9s\tremaining: 25.5s\n",
            "7884:\tlearn: 7.7217540\ttotal: 46.9s\tremaining: 25.5s\n",
            "7885:\tlearn: 7.7217476\ttotal: 46.9s\tremaining: 25.5s\n",
            "7886:\tlearn: 7.7217304\ttotal: 46.9s\tremaining: 25.5s\n",
            "7887:\tlearn: 7.7217137\ttotal: 46.9s\tremaining: 25.5s\n",
            "7888:\tlearn: 7.7216993\ttotal: 46.9s\tremaining: 25.5s\n",
            "7889:\tlearn: 7.7216970\ttotal: 46.9s\tremaining: 25.5s\n",
            "7890:\tlearn: 7.7216743\ttotal: 46.9s\tremaining: 25.5s\n",
            "7891:\tlearn: 7.7216699\ttotal: 46.9s\tremaining: 25.5s\n",
            "7892:\tlearn: 7.7216633\ttotal: 46.9s\tremaining: 25.5s\n",
            "7893:\tlearn: 7.7216449\ttotal: 46.9s\tremaining: 25.5s\n",
            "7894:\tlearn: 7.7216322\ttotal: 46.9s\tremaining: 25.5s\n",
            "7895:\tlearn: 7.7216210\ttotal: 46.9s\tremaining: 25.5s\n",
            "7896:\tlearn: 7.7216132\ttotal: 46.9s\tremaining: 25.5s\n",
            "7897:\tlearn: 7.7215885\ttotal: 46.9s\tremaining: 25.5s\n",
            "7898:\tlearn: 7.7215764\ttotal: 46.9s\tremaining: 25.4s\n",
            "7899:\tlearn: 7.7215753\ttotal: 47s\tremaining: 25.4s\n",
            "7900:\tlearn: 7.7215701\ttotal: 47s\tremaining: 25.4s\n",
            "7901:\tlearn: 7.7215626\ttotal: 47s\tremaining: 25.4s\n",
            "7902:\tlearn: 7.7215433\ttotal: 47s\tremaining: 25.4s\n",
            "7903:\tlearn: 7.7215387\ttotal: 47s\tremaining: 25.4s\n",
            "7904:\tlearn: 7.7215361\ttotal: 47s\tremaining: 25.4s\n",
            "7905:\tlearn: 7.7215255\ttotal: 47s\tremaining: 25.4s\n",
            "7906:\tlearn: 7.7215177\ttotal: 47s\tremaining: 25.4s\n",
            "7907:\tlearn: 7.7215050\ttotal: 47s\tremaining: 25.4s\n",
            "7908:\tlearn: 7.7214872\ttotal: 47s\tremaining: 25.4s\n",
            "7909:\tlearn: 7.7214584\ttotal: 47s\tremaining: 25.4s\n",
            "7910:\tlearn: 7.7214455\ttotal: 47s\tremaining: 25.4s\n",
            "7911:\tlearn: 7.7214305\ttotal: 47s\tremaining: 25.4s\n",
            "7912:\tlearn: 7.7214181\ttotal: 47s\tremaining: 25.4s\n",
            "7913:\tlearn: 7.7214072\ttotal: 47s\tremaining: 25.4s\n",
            "7914:\tlearn: 7.7213925\ttotal: 47s\tremaining: 25.3s\n",
            "7915:\tlearn: 7.7213859\ttotal: 47s\tremaining: 25.3s\n",
            "7916:\tlearn: 7.7213660\ttotal: 47s\tremaining: 25.3s\n",
            "7917:\tlearn: 7.7213522\ttotal: 47s\tremaining: 25.3s\n",
            "7918:\tlearn: 7.7213427\ttotal: 47.1s\tremaining: 25.3s\n",
            "7919:\tlearn: 7.7213275\ttotal: 47.1s\tremaining: 25.3s\n",
            "7920:\tlearn: 7.7213229\ttotal: 47.1s\tremaining: 25.3s\n",
            "7921:\tlearn: 7.7213108\ttotal: 47.1s\tremaining: 25.3s\n",
            "7922:\tlearn: 7.7213013\ttotal: 47.1s\tremaining: 25.3s\n",
            "7923:\tlearn: 7.7212984\ttotal: 47.1s\tremaining: 25.3s\n",
            "7924:\tlearn: 7.7212932\ttotal: 47.1s\tremaining: 25.3s\n",
            "7925:\tlearn: 7.7212728\ttotal: 47.1s\tremaining: 25.3s\n",
            "7926:\tlearn: 7.7212555\ttotal: 47.1s\tremaining: 25.3s\n",
            "7927:\tlearn: 7.7212400\ttotal: 47.1s\tremaining: 25.3s\n",
            "7928:\tlearn: 7.7212204\ttotal: 47.1s\tremaining: 25.3s\n",
            "7929:\tlearn: 7.7212066\ttotal: 47.1s\tremaining: 25.3s\n",
            "7930:\tlearn: 7.7211815\ttotal: 47.1s\tremaining: 25.3s\n",
            "7931:\tlearn: 7.7211764\ttotal: 47.1s\tremaining: 25.2s\n",
            "7932:\tlearn: 7.7211640\ttotal: 47.1s\tremaining: 25.2s\n",
            "7933:\tlearn: 7.7211548\ttotal: 47.1s\tremaining: 25.2s\n",
            "7934:\tlearn: 7.7211404\ttotal: 47.1s\tremaining: 25.2s\n",
            "7935:\tlearn: 7.7211165\ttotal: 47.2s\tremaining: 25.2s\n",
            "7936:\tlearn: 7.7211093\ttotal: 47.2s\tremaining: 25.2s\n",
            "7937:\tlearn: 7.7210987\ttotal: 47.2s\tremaining: 25.2s\n",
            "7938:\tlearn: 7.7210802\ttotal: 47.2s\tremaining: 25.2s\n",
            "7939:\tlearn: 7.7210690\ttotal: 47.2s\tremaining: 25.2s\n",
            "7940:\tlearn: 7.7210523\ttotal: 47.2s\tremaining: 25.2s\n",
            "7941:\tlearn: 7.7210319\ttotal: 47.2s\tremaining: 25.2s\n",
            "7942:\tlearn: 7.7210112\ttotal: 47.2s\tremaining: 25.2s\n",
            "7943:\tlearn: 7.7209962\ttotal: 47.2s\tremaining: 25.2s\n",
            "7944:\tlearn: 7.7209870\ttotal: 47.2s\tremaining: 25.2s\n",
            "7945:\tlearn: 7.7209795\ttotal: 47.2s\tremaining: 25.2s\n",
            "7946:\tlearn: 7.7209671\ttotal: 47.2s\tremaining: 25.2s\n",
            "7947:\tlearn: 7.7209478\ttotal: 47.2s\tremaining: 25.1s\n",
            "7948:\tlearn: 7.7209283\ttotal: 47.2s\tremaining: 25.1s\n",
            "7949:\tlearn: 7.7209093\ttotal: 47.2s\tremaining: 25.1s\n",
            "7950:\tlearn: 7.7209009\ttotal: 47.2s\tremaining: 25.1s\n",
            "7951:\tlearn: 7.7208923\ttotal: 47.2s\tremaining: 25.1s\n",
            "7952:\tlearn: 7.7208632\ttotal: 47.2s\tremaining: 25.1s\n",
            "7953:\tlearn: 7.7208560\ttotal: 47.2s\tremaining: 25.1s\n",
            "7954:\tlearn: 7.7208442\ttotal: 47.3s\tremaining: 25.1s\n",
            "7955:\tlearn: 7.7208295\ttotal: 47.3s\tremaining: 25.1s\n",
            "7956:\tlearn: 7.7208062\ttotal: 47.3s\tremaining: 25.1s\n",
            "7957:\tlearn: 7.7207962\ttotal: 47.3s\tremaining: 25.1s\n",
            "7958:\tlearn: 7.7207881\ttotal: 47.3s\tremaining: 25.1s\n",
            "7959:\tlearn: 7.7207786\ttotal: 47.3s\tremaining: 25.1s\n",
            "7960:\tlearn: 7.7207682\ttotal: 47.3s\tremaining: 25.1s\n",
            "7961:\tlearn: 7.7207564\ttotal: 47.3s\tremaining: 25.1s\n",
            "7962:\tlearn: 7.7207432\ttotal: 47.3s\tremaining: 25.1s\n",
            "7963:\tlearn: 7.7207343\ttotal: 47.3s\tremaining: 25.1s\n",
            "7964:\tlearn: 7.7207233\ttotal: 47.3s\tremaining: 25s\n",
            "7965:\tlearn: 7.7207089\ttotal: 47.3s\tremaining: 25s\n",
            "7966:\tlearn: 7.7206969\ttotal: 47.3s\tremaining: 25s\n",
            "7967:\tlearn: 7.7206802\ttotal: 47.3s\tremaining: 25s\n",
            "7968:\tlearn: 7.7206675\ttotal: 47.3s\tremaining: 25s\n",
            "7969:\tlearn: 7.7206370\ttotal: 47.3s\tremaining: 25s\n",
            "7970:\tlearn: 7.7206269\ttotal: 47.4s\tremaining: 25s\n",
            "7971:\tlearn: 7.7206114\ttotal: 47.4s\tremaining: 25s\n",
            "7972:\tlearn: 7.7206013\ttotal: 47.4s\tremaining: 25s\n",
            "7973:\tlearn: 7.7205904\ttotal: 47.4s\tremaining: 25s\n",
            "7974:\tlearn: 7.7205829\ttotal: 47.4s\tremaining: 25s\n",
            "7975:\tlearn: 7.7205691\ttotal: 47.4s\tremaining: 25s\n",
            "7976:\tlearn: 7.7205570\ttotal: 47.4s\tremaining: 25s\n",
            "7977:\tlearn: 7.7205440\ttotal: 47.4s\tremaining: 25s\n",
            "7978:\tlearn: 7.7205239\ttotal: 47.4s\tremaining: 25s\n",
            "7979:\tlearn: 7.7205158\ttotal: 47.4s\tremaining: 25s\n",
            "7980:\tlearn: 7.7204991\ttotal: 47.4s\tremaining: 24.9s\n",
            "7981:\tlearn: 7.7204890\ttotal: 47.4s\tremaining: 24.9s\n",
            "7982:\tlearn: 7.7204770\ttotal: 47.4s\tremaining: 24.9s\n",
            "7983:\tlearn: 7.7204608\ttotal: 47.4s\tremaining: 24.9s\n",
            "7984:\tlearn: 7.7204326\ttotal: 47.4s\tremaining: 24.9s\n",
            "7985:\tlearn: 7.7204188\ttotal: 47.4s\tremaining: 24.9s\n",
            "7986:\tlearn: 7.7204061\ttotal: 47.4s\tremaining: 24.9s\n",
            "7987:\tlearn: 7.7203935\ttotal: 47.4s\tremaining: 24.9s\n",
            "7988:\tlearn: 7.7203851\ttotal: 47.4s\tremaining: 24.9s\n",
            "7989:\tlearn: 7.7203716\ttotal: 47.5s\tremaining: 24.9s\n",
            "7990:\tlearn: 7.7203578\ttotal: 47.5s\tremaining: 24.9s\n",
            "7991:\tlearn: 7.7203471\ttotal: 47.5s\tremaining: 24.9s\n",
            "7992:\tlearn: 7.7203376\ttotal: 47.5s\tremaining: 24.9s\n",
            "7993:\tlearn: 7.7203212\ttotal: 47.5s\tremaining: 24.9s\n",
            "7994:\tlearn: 7.7203091\ttotal: 47.5s\tremaining: 24.9s\n",
            "7995:\tlearn: 7.7203048\ttotal: 47.5s\tremaining: 24.9s\n",
            "7996:\tlearn: 7.7202971\ttotal: 47.5s\tremaining: 24.9s\n",
            "7997:\tlearn: 7.7202729\ttotal: 47.5s\tremaining: 24.8s\n",
            "7998:\tlearn: 7.7202530\ttotal: 47.5s\tremaining: 24.8s\n",
            "7999:\tlearn: 7.7202455\ttotal: 47.5s\tremaining: 24.8s\n",
            "8000:\tlearn: 7.7202242\ttotal: 47.5s\tremaining: 24.8s\n",
            "8001:\tlearn: 7.7202018\ttotal: 47.5s\tremaining: 24.8s\n",
            "8002:\tlearn: 7.7201845\ttotal: 47.5s\tremaining: 24.8s\n",
            "8003:\tlearn: 7.7201767\ttotal: 47.5s\tremaining: 24.8s\n",
            "8004:\tlearn: 7.7201721\ttotal: 47.5s\tremaining: 24.8s\n",
            "8005:\tlearn: 7.7201583\ttotal: 47.6s\tremaining: 24.8s\n",
            "8006:\tlearn: 7.7201324\ttotal: 47.6s\tremaining: 24.8s\n",
            "8007:\tlearn: 7.7201189\ttotal: 47.6s\tremaining: 24.8s\n",
            "8008:\tlearn: 7.7201131\ttotal: 47.6s\tremaining: 24.8s\n",
            "8009:\tlearn: 7.7201045\ttotal: 47.6s\tremaining: 24.8s\n",
            "8010:\tlearn: 7.7200823\ttotal: 47.6s\tremaining: 24.8s\n",
            "8011:\tlearn: 7.7200697\ttotal: 47.6s\tremaining: 24.8s\n",
            "8012:\tlearn: 7.7200475\ttotal: 47.6s\tremaining: 24.8s\n",
            "8013:\tlearn: 7.7200380\ttotal: 47.6s\tremaining: 24.7s\n",
            "8014:\tlearn: 7.7200317\ttotal: 47.6s\tremaining: 24.7s\n",
            "8015:\tlearn: 7.7200181\ttotal: 47.6s\tremaining: 24.7s\n",
            "8016:\tlearn: 7.7200161\ttotal: 47.6s\tremaining: 24.7s\n",
            "8017:\tlearn: 7.7199968\ttotal: 47.6s\tremaining: 24.7s\n",
            "8018:\tlearn: 7.7199893\ttotal: 47.6s\tremaining: 24.7s\n",
            "8019:\tlearn: 7.7199752\ttotal: 47.6s\tremaining: 24.7s\n",
            "8020:\tlearn: 7.7199580\ttotal: 47.6s\tremaining: 24.7s\n",
            "8021:\tlearn: 7.7199496\ttotal: 47.6s\tremaining: 24.7s\n",
            "8022:\tlearn: 7.7199306\ttotal: 47.6s\tremaining: 24.7s\n",
            "8023:\tlearn: 7.7199234\ttotal: 47.7s\tremaining: 24.7s\n",
            "8024:\tlearn: 7.7199085\ttotal: 47.7s\tremaining: 24.7s\n",
            "8025:\tlearn: 7.7198915\ttotal: 47.7s\tremaining: 24.7s\n",
            "8026:\tlearn: 7.7198811\ttotal: 47.7s\tremaining: 24.7s\n",
            "8027:\tlearn: 7.7198647\ttotal: 47.7s\tremaining: 24.7s\n",
            "8028:\tlearn: 7.7198506\ttotal: 47.7s\tremaining: 24.7s\n",
            "8029:\tlearn: 7.7198362\ttotal: 47.7s\tremaining: 24.7s\n",
            "8030:\tlearn: 7.7198195\ttotal: 47.7s\tremaining: 24.6s\n",
            "8031:\tlearn: 7.7198057\ttotal: 47.7s\tremaining: 24.6s\n",
            "8032:\tlearn: 7.7197907\ttotal: 47.7s\tremaining: 24.6s\n",
            "8033:\tlearn: 7.7197812\ttotal: 47.7s\tremaining: 24.6s\n",
            "8034:\tlearn: 7.7197651\ttotal: 47.7s\tremaining: 24.6s\n",
            "8035:\tlearn: 7.7197447\ttotal: 47.7s\tremaining: 24.6s\n",
            "8036:\tlearn: 7.7197208\ttotal: 47.7s\tremaining: 24.6s\n",
            "8037:\tlearn: 7.7197130\ttotal: 47.7s\tremaining: 24.6s\n",
            "8038:\tlearn: 7.7196952\ttotal: 47.7s\tremaining: 24.6s\n",
            "8039:\tlearn: 7.7196874\ttotal: 47.8s\tremaining: 24.6s\n",
            "8040:\tlearn: 7.7196839\ttotal: 47.8s\tremaining: 24.6s\n",
            "8041:\tlearn: 7.7196690\ttotal: 47.8s\tremaining: 24.6s\n",
            "8042:\tlearn: 7.7196598\ttotal: 47.8s\tremaining: 24.6s\n",
            "8043:\tlearn: 7.7196451\ttotal: 47.8s\tremaining: 24.6s\n",
            "8044:\tlearn: 7.7196367\ttotal: 47.8s\tremaining: 24.6s\n",
            "8045:\tlearn: 7.7196243\ttotal: 47.8s\tremaining: 24.6s\n",
            "8046:\tlearn: 7.7196154\ttotal: 47.8s\tremaining: 24.6s\n",
            "8047:\tlearn: 7.7196022\ttotal: 47.8s\tremaining: 24.6s\n",
            "8048:\tlearn: 7.7195884\ttotal: 47.8s\tremaining: 24.5s\n",
            "8049:\tlearn: 7.7195714\ttotal: 47.8s\tremaining: 24.5s\n",
            "8050:\tlearn: 7.7195676\ttotal: 47.8s\tremaining: 24.5s\n",
            "8051:\tlearn: 7.7195550\ttotal: 47.8s\tremaining: 24.5s\n",
            "8052:\tlearn: 7.7195328\ttotal: 47.8s\tremaining: 24.5s\n",
            "8053:\tlearn: 7.7195210\ttotal: 47.8s\tremaining: 24.5s\n",
            "8054:\tlearn: 7.7195066\ttotal: 47.9s\tremaining: 24.5s\n",
            "8055:\tlearn: 7.7194980\ttotal: 47.9s\tremaining: 24.5s\n",
            "8056:\tlearn: 7.7194856\ttotal: 47.9s\tremaining: 24.5s\n",
            "8057:\tlearn: 7.7194677\ttotal: 47.9s\tremaining: 24.5s\n",
            "8058:\tlearn: 7.7194562\ttotal: 47.9s\tremaining: 24.5s\n",
            "8059:\tlearn: 7.7194476\ttotal: 47.9s\tremaining: 24.5s\n",
            "8060:\tlearn: 7.7194378\ttotal: 47.9s\tremaining: 24.5s\n",
            "8061:\tlearn: 7.7194246\ttotal: 47.9s\tremaining: 24.5s\n",
            "8062:\tlearn: 7.7194228\ttotal: 47.9s\tremaining: 24.5s\n",
            "8063:\tlearn: 7.7194082\ttotal: 47.9s\tremaining: 24.5s\n",
            "8064:\tlearn: 7.7193892\ttotal: 47.9s\tremaining: 24.5s\n",
            "8065:\tlearn: 7.7193678\ttotal: 47.9s\tremaining: 24.4s\n",
            "8066:\tlearn: 7.7193598\ttotal: 47.9s\tremaining: 24.4s\n",
            "8067:\tlearn: 7.7193486\ttotal: 47.9s\tremaining: 24.4s\n",
            "8068:\tlearn: 7.7193350\ttotal: 47.9s\tremaining: 24.4s\n",
            "8069:\tlearn: 7.7193258\ttotal: 47.9s\tremaining: 24.4s\n",
            "8070:\tlearn: 7.7193238\ttotal: 48s\tremaining: 24.4s\n",
            "8071:\tlearn: 7.7193077\ttotal: 48s\tremaining: 24.4s\n",
            "8072:\tlearn: 7.7193031\ttotal: 48s\tremaining: 24.4s\n",
            "8073:\tlearn: 7.7192829\ttotal: 48s\tremaining: 24.4s\n",
            "8074:\tlearn: 7.7192628\ttotal: 48s\tremaining: 24.4s\n",
            "8075:\tlearn: 7.7192564\ttotal: 48s\tremaining: 24.4s\n",
            "8076:\tlearn: 7.7192438\ttotal: 48s\tremaining: 24.4s\n",
            "8077:\tlearn: 7.7192325\ttotal: 48s\tremaining: 24.4s\n",
            "8078:\tlearn: 7.7192182\ttotal: 48s\tremaining: 24.4s\n",
            "8079:\tlearn: 7.7192043\ttotal: 48s\tremaining: 24.4s\n",
            "8080:\tlearn: 7.7191977\ttotal: 48s\tremaining: 24.4s\n",
            "8081:\tlearn: 7.7191905\ttotal: 48s\tremaining: 24.4s\n",
            "8082:\tlearn: 7.7191871\ttotal: 48s\tremaining: 24.3s\n",
            "8083:\tlearn: 7.7191773\ttotal: 48s\tremaining: 24.3s\n",
            "8084:\tlearn: 7.7191718\ttotal: 48s\tremaining: 24.3s\n",
            "8085:\tlearn: 7.7191683\ttotal: 48s\tremaining: 24.3s\n",
            "8086:\tlearn: 7.7191548\ttotal: 48s\tremaining: 24.3s\n",
            "8087:\tlearn: 7.7191364\ttotal: 48s\tremaining: 24.3s\n",
            "8088:\tlearn: 7.7191272\ttotal: 48s\tremaining: 24.3s\n",
            "8089:\tlearn: 7.7191185\ttotal: 48.1s\tremaining: 24.3s\n",
            "8090:\tlearn: 7.7190964\ttotal: 48.1s\tremaining: 24.3s\n",
            "8091:\tlearn: 7.7190967\ttotal: 48.1s\tremaining: 24.3s\n",
            "8092:\tlearn: 7.7190756\ttotal: 48.1s\tremaining: 24.3s\n",
            "8093:\tlearn: 7.7190659\ttotal: 48.1s\tremaining: 24.3s\n",
            "8094:\tlearn: 7.7190564\ttotal: 48.1s\tremaining: 24.3s\n",
            "8095:\tlearn: 7.7190385\ttotal: 48.1s\tremaining: 24.3s\n",
            "8096:\tlearn: 7.7190328\ttotal: 48.1s\tremaining: 24.3s\n",
            "8097:\tlearn: 7.7190201\ttotal: 48.1s\tremaining: 24.3s\n",
            "8098:\tlearn: 7.7190071\ttotal: 48.1s\tremaining: 24.3s\n",
            "8099:\tlearn: 7.7189942\ttotal: 48.1s\tremaining: 24.2s\n",
            "8100:\tlearn: 7.7189853\ttotal: 48.1s\tremaining: 24.2s\n",
            "8101:\tlearn: 7.7189832\ttotal: 48.1s\tremaining: 24.2s\n",
            "8102:\tlearn: 7.7189769\ttotal: 48.1s\tremaining: 24.2s\n",
            "8103:\tlearn: 7.7189709\ttotal: 48.1s\tremaining: 24.2s\n",
            "8104:\tlearn: 7.7189651\ttotal: 48.2s\tremaining: 24.2s\n",
            "8105:\tlearn: 7.7189570\ttotal: 48.2s\tremaining: 24.2s\n",
            "8106:\tlearn: 7.7189501\ttotal: 48.2s\tremaining: 24.2s\n",
            "8107:\tlearn: 7.7189291\ttotal: 48.2s\tremaining: 24.2s\n",
            "8108:\tlearn: 7.7189164\ttotal: 48.2s\tremaining: 24.2s\n",
            "8109:\tlearn: 7.7189078\ttotal: 48.2s\tremaining: 24.2s\n",
            "8110:\tlearn: 7.7189052\ttotal: 48.2s\tremaining: 24.2s\n",
            "8111:\tlearn: 7.7188902\ttotal: 48.2s\tremaining: 24.2s\n",
            "8112:\tlearn: 7.7188784\ttotal: 48.2s\tremaining: 24.2s\n",
            "8113:\tlearn: 7.7188609\ttotal: 48.2s\tremaining: 24.2s\n",
            "8114:\tlearn: 7.7188476\ttotal: 48.2s\tremaining: 24.2s\n",
            "8115:\tlearn: 7.7188292\ttotal: 48.2s\tremaining: 24.2s\n",
            "8116:\tlearn: 7.7188180\ttotal: 48.2s\tremaining: 24.1s\n",
            "8117:\tlearn: 7.7188108\ttotal: 48.2s\tremaining: 24.1s\n",
            "8118:\tlearn: 7.7188070\ttotal: 48.2s\tremaining: 24.1s\n",
            "8119:\tlearn: 7.7187955\ttotal: 48.2s\tremaining: 24.1s\n",
            "8120:\tlearn: 7.7187791\ttotal: 48.2s\tremaining: 24.1s\n",
            "8121:\tlearn: 7.7187624\ttotal: 48.3s\tremaining: 24.1s\n",
            "8122:\tlearn: 7.7187500\ttotal: 48.3s\tremaining: 24.1s\n",
            "8123:\tlearn: 7.7187348\ttotal: 48.3s\tremaining: 24.1s\n",
            "8124:\tlearn: 7.7187155\ttotal: 48.3s\tremaining: 24.1s\n",
            "8125:\tlearn: 7.7187152\ttotal: 48.3s\tremaining: 24.1s\n",
            "8126:\tlearn: 7.7186876\ttotal: 48.3s\tremaining: 24.1s\n",
            "8127:\tlearn: 7.7186881\ttotal: 48.3s\tremaining: 24.1s\n",
            "8128:\tlearn: 7.7186775\ttotal: 48.3s\tremaining: 24.1s\n",
            "8129:\tlearn: 7.7186614\ttotal: 48.3s\tremaining: 24.1s\n",
            "8130:\tlearn: 7.7186516\ttotal: 48.3s\tremaining: 24.1s\n",
            "8131:\tlearn: 7.7186366\ttotal: 48.3s\tremaining: 24.1s\n",
            "8132:\tlearn: 7.7186332\ttotal: 48.3s\tremaining: 24.1s\n",
            "8133:\tlearn: 7.7186216\ttotal: 48.3s\tremaining: 24s\n",
            "8134:\tlearn: 7.7186098\ttotal: 48.3s\tremaining: 24s\n",
            "8135:\tlearn: 7.7186032\ttotal: 48.3s\tremaining: 24s\n",
            "8136:\tlearn: 7.7185857\ttotal: 48.3s\tremaining: 24s\n",
            "8137:\tlearn: 7.7185638\ttotal: 48.4s\tremaining: 24s\n",
            "8138:\tlearn: 7.7185589\ttotal: 48.4s\tremaining: 24s\n",
            "8139:\tlearn: 7.7185456\ttotal: 48.4s\tremaining: 24s\n",
            "8140:\tlearn: 7.7185238\ttotal: 48.4s\tremaining: 24s\n",
            "8141:\tlearn: 7.7185068\ttotal: 48.4s\tremaining: 24s\n",
            "8142:\tlearn: 7.7184970\ttotal: 48.4s\tremaining: 24s\n",
            "8143:\tlearn: 7.7184886\ttotal: 48.4s\tremaining: 24s\n",
            "8144:\tlearn: 7.7184716\ttotal: 48.4s\tremaining: 24s\n",
            "8145:\tlearn: 7.7184595\ttotal: 48.4s\tremaining: 24s\n",
            "8146:\tlearn: 7.7184489\ttotal: 48.4s\tremaining: 24s\n",
            "8147:\tlearn: 7.7184325\ttotal: 48.4s\tremaining: 24s\n",
            "8148:\tlearn: 7.7184143\ttotal: 48.4s\tremaining: 24s\n",
            "8149:\tlearn: 7.7183991\ttotal: 48.4s\tremaining: 23.9s\n",
            "8150:\tlearn: 7.7183881\ttotal: 48.4s\tremaining: 23.9s\n",
            "8151:\tlearn: 7.7183827\ttotal: 48.4s\tremaining: 23.9s\n",
            "8152:\tlearn: 7.7183611\ttotal: 48.4s\tremaining: 23.9s\n",
            "8153:\tlearn: 7.7183530\ttotal: 48.4s\tremaining: 23.9s\n",
            "8154:\tlearn: 7.7183412\ttotal: 48.4s\tremaining: 23.9s\n",
            "8155:\tlearn: 7.7183317\ttotal: 48.4s\tremaining: 23.9s\n",
            "8156:\tlearn: 7.7183190\ttotal: 48.5s\tremaining: 23.9s\n",
            "8157:\tlearn: 7.7183018\ttotal: 48.5s\tremaining: 23.9s\n",
            "8158:\tlearn: 7.7182862\ttotal: 48.5s\tremaining: 23.9s\n",
            "8159:\tlearn: 7.7182704\ttotal: 48.5s\tremaining: 23.9s\n",
            "8160:\tlearn: 7.7182569\ttotal: 48.5s\tremaining: 23.9s\n",
            "8161:\tlearn: 7.7182554\ttotal: 48.5s\tremaining: 23.9s\n",
            "8162:\tlearn: 7.7182413\ttotal: 48.5s\tremaining: 23.9s\n",
            "8163:\tlearn: 7.7182376\ttotal: 48.5s\tremaining: 23.9s\n",
            "8164:\tlearn: 7.7182321\ttotal: 48.5s\tremaining: 23.9s\n",
            "8165:\tlearn: 7.7182243\ttotal: 48.5s\tremaining: 23.9s\n",
            "8166:\tlearn: 7.7182027\ttotal: 48.5s\tremaining: 23.8s\n",
            "8167:\tlearn: 7.7181941\ttotal: 48.5s\tremaining: 23.8s\n",
            "8168:\tlearn: 7.7181739\ttotal: 48.5s\tremaining: 23.8s\n",
            "8169:\tlearn: 7.7181515\ttotal: 48.5s\tremaining: 23.8s\n",
            "8170:\tlearn: 7.7181296\ttotal: 48.5s\tremaining: 23.8s\n",
            "8171:\tlearn: 7.7181175\ttotal: 48.6s\tremaining: 23.8s\n",
            "8172:\tlearn: 7.7181094\ttotal: 48.6s\tremaining: 23.8s\n",
            "8173:\tlearn: 7.7180953\ttotal: 48.6s\tremaining: 23.8s\n",
            "8174:\tlearn: 7.7180789\ttotal: 48.6s\tremaining: 23.8s\n",
            "8175:\tlearn: 7.7180717\ttotal: 48.6s\tremaining: 23.8s\n",
            "8176:\tlearn: 7.7180593\ttotal: 48.6s\tremaining: 23.8s\n",
            "8177:\tlearn: 7.7180461\ttotal: 48.6s\tremaining: 23.8s\n",
            "8178:\tlearn: 7.7180426\ttotal: 48.6s\tremaining: 23.8s\n",
            "8179:\tlearn: 7.7180323\ttotal: 48.6s\tremaining: 23.8s\n",
            "8180:\tlearn: 7.7180282\ttotal: 48.6s\tremaining: 23.8s\n",
            "8181:\tlearn: 7.7180153\ttotal: 48.6s\tremaining: 23.8s\n",
            "8182:\tlearn: 7.7179813\ttotal: 48.6s\tremaining: 23.7s\n",
            "8183:\tlearn: 7.7179704\ttotal: 48.6s\tremaining: 23.7s\n",
            "8184:\tlearn: 7.7179450\ttotal: 48.6s\tremaining: 23.7s\n",
            "8185:\tlearn: 7.7179347\ttotal: 48.6s\tremaining: 23.7s\n",
            "8186:\tlearn: 7.7179266\ttotal: 48.6s\tremaining: 23.7s\n",
            "8187:\tlearn: 7.7179102\ttotal: 48.6s\tremaining: 23.7s\n",
            "8188:\tlearn: 7.7179070\ttotal: 48.6s\tremaining: 23.7s\n",
            "8189:\tlearn: 7.7178912\ttotal: 48.6s\tremaining: 23.7s\n",
            "8190:\tlearn: 7.7178745\ttotal: 48.7s\tremaining: 23.7s\n",
            "8191:\tlearn: 7.7178624\ttotal: 48.7s\tremaining: 23.7s\n",
            "8192:\tlearn: 7.7178483\ttotal: 48.7s\tremaining: 23.7s\n",
            "8193:\tlearn: 7.7178365\ttotal: 48.7s\tremaining: 23.7s\n",
            "8194:\tlearn: 7.7178192\ttotal: 48.7s\tremaining: 23.7s\n",
            "8195:\tlearn: 7.7178120\ttotal: 48.7s\tremaining: 23.7s\n",
            "8196:\tlearn: 7.7177965\ttotal: 48.7s\tremaining: 23.7s\n",
            "8197:\tlearn: 7.7177898\ttotal: 48.7s\tremaining: 23.7s\n",
            "8198:\tlearn: 7.7177760\ttotal: 48.7s\tremaining: 23.7s\n",
            "8199:\tlearn: 7.7177616\ttotal: 48.7s\tremaining: 23.6s\n",
            "8200:\tlearn: 7.7177443\ttotal: 48.7s\tremaining: 23.6s\n",
            "8201:\tlearn: 7.7177348\ttotal: 48.7s\tremaining: 23.6s\n",
            "8202:\tlearn: 7.7177253\ttotal: 48.7s\tremaining: 23.6s\n",
            "8203:\tlearn: 7.7177196\ttotal: 48.7s\tremaining: 23.6s\n",
            "8204:\tlearn: 7.7177086\ttotal: 48.8s\tremaining: 23.6s\n",
            "8205:\tlearn: 7.7176948\ttotal: 48.8s\tremaining: 23.6s\n",
            "8206:\tlearn: 7.7176804\ttotal: 48.8s\tremaining: 23.6s\n",
            "8207:\tlearn: 7.7176695\ttotal: 48.8s\tremaining: 23.6s\n",
            "8208:\tlearn: 7.7176588\ttotal: 48.8s\tremaining: 23.6s\n",
            "8209:\tlearn: 7.7176447\ttotal: 48.8s\tremaining: 23.6s\n",
            "8210:\tlearn: 7.7176335\ttotal: 48.8s\tremaining: 23.6s\n",
            "8211:\tlearn: 7.7176202\ttotal: 48.8s\tremaining: 23.6s\n",
            "8212:\tlearn: 7.7176076\ttotal: 48.8s\tremaining: 23.6s\n",
            "8213:\tlearn: 7.7176021\ttotal: 48.8s\tremaining: 23.6s\n",
            "8214:\tlearn: 7.7175903\ttotal: 48.8s\tremaining: 23.6s\n",
            "8215:\tlearn: 7.7175753\ttotal: 48.8s\tremaining: 23.6s\n",
            "8216:\tlearn: 7.7175699\ttotal: 48.8s\tremaining: 23.6s\n",
            "8217:\tlearn: 7.7175635\ttotal: 48.8s\tremaining: 23.6s\n",
            "8218:\tlearn: 7.7175330\ttotal: 48.8s\tremaining: 23.5s\n",
            "8219:\tlearn: 7.7175146\ttotal: 48.8s\tremaining: 23.5s\n",
            "8220:\tlearn: 7.7174956\ttotal: 48.9s\tremaining: 23.5s\n",
            "8221:\tlearn: 7.7174895\ttotal: 48.9s\tremaining: 23.5s\n",
            "8222:\tlearn: 7.7174783\ttotal: 48.9s\tremaining: 23.5s\n",
            "8223:\tlearn: 7.7174642\ttotal: 48.9s\tremaining: 23.5s\n",
            "8224:\tlearn: 7.7174587\ttotal: 48.9s\tremaining: 23.5s\n",
            "8225:\tlearn: 7.7174544\ttotal: 48.9s\tremaining: 23.5s\n",
            "8226:\tlearn: 7.7174426\ttotal: 48.9s\tremaining: 23.5s\n",
            "8227:\tlearn: 7.7174331\ttotal: 48.9s\tremaining: 23.5s\n",
            "8228:\tlearn: 7.7174184\ttotal: 48.9s\tremaining: 23.5s\n",
            "8229:\tlearn: 7.7174023\ttotal: 48.9s\tremaining: 23.5s\n",
            "8230:\tlearn: 7.7174003\ttotal: 48.9s\tremaining: 23.5s\n",
            "8231:\tlearn: 7.7173844\ttotal: 48.9s\tremaining: 23.5s\n",
            "8232:\tlearn: 7.7173787\ttotal: 48.9s\tremaining: 23.5s\n",
            "8233:\tlearn: 7.7173732\ttotal: 48.9s\tremaining: 23.5s\n",
            "8234:\tlearn: 7.7173622\ttotal: 48.9s\tremaining: 23.4s\n",
            "8235:\tlearn: 7.7173484\ttotal: 48.9s\tremaining: 23.4s\n",
            "8236:\tlearn: 7.7173424\ttotal: 48.9s\tremaining: 23.4s\n",
            "8237:\tlearn: 7.7173311\ttotal: 49s\tremaining: 23.4s\n",
            "8238:\tlearn: 7.7173245\ttotal: 49s\tremaining: 23.4s\n",
            "8239:\tlearn: 7.7173133\ttotal: 49s\tremaining: 23.4s\n",
            "8240:\tlearn: 7.7173101\ttotal: 49s\tremaining: 23.4s\n",
            "8241:\tlearn: 7.7172897\ttotal: 49s\tremaining: 23.4s\n",
            "8242:\tlearn: 7.7172782\ttotal: 49s\tremaining: 23.4s\n",
            "8243:\tlearn: 7.7172514\ttotal: 49s\tremaining: 23.4s\n",
            "8244:\tlearn: 7.7172384\ttotal: 49s\tremaining: 23.4s\n",
            "8245:\tlearn: 7.7172240\ttotal: 49s\tremaining: 23.4s\n",
            "8246:\tlearn: 7.7172082\ttotal: 49s\tremaining: 23.4s\n",
            "8247:\tlearn: 7.7171929\ttotal: 49s\tremaining: 23.4s\n",
            "8248:\tlearn: 7.7171828\ttotal: 49s\tremaining: 23.4s\n",
            "8249:\tlearn: 7.7171693\ttotal: 49s\tremaining: 23.4s\n",
            "8250:\tlearn: 7.7171584\ttotal: 49s\tremaining: 23.3s\n",
            "8251:\tlearn: 7.7171394\ttotal: 49s\tremaining: 23.3s\n",
            "8252:\tlearn: 7.7171146\ttotal: 49s\tremaining: 23.3s\n",
            "8253:\tlearn: 7.7170991\ttotal: 49s\tremaining: 23.3s\n",
            "8254:\tlearn: 7.7170924\ttotal: 49s\tremaining: 23.3s\n",
            "8255:\tlearn: 7.7170826\ttotal: 49.1s\tremaining: 23.3s\n",
            "8256:\tlearn: 7.7170665\ttotal: 49.1s\tremaining: 23.3s\n",
            "8257:\tlearn: 7.7170590\ttotal: 49.1s\tremaining: 23.3s\n",
            "8258:\tlearn: 7.7170340\ttotal: 49.1s\tremaining: 23.3s\n",
            "8259:\tlearn: 7.7170288\ttotal: 49.1s\tremaining: 23.3s\n",
            "8260:\tlearn: 7.7170115\ttotal: 49.1s\tremaining: 23.3s\n",
            "8261:\tlearn: 7.7169977\ttotal: 49.1s\tremaining: 23.3s\n",
            "8262:\tlearn: 7.7169899\ttotal: 49.1s\tremaining: 23.3s\n",
            "8263:\tlearn: 7.7169744\ttotal: 49.1s\tremaining: 23.3s\n",
            "8264:\tlearn: 7.7169680\ttotal: 49.1s\tremaining: 23.3s\n",
            "8265:\tlearn: 7.7169571\ttotal: 49.1s\tremaining: 23.3s\n",
            "8266:\tlearn: 7.7169372\ttotal: 49.1s\tremaining: 23.3s\n",
            "8267:\tlearn: 7.7169222\ttotal: 49.1s\tremaining: 23.2s\n",
            "8268:\tlearn: 7.7169165\ttotal: 49.1s\tremaining: 23.2s\n",
            "8269:\tlearn: 7.7169116\ttotal: 49.1s\tremaining: 23.2s\n",
            "8270:\tlearn: 7.7169021\ttotal: 49.1s\tremaining: 23.2s\n",
            "8271:\tlearn: 7.7168903\ttotal: 49.1s\tremaining: 23.2s\n",
            "8272:\tlearn: 7.7168698\ttotal: 49.1s\tremaining: 23.2s\n",
            "8273:\tlearn: 7.7168618\ttotal: 49.2s\tremaining: 23.2s\n",
            "8274:\tlearn: 7.7168491\ttotal: 49.2s\tremaining: 23.2s\n",
            "8275:\tlearn: 7.7168220\ttotal: 49.2s\tremaining: 23.2s\n",
            "8276:\tlearn: 7.7168143\ttotal: 49.2s\tremaining: 23.2s\n",
            "8277:\tlearn: 7.7168016\ttotal: 49.2s\tremaining: 23.2s\n",
            "8278:\tlearn: 7.7168013\ttotal: 49.2s\tremaining: 23.2s\n",
            "8279:\tlearn: 7.7167898\ttotal: 49.2s\tremaining: 23.2s\n",
            "8280:\tlearn: 7.7167817\ttotal: 49.2s\tremaining: 23.2s\n",
            "8281:\tlearn: 7.7167702\ttotal: 49.2s\tremaining: 23.2s\n",
            "8282:\tlearn: 7.7167636\ttotal: 49.2s\tremaining: 23.2s\n",
            "8283:\tlearn: 7.7167587\ttotal: 49.2s\tremaining: 23.1s\n",
            "8284:\tlearn: 7.7167446\ttotal: 49.2s\tremaining: 23.1s\n",
            "8285:\tlearn: 7.7167339\ttotal: 49.2s\tremaining: 23.1s\n",
            "8286:\tlearn: 7.7167172\ttotal: 49.2s\tremaining: 23.1s\n",
            "8287:\tlearn: 7.7167045\ttotal: 49.2s\tremaining: 23.1s\n",
            "8288:\tlearn: 7.7166927\ttotal: 49.2s\tremaining: 23.1s\n",
            "8289:\tlearn: 7.7166873\ttotal: 49.2s\tremaining: 23.1s\n",
            "8290:\tlearn: 7.7166801\ttotal: 49.2s\tremaining: 23.1s\n",
            "8291:\tlearn: 7.7166688\ttotal: 49.3s\tremaining: 23.1s\n",
            "8292:\tlearn: 7.7166593\ttotal: 49.3s\tremaining: 23.1s\n",
            "8293:\tlearn: 7.7166518\ttotal: 49.3s\tremaining: 23.1s\n",
            "8294:\tlearn: 7.7166397\ttotal: 49.3s\tremaining: 23.1s\n",
            "8295:\tlearn: 7.7166210\ttotal: 49.3s\tremaining: 23.1s\n",
            "8296:\tlearn: 7.7166089\ttotal: 49.3s\tremaining: 23.1s\n",
            "8297:\tlearn: 7.7165931\ttotal: 49.3s\tremaining: 23.1s\n",
            "8298:\tlearn: 7.7165850\ttotal: 49.3s\tremaining: 23.1s\n",
            "8299:\tlearn: 7.7165749\ttotal: 49.3s\tremaining: 23.1s\n",
            "8300:\tlearn: 7.7165522\ttotal: 49.3s\tremaining: 23s\n",
            "8301:\tlearn: 7.7165398\ttotal: 49.3s\tremaining: 23s\n",
            "8302:\tlearn: 7.7165309\ttotal: 49.3s\tremaining: 23s\n",
            "8303:\tlearn: 7.7165156\ttotal: 49.3s\tremaining: 23s\n",
            "8304:\tlearn: 7.7165021\ttotal: 49.4s\tremaining: 23s\n",
            "8305:\tlearn: 7.7164851\ttotal: 49.4s\tremaining: 23s\n",
            "8306:\tlearn: 7.7164667\ttotal: 49.4s\tremaining: 23s\n",
            "8307:\tlearn: 7.7164592\ttotal: 49.4s\tremaining: 23s\n",
            "8308:\tlearn: 7.7164462\ttotal: 49.4s\tremaining: 23s\n",
            "8309:\tlearn: 7.7164413\ttotal: 49.4s\tremaining: 23s\n",
            "8310:\tlearn: 7.7164157\ttotal: 49.4s\tremaining: 23s\n",
            "8311:\tlearn: 7.7164024\ttotal: 49.4s\tremaining: 23s\n",
            "8312:\tlearn: 7.7163924\ttotal: 49.4s\tremaining: 23s\n",
            "8313:\tlearn: 7.7163823\ttotal: 49.4s\tremaining: 23s\n",
            "8314:\tlearn: 7.7163734\ttotal: 49.4s\tremaining: 23s\n",
            "8315:\tlearn: 7.7163590\ttotal: 49.4s\tremaining: 23s\n",
            "8316:\tlearn: 7.7163440\ttotal: 49.4s\tremaining: 23s\n",
            "8317:\tlearn: 7.7163397\ttotal: 49.4s\tremaining: 23s\n",
            "8318:\tlearn: 7.7163264\ttotal: 49.4s\tremaining: 22.9s\n",
            "8319:\tlearn: 7.7163120\ttotal: 49.4s\tremaining: 22.9s\n",
            "8320:\tlearn: 7.7162985\ttotal: 49.4s\tremaining: 22.9s\n",
            "8321:\tlearn: 7.7162832\ttotal: 49.5s\tremaining: 22.9s\n",
            "8322:\tlearn: 7.7162783\ttotal: 49.5s\tremaining: 22.9s\n",
            "8323:\tlearn: 7.7162599\ttotal: 49.5s\tremaining: 22.9s\n",
            "8324:\tlearn: 7.7162492\ttotal: 49.5s\tremaining: 22.9s\n",
            "8325:\tlearn: 7.7162435\ttotal: 49.5s\tremaining: 22.9s\n",
            "8326:\tlearn: 7.7162305\ttotal: 49.5s\tremaining: 22.9s\n",
            "8327:\tlearn: 7.7162080\ttotal: 49.5s\tremaining: 22.9s\n",
            "8328:\tlearn: 7.7161937\ttotal: 49.5s\tremaining: 22.9s\n",
            "8329:\tlearn: 7.7161772\ttotal: 49.5s\tremaining: 22.9s\n",
            "8330:\tlearn: 7.7161697\ttotal: 49.5s\tremaining: 22.9s\n",
            "8331:\tlearn: 7.7161680\ttotal: 49.5s\tremaining: 22.9s\n",
            "8332:\tlearn: 7.7161519\ttotal: 49.5s\tremaining: 22.9s\n",
            "8333:\tlearn: 7.7161361\ttotal: 49.5s\tremaining: 22.9s\n",
            "8334:\tlearn: 7.7161156\ttotal: 49.5s\tremaining: 22.9s\n",
            "8335:\tlearn: 7.7161075\ttotal: 49.5s\tremaining: 22.9s\n",
            "8336:\tlearn: 7.7160954\ttotal: 49.5s\tremaining: 22.8s\n",
            "8337:\tlearn: 7.7160900\ttotal: 49.5s\tremaining: 22.8s\n",
            "8338:\tlearn: 7.7160796\ttotal: 49.6s\tremaining: 22.8s\n",
            "8339:\tlearn: 7.7160589\ttotal: 49.6s\tremaining: 22.8s\n",
            "8340:\tlearn: 7.7160404\ttotal: 49.6s\tremaining: 22.8s\n",
            "8341:\tlearn: 7.7160364\ttotal: 49.6s\tremaining: 22.8s\n",
            "8342:\tlearn: 7.7160260\ttotal: 49.6s\tremaining: 22.8s\n",
            "8343:\tlearn: 7.7160105\ttotal: 49.6s\tremaining: 22.8s\n",
            "8344:\tlearn: 7.7159886\ttotal: 49.6s\tremaining: 22.8s\n",
            "8345:\tlearn: 7.7159736\ttotal: 49.6s\tremaining: 22.8s\n",
            "8346:\tlearn: 7.7159621\ttotal: 49.6s\tremaining: 22.8s\n",
            "8347:\tlearn: 7.7159500\ttotal: 49.6s\tremaining: 22.8s\n",
            "8348:\tlearn: 7.7159391\ttotal: 49.6s\tremaining: 22.8s\n",
            "8349:\tlearn: 7.7159252\ttotal: 49.6s\tremaining: 22.8s\n",
            "8350:\tlearn: 7.7159137\ttotal: 49.6s\tremaining: 22.8s\n",
            "8351:\tlearn: 7.7159016\ttotal: 49.6s\tremaining: 22.8s\n",
            "8352:\tlearn: 7.7158887\ttotal: 49.6s\tremaining: 22.7s\n",
            "8353:\tlearn: 7.7158846\ttotal: 49.6s\tremaining: 22.7s\n",
            "8354:\tlearn: 7.7158766\ttotal: 49.6s\tremaining: 22.7s\n",
            "8355:\tlearn: 7.7158633\ttotal: 49.6s\tremaining: 22.7s\n",
            "8356:\tlearn: 7.7158527\ttotal: 49.7s\tremaining: 22.7s\n",
            "8357:\tlearn: 7.7158288\ttotal: 49.7s\tremaining: 22.7s\n",
            "8358:\tlearn: 7.7158175\ttotal: 49.7s\tremaining: 22.7s\n",
            "8359:\tlearn: 7.7158112\ttotal: 49.7s\tremaining: 22.7s\n",
            "8360:\tlearn: 7.7157965\ttotal: 49.7s\tremaining: 22.7s\n",
            "8361:\tlearn: 7.7157896\ttotal: 49.7s\tremaining: 22.7s\n",
            "8362:\tlearn: 7.7157792\ttotal: 49.7s\tremaining: 22.7s\n",
            "8363:\tlearn: 7.7157524\ttotal: 49.7s\tremaining: 22.7s\n",
            "8364:\tlearn: 7.7157377\ttotal: 49.7s\tremaining: 22.7s\n",
            "8365:\tlearn: 7.7157288\ttotal: 49.7s\tremaining: 22.7s\n",
            "8366:\tlearn: 7.7157202\ttotal: 49.7s\tremaining: 22.7s\n",
            "8367:\tlearn: 7.7157095\ttotal: 49.7s\tremaining: 22.7s\n",
            "8368:\tlearn: 7.7157012\ttotal: 49.7s\tremaining: 22.6s\n",
            "8369:\tlearn: 7.7156954\ttotal: 49.7s\tremaining: 22.7s\n",
            "8370:\tlearn: 7.7156799\ttotal: 49.8s\tremaining: 22.6s\n",
            "8371:\tlearn: 7.7156724\ttotal: 49.8s\tremaining: 22.6s\n",
            "8372:\tlearn: 7.7156620\ttotal: 49.8s\tremaining: 22.6s\n",
            "8373:\tlearn: 7.7156516\ttotal: 49.8s\tremaining: 22.6s\n",
            "8374:\tlearn: 7.7156433\ttotal: 49.8s\tremaining: 22.6s\n",
            "8375:\tlearn: 7.7156392\ttotal: 49.8s\tremaining: 22.6s\n",
            "8376:\tlearn: 7.7156294\ttotal: 49.8s\tremaining: 22.6s\n",
            "8377:\tlearn: 7.7156248\ttotal: 49.8s\tremaining: 22.6s\n",
            "8378:\tlearn: 7.7156220\ttotal: 49.8s\tremaining: 22.6s\n",
            "8379:\tlearn: 7.7156113\ttotal: 49.8s\tremaining: 22.6s\n",
            "8380:\tlearn: 7.7156015\ttotal: 49.8s\tremaining: 22.6s\n",
            "8381:\tlearn: 7.7155842\ttotal: 49.8s\tremaining: 22.6s\n",
            "8382:\tlearn: 7.7155672\ttotal: 49.8s\tremaining: 22.6s\n",
            "8383:\tlearn: 7.7155618\ttotal: 49.8s\tremaining: 22.6s\n",
            "8384:\tlearn: 7.7155517\ttotal: 49.8s\tremaining: 22.6s\n",
            "8385:\tlearn: 7.7155451\ttotal: 49.8s\tremaining: 22.6s\n",
            "8386:\tlearn: 7.7155148\ttotal: 49.9s\tremaining: 22.6s\n",
            "8387:\tlearn: 7.7155010\ttotal: 49.9s\tremaining: 22.5s\n",
            "8388:\tlearn: 7.7154768\ttotal: 49.9s\tremaining: 22.5s\n",
            "8389:\tlearn: 7.7154702\ttotal: 49.9s\tremaining: 22.5s\n",
            "8390:\tlearn: 7.7154647\ttotal: 49.9s\tremaining: 22.5s\n",
            "8391:\tlearn: 7.7154529\ttotal: 49.9s\tremaining: 22.5s\n",
            "8392:\tlearn: 7.7154460\ttotal: 49.9s\tremaining: 22.5s\n",
            "8393:\tlearn: 7.7154299\ttotal: 49.9s\tremaining: 22.5s\n",
            "8394:\tlearn: 7.7154198\ttotal: 49.9s\tremaining: 22.5s\n",
            "8395:\tlearn: 7.7154062\ttotal: 49.9s\tremaining: 22.5s\n",
            "8396:\tlearn: 7.7153861\ttotal: 49.9s\tremaining: 22.5s\n",
            "8397:\tlearn: 7.7153688\ttotal: 49.9s\tremaining: 22.5s\n",
            "8398:\tlearn: 7.7153691\ttotal: 49.9s\tremaining: 22.5s\n",
            "8399:\tlearn: 7.7153547\ttotal: 49.9s\tremaining: 22.5s\n",
            "8400:\tlearn: 7.7153319\ttotal: 49.9s\tremaining: 22.5s\n",
            "8401:\tlearn: 7.7153106\ttotal: 49.9s\tremaining: 22.5s\n",
            "8402:\tlearn: 7.7152953\ttotal: 49.9s\tremaining: 22.5s\n",
            "8403:\tlearn: 7.7152795\ttotal: 50s\tremaining: 22.4s\n",
            "8404:\tlearn: 7.7152700\ttotal: 50s\tremaining: 22.4s\n",
            "8405:\tlearn: 7.7152495\ttotal: 50s\tremaining: 22.4s\n",
            "8406:\tlearn: 7.7152285\ttotal: 50s\tremaining: 22.4s\n",
            "8407:\tlearn: 7.7152233\ttotal: 50s\tremaining: 22.4s\n",
            "8408:\tlearn: 7.7152130\ttotal: 50s\tremaining: 22.4s\n",
            "8409:\tlearn: 7.7152055\ttotal: 50s\tremaining: 22.4s\n",
            "8410:\tlearn: 7.7151986\ttotal: 50s\tremaining: 22.4s\n",
            "8411:\tlearn: 7.7151873\ttotal: 50s\tremaining: 22.4s\n",
            "8412:\tlearn: 7.7151813\ttotal: 50s\tremaining: 22.4s\n",
            "8413:\tlearn: 7.7151833\ttotal: 50s\tremaining: 22.4s\n",
            "8414:\tlearn: 7.7151626\ttotal: 50s\tremaining: 22.4s\n",
            "8415:\tlearn: 7.7151450\ttotal: 50s\tremaining: 22.4s\n",
            "8416:\tlearn: 7.7151326\ttotal: 50s\tremaining: 22.4s\n",
            "8417:\tlearn: 7.7151289\ttotal: 50s\tremaining: 22.4s\n",
            "8418:\tlearn: 7.7151156\ttotal: 50s\tremaining: 22.4s\n",
            "8419:\tlearn: 7.7151113\ttotal: 50s\tremaining: 22.4s\n",
            "8420:\tlearn: 7.7150975\ttotal: 50s\tremaining: 22.3s\n",
            "8421:\tlearn: 7.7150888\ttotal: 50.1s\tremaining: 22.3s\n",
            "8422:\tlearn: 7.7150888\ttotal: 50.1s\tremaining: 22.3s\n",
            "8423:\tlearn: 7.7150733\ttotal: 50.1s\tremaining: 22.3s\n",
            "8424:\tlearn: 7.7150701\ttotal: 50.1s\tremaining: 22.3s\n",
            "8425:\tlearn: 7.7150626\ttotal: 50.1s\tremaining: 22.3s\n",
            "8426:\tlearn: 7.7150569\ttotal: 50.1s\tremaining: 22.3s\n",
            "8427:\tlearn: 7.7150396\ttotal: 50.1s\tremaining: 22.3s\n",
            "8428:\tlearn: 7.7150304\ttotal: 50.1s\tremaining: 22.3s\n",
            "8429:\tlearn: 7.7150203\ttotal: 50.1s\tremaining: 22.3s\n",
            "8430:\tlearn: 7.7150136\ttotal: 50.1s\tremaining: 22.3s\n",
            "8431:\tlearn: 7.7150050\ttotal: 50.1s\tremaining: 22.3s\n",
            "8432:\tlearn: 7.7149912\ttotal: 50.1s\tremaining: 22.3s\n",
            "8433:\tlearn: 7.7149799\ttotal: 50.1s\tremaining: 22.3s\n",
            "8434:\tlearn: 7.7149655\ttotal: 50.1s\tremaining: 22.3s\n",
            "8435:\tlearn: 7.7149500\ttotal: 50.1s\tremaining: 22.3s\n",
            "8436:\tlearn: 7.7149379\ttotal: 50.1s\tremaining: 22.2s\n",
            "8437:\tlearn: 7.7149261\ttotal: 50.1s\tremaining: 22.2s\n",
            "8438:\tlearn: 7.7149068\ttotal: 50.1s\tremaining: 22.2s\n",
            "8439:\tlearn: 7.7148981\ttotal: 50.2s\tremaining: 22.2s\n",
            "8440:\tlearn: 7.7148889\ttotal: 50.2s\tremaining: 22.2s\n",
            "8441:\tlearn: 7.7148734\ttotal: 50.2s\tremaining: 22.2s\n",
            "8442:\tlearn: 7.7148656\ttotal: 50.2s\tremaining: 22.2s\n",
            "8443:\tlearn: 7.7148598\ttotal: 50.2s\tremaining: 22.2s\n",
            "8444:\tlearn: 7.7148472\ttotal: 50.2s\tremaining: 22.2s\n",
            "8445:\tlearn: 7.7148420\ttotal: 50.2s\tremaining: 22.2s\n",
            "8446:\tlearn: 7.7148359\ttotal: 50.2s\tremaining: 22.2s\n",
            "8447:\tlearn: 7.7148293\ttotal: 50.2s\tremaining: 22.2s\n",
            "8448:\tlearn: 7.7148120\ttotal: 50.2s\tremaining: 22.2s\n",
            "8449:\tlearn: 7.7148028\ttotal: 50.2s\tremaining: 22.2s\n",
            "8450:\tlearn: 7.7147907\ttotal: 50.2s\tremaining: 22.2s\n",
            "8451:\tlearn: 7.7147746\ttotal: 50.2s\tremaining: 22.2s\n",
            "8452:\tlearn: 7.7147639\ttotal: 50.2s\tremaining: 22.2s\n",
            "8453:\tlearn: 7.7147527\ttotal: 50.2s\tremaining: 22.1s\n",
            "8454:\tlearn: 7.7147432\ttotal: 50.2s\tremaining: 22.1s\n",
            "8455:\tlearn: 7.7147265\ttotal: 50.3s\tremaining: 22.1s\n",
            "8456:\tlearn: 7.7147141\ttotal: 50.3s\tremaining: 22.1s\n",
            "8457:\tlearn: 7.7147072\ttotal: 50.3s\tremaining: 22.1s\n",
            "8458:\tlearn: 7.7146988\ttotal: 50.3s\tremaining: 22.1s\n",
            "8459:\tlearn: 7.7146913\ttotal: 50.3s\tremaining: 22.1s\n",
            "8460:\tlearn: 7.7146729\ttotal: 50.3s\tremaining: 22.1s\n",
            "8461:\tlearn: 7.7146599\ttotal: 50.3s\tremaining: 22.1s\n",
            "8462:\tlearn: 7.7146565\ttotal: 50.3s\tremaining: 22.1s\n",
            "8463:\tlearn: 7.7146424\ttotal: 50.3s\tremaining: 22.1s\n",
            "8464:\tlearn: 7.7146337\ttotal: 50.3s\tremaining: 22.1s\n",
            "8465:\tlearn: 7.7146213\ttotal: 50.3s\tremaining: 22.1s\n",
            "8466:\tlearn: 7.7146003\ttotal: 50.3s\tremaining: 22.1s\n",
            "8467:\tlearn: 7.7145899\ttotal: 50.3s\tremaining: 22.1s\n",
            "8468:\tlearn: 7.7145839\ttotal: 50.3s\tremaining: 22.1s\n",
            "8469:\tlearn: 7.7145646\ttotal: 50.3s\tremaining: 22.1s\n",
            "8470:\tlearn: 7.7145467\ttotal: 50.3s\tremaining: 22s\n",
            "8471:\tlearn: 7.7145389\ttotal: 50.3s\tremaining: 22s\n",
            "8472:\tlearn: 7.7145329\ttotal: 50.3s\tremaining: 22s\n",
            "8473:\tlearn: 7.7145084\ttotal: 50.3s\tremaining: 22s\n",
            "8474:\tlearn: 7.7144940\ttotal: 50.4s\tremaining: 22s\n",
            "8475:\tlearn: 7.7144799\ttotal: 50.4s\tremaining: 22s\n",
            "8476:\tlearn: 7.7144672\ttotal: 50.4s\tremaining: 22s\n",
            "8477:\tlearn: 7.7144592\ttotal: 50.4s\tremaining: 22s\n",
            "8478:\tlearn: 7.7144554\ttotal: 50.4s\tremaining: 22s\n",
            "8479:\tlearn: 7.7144445\ttotal: 50.4s\tremaining: 22s\n",
            "8480:\tlearn: 7.7144326\ttotal: 50.4s\tremaining: 22s\n",
            "8481:\tlearn: 7.7144234\ttotal: 50.4s\tremaining: 22s\n",
            "8482:\tlearn: 7.7144099\ttotal: 50.4s\tremaining: 22s\n",
            "8483:\tlearn: 7.7143943\ttotal: 50.4s\tremaining: 22s\n",
            "8484:\tlearn: 7.7143912\ttotal: 50.4s\tremaining: 22s\n",
            "8485:\tlearn: 7.7143750\ttotal: 50.4s\tremaining: 22s\n",
            "8486:\tlearn: 7.7143632\ttotal: 50.4s\tremaining: 21.9s\n",
            "8487:\tlearn: 7.7143589\ttotal: 50.4s\tremaining: 21.9s\n",
            "8488:\tlearn: 7.7143520\ttotal: 50.4s\tremaining: 21.9s\n",
            "8489:\tlearn: 7.7143482\ttotal: 50.4s\tremaining: 21.9s\n",
            "8490:\tlearn: 7.7143307\ttotal: 50.4s\tremaining: 21.9s\n",
            "8491:\tlearn: 7.7143223\ttotal: 50.5s\tremaining: 21.9s\n",
            "8492:\tlearn: 7.7143151\ttotal: 50.5s\tremaining: 21.9s\n",
            "8493:\tlearn: 7.7143145\ttotal: 50.5s\tremaining: 21.9s\n",
            "8494:\tlearn: 7.7143088\ttotal: 50.5s\tremaining: 21.9s\n",
            "8495:\tlearn: 7.7142892\ttotal: 50.5s\tremaining: 21.9s\n",
            "8496:\tlearn: 7.7142817\ttotal: 50.5s\tremaining: 21.9s\n",
            "8497:\tlearn: 7.7142765\ttotal: 50.5s\tremaining: 21.9s\n",
            "8498:\tlearn: 7.7142624\ttotal: 50.5s\tremaining: 21.9s\n",
            "8499:\tlearn: 7.7142592\ttotal: 50.5s\tremaining: 21.9s\n",
            "8500:\tlearn: 7.7142448\ttotal: 50.5s\tremaining: 21.9s\n",
            "8501:\tlearn: 7.7142255\ttotal: 50.5s\tremaining: 21.9s\n",
            "8502:\tlearn: 7.7142183\ttotal: 50.5s\tremaining: 21.9s\n",
            "8503:\tlearn: 7.7141970\ttotal: 50.5s\tremaining: 21.8s\n",
            "8504:\tlearn: 7.7141826\ttotal: 50.5s\tremaining: 21.8s\n",
            "8505:\tlearn: 7.7141731\ttotal: 50.5s\tremaining: 21.8s\n",
            "8506:\tlearn: 7.7141656\ttotal: 50.5s\tremaining: 21.8s\n",
            "8507:\tlearn: 7.7141645\ttotal: 50.5s\tremaining: 21.8s\n",
            "8508:\tlearn: 7.7141593\ttotal: 50.5s\tremaining: 21.8s\n",
            "8509:\tlearn: 7.7141457\ttotal: 50.6s\tremaining: 21.8s\n",
            "8510:\tlearn: 7.7141397\ttotal: 50.6s\tremaining: 21.8s\n",
            "8511:\tlearn: 7.7141296\ttotal: 50.6s\tremaining: 21.8s\n",
            "8512:\tlearn: 7.7141172\ttotal: 50.6s\tremaining: 21.8s\n",
            "8513:\tlearn: 7.7141149\ttotal: 50.6s\tremaining: 21.8s\n",
            "8514:\tlearn: 7.7141011\ttotal: 50.6s\tremaining: 21.8s\n",
            "8515:\tlearn: 7.7140913\ttotal: 50.6s\tremaining: 21.8s\n",
            "8516:\tlearn: 7.7140772\ttotal: 50.6s\tremaining: 21.8s\n",
            "8517:\tlearn: 7.7140760\ttotal: 50.6s\tremaining: 21.8s\n",
            "8518:\tlearn: 7.7140622\ttotal: 50.6s\tremaining: 21.8s\n",
            "8519:\tlearn: 7.7140492\ttotal: 50.6s\tremaining: 21.8s\n",
            "8520:\tlearn: 7.7140409\ttotal: 50.6s\tremaining: 21.7s\n",
            "8521:\tlearn: 7.7140184\ttotal: 50.6s\tremaining: 21.7s\n",
            "8522:\tlearn: 7.7140011\ttotal: 50.6s\tremaining: 21.7s\n",
            "8523:\tlearn: 7.7139919\ttotal: 50.6s\tremaining: 21.7s\n",
            "8524:\tlearn: 7.7139807\ttotal: 50.7s\tremaining: 21.7s\n",
            "8525:\tlearn: 7.7139712\ttotal: 50.7s\tremaining: 21.7s\n",
            "8526:\tlearn: 7.7139594\ttotal: 50.7s\tremaining: 21.7s\n",
            "8527:\tlearn: 7.7139498\ttotal: 50.7s\tremaining: 21.7s\n",
            "8528:\tlearn: 7.7139320\ttotal: 50.7s\tremaining: 21.7s\n",
            "8529:\tlearn: 7.7139242\ttotal: 50.7s\tremaining: 21.7s\n",
            "8530:\tlearn: 7.7139173\ttotal: 50.7s\tremaining: 21.7s\n",
            "8531:\tlearn: 7.7139072\ttotal: 50.7s\tremaining: 21.7s\n",
            "8532:\tlearn: 7.7139003\ttotal: 50.7s\tremaining: 21.7s\n",
            "8533:\tlearn: 7.7138709\ttotal: 50.7s\tremaining: 21.7s\n",
            "8534:\tlearn: 7.7138548\ttotal: 50.7s\tremaining: 21.7s\n",
            "8535:\tlearn: 7.7138427\ttotal: 50.7s\tremaining: 21.7s\n",
            "8536:\tlearn: 7.7138401\ttotal: 50.7s\tremaining: 21.7s\n",
            "8537:\tlearn: 7.7138248\ttotal: 50.7s\tremaining: 21.6s\n",
            "8538:\tlearn: 7.7137989\ttotal: 50.7s\tremaining: 21.6s\n",
            "8539:\tlearn: 7.7137951\ttotal: 50.7s\tremaining: 21.6s\n",
            "8540:\tlearn: 7.7137879\ttotal: 50.8s\tremaining: 21.6s\n",
            "8541:\tlearn: 7.7137733\ttotal: 50.8s\tremaining: 21.6s\n",
            "8542:\tlearn: 7.7137632\ttotal: 50.8s\tremaining: 21.6s\n",
            "8543:\tlearn: 7.7137594\ttotal: 50.8s\tremaining: 21.6s\n",
            "8544:\tlearn: 7.7137413\ttotal: 50.8s\tremaining: 21.6s\n",
            "8545:\tlearn: 7.7137295\ttotal: 50.8s\tremaining: 21.6s\n",
            "8546:\tlearn: 7.7137168\ttotal: 50.8s\tremaining: 21.6s\n",
            "8547:\tlearn: 7.7137012\ttotal: 50.8s\tremaining: 21.6s\n",
            "8548:\tlearn: 7.7136862\ttotal: 50.8s\tremaining: 21.6s\n",
            "8549:\tlearn: 7.7136704\ttotal: 50.8s\tremaining: 21.6s\n",
            "8550:\tlearn: 7.7136548\ttotal: 50.8s\tremaining: 21.6s\n",
            "8551:\tlearn: 7.7136419\ttotal: 50.8s\tremaining: 21.6s\n",
            "8552:\tlearn: 7.7136258\ttotal: 50.8s\tremaining: 21.6s\n",
            "8553:\tlearn: 7.7136137\ttotal: 50.8s\tremaining: 21.6s\n",
            "8554:\tlearn: 7.7136056\ttotal: 50.8s\tremaining: 21.6s\n",
            "8555:\tlearn: 7.7136036\ttotal: 50.9s\tremaining: 21.5s\n",
            "8556:\tlearn: 7.7135987\ttotal: 50.9s\tremaining: 21.5s\n",
            "8557:\tlearn: 7.7135874\ttotal: 50.9s\tremaining: 21.5s\n",
            "8558:\tlearn: 7.7135779\ttotal: 50.9s\tremaining: 21.5s\n",
            "8559:\tlearn: 7.7135681\ttotal: 50.9s\tremaining: 21.5s\n",
            "8560:\tlearn: 7.7135500\ttotal: 50.9s\tremaining: 21.5s\n",
            "8561:\tlearn: 7.7135405\ttotal: 50.9s\tremaining: 21.5s\n",
            "8562:\tlearn: 7.7135275\ttotal: 50.9s\tremaining: 21.5s\n",
            "8563:\tlearn: 7.7135013\ttotal: 50.9s\tremaining: 21.5s\n",
            "8564:\tlearn: 7.7134950\ttotal: 50.9s\tremaining: 21.5s\n",
            "8565:\tlearn: 7.7134797\ttotal: 50.9s\tremaining: 21.5s\n",
            "8566:\tlearn: 7.7134558\ttotal: 50.9s\tremaining: 21.5s\n",
            "8567:\tlearn: 7.7134466\ttotal: 50.9s\tremaining: 21.5s\n",
            "8568:\tlearn: 7.7134327\ttotal: 50.9s\tremaining: 21.5s\n",
            "8569:\tlearn: 7.7134273\ttotal: 50.9s\tremaining: 21.5s\n",
            "8570:\tlearn: 7.7134221\ttotal: 50.9s\tremaining: 21.5s\n",
            "8571:\tlearn: 7.7134131\ttotal: 50.9s\tremaining: 21.4s\n",
            "8572:\tlearn: 7.7134080\ttotal: 50.9s\tremaining: 21.4s\n",
            "8573:\tlearn: 7.7133930\ttotal: 50.9s\tremaining: 21.4s\n",
            "8574:\tlearn: 7.7133757\ttotal: 51s\tremaining: 21.4s\n",
            "8575:\tlearn: 7.7133702\ttotal: 51s\tremaining: 21.4s\n",
            "8576:\tlearn: 7.7133555\ttotal: 51s\tremaining: 21.4s\n",
            "8577:\tlearn: 7.7133431\ttotal: 51s\tremaining: 21.4s\n",
            "8578:\tlearn: 7.7133362\ttotal: 51s\tremaining: 21.4s\n",
            "8579:\tlearn: 7.7133293\ttotal: 51s\tremaining: 21.4s\n",
            "8580:\tlearn: 7.7133152\ttotal: 51s\tremaining: 21.4s\n",
            "8581:\tlearn: 7.7133083\ttotal: 51s\tremaining: 21.4s\n",
            "8582:\tlearn: 7.7132942\ttotal: 51s\tremaining: 21.4s\n",
            "8583:\tlearn: 7.7132711\ttotal: 51s\tremaining: 21.4s\n",
            "8584:\tlearn: 7.7132648\ttotal: 51s\tremaining: 21.4s\n",
            "8585:\tlearn: 7.7132616\ttotal: 51s\tremaining: 21.4s\n",
            "8586:\tlearn: 7.7132455\ttotal: 51s\tremaining: 21.4s\n",
            "8587:\tlearn: 7.7132164\ttotal: 51s\tremaining: 21.4s\n",
            "8588:\tlearn: 7.7132135\ttotal: 51s\tremaining: 21.3s\n",
            "8589:\tlearn: 7.7131973\ttotal: 51s\tremaining: 21.3s\n",
            "8590:\tlearn: 7.7131884\ttotal: 51.1s\tremaining: 21.3s\n",
            "8591:\tlearn: 7.7131798\ttotal: 51.1s\tremaining: 21.3s\n",
            "8592:\tlearn: 7.7131657\ttotal: 51.1s\tremaining: 21.3s\n",
            "8593:\tlearn: 7.7131622\ttotal: 51.1s\tremaining: 21.3s\n",
            "8594:\tlearn: 7.7131527\ttotal: 51.1s\tremaining: 21.3s\n",
            "8595:\tlearn: 7.7131386\ttotal: 51.1s\tremaining: 21.3s\n",
            "8596:\tlearn: 7.7131247\ttotal: 51.1s\tremaining: 21.3s\n",
            "8597:\tlearn: 7.7131224\ttotal: 51.1s\tremaining: 21.3s\n",
            "8598:\tlearn: 7.7131089\ttotal: 51.1s\tremaining: 21.3s\n",
            "8599:\tlearn: 7.7130893\ttotal: 51.1s\tremaining: 21.3s\n",
            "8600:\tlearn: 7.7130859\ttotal: 51.1s\tremaining: 21.3s\n",
            "8601:\tlearn: 7.7130677\ttotal: 51.1s\tremaining: 21.3s\n",
            "8602:\tlearn: 7.7130579\ttotal: 51.1s\tremaining: 21.3s\n",
            "8603:\tlearn: 7.7130432\ttotal: 51.1s\tremaining: 21.3s\n",
            "8604:\tlearn: 7.7130331\ttotal: 51.1s\tremaining: 21.2s\n",
            "8605:\tlearn: 7.7130228\ttotal: 51.1s\tremaining: 21.2s\n",
            "8606:\tlearn: 7.7130069\ttotal: 51.1s\tremaining: 21.2s\n",
            "8607:\tlearn: 7.7129980\ttotal: 51.1s\tremaining: 21.2s\n",
            "8608:\tlearn: 7.7129931\ttotal: 51.2s\tremaining: 21.2s\n",
            "8609:\tlearn: 7.7129787\ttotal: 51.2s\tremaining: 21.2s\n",
            "8610:\tlearn: 7.7129689\ttotal: 51.2s\tremaining: 21.2s\n",
            "8611:\tlearn: 7.7129571\ttotal: 51.2s\tremaining: 21.2s\n",
            "8612:\tlearn: 7.7129478\ttotal: 51.2s\tremaining: 21.2s\n",
            "8613:\tlearn: 7.7129383\ttotal: 51.2s\tremaining: 21.2s\n",
            "8614:\tlearn: 7.7129271\ttotal: 51.2s\tremaining: 21.2s\n",
            "8615:\tlearn: 7.7129234\ttotal: 51.2s\tremaining: 21.2s\n",
            "8616:\tlearn: 7.7129136\ttotal: 51.2s\tremaining: 21.2s\n",
            "8617:\tlearn: 7.7129087\ttotal: 51.2s\tremaining: 21.2s\n",
            "8618:\tlearn: 7.7129029\ttotal: 51.2s\tremaining: 21.2s\n",
            "8619:\tlearn: 7.7128905\ttotal: 51.2s\tremaining: 21.2s\n",
            "8620:\tlearn: 7.7128726\ttotal: 51.2s\tremaining: 21.2s\n",
            "8621:\tlearn: 7.7128545\ttotal: 51.2s\tremaining: 21.1s\n",
            "8622:\tlearn: 7.7128467\ttotal: 51.2s\tremaining: 21.1s\n",
            "8623:\tlearn: 7.7128421\ttotal: 51.2s\tremaining: 21.1s\n",
            "8624:\tlearn: 7.7128343\ttotal: 51.3s\tremaining: 21.1s\n",
            "8625:\tlearn: 7.7128142\ttotal: 51.3s\tremaining: 21.1s\n",
            "8626:\tlearn: 7.7127954\ttotal: 51.3s\tremaining: 21.1s\n",
            "8627:\tlearn: 7.7127943\ttotal: 51.3s\tremaining: 21.1s\n",
            "8628:\tlearn: 7.7127761\ttotal: 51.3s\tremaining: 21.1s\n",
            "8629:\tlearn: 7.7127640\ttotal: 51.3s\tremaining: 21.1s\n",
            "8630:\tlearn: 7.7127413\ttotal: 51.3s\tremaining: 21.1s\n",
            "8631:\tlearn: 7.7127156\ttotal: 51.3s\tremaining: 21.1s\n",
            "8632:\tlearn: 7.7127099\ttotal: 51.3s\tremaining: 21.1s\n",
            "8633:\tlearn: 7.7127032\ttotal: 51.3s\tremaining: 21.1s\n",
            "8634:\tlearn: 7.7126900\ttotal: 51.3s\tremaining: 21.1s\n",
            "8635:\tlearn: 7.7126799\ttotal: 51.3s\tremaining: 21.1s\n",
            "8636:\tlearn: 7.7126681\ttotal: 51.3s\tremaining: 21.1s\n",
            "8637:\tlearn: 7.7126600\ttotal: 51.3s\tremaining: 21.1s\n",
            "8638:\tlearn: 7.7126459\ttotal: 51.3s\tremaining: 21s\n",
            "8639:\tlearn: 7.7126329\ttotal: 51.3s\tremaining: 21s\n",
            "8640:\tlearn: 7.7126197\ttotal: 51.3s\tremaining: 21s\n",
            "8641:\tlearn: 7.7126116\ttotal: 51.4s\tremaining: 21s\n",
            "8642:\tlearn: 7.7126018\ttotal: 51.4s\tremaining: 21s\n",
            "8643:\tlearn: 7.7125969\ttotal: 51.4s\tremaining: 21s\n",
            "8644:\tlearn: 7.7125854\ttotal: 51.4s\tremaining: 21s\n",
            "8645:\tlearn: 7.7125704\ttotal: 51.4s\tremaining: 21s\n",
            "8646:\tlearn: 7.7125502\ttotal: 51.4s\tremaining: 21s\n",
            "8647:\tlearn: 7.7125390\ttotal: 51.4s\tremaining: 21s\n",
            "8648:\tlearn: 7.7125275\ttotal: 51.4s\tremaining: 21s\n",
            "8649:\tlearn: 7.7125214\ttotal: 51.4s\tremaining: 21s\n",
            "8650:\tlearn: 7.7125119\ttotal: 51.4s\tremaining: 21s\n",
            "8651:\tlearn: 7.7124863\ttotal: 51.4s\tremaining: 21s\n",
            "8652:\tlearn: 7.7124779\ttotal: 51.4s\tremaining: 21s\n",
            "8653:\tlearn: 7.7124722\ttotal: 51.4s\tremaining: 21s\n",
            "8654:\tlearn: 7.7124583\ttotal: 51.4s\tremaining: 21s\n",
            "8655:\tlearn: 7.7124422\ttotal: 51.4s\tremaining: 20.9s\n",
            "8656:\tlearn: 7.7124309\ttotal: 51.4s\tremaining: 20.9s\n",
            "8657:\tlearn: 7.7124191\ttotal: 51.4s\tremaining: 20.9s\n",
            "8658:\tlearn: 7.7124016\ttotal: 51.5s\tremaining: 20.9s\n",
            "8659:\tlearn: 7.7123903\ttotal: 51.5s\tremaining: 20.9s\n",
            "8660:\tlearn: 7.7123736\ttotal: 51.5s\tremaining: 20.9s\n",
            "8661:\tlearn: 7.7123624\ttotal: 51.5s\tremaining: 20.9s\n",
            "8662:\tlearn: 7.7123575\ttotal: 51.5s\tremaining: 20.9s\n",
            "8663:\tlearn: 7.7123503\ttotal: 51.5s\tremaining: 20.9s\n",
            "8664:\tlearn: 7.7123327\ttotal: 51.5s\tremaining: 20.9s\n",
            "8665:\tlearn: 7.7123168\ttotal: 51.5s\tremaining: 20.9s\n",
            "8666:\tlearn: 7.7123079\ttotal: 51.5s\tremaining: 20.9s\n",
            "8667:\tlearn: 7.7123030\ttotal: 51.5s\tremaining: 20.9s\n",
            "8668:\tlearn: 7.7122797\ttotal: 51.5s\tremaining: 20.9s\n",
            "8669:\tlearn: 7.7122604\ttotal: 51.5s\tremaining: 20.9s\n",
            "8670:\tlearn: 7.7122474\ttotal: 51.5s\tremaining: 20.9s\n",
            "8671:\tlearn: 7.7122307\ttotal: 51.5s\tremaining: 20.8s\n",
            "8672:\tlearn: 7.7122079\ttotal: 51.5s\tremaining: 20.8s\n",
            "8673:\tlearn: 7.7121924\ttotal: 51.5s\tremaining: 20.8s\n",
            "8674:\tlearn: 7.7121863\ttotal: 51.5s\tremaining: 20.8s\n",
            "8675:\tlearn: 7.7121777\ttotal: 51.5s\tremaining: 20.8s\n",
            "8676:\tlearn: 7.7121664\ttotal: 51.6s\tremaining: 20.8s\n",
            "8677:\tlearn: 7.7121592\ttotal: 51.6s\tremaining: 20.8s\n",
            "8678:\tlearn: 7.7121463\ttotal: 51.6s\tremaining: 20.8s\n",
            "8679:\tlearn: 7.7121327\ttotal: 51.6s\tremaining: 20.8s\n",
            "8680:\tlearn: 7.7121045\ttotal: 51.6s\tremaining: 20.8s\n",
            "8681:\tlearn: 7.7121004\ttotal: 51.6s\tremaining: 20.8s\n",
            "8682:\tlearn: 7.7120797\ttotal: 51.6s\tremaining: 20.8s\n",
            "8683:\tlearn: 7.7120742\ttotal: 51.6s\tremaining: 20.8s\n",
            "8684:\tlearn: 7.7120569\ttotal: 51.6s\tremaining: 20.8s\n",
            "8685:\tlearn: 7.7120489\ttotal: 51.6s\tremaining: 20.8s\n",
            "8686:\tlearn: 7.7120365\ttotal: 51.6s\tremaining: 20.8s\n",
            "8687:\tlearn: 7.7120221\ttotal: 51.6s\tremaining: 20.8s\n",
            "8688:\tlearn: 7.7120140\ttotal: 51.6s\tremaining: 20.7s\n",
            "8689:\tlearn: 7.7120085\ttotal: 51.6s\tremaining: 20.7s\n",
            "8690:\tlearn: 7.7119964\ttotal: 51.6s\tremaining: 20.7s\n",
            "8691:\tlearn: 7.7119886\ttotal: 51.6s\tremaining: 20.7s\n",
            "8692:\tlearn: 7.7119740\ttotal: 51.7s\tremaining: 20.7s\n",
            "8693:\tlearn: 7.7119676\ttotal: 51.7s\tremaining: 20.7s\n",
            "8694:\tlearn: 7.7119451\ttotal: 51.7s\tremaining: 20.7s\n",
            "8695:\tlearn: 7.7119368\ttotal: 51.7s\tremaining: 20.7s\n",
            "8696:\tlearn: 7.7119120\ttotal: 51.7s\tremaining: 20.7s\n",
            "8697:\tlearn: 7.7119010\ttotal: 51.7s\tremaining: 20.7s\n",
            "8698:\tlearn: 7.7118953\ttotal: 51.7s\tremaining: 20.7s\n",
            "8699:\tlearn: 7.7118858\ttotal: 51.7s\tremaining: 20.7s\n",
            "8700:\tlearn: 7.7118789\ttotal: 51.7s\tremaining: 20.7s\n",
            "8701:\tlearn: 7.7118682\ttotal: 51.7s\tremaining: 20.7s\n",
            "8702:\tlearn: 7.7118495\ttotal: 51.7s\tremaining: 20.7s\n",
            "8703:\tlearn: 7.7118400\ttotal: 51.7s\tremaining: 20.7s\n",
            "8704:\tlearn: 7.7118267\ttotal: 51.7s\tremaining: 20.7s\n",
            "8705:\tlearn: 7.7118114\ttotal: 51.7s\tremaining: 20.7s\n",
            "8706:\tlearn: 7.7117950\ttotal: 51.7s\tremaining: 20.6s\n",
            "8707:\tlearn: 7.7117815\ttotal: 51.8s\tremaining: 20.6s\n",
            "8708:\tlearn: 7.7117725\ttotal: 51.8s\tremaining: 20.6s\n",
            "8709:\tlearn: 7.7117610\ttotal: 51.8s\tremaining: 20.6s\n",
            "8710:\tlearn: 7.7117486\ttotal: 51.8s\tremaining: 20.6s\n",
            "8711:\tlearn: 7.7117359\ttotal: 51.8s\tremaining: 20.6s\n",
            "8712:\tlearn: 7.7117261\ttotal: 51.8s\tremaining: 20.6s\n",
            "8713:\tlearn: 7.7117218\ttotal: 51.8s\tremaining: 20.6s\n",
            "8714:\tlearn: 7.7117137\ttotal: 51.8s\tremaining: 20.6s\n",
            "8715:\tlearn: 7.7117086\ttotal: 51.8s\tremaining: 20.6s\n",
            "8716:\tlearn: 7.7116838\ttotal: 51.8s\tremaining: 20.6s\n",
            "8717:\tlearn: 7.7116699\ttotal: 51.8s\tremaining: 20.6s\n",
            "8718:\tlearn: 7.7116593\ttotal: 51.8s\tremaining: 20.6s\n",
            "8719:\tlearn: 7.7116466\ttotal: 51.8s\tremaining: 20.6s\n",
            "8720:\tlearn: 7.7116411\ttotal: 51.8s\tremaining: 20.6s\n",
            "8721:\tlearn: 7.7116325\ttotal: 51.8s\tremaining: 20.6s\n",
            "8722:\tlearn: 7.7116236\ttotal: 51.8s\tremaining: 20.6s\n",
            "8723:\tlearn: 7.7116163\ttotal: 51.9s\tremaining: 20.5s\n",
            "8724:\tlearn: 7.7116016\ttotal: 51.9s\tremaining: 20.5s\n",
            "8725:\tlearn: 7.7115965\ttotal: 51.9s\tremaining: 20.5s\n",
            "8726:\tlearn: 7.7115884\ttotal: 51.9s\tremaining: 20.5s\n",
            "8727:\tlearn: 7.7115821\ttotal: 51.9s\tremaining: 20.5s\n",
            "8728:\tlearn: 7.7115725\ttotal: 51.9s\tremaining: 20.5s\n",
            "8729:\tlearn: 7.7115619\ttotal: 51.9s\tremaining: 20.5s\n",
            "8730:\tlearn: 7.7115486\ttotal: 51.9s\tremaining: 20.5s\n",
            "8731:\tlearn: 7.7115334\ttotal: 51.9s\tremaining: 20.5s\n",
            "8732:\tlearn: 7.7115282\ttotal: 51.9s\tremaining: 20.5s\n",
            "8733:\tlearn: 7.7115204\ttotal: 51.9s\tremaining: 20.5s\n",
            "8734:\tlearn: 7.7114970\ttotal: 51.9s\tremaining: 20.5s\n",
            "8735:\tlearn: 7.7114786\ttotal: 51.9s\tremaining: 20.5s\n",
            "8736:\tlearn: 7.7114694\ttotal: 51.9s\tremaining: 20.5s\n",
            "8737:\tlearn: 7.7114619\ttotal: 51.9s\tremaining: 20.5s\n",
            "8738:\tlearn: 7.7114541\ttotal: 51.9s\tremaining: 20.5s\n",
            "8739:\tlearn: 7.7114409\ttotal: 51.9s\tremaining: 20.5s\n",
            "8740:\tlearn: 7.7114233\ttotal: 52s\tremaining: 20.4s\n",
            "8741:\tlearn: 7.7114083\ttotal: 52s\tremaining: 20.4s\n",
            "8742:\tlearn: 7.7113976\ttotal: 52s\tremaining: 20.4s\n",
            "8743:\tlearn: 7.7113890\ttotal: 52s\tremaining: 20.4s\n",
            "8744:\tlearn: 7.7113829\ttotal: 52s\tremaining: 20.4s\n",
            "8745:\tlearn: 7.7113740\ttotal: 52s\tremaining: 20.4s\n",
            "8746:\tlearn: 7.7113607\ttotal: 52s\tremaining: 20.4s\n",
            "8747:\tlearn: 7.7113495\ttotal: 52s\tremaining: 20.4s\n",
            "8748:\tlearn: 7.7113385\ttotal: 52s\tremaining: 20.4s\n",
            "8749:\tlearn: 7.7113253\ttotal: 52s\tremaining: 20.4s\n",
            "8750:\tlearn: 7.7113161\ttotal: 52s\tremaining: 20.4s\n",
            "8751:\tlearn: 7.7112962\ttotal: 52s\tremaining: 20.4s\n",
            "8752:\tlearn: 7.7112792\ttotal: 52s\tremaining: 20.4s\n",
            "8753:\tlearn: 7.7112746\ttotal: 52s\tremaining: 20.4s\n",
            "8754:\tlearn: 7.7112558\ttotal: 52s\tremaining: 20.4s\n",
            "8755:\tlearn: 7.7112331\ttotal: 52s\tremaining: 20.4s\n",
            "8756:\tlearn: 7.7112236\ttotal: 52.1s\tremaining: 20.4s\n",
            "8757:\tlearn: 7.7112071\ttotal: 52.1s\tremaining: 20.3s\n",
            "8758:\tlearn: 7.7111939\ttotal: 52.1s\tremaining: 20.3s\n",
            "8759:\tlearn: 7.7111752\ttotal: 52.1s\tremaining: 20.3s\n",
            "8760:\tlearn: 7.7111610\ttotal: 52.1s\tremaining: 20.3s\n",
            "8761:\tlearn: 7.7111538\ttotal: 52.1s\tremaining: 20.3s\n",
            "8762:\tlearn: 7.7111432\ttotal: 52.1s\tremaining: 20.3s\n",
            "8763:\tlearn: 7.7111279\ttotal: 52.1s\tremaining: 20.3s\n",
            "8764:\tlearn: 7.7111132\ttotal: 52.1s\tremaining: 20.3s\n",
            "8765:\tlearn: 7.7110942\ttotal: 52.1s\tremaining: 20.3s\n",
            "8766:\tlearn: 7.7110832\ttotal: 52.1s\tremaining: 20.3s\n",
            "8767:\tlearn: 7.7110723\ttotal: 52.1s\tremaining: 20.3s\n",
            "8768:\tlearn: 7.7110651\ttotal: 52.1s\tremaining: 20.3s\n",
            "8769:\tlearn: 7.7110567\ttotal: 52.1s\tremaining: 20.3s\n",
            "8770:\tlearn: 7.7110489\ttotal: 52.1s\tremaining: 20.3s\n",
            "8771:\tlearn: 7.7110435\ttotal: 52.1s\tremaining: 20.3s\n",
            "8772:\tlearn: 7.7110394\ttotal: 52.1s\tremaining: 20.3s\n",
            "8773:\tlearn: 7.7110178\ttotal: 52.1s\tremaining: 20.2s\n",
            "8774:\tlearn: 7.7110100\ttotal: 52.2s\tremaining: 20.2s\n",
            "8775:\tlearn: 7.7110005\ttotal: 52.2s\tremaining: 20.2s\n",
            "8776:\tlearn: 7.7109847\ttotal: 52.2s\tremaining: 20.2s\n",
            "8777:\tlearn: 7.7109737\ttotal: 52.2s\tremaining: 20.2s\n",
            "8778:\tlearn: 7.7109677\ttotal: 52.2s\tremaining: 20.2s\n",
            "8779:\tlearn: 7.7109607\ttotal: 52.2s\tremaining: 20.2s\n",
            "8780:\tlearn: 7.7109556\ttotal: 52.2s\tremaining: 20.2s\n",
            "8781:\tlearn: 7.7109443\ttotal: 52.2s\tremaining: 20.2s\n",
            "8782:\tlearn: 7.7109403\ttotal: 52.2s\tremaining: 20.2s\n",
            "8783:\tlearn: 7.7109406\ttotal: 52.2s\tremaining: 20.2s\n",
            "8784:\tlearn: 7.7109328\ttotal: 52.2s\tremaining: 20.2s\n",
            "8785:\tlearn: 7.7109221\ttotal: 52.2s\tremaining: 20.2s\n",
            "8786:\tlearn: 7.7109048\ttotal: 52.2s\tremaining: 20.2s\n",
            "8787:\tlearn: 7.7108898\ttotal: 52.2s\tremaining: 20.2s\n",
            "8788:\tlearn: 7.7108763\ttotal: 52.2s\tremaining: 20.2s\n",
            "8789:\tlearn: 7.7108607\ttotal: 52.3s\tremaining: 20.2s\n",
            "8790:\tlearn: 7.7108478\ttotal: 52.3s\tremaining: 20.2s\n",
            "8791:\tlearn: 7.7108331\ttotal: 52.3s\tremaining: 20.1s\n",
            "8792:\tlearn: 7.7108308\ttotal: 52.3s\tremaining: 20.1s\n",
            "8793:\tlearn: 7.7108227\ttotal: 52.3s\tremaining: 20.1s\n",
            "8794:\tlearn: 7.7108161\ttotal: 52.3s\tremaining: 20.1s\n",
            "8795:\tlearn: 7.7107953\ttotal: 52.3s\tremaining: 20.1s\n",
            "8796:\tlearn: 7.7107921\ttotal: 52.3s\tremaining: 20.1s\n",
            "8797:\tlearn: 7.7107844\ttotal: 52.3s\tremaining: 20.1s\n",
            "8798:\tlearn: 7.7107795\ttotal: 52.3s\tremaining: 20.1s\n",
            "8799:\tlearn: 7.7107659\ttotal: 52.3s\tremaining: 20.1s\n",
            "8800:\tlearn: 7.7107639\ttotal: 52.3s\tremaining: 20.1s\n",
            "8801:\tlearn: 7.7107547\ttotal: 52.3s\tremaining: 20.1s\n",
            "8802:\tlearn: 7.7107469\ttotal: 52.3s\tremaining: 20.1s\n",
            "8803:\tlearn: 7.7107236\ttotal: 52.3s\tremaining: 20.1s\n",
            "8804:\tlearn: 7.7107074\ttotal: 52.3s\tremaining: 20.1s\n",
            "8805:\tlearn: 7.7107008\ttotal: 52.3s\tremaining: 20.1s\n",
            "8806:\tlearn: 7.7106867\ttotal: 52.4s\tremaining: 20.1s\n",
            "8807:\tlearn: 7.7106789\ttotal: 52.4s\tremaining: 20.1s\n",
            "8808:\tlearn: 7.7106734\ttotal: 52.4s\tremaining: 20s\n",
            "8809:\tlearn: 7.7106630\ttotal: 52.4s\tremaining: 20s\n",
            "8810:\tlearn: 7.7106564\ttotal: 52.4s\tremaining: 20s\n",
            "8811:\tlearn: 7.7106417\ttotal: 52.4s\tremaining: 20s\n",
            "8812:\tlearn: 7.7106227\ttotal: 52.4s\tremaining: 20s\n",
            "8813:\tlearn: 7.7106163\ttotal: 52.4s\tremaining: 20s\n",
            "8814:\tlearn: 7.7106074\ttotal: 52.4s\tremaining: 20s\n",
            "8815:\tlearn: 7.7105993\ttotal: 52.4s\tremaining: 20s\n",
            "8816:\tlearn: 7.7105826\ttotal: 52.4s\tremaining: 20s\n",
            "8817:\tlearn: 7.7105705\ttotal: 52.4s\tremaining: 20s\n",
            "8818:\tlearn: 7.7105544\ttotal: 52.4s\tremaining: 20s\n",
            "8819:\tlearn: 7.7105446\ttotal: 52.4s\tremaining: 20s\n",
            "8820:\tlearn: 7.7105359\ttotal: 52.4s\tremaining: 20s\n",
            "8821:\tlearn: 7.7105287\ttotal: 52.4s\tremaining: 20s\n",
            "8822:\tlearn: 7.7105117\ttotal: 52.5s\tremaining: 20s\n",
            "8823:\tlearn: 7.7105022\ttotal: 52.5s\tremaining: 20s\n",
            "8824:\tlearn: 7.7104867\ttotal: 52.5s\tremaining: 20s\n",
            "8825:\tlearn: 7.7104725\ttotal: 52.5s\tremaining: 19.9s\n",
            "8826:\tlearn: 7.7104694\ttotal: 52.5s\tremaining: 19.9s\n",
            "8827:\tlearn: 7.7104443\ttotal: 52.5s\tremaining: 19.9s\n",
            "8828:\tlearn: 7.7104382\ttotal: 52.5s\tremaining: 19.9s\n",
            "8829:\tlearn: 7.7104299\ttotal: 52.5s\tremaining: 19.9s\n",
            "8830:\tlearn: 7.7104123\ttotal: 52.5s\tremaining: 19.9s\n",
            "8831:\tlearn: 7.7104091\ttotal: 52.5s\tremaining: 19.9s\n",
            "8832:\tlearn: 7.7104034\ttotal: 52.5s\tremaining: 19.9s\n",
            "8833:\tlearn: 7.7103895\ttotal: 52.5s\tremaining: 19.9s\n",
            "8834:\tlearn: 7.7103757\ttotal: 52.5s\tremaining: 19.9s\n",
            "8835:\tlearn: 7.7103541\ttotal: 52.5s\tremaining: 19.9s\n",
            "8836:\tlearn: 7.7103486\ttotal: 52.5s\tremaining: 19.9s\n",
            "8837:\tlearn: 7.7103371\ttotal: 52.5s\tremaining: 19.9s\n",
            "8838:\tlearn: 7.7103215\ttotal: 52.5s\tremaining: 19.9s\n",
            "8839:\tlearn: 7.7103134\ttotal: 52.5s\tremaining: 19.9s\n",
            "8840:\tlearn: 7.7103062\ttotal: 52.6s\tremaining: 19.9s\n",
            "8841:\tlearn: 7.7102976\ttotal: 52.6s\tremaining: 19.8s\n",
            "8842:\tlearn: 7.7102878\ttotal: 52.6s\tremaining: 19.8s\n",
            "8843:\tlearn: 7.7102722\ttotal: 52.6s\tremaining: 19.8s\n",
            "8844:\tlearn: 7.7102544\ttotal: 52.6s\tremaining: 19.8s\n",
            "8845:\tlearn: 7.7102477\ttotal: 52.6s\tremaining: 19.8s\n",
            "8846:\tlearn: 7.7102333\ttotal: 52.6s\tremaining: 19.8s\n",
            "8847:\tlearn: 7.7102273\ttotal: 52.6s\tremaining: 19.8s\n",
            "8848:\tlearn: 7.7102166\ttotal: 52.6s\tremaining: 19.8s\n",
            "8849:\tlearn: 7.7102126\ttotal: 52.6s\tremaining: 19.8s\n",
            "8850:\tlearn: 7.7101918\ttotal: 52.6s\tremaining: 19.8s\n",
            "8851:\tlearn: 7.7101826\ttotal: 52.6s\tremaining: 19.8s\n",
            "8852:\tlearn: 7.7101742\ttotal: 52.6s\tremaining: 19.8s\n",
            "8853:\tlearn: 7.7101613\ttotal: 52.7s\tremaining: 19.8s\n",
            "8854:\tlearn: 7.7101483\ttotal: 52.7s\tremaining: 19.8s\n",
            "8855:\tlearn: 7.7101422\ttotal: 52.7s\tremaining: 19.8s\n",
            "8856:\tlearn: 7.7101247\ttotal: 52.7s\tremaining: 19.8s\n",
            "8857:\tlearn: 7.7101215\ttotal: 52.7s\tremaining: 19.8s\n",
            "8858:\tlearn: 7.7101134\ttotal: 52.7s\tremaining: 19.8s\n",
            "8859:\tlearn: 7.7101071\ttotal: 52.7s\tremaining: 19.7s\n",
            "8860:\tlearn: 7.7100961\ttotal: 52.7s\tremaining: 19.7s\n",
            "8861:\tlearn: 7.7100875\ttotal: 52.7s\tremaining: 19.7s\n",
            "8862:\tlearn: 7.7100751\ttotal: 52.7s\tremaining: 19.7s\n",
            "8863:\tlearn: 7.7100549\ttotal: 52.7s\tremaining: 19.7s\n",
            "8864:\tlearn: 7.7100437\ttotal: 52.7s\tremaining: 19.7s\n",
            "8865:\tlearn: 7.7100402\ttotal: 52.7s\tremaining: 19.7s\n",
            "8866:\tlearn: 7.7100298\ttotal: 52.7s\tremaining: 19.7s\n",
            "8867:\tlearn: 7.7100120\ttotal: 52.7s\tremaining: 19.7s\n",
            "8868:\tlearn: 7.7099981\ttotal: 52.7s\tremaining: 19.7s\n",
            "8869:\tlearn: 7.7099863\ttotal: 52.7s\tremaining: 19.7s\n",
            "8870:\tlearn: 7.7099693\ttotal: 52.7s\tremaining: 19.7s\n",
            "8871:\tlearn: 7.7099679\ttotal: 52.7s\tremaining: 19.7s\n",
            "8872:\tlearn: 7.7099595\ttotal: 52.8s\tremaining: 19.7s\n",
            "8873:\tlearn: 7.7099454\ttotal: 52.8s\tremaining: 19.7s\n",
            "8874:\tlearn: 7.7099399\ttotal: 52.8s\tremaining: 19.7s\n",
            "8875:\tlearn: 7.7099290\ttotal: 52.8s\tremaining: 19.6s\n",
            "8876:\tlearn: 7.7099180\ttotal: 52.8s\tremaining: 19.6s\n",
            "8877:\tlearn: 7.7099085\ttotal: 52.8s\tremaining: 19.6s\n",
            "8878:\tlearn: 7.7098987\ttotal: 52.8s\tremaining: 19.6s\n",
            "8879:\tlearn: 7.7098886\ttotal: 52.8s\tremaining: 19.6s\n",
            "8880:\tlearn: 7.7098805\ttotal: 52.8s\tremaining: 19.6s\n",
            "8881:\tlearn: 7.7098592\ttotal: 52.8s\tremaining: 19.6s\n",
            "8882:\tlearn: 7.7098402\ttotal: 52.8s\tremaining: 19.6s\n",
            "8883:\tlearn: 7.7098327\ttotal: 52.8s\tremaining: 19.6s\n",
            "8884:\tlearn: 7.7098286\ttotal: 52.8s\tremaining: 19.6s\n",
            "8885:\tlearn: 7.7098154\ttotal: 52.8s\tremaining: 19.6s\n",
            "8886:\tlearn: 7.7098065\ttotal: 52.8s\tremaining: 19.6s\n",
            "8887:\tlearn: 7.7097955\ttotal: 52.9s\tremaining: 19.6s\n",
            "8888:\tlearn: 7.7097785\ttotal: 52.9s\tremaining: 19.6s\n",
            "8889:\tlearn: 7.7097707\ttotal: 52.9s\tremaining: 19.6s\n",
            "8890:\tlearn: 7.7097589\ttotal: 52.9s\tremaining: 19.6s\n",
            "8891:\tlearn: 7.7097451\ttotal: 52.9s\tremaining: 19.6s\n",
            "8892:\tlearn: 7.7097306\ttotal: 52.9s\tremaining: 19.5s\n",
            "8893:\tlearn: 7.7097136\ttotal: 52.9s\tremaining: 19.5s\n",
            "8894:\tlearn: 7.7096914\ttotal: 52.9s\tremaining: 19.5s\n",
            "8895:\tlearn: 7.7096701\ttotal: 52.9s\tremaining: 19.5s\n",
            "8896:\tlearn: 7.7096618\ttotal: 52.9s\tremaining: 19.5s\n",
            "8897:\tlearn: 7.7096514\ttotal: 52.9s\tremaining: 19.5s\n",
            "8898:\tlearn: 7.7096433\ttotal: 52.9s\tremaining: 19.5s\n",
            "8899:\tlearn: 7.7096295\ttotal: 52.9s\tremaining: 19.5s\n",
            "8900:\tlearn: 7.7096171\ttotal: 52.9s\tremaining: 19.5s\n",
            "8901:\tlearn: 7.7096009\ttotal: 52.9s\tremaining: 19.5s\n",
            "8902:\tlearn: 7.7095903\ttotal: 52.9s\tremaining: 19.5s\n",
            "8903:\tlearn: 7.7095796\ttotal: 52.9s\tremaining: 19.5s\n",
            "8904:\tlearn: 7.7095568\ttotal: 52.9s\tremaining: 19.5s\n",
            "8905:\tlearn: 7.7095493\ttotal: 53s\tremaining: 19.5s\n",
            "8906:\tlearn: 7.7095473\ttotal: 53s\tremaining: 19.5s\n",
            "8907:\tlearn: 7.7095404\ttotal: 53s\tremaining: 19.5s\n",
            "8908:\tlearn: 7.7095326\ttotal: 53s\tremaining: 19.5s\n",
            "8909:\tlearn: 7.7095303\ttotal: 53s\tremaining: 19.4s\n",
            "8910:\tlearn: 7.7095205\ttotal: 53s\tremaining: 19.4s\n",
            "8911:\tlearn: 7.7095130\ttotal: 53s\tremaining: 19.4s\n",
            "8912:\tlearn: 7.7094966\ttotal: 53s\tremaining: 19.4s\n",
            "8913:\tlearn: 7.7094926\ttotal: 53s\tremaining: 19.4s\n",
            "8914:\tlearn: 7.7094813\ttotal: 53s\tremaining: 19.4s\n",
            "8915:\tlearn: 7.7094738\ttotal: 53s\tremaining: 19.4s\n",
            "8916:\tlearn: 7.7094660\ttotal: 53s\tremaining: 19.4s\n",
            "8917:\tlearn: 7.7094609\ttotal: 53s\tremaining: 19.4s\n",
            "8918:\tlearn: 7.7094534\ttotal: 53s\tremaining: 19.4s\n",
            "8919:\tlearn: 7.7094473\ttotal: 53s\tremaining: 19.4s\n",
            "8920:\tlearn: 7.7094369\ttotal: 53s\tremaining: 19.4s\n",
            "8921:\tlearn: 7.7094254\ttotal: 53s\tremaining: 19.4s\n",
            "8922:\tlearn: 7.7094179\ttotal: 53.1s\tremaining: 19.4s\n",
            "8923:\tlearn: 7.7094052\ttotal: 53.1s\tremaining: 19.4s\n",
            "8924:\tlearn: 7.7093891\ttotal: 53.1s\tremaining: 19.4s\n",
            "8925:\tlearn: 7.7093839\ttotal: 53.1s\tremaining: 19.4s\n",
            "8926:\tlearn: 7.7093721\ttotal: 53.1s\tremaining: 19.3s\n",
            "8927:\tlearn: 7.7093600\ttotal: 53.1s\tremaining: 19.3s\n",
            "8928:\tlearn: 7.7093409\ttotal: 53.1s\tremaining: 19.3s\n",
            "8929:\tlearn: 7.7093199\ttotal: 53.1s\tremaining: 19.3s\n",
            "8930:\tlearn: 7.7092940\ttotal: 53.1s\tremaining: 19.3s\n",
            "8931:\tlearn: 7.7092873\ttotal: 53.1s\tremaining: 19.3s\n",
            "8932:\tlearn: 7.7092830\ttotal: 53.1s\tremaining: 19.3s\n",
            "8933:\tlearn: 7.7092695\ttotal: 53.1s\tremaining: 19.3s\n",
            "8934:\tlearn: 7.7092637\ttotal: 53.1s\tremaining: 19.3s\n",
            "8935:\tlearn: 7.7092548\ttotal: 53.1s\tremaining: 19.3s\n",
            "8936:\tlearn: 7.7092458\ttotal: 53.1s\tremaining: 19.3s\n",
            "8937:\tlearn: 7.7092383\ttotal: 53.1s\tremaining: 19.3s\n",
            "8938:\tlearn: 7.7092337\ttotal: 53.1s\tremaining: 19.3s\n",
            "8939:\tlearn: 7.7092173\ttotal: 53.1s\tremaining: 19.3s\n",
            "8940:\tlearn: 7.7092081\ttotal: 53.1s\tremaining: 19.3s\n",
            "8941:\tlearn: 7.7092014\ttotal: 53.2s\tremaining: 19.3s\n",
            "8942:\tlearn: 7.7091942\ttotal: 53.2s\tremaining: 19.2s\n",
            "8943:\tlearn: 7.7091789\ttotal: 53.2s\tremaining: 19.2s\n",
            "8944:\tlearn: 7.7091700\ttotal: 53.2s\tremaining: 19.2s\n",
            "8945:\tlearn: 7.7091642\ttotal: 53.2s\tremaining: 19.2s\n",
            "8946:\tlearn: 7.7091527\ttotal: 53.2s\tremaining: 19.2s\n",
            "8947:\tlearn: 7.7091469\ttotal: 53.2s\tremaining: 19.2s\n",
            "8948:\tlearn: 7.7091392\ttotal: 53.2s\tremaining: 19.2s\n",
            "8949:\tlearn: 7.7091320\ttotal: 53.2s\tremaining: 19.2s\n",
            "8950:\tlearn: 7.7091259\ttotal: 53.2s\tremaining: 19.2s\n",
            "8951:\tlearn: 7.7091167\ttotal: 53.2s\tremaining: 19.2s\n",
            "8952:\tlearn: 7.7091011\ttotal: 53.2s\tremaining: 19.2s\n",
            "8953:\tlearn: 7.7090951\ttotal: 53.2s\tremaining: 19.2s\n",
            "8954:\tlearn: 7.7090795\ttotal: 53.2s\tremaining: 19.2s\n",
            "8955:\tlearn: 7.7090634\ttotal: 53.2s\tremaining: 19.2s\n",
            "8956:\tlearn: 7.7090541\ttotal: 53.2s\tremaining: 19.2s\n",
            "8957:\tlearn: 7.7090391\ttotal: 53.3s\tremaining: 19.2s\n",
            "8958:\tlearn: 7.7090259\ttotal: 53.3s\tremaining: 19.2s\n",
            "8959:\tlearn: 7.7089968\ttotal: 53.3s\tremaining: 19.1s\n",
            "8960:\tlearn: 7.7089849\ttotal: 53.3s\tremaining: 19.1s\n",
            "8961:\tlearn: 7.7089849\ttotal: 53.3s\tremaining: 19.1s\n",
            "8962:\tlearn: 7.7089763\ttotal: 53.3s\tremaining: 19.1s\n",
            "8963:\tlearn: 7.7089587\ttotal: 53.3s\tremaining: 19.1s\n",
            "8964:\tlearn: 7.7089394\ttotal: 53.3s\tremaining: 19.1s\n",
            "8965:\tlearn: 7.7089339\ttotal: 53.3s\tremaining: 19.1s\n",
            "8966:\tlearn: 7.7089198\ttotal: 53.3s\tremaining: 19.1s\n",
            "8967:\tlearn: 7.7089037\ttotal: 53.3s\tremaining: 19.1s\n",
            "8968:\tlearn: 7.7088892\ttotal: 53.3s\tremaining: 19.1s\n",
            "8969:\tlearn: 7.7088878\ttotal: 53.3s\tremaining: 19.1s\n",
            "8970:\tlearn: 7.7088809\ttotal: 53.3s\tremaining: 19.1s\n",
            "8971:\tlearn: 7.7088665\ttotal: 53.3s\tremaining: 19.1s\n",
            "8972:\tlearn: 7.7088607\ttotal: 53.3s\tremaining: 19.1s\n",
            "8973:\tlearn: 7.7088546\ttotal: 53.3s\tremaining: 19.1s\n",
            "8974:\tlearn: 7.7088394\ttotal: 53.3s\tremaining: 19.1s\n",
            "8975:\tlearn: 7.7088255\ttotal: 53.4s\tremaining: 19s\n",
            "8976:\tlearn: 7.7088206\ttotal: 53.4s\tremaining: 19s\n",
            "8977:\tlearn: 7.7088091\ttotal: 53.4s\tremaining: 19s\n",
            "8978:\tlearn: 7.7088033\ttotal: 53.4s\tremaining: 19s\n",
            "8979:\tlearn: 7.7087950\ttotal: 53.4s\tremaining: 19s\n",
            "8980:\tlearn: 7.7087771\ttotal: 53.4s\tremaining: 19s\n",
            "8981:\tlearn: 7.7087659\ttotal: 53.4s\tremaining: 19s\n",
            "8982:\tlearn: 7.7087581\ttotal: 53.4s\tremaining: 19s\n",
            "8983:\tlearn: 7.7087468\ttotal: 53.4s\tremaining: 19s\n",
            "8984:\tlearn: 7.7087304\ttotal: 53.4s\tremaining: 19s\n",
            "8985:\tlearn: 7.7087047\ttotal: 53.4s\tremaining: 19s\n",
            "8986:\tlearn: 7.7086981\ttotal: 53.4s\tremaining: 19s\n",
            "8987:\tlearn: 7.7086929\ttotal: 53.4s\tremaining: 19s\n",
            "8988:\tlearn: 7.7086776\ttotal: 53.5s\tremaining: 19s\n",
            "8989:\tlearn: 7.7086678\ttotal: 53.5s\tremaining: 19s\n",
            "8990:\tlearn: 7.7086618\ttotal: 53.5s\tremaining: 19s\n",
            "8991:\tlearn: 7.7086555\ttotal: 53.5s\tremaining: 19s\n",
            "8992:\tlearn: 7.7086494\ttotal: 53.5s\tremaining: 19s\n",
            "8993:\tlearn: 7.7086396\ttotal: 53.5s\tremaining: 19s\n",
            "8994:\tlearn: 7.7086284\ttotal: 53.5s\tremaining: 18.9s\n",
            "8995:\tlearn: 7.7086252\ttotal: 53.5s\tremaining: 18.9s\n",
            "8996:\tlearn: 7.7086162\ttotal: 53.5s\tremaining: 18.9s\n",
            "8997:\tlearn: 7.7086062\ttotal: 53.5s\tremaining: 18.9s\n",
            "8998:\tlearn: 7.7085975\ttotal: 53.5s\tremaining: 18.9s\n",
            "8999:\tlearn: 7.7085929\ttotal: 53.5s\tremaining: 18.9s\n",
            "9000:\tlearn: 7.7085739\ttotal: 53.5s\tremaining: 18.9s\n",
            "9001:\tlearn: 7.7085557\ttotal: 53.5s\tremaining: 18.9s\n",
            "9002:\tlearn: 7.7085427\ttotal: 53.5s\tremaining: 18.9s\n",
            "9003:\tlearn: 7.7085182\ttotal: 53.5s\tremaining: 18.9s\n",
            "9004:\tlearn: 7.7084995\ttotal: 53.5s\tremaining: 18.9s\n",
            "9005:\tlearn: 7.7084796\ttotal: 53.5s\tremaining: 18.9s\n",
            "9006:\tlearn: 7.7084724\ttotal: 53.6s\tremaining: 18.9s\n",
            "9007:\tlearn: 7.7084606\ttotal: 53.6s\tremaining: 18.9s\n",
            "9008:\tlearn: 7.7084574\ttotal: 53.6s\tremaining: 18.9s\n",
            "9009:\tlearn: 7.7084485\ttotal: 53.6s\tremaining: 18.9s\n",
            "9010:\tlearn: 7.7084352\ttotal: 53.6s\tremaining: 18.8s\n",
            "9011:\tlearn: 7.7084292\ttotal: 53.6s\tremaining: 18.8s\n",
            "9012:\tlearn: 7.7084139\ttotal: 53.6s\tremaining: 18.8s\n",
            "9013:\tlearn: 7.7084052\ttotal: 53.6s\tremaining: 18.8s\n",
            "9014:\tlearn: 7.7083969\ttotal: 53.6s\tremaining: 18.8s\n",
            "9015:\tlearn: 7.7083726\ttotal: 53.6s\tremaining: 18.8s\n",
            "9016:\tlearn: 7.7083600\ttotal: 53.6s\tremaining: 18.8s\n",
            "9017:\tlearn: 7.7083565\ttotal: 53.6s\tremaining: 18.8s\n",
            "9018:\tlearn: 7.7083530\ttotal: 53.6s\tremaining: 18.8s\n",
            "9019:\tlearn: 7.7083320\ttotal: 53.6s\tremaining: 18.8s\n",
            "9020:\tlearn: 7.7083271\ttotal: 53.7s\tremaining: 18.8s\n",
            "9021:\tlearn: 7.7083213\ttotal: 53.7s\tremaining: 18.8s\n",
            "9022:\tlearn: 7.7083147\ttotal: 53.7s\tremaining: 18.8s\n",
            "9023:\tlearn: 7.7083124\ttotal: 53.7s\tremaining: 18.8s\n",
            "9024:\tlearn: 7.7082988\ttotal: 53.7s\tremaining: 18.8s\n",
            "9025:\tlearn: 7.7082890\ttotal: 53.7s\tremaining: 18.8s\n",
            "9026:\tlearn: 7.7082732\ttotal: 53.7s\tremaining: 18.8s\n",
            "9027:\tlearn: 7.7082648\ttotal: 53.7s\tremaining: 18.8s\n",
            "9028:\tlearn: 7.7082579\ttotal: 53.7s\tremaining: 18.7s\n",
            "9029:\tlearn: 7.7082415\ttotal: 53.7s\tremaining: 18.7s\n",
            "9030:\tlearn: 7.7082314\ttotal: 53.7s\tremaining: 18.7s\n",
            "9031:\tlearn: 7.7082245\ttotal: 53.7s\tremaining: 18.7s\n",
            "9032:\tlearn: 7.7082008\ttotal: 53.7s\tremaining: 18.7s\n",
            "9033:\tlearn: 7.7081876\ttotal: 53.7s\tremaining: 18.7s\n",
            "9034:\tlearn: 7.7081812\ttotal: 53.7s\tremaining: 18.7s\n",
            "9035:\tlearn: 7.7081659\ttotal: 53.7s\tremaining: 18.7s\n",
            "9036:\tlearn: 7.7081507\ttotal: 53.8s\tremaining: 18.7s\n",
            "9037:\tlearn: 7.7081423\ttotal: 53.8s\tremaining: 18.7s\n",
            "9038:\tlearn: 7.7081311\ttotal: 53.8s\tremaining: 18.7s\n",
            "9039:\tlearn: 7.7081259\ttotal: 53.8s\tremaining: 18.7s\n",
            "9040:\tlearn: 7.7081201\ttotal: 53.8s\tremaining: 18.7s\n",
            "9041:\tlearn: 7.7081083\ttotal: 53.8s\tremaining: 18.7s\n",
            "9042:\tlearn: 7.7081071\ttotal: 53.8s\tremaining: 18.7s\n",
            "9043:\tlearn: 7.7080976\ttotal: 53.8s\tremaining: 18.7s\n",
            "9044:\tlearn: 7.7080754\ttotal: 53.8s\tremaining: 18.7s\n",
            "9045:\tlearn: 7.7080682\ttotal: 53.8s\tremaining: 18.6s\n",
            "9046:\tlearn: 7.7080610\ttotal: 53.8s\tremaining: 18.6s\n",
            "9047:\tlearn: 7.7080420\ttotal: 53.8s\tremaining: 18.6s\n",
            "9048:\tlearn: 7.7080218\ttotal: 53.8s\tremaining: 18.6s\n",
            "9049:\tlearn: 7.7080106\ttotal: 53.8s\tremaining: 18.6s\n",
            "9050:\tlearn: 7.7079956\ttotal: 53.8s\tremaining: 18.6s\n",
            "9051:\tlearn: 7.7079907\ttotal: 53.8s\tremaining: 18.6s\n",
            "9052:\tlearn: 7.7079806\ttotal: 53.8s\tremaining: 18.6s\n",
            "9053:\tlearn: 7.7079685\ttotal: 53.9s\tremaining: 18.6s\n",
            "9054:\tlearn: 7.7079581\ttotal: 53.9s\tremaining: 18.6s\n",
            "9055:\tlearn: 7.7079399\ttotal: 53.9s\tremaining: 18.6s\n",
            "9056:\tlearn: 7.7079249\ttotal: 53.9s\tremaining: 18.6s\n",
            "9057:\tlearn: 7.7079024\ttotal: 53.9s\tremaining: 18.6s\n",
            "9058:\tlearn: 7.7078929\ttotal: 53.9s\tremaining: 18.6s\n",
            "9059:\tlearn: 7.7078788\ttotal: 53.9s\tremaining: 18.6s\n",
            "9060:\tlearn: 7.7078650\ttotal: 53.9s\tremaining: 18.6s\n",
            "9061:\tlearn: 7.7078554\ttotal: 53.9s\tremaining: 18.6s\n",
            "9062:\tlearn: 7.7078390\ttotal: 53.9s\tremaining: 18.5s\n",
            "9063:\tlearn: 7.7078335\ttotal: 53.9s\tremaining: 18.5s\n",
            "9064:\tlearn: 7.7078087\ttotal: 53.9s\tremaining: 18.5s\n",
            "9065:\tlearn: 7.7078041\ttotal: 53.9s\tremaining: 18.5s\n",
            "9066:\tlearn: 7.7077972\ttotal: 53.9s\tremaining: 18.5s\n",
            "9067:\tlearn: 7.7077888\ttotal: 53.9s\tremaining: 18.5s\n",
            "9068:\tlearn: 7.7077776\ttotal: 53.9s\tremaining: 18.5s\n",
            "9069:\tlearn: 7.7077687\ttotal: 53.9s\tremaining: 18.5s\n",
            "9070:\tlearn: 7.7077335\ttotal: 54s\tremaining: 18.5s\n",
            "9071:\tlearn: 7.7077194\ttotal: 54s\tremaining: 18.5s\n",
            "9072:\tlearn: 7.7077165\ttotal: 54s\tremaining: 18.5s\n",
            "9073:\tlearn: 7.7077064\ttotal: 54s\tremaining: 18.5s\n",
            "9074:\tlearn: 7.7076928\ttotal: 54s\tremaining: 18.5s\n",
            "9075:\tlearn: 7.7076862\ttotal: 54s\tremaining: 18.5s\n",
            "9076:\tlearn: 7.7076738\ttotal: 54s\tremaining: 18.5s\n",
            "9077:\tlearn: 7.7076574\ttotal: 54s\tremaining: 18.5s\n",
            "9078:\tlearn: 7.7076409\ttotal: 54s\tremaining: 18.4s\n",
            "9079:\tlearn: 7.7076216\ttotal: 54s\tremaining: 18.4s\n",
            "9080:\tlearn: 7.7076176\ttotal: 54s\tremaining: 18.4s\n",
            "9081:\tlearn: 7.7075991\ttotal: 54s\tremaining: 18.4s\n",
            "9082:\tlearn: 7.7075876\ttotal: 54s\tremaining: 18.4s\n",
            "9083:\tlearn: 7.7075746\ttotal: 54s\tremaining: 18.4s\n",
            "9084:\tlearn: 7.7075654\ttotal: 54s\tremaining: 18.4s\n",
            "9085:\tlearn: 7.7075470\ttotal: 54s\tremaining: 18.4s\n",
            "9086:\tlearn: 7.7075363\ttotal: 54s\tremaining: 18.4s\n",
            "9087:\tlearn: 7.7075299\ttotal: 54s\tremaining: 18.4s\n",
            "9088:\tlearn: 7.7075115\ttotal: 54.1s\tremaining: 18.4s\n",
            "9089:\tlearn: 7.7075014\ttotal: 54.1s\tremaining: 18.4s\n",
            "9090:\tlearn: 7.7074948\ttotal: 54.1s\tremaining: 18.4s\n",
            "9091:\tlearn: 7.7074818\ttotal: 54.1s\tremaining: 18.4s\n",
            "9092:\tlearn: 7.7074740\ttotal: 54.1s\tremaining: 18.4s\n",
            "9093:\tlearn: 7.7074590\ttotal: 54.1s\tremaining: 18.4s\n",
            "9094:\tlearn: 7.7074380\ttotal: 54.1s\tremaining: 18.4s\n",
            "9095:\tlearn: 7.7074129\ttotal: 54.1s\tremaining: 18.3s\n",
            "9096:\tlearn: 7.7074019\ttotal: 54.1s\tremaining: 18.3s\n",
            "9097:\tlearn: 7.7073832\ttotal: 54.1s\tremaining: 18.3s\n",
            "9098:\tlearn: 7.7073719\ttotal: 54.1s\tremaining: 18.3s\n",
            "9099:\tlearn: 7.7073578\ttotal: 54.1s\tremaining: 18.3s\n",
            "9100:\tlearn: 7.7073408\ttotal: 54.1s\tremaining: 18.3s\n",
            "9101:\tlearn: 7.7073252\ttotal: 54.1s\tremaining: 18.3s\n",
            "9102:\tlearn: 7.7072857\ttotal: 54.1s\tremaining: 18.3s\n",
            "9103:\tlearn: 7.7072725\ttotal: 54.1s\tremaining: 18.3s\n",
            "9104:\tlearn: 7.7072557\ttotal: 54.1s\tremaining: 18.3s\n",
            "9105:\tlearn: 7.7072477\ttotal: 54.1s\tremaining: 18.3s\n",
            "9106:\tlearn: 7.7072289\ttotal: 54.2s\tremaining: 18.3s\n",
            "9107:\tlearn: 7.7072154\ttotal: 54.2s\tremaining: 18.3s\n",
            "9108:\tlearn: 7.7072007\ttotal: 54.2s\tremaining: 18.3s\n",
            "9109:\tlearn: 7.7071854\ttotal: 54.2s\tremaining: 18.3s\n",
            "9110:\tlearn: 7.7071739\ttotal: 54.2s\tremaining: 18.3s\n",
            "9111:\tlearn: 7.7071623\ttotal: 54.2s\tremaining: 18.2s\n",
            "9112:\tlearn: 7.7071566\ttotal: 54.2s\tremaining: 18.2s\n",
            "9113:\tlearn: 7.7071381\ttotal: 54.2s\tremaining: 18.2s\n",
            "9114:\tlearn: 7.7071246\ttotal: 54.2s\tremaining: 18.2s\n",
            "9115:\tlearn: 7.7071159\ttotal: 54.2s\tremaining: 18.2s\n",
            "9116:\tlearn: 7.7071096\ttotal: 54.2s\tremaining: 18.2s\n",
            "9117:\tlearn: 7.7070963\ttotal: 54.2s\tremaining: 18.2s\n",
            "9118:\tlearn: 7.7070865\ttotal: 54.2s\tremaining: 18.2s\n",
            "9119:\tlearn: 7.7070773\ttotal: 54.2s\tremaining: 18.2s\n",
            "9120:\tlearn: 7.7070539\ttotal: 54.2s\tremaining: 18.2s\n",
            "9121:\tlearn: 7.7070418\ttotal: 54.2s\tremaining: 18.2s\n",
            "9122:\tlearn: 7.7070282\ttotal: 54.2s\tremaining: 18.2s\n",
            "9123:\tlearn: 7.7070167\ttotal: 54.2s\tremaining: 18.2s\n",
            "9124:\tlearn: 7.7069991\ttotal: 54.3s\tremaining: 18.2s\n",
            "9125:\tlearn: 7.7069856\ttotal: 54.3s\tremaining: 18.2s\n",
            "9126:\tlearn: 7.7069778\ttotal: 54.3s\tremaining: 18.2s\n",
            "9127:\tlearn: 7.7069671\ttotal: 54.3s\tremaining: 18.2s\n",
            "9128:\tlearn: 7.7069648\ttotal: 54.3s\tremaining: 18.1s\n",
            "9129:\tlearn: 7.7069582\ttotal: 54.3s\tremaining: 18.1s\n",
            "9130:\tlearn: 7.7069383\ttotal: 54.3s\tremaining: 18.1s\n",
            "9131:\tlearn: 7.7069276\ttotal: 54.3s\tremaining: 18.1s\n",
            "9132:\tlearn: 7.7069242\ttotal: 54.3s\tremaining: 18.1s\n",
            "9133:\tlearn: 7.7069236\ttotal: 54.3s\tremaining: 18.1s\n",
            "9134:\tlearn: 7.7069172\ttotal: 54.3s\tremaining: 18.1s\n",
            "9135:\tlearn: 7.7068985\ttotal: 54.3s\tremaining: 18.1s\n",
            "9136:\tlearn: 7.7068867\ttotal: 54.3s\tremaining: 18.1s\n",
            "9137:\tlearn: 7.7068749\ttotal: 54.3s\tremaining: 18.1s\n",
            "9138:\tlearn: 7.7068630\ttotal: 54.3s\tremaining: 18.1s\n",
            "9139:\tlearn: 7.7068544\ttotal: 54.3s\tremaining: 18.1s\n",
            "9140:\tlearn: 7.7068426\ttotal: 54.4s\tremaining: 18.1s\n",
            "9141:\tlearn: 7.7068362\ttotal: 54.4s\tremaining: 18.1s\n",
            "9142:\tlearn: 7.7068296\ttotal: 54.4s\tremaining: 18.1s\n",
            "9143:\tlearn: 7.7068232\ttotal: 54.4s\tremaining: 18.1s\n",
            "9144:\tlearn: 7.7068131\ttotal: 54.4s\tremaining: 18.1s\n",
            "9145:\tlearn: 7.7067915\ttotal: 54.4s\tremaining: 18s\n",
            "9146:\tlearn: 7.7067768\ttotal: 54.4s\tremaining: 18s\n",
            "9147:\tlearn: 7.7067656\ttotal: 54.4s\tremaining: 18s\n",
            "9148:\tlearn: 7.7067586\ttotal: 54.4s\tremaining: 18s\n",
            "9149:\tlearn: 7.7067408\ttotal: 54.4s\tremaining: 18s\n",
            "9150:\tlearn: 7.7067238\ttotal: 54.4s\tremaining: 18s\n",
            "9151:\tlearn: 7.7067059\ttotal: 54.4s\tremaining: 18s\n",
            "9152:\tlearn: 7.7066967\ttotal: 54.4s\tremaining: 18s\n",
            "9153:\tlearn: 7.7066799\ttotal: 54.4s\tremaining: 18s\n",
            "9154:\tlearn: 7.7066652\ttotal: 54.4s\tremaining: 18s\n",
            "9155:\tlearn: 7.7066528\ttotal: 54.4s\tremaining: 18s\n",
            "9156:\tlearn: 7.7066416\ttotal: 54.4s\tremaining: 18s\n",
            "9157:\tlearn: 7.7066263\ttotal: 54.5s\tremaining: 18s\n",
            "9158:\tlearn: 7.7066076\ttotal: 54.5s\tremaining: 18s\n",
            "9159:\tlearn: 7.7065952\ttotal: 54.5s\tremaining: 18s\n",
            "9160:\tlearn: 7.7065882\ttotal: 54.5s\tremaining: 18s\n",
            "9161:\tlearn: 7.7065787\ttotal: 54.5s\tremaining: 18s\n",
            "9162:\tlearn: 7.7065672\ttotal: 54.5s\tremaining: 17.9s\n",
            "9163:\tlearn: 7.7065565\ttotal: 54.5s\tremaining: 17.9s\n",
            "9164:\tlearn: 7.7065464\ttotal: 54.5s\tremaining: 17.9s\n",
            "9165:\tlearn: 7.7065346\ttotal: 54.5s\tremaining: 17.9s\n",
            "9166:\tlearn: 7.7065164\ttotal: 54.5s\tremaining: 17.9s\n",
            "9167:\tlearn: 7.7065072\ttotal: 54.5s\tremaining: 17.9s\n",
            "9168:\tlearn: 7.7064994\ttotal: 54.5s\tremaining: 17.9s\n",
            "9169:\tlearn: 7.7064885\ttotal: 54.5s\tremaining: 17.9s\n",
            "9170:\tlearn: 7.7064706\ttotal: 54.5s\tremaining: 17.9s\n",
            "9171:\tlearn: 7.7064593\ttotal: 54.5s\tremaining: 17.9s\n",
            "9172:\tlearn: 7.7064443\ttotal: 54.5s\tremaining: 17.9s\n",
            "9173:\tlearn: 7.7064219\ttotal: 54.6s\tremaining: 17.9s\n",
            "9174:\tlearn: 7.7064170\ttotal: 54.6s\tremaining: 17.9s\n",
            "9175:\tlearn: 7.7064014\ttotal: 54.6s\tremaining: 17.9s\n",
            "9176:\tlearn: 7.7063838\ttotal: 54.6s\tremaining: 17.9s\n",
            "9177:\tlearn: 7.7063734\ttotal: 54.6s\tremaining: 17.9s\n",
            "9178:\tlearn: 7.7063613\ttotal: 54.6s\tremaining: 17.9s\n",
            "9179:\tlearn: 7.7063348\ttotal: 54.6s\tremaining: 17.8s\n",
            "9180:\tlearn: 7.7063238\ttotal: 54.6s\tremaining: 17.8s\n",
            "9181:\tlearn: 7.7063131\ttotal: 54.6s\tremaining: 17.8s\n",
            "9182:\tlearn: 7.7063013\ttotal: 54.6s\tremaining: 17.8s\n",
            "9183:\tlearn: 7.7062757\ttotal: 54.6s\tremaining: 17.8s\n",
            "9184:\tlearn: 7.7062650\ttotal: 54.6s\tremaining: 17.8s\n",
            "9185:\tlearn: 7.7062500\ttotal: 54.6s\tremaining: 17.8s\n",
            "9186:\tlearn: 7.7062408\ttotal: 54.6s\tremaining: 17.8s\n",
            "9187:\tlearn: 7.7062272\ttotal: 54.6s\tremaining: 17.8s\n",
            "9188:\tlearn: 7.7062235\ttotal: 54.7s\tremaining: 17.8s\n",
            "9189:\tlearn: 7.7062096\ttotal: 54.7s\tremaining: 17.8s\n",
            "9190:\tlearn: 7.7061920\ttotal: 54.7s\tremaining: 17.8s\n",
            "9191:\tlearn: 7.7061854\ttotal: 54.7s\tremaining: 17.8s\n",
            "9192:\tlearn: 7.7061802\ttotal: 54.7s\tremaining: 17.8s\n",
            "9193:\tlearn: 7.7061733\ttotal: 54.7s\tremaining: 17.8s\n",
            "9194:\tlearn: 7.7061649\ttotal: 54.7s\tremaining: 17.8s\n",
            "9195:\tlearn: 7.7061554\ttotal: 54.7s\tremaining: 17.8s\n",
            "9196:\tlearn: 7.7061473\ttotal: 54.7s\tremaining: 17.8s\n",
            "9197:\tlearn: 7.7061378\ttotal: 54.7s\tremaining: 17.7s\n",
            "9198:\tlearn: 7.7061332\ttotal: 54.7s\tremaining: 17.7s\n",
            "9199:\tlearn: 7.7061159\ttotal: 54.7s\tremaining: 17.7s\n",
            "9200:\tlearn: 7.7061142\ttotal: 54.7s\tremaining: 17.7s\n",
            "9201:\tlearn: 7.7060951\ttotal: 54.7s\tremaining: 17.7s\n",
            "9202:\tlearn: 7.7060816\ttotal: 54.7s\tremaining: 17.7s\n",
            "9203:\tlearn: 7.7060666\ttotal: 54.8s\tremaining: 17.7s\n",
            "9204:\tlearn: 7.7060588\ttotal: 54.8s\tremaining: 17.7s\n",
            "9205:\tlearn: 7.7060496\ttotal: 54.8s\tremaining: 17.7s\n",
            "9206:\tlearn: 7.7060441\ttotal: 54.8s\tremaining: 17.7s\n",
            "9207:\tlearn: 7.7060251\ttotal: 54.8s\tremaining: 17.7s\n",
            "9208:\tlearn: 7.7060144\ttotal: 54.8s\tremaining: 17.7s\n",
            "9209:\tlearn: 7.7060020\ttotal: 54.8s\tremaining: 17.7s\n",
            "9210:\tlearn: 7.7059913\ttotal: 54.8s\tremaining: 17.7s\n",
            "9211:\tlearn: 7.7059795\ttotal: 54.8s\tremaining: 17.7s\n",
            "9212:\tlearn: 7.7059633\ttotal: 54.8s\tremaining: 17.7s\n",
            "9213:\tlearn: 7.7059590\ttotal: 54.8s\tremaining: 17.6s\n",
            "9214:\tlearn: 7.7059463\ttotal: 54.8s\tremaining: 17.6s\n",
            "9215:\tlearn: 7.7059406\ttotal: 54.8s\tremaining: 17.6s\n",
            "9216:\tlearn: 7.7059207\ttotal: 54.8s\tremaining: 17.6s\n",
            "9217:\tlearn: 7.7059137\ttotal: 54.8s\tremaining: 17.6s\n",
            "9218:\tlearn: 7.7059013\ttotal: 54.8s\tremaining: 17.6s\n",
            "9219:\tlearn: 7.7058866\ttotal: 54.8s\tremaining: 17.6s\n",
            "9220:\tlearn: 7.7058791\ttotal: 54.8s\tremaining: 17.6s\n",
            "9221:\tlearn: 7.7058760\ttotal: 54.9s\tremaining: 17.6s\n",
            "9222:\tlearn: 7.7058610\ttotal: 54.9s\tremaining: 17.6s\n",
            "9223:\tlearn: 7.7058509\ttotal: 54.9s\tremaining: 17.6s\n",
            "9224:\tlearn: 7.7058402\ttotal: 54.9s\tremaining: 17.6s\n",
            "9225:\tlearn: 7.7058241\ttotal: 54.9s\tremaining: 17.6s\n",
            "9226:\tlearn: 7.7058163\ttotal: 54.9s\tremaining: 17.6s\n",
            "9227:\tlearn: 7.7058065\ttotal: 54.9s\tremaining: 17.6s\n",
            "9228:\tlearn: 7.7057895\ttotal: 54.9s\tremaining: 17.6s\n",
            "9229:\tlearn: 7.7057820\ttotal: 54.9s\tremaining: 17.6s\n",
            "9230:\tlearn: 7.7057745\ttotal: 54.9s\tremaining: 17.5s\n",
            "9231:\tlearn: 7.7057600\ttotal: 54.9s\tremaining: 17.5s\n",
            "9232:\tlearn: 7.7057499\ttotal: 54.9s\tremaining: 17.5s\n",
            "9233:\tlearn: 7.7057344\ttotal: 54.9s\tremaining: 17.5s\n",
            "9234:\tlearn: 7.7057329\ttotal: 54.9s\tremaining: 17.5s\n",
            "9235:\tlearn: 7.7057208\ttotal: 54.9s\tremaining: 17.5s\n",
            "9236:\tlearn: 7.7057142\ttotal: 54.9s\tremaining: 17.5s\n",
            "9237:\tlearn: 7.7056952\ttotal: 55s\tremaining: 17.5s\n",
            "9238:\tlearn: 7.7056856\ttotal: 55s\tremaining: 17.5s\n",
            "9239:\tlearn: 7.7056747\ttotal: 55s\tremaining: 17.5s\n",
            "9240:\tlearn: 7.7056646\ttotal: 55s\tremaining: 17.5s\n",
            "9241:\tlearn: 7.7056481\ttotal: 55s\tremaining: 17.5s\n",
            "9242:\tlearn: 7.7056441\ttotal: 55s\tremaining: 17.5s\n",
            "9243:\tlearn: 7.7056435\ttotal: 55s\tremaining: 17.5s\n",
            "9244:\tlearn: 7.7056294\ttotal: 55s\tremaining: 17.5s\n",
            "9245:\tlearn: 7.7056199\ttotal: 55s\tremaining: 17.5s\n",
            "9246:\tlearn: 7.7056060\ttotal: 55s\tremaining: 17.5s\n",
            "9247:\tlearn: 7.7055968\ttotal: 55s\tremaining: 17.4s\n",
            "9248:\tlearn: 7.7055902\ttotal: 55s\tremaining: 17.4s\n",
            "9249:\tlearn: 7.7055847\ttotal: 55s\tremaining: 17.4s\n",
            "9250:\tlearn: 7.7055582\ttotal: 55s\tremaining: 17.4s\n",
            "9251:\tlearn: 7.7055472\ttotal: 55s\tremaining: 17.4s\n",
            "9252:\tlearn: 7.7055403\ttotal: 55s\tremaining: 17.4s\n",
            "9253:\tlearn: 7.7055259\ttotal: 55s\tremaining: 17.4s\n",
            "9254:\tlearn: 7.7055172\ttotal: 55.1s\tremaining: 17.4s\n",
            "9255:\tlearn: 7.7054982\ttotal: 55.1s\tremaining: 17.4s\n",
            "9256:\tlearn: 7.7054806\ttotal: 55.1s\tremaining: 17.4s\n",
            "9257:\tlearn: 7.7054610\ttotal: 55.1s\tremaining: 17.4s\n",
            "9258:\tlearn: 7.7054497\ttotal: 55.1s\tremaining: 17.4s\n",
            "9259:\tlearn: 7.7054295\ttotal: 55.1s\tremaining: 17.4s\n",
            "9260:\tlearn: 7.7054186\ttotal: 55.1s\tremaining: 17.4s\n",
            "9261:\tlearn: 7.7054108\ttotal: 55.1s\tremaining: 17.4s\n",
            "9262:\tlearn: 7.7053972\ttotal: 55.1s\tremaining: 17.4s\n",
            "9263:\tlearn: 7.7053843\ttotal: 55.1s\tremaining: 17.4s\n",
            "9264:\tlearn: 7.7053753\ttotal: 55.1s\tremaining: 17.3s\n",
            "9265:\tlearn: 7.7053629\ttotal: 55.1s\tremaining: 17.3s\n",
            "9266:\tlearn: 7.7053497\ttotal: 55.1s\tremaining: 17.3s\n",
            "9267:\tlearn: 7.7053407\ttotal: 55.1s\tremaining: 17.3s\n",
            "9268:\tlearn: 7.7053303\ttotal: 55.1s\tremaining: 17.3s\n",
            "9269:\tlearn: 7.7053205\ttotal: 55.2s\tremaining: 17.3s\n",
            "9270:\tlearn: 7.7053076\ttotal: 55.2s\tremaining: 17.3s\n",
            "9271:\tlearn: 7.7052963\ttotal: 55.2s\tremaining: 17.3s\n",
            "9272:\tlearn: 7.7052865\ttotal: 55.2s\tremaining: 17.3s\n",
            "9273:\tlearn: 7.7052703\ttotal: 55.2s\tremaining: 17.3s\n",
            "9274:\tlearn: 7.7052565\ttotal: 55.2s\tremaining: 17.3s\n",
            "9275:\tlearn: 7.7052496\ttotal: 55.2s\tremaining: 17.3s\n",
            "9276:\tlearn: 7.7052317\ttotal: 55.2s\tremaining: 17.3s\n",
            "9277:\tlearn: 7.7052135\ttotal: 55.2s\tremaining: 17.3s\n",
            "9278:\tlearn: 7.7052063\ttotal: 55.2s\tremaining: 17.3s\n",
            "9279:\tlearn: 7.7051939\ttotal: 55.2s\tremaining: 17.3s\n",
            "9280:\tlearn: 7.7051856\ttotal: 55.2s\tremaining: 17.3s\n",
            "9281:\tlearn: 7.7051720\ttotal: 55.2s\tremaining: 17.2s\n",
            "9282:\tlearn: 7.7051631\ttotal: 55.2s\tremaining: 17.2s\n",
            "9283:\tlearn: 7.7051596\ttotal: 55.2s\tremaining: 17.2s\n",
            "9284:\tlearn: 7.7051533\ttotal: 55.2s\tremaining: 17.2s\n",
            "9285:\tlearn: 7.7051342\ttotal: 55.2s\tremaining: 17.2s\n",
            "9286:\tlearn: 7.7051207\ttotal: 55.2s\tremaining: 17.2s\n",
            "9287:\tlearn: 7.7051129\ttotal: 55.3s\tremaining: 17.2s\n",
            "9288:\tlearn: 7.7051036\ttotal: 55.3s\tremaining: 17.2s\n",
            "9289:\tlearn: 7.7050832\ttotal: 55.3s\tremaining: 17.2s\n",
            "9290:\tlearn: 7.7050708\ttotal: 55.3s\tremaining: 17.2s\n",
            "9291:\tlearn: 7.7050615\ttotal: 55.3s\tremaining: 17.2s\n",
            "9292:\tlearn: 7.7050468\ttotal: 55.3s\tremaining: 17.2s\n",
            "9293:\tlearn: 7.7050379\ttotal: 55.3s\tremaining: 17.2s\n",
            "9294:\tlearn: 7.7050223\ttotal: 55.3s\tremaining: 17.2s\n",
            "9295:\tlearn: 7.7050160\ttotal: 55.3s\tremaining: 17.2s\n",
            "9296:\tlearn: 7.7050047\ttotal: 55.3s\tremaining: 17.2s\n",
            "9297:\tlearn: 7.7049894\ttotal: 55.3s\tremaining: 17.2s\n",
            "9298:\tlearn: 7.7049889\ttotal: 55.3s\tremaining: 17.1s\n",
            "9299:\tlearn: 7.7049799\ttotal: 55.3s\tremaining: 17.1s\n",
            "9300:\tlearn: 7.7049635\ttotal: 55.3s\tremaining: 17.1s\n",
            "9301:\tlearn: 7.7049560\ttotal: 55.3s\tremaining: 17.1s\n",
            "9302:\tlearn: 7.7049531\ttotal: 55.3s\tremaining: 17.1s\n",
            "9303:\tlearn: 7.7049384\ttotal: 55.4s\tremaining: 17.1s\n",
            "9304:\tlearn: 7.7049294\ttotal: 55.4s\tremaining: 17.1s\n",
            "9305:\tlearn: 7.7049248\ttotal: 55.4s\tremaining: 17.1s\n",
            "9306:\tlearn: 7.7049147\ttotal: 55.4s\tremaining: 17.1s\n",
            "9307:\tlearn: 7.7048986\ttotal: 55.4s\tremaining: 17.1s\n",
            "9308:\tlearn: 7.7048888\ttotal: 55.4s\tremaining: 17.1s\n",
            "9309:\tlearn: 7.7048744\ttotal: 55.4s\tremaining: 17.1s\n",
            "9310:\tlearn: 7.7048599\ttotal: 55.4s\tremaining: 17.1s\n",
            "9311:\tlearn: 7.7048524\ttotal: 55.4s\tremaining: 17.1s\n",
            "9312:\tlearn: 7.7048435\ttotal: 55.4s\tremaining: 17.1s\n",
            "9313:\tlearn: 7.7048259\ttotal: 55.4s\tremaining: 17.1s\n",
            "9314:\tlearn: 7.7048216\ttotal: 55.4s\tremaining: 17s\n",
            "9315:\tlearn: 7.7048147\ttotal: 55.4s\tremaining: 17s\n",
            "9316:\tlearn: 7.7048023\ttotal: 55.4s\tremaining: 17s\n",
            "9317:\tlearn: 7.7047930\ttotal: 55.4s\tremaining: 17s\n",
            "9318:\tlearn: 7.7047815\ttotal: 55.4s\tremaining: 17s\n",
            "9319:\tlearn: 7.7047616\ttotal: 55.4s\tremaining: 17s\n",
            "9320:\tlearn: 7.7047526\ttotal: 55.4s\tremaining: 17s\n",
            "9321:\tlearn: 7.7047325\ttotal: 55.5s\tremaining: 17s\n",
            "9322:\tlearn: 7.7047163\ttotal: 55.5s\tremaining: 17s\n",
            "9323:\tlearn: 7.7047068\ttotal: 55.5s\tremaining: 17s\n",
            "9324:\tlearn: 7.7047007\ttotal: 55.5s\tremaining: 17s\n",
            "9325:\tlearn: 7.7046857\ttotal: 55.5s\tremaining: 17s\n",
            "9326:\tlearn: 7.7046814\ttotal: 55.5s\tremaining: 17s\n",
            "9327:\tlearn: 7.7046762\ttotal: 55.5s\tremaining: 17s\n",
            "9328:\tlearn: 7.7046655\ttotal: 55.5s\tremaining: 17s\n",
            "9329:\tlearn: 7.7046526\ttotal: 55.5s\tremaining: 17s\n",
            "9330:\tlearn: 7.7046396\ttotal: 55.5s\tremaining: 17s\n",
            "9331:\tlearn: 7.7046278\ttotal: 55.5s\tremaining: 16.9s\n",
            "9332:\tlearn: 7.7046188\ttotal: 55.5s\tremaining: 16.9s\n",
            "9333:\tlearn: 7.7045957\ttotal: 55.5s\tremaining: 16.9s\n",
            "9334:\tlearn: 7.7045790\ttotal: 55.5s\tremaining: 16.9s\n",
            "9335:\tlearn: 7.7045545\ttotal: 55.5s\tremaining: 16.9s\n",
            "9336:\tlearn: 7.7045458\ttotal: 55.6s\tremaining: 16.9s\n",
            "9337:\tlearn: 7.7045363\ttotal: 55.6s\tremaining: 16.9s\n",
            "9338:\tlearn: 7.7045297\ttotal: 55.6s\tremaining: 16.9s\n",
            "9339:\tlearn: 7.7045196\ttotal: 55.6s\tremaining: 16.9s\n",
            "9340:\tlearn: 7.7045135\ttotal: 55.6s\tremaining: 16.9s\n",
            "9341:\tlearn: 7.7044968\ttotal: 55.6s\tremaining: 16.9s\n",
            "9342:\tlearn: 7.7044882\ttotal: 55.6s\tremaining: 16.9s\n",
            "9343:\tlearn: 7.7044732\ttotal: 55.6s\tremaining: 16.9s\n",
            "9344:\tlearn: 7.7044559\ttotal: 55.6s\tremaining: 16.9s\n",
            "9345:\tlearn: 7.7044368\ttotal: 55.6s\tremaining: 16.9s\n",
            "9346:\tlearn: 7.7044302\ttotal: 55.6s\tremaining: 16.9s\n",
            "9347:\tlearn: 7.7044215\ttotal: 55.6s\tremaining: 16.9s\n",
            "9348:\tlearn: 7.7044097\ttotal: 55.6s\tremaining: 16.9s\n",
            "9349:\tlearn: 7.7043881\ttotal: 55.6s\tremaining: 16.8s\n",
            "9350:\tlearn: 7.7043832\ttotal: 55.6s\tremaining: 16.8s\n",
            "9351:\tlearn: 7.7043751\ttotal: 55.6s\tremaining: 16.8s\n",
            "9352:\tlearn: 7.7043676\ttotal: 55.7s\tremaining: 16.8s\n",
            "9353:\tlearn: 7.7043558\ttotal: 55.7s\tremaining: 16.8s\n",
            "9354:\tlearn: 7.7043434\ttotal: 55.7s\tremaining: 16.8s\n",
            "9355:\tlearn: 7.7043304\ttotal: 55.7s\tremaining: 16.8s\n",
            "9356:\tlearn: 7.7043220\ttotal: 55.7s\tremaining: 16.8s\n",
            "9357:\tlearn: 7.7043151\ttotal: 55.7s\tremaining: 16.8s\n",
            "9358:\tlearn: 7.7043030\ttotal: 55.7s\tremaining: 16.8s\n",
            "9359:\tlearn: 7.7042880\ttotal: 55.7s\tremaining: 16.8s\n",
            "9360:\tlearn: 7.7042770\ttotal: 55.7s\tremaining: 16.8s\n",
            "9361:\tlearn: 7.7042586\ttotal: 55.7s\tremaining: 16.8s\n",
            "9362:\tlearn: 7.7042415\ttotal: 55.7s\tremaining: 16.8s\n",
            "9363:\tlearn: 7.7042366\ttotal: 55.7s\tremaining: 16.8s\n",
            "9364:\tlearn: 7.7042271\ttotal: 55.7s\tremaining: 16.8s\n",
            "9365:\tlearn: 7.7042162\ttotal: 55.7s\tremaining: 16.8s\n",
            "9366:\tlearn: 7.7041974\ttotal: 55.7s\tremaining: 16.7s\n",
            "9367:\tlearn: 7.7041859\ttotal: 55.7s\tremaining: 16.7s\n",
            "9368:\tlearn: 7.7041778\ttotal: 55.8s\tremaining: 16.7s\n",
            "9369:\tlearn: 7.7041726\ttotal: 55.8s\tremaining: 16.7s\n",
            "9370:\tlearn: 7.7041590\ttotal: 55.8s\tremaining: 16.7s\n",
            "9371:\tlearn: 7.7041394\ttotal: 55.8s\tremaining: 16.7s\n",
            "9372:\tlearn: 7.7041164\ttotal: 55.8s\tremaining: 16.7s\n",
            "9373:\tlearn: 7.7041126\ttotal: 55.8s\tremaining: 16.7s\n",
            "9374:\tlearn: 7.7040988\ttotal: 55.8s\tremaining: 16.7s\n",
            "9375:\tlearn: 7.7040901\ttotal: 55.8s\tremaining: 16.7s\n",
            "9376:\tlearn: 7.7040820\ttotal: 55.8s\tremaining: 16.7s\n",
            "9377:\tlearn: 7.7040590\ttotal: 55.8s\tremaining: 16.7s\n",
            "9378:\tlearn: 7.7040494\ttotal: 55.8s\tremaining: 16.7s\n",
            "9379:\tlearn: 7.7040391\ttotal: 55.8s\tremaining: 16.7s\n",
            "9380:\tlearn: 7.7040252\ttotal: 55.8s\tremaining: 16.7s\n",
            "9381:\tlearn: 7.7040209\ttotal: 55.8s\tremaining: 16.7s\n",
            "9382:\tlearn: 7.7040079\ttotal: 55.8s\tremaining: 16.6s\n",
            "9383:\tlearn: 7.7039946\ttotal: 55.8s\tremaining: 16.6s\n",
            "9384:\tlearn: 7.7039819\ttotal: 55.8s\tremaining: 16.6s\n",
            "9385:\tlearn: 7.7039684\ttotal: 55.8s\tremaining: 16.6s\n",
            "9386:\tlearn: 7.7039493\ttotal: 55.9s\tremaining: 16.6s\n",
            "9387:\tlearn: 7.7039335\ttotal: 55.9s\tremaining: 16.6s\n",
            "9388:\tlearn: 7.7039271\ttotal: 55.9s\tremaining: 16.6s\n",
            "9389:\tlearn: 7.7039000\ttotal: 55.9s\tremaining: 16.6s\n",
            "9390:\tlearn: 7.7038940\ttotal: 55.9s\tremaining: 16.6s\n",
            "9391:\tlearn: 7.7038752\ttotal: 55.9s\tremaining: 16.6s\n",
            "9392:\tlearn: 7.7038556\ttotal: 55.9s\tremaining: 16.6s\n",
            "9393:\tlearn: 7.7038484\ttotal: 55.9s\tremaining: 16.6s\n",
            "9394:\tlearn: 7.7038397\ttotal: 55.9s\tremaining: 16.6s\n",
            "9395:\tlearn: 7.7038317\ttotal: 55.9s\tremaining: 16.6s\n",
            "9396:\tlearn: 7.7038181\ttotal: 55.9s\tremaining: 16.6s\n",
            "9397:\tlearn: 7.7038086\ttotal: 55.9s\tremaining: 16.6s\n",
            "9398:\tlearn: 7.7037939\ttotal: 55.9s\tremaining: 16.6s\n",
            "9399:\tlearn: 7.7037797\ttotal: 55.9s\tremaining: 16.5s\n",
            "9400:\tlearn: 7.7037760\ttotal: 55.9s\tremaining: 16.5s\n",
            "9401:\tlearn: 7.7037705\ttotal: 55.9s\tremaining: 16.5s\n",
            "9402:\tlearn: 7.7037532\ttotal: 56s\tremaining: 16.5s\n",
            "9403:\tlearn: 7.7037440\ttotal: 56s\tremaining: 16.5s\n",
            "9404:\tlearn: 7.7037310\ttotal: 56s\tremaining: 16.5s\n",
            "9405:\tlearn: 7.7037264\ttotal: 56s\tremaining: 16.5s\n",
            "9406:\tlearn: 7.7037183\ttotal: 56s\tremaining: 16.5s\n",
            "9407:\tlearn: 7.7037039\ttotal: 56s\tremaining: 16.5s\n",
            "9408:\tlearn: 7.7037007\ttotal: 56s\tremaining: 16.5s\n",
            "9409:\tlearn: 7.7036903\ttotal: 56s\tremaining: 16.5s\n",
            "9410:\tlearn: 7.7036759\ttotal: 56s\tremaining: 16.5s\n",
            "9411:\tlearn: 7.7036543\ttotal: 56s\tremaining: 16.5s\n",
            "9412:\tlearn: 7.7036393\ttotal: 56s\tremaining: 16.5s\n",
            "9413:\tlearn: 7.7036168\ttotal: 56s\tremaining: 16.5s\n",
            "9414:\tlearn: 7.7035940\ttotal: 56s\tremaining: 16.5s\n",
            "9415:\tlearn: 7.7035767\ttotal: 56s\tremaining: 16.4s\n",
            "9416:\tlearn: 7.7035628\ttotal: 56s\tremaining: 16.4s\n",
            "9417:\tlearn: 7.7035475\ttotal: 56s\tremaining: 16.4s\n",
            "9418:\tlearn: 7.7035371\ttotal: 56s\tremaining: 16.4s\n",
            "9419:\tlearn: 7.7035230\ttotal: 56s\tremaining: 16.4s\n",
            "9420:\tlearn: 7.7035106\ttotal: 56.1s\tremaining: 16.4s\n",
            "9421:\tlearn: 7.7034953\ttotal: 56.1s\tremaining: 16.4s\n",
            "9422:\tlearn: 7.7034763\ttotal: 56.1s\tremaining: 16.4s\n",
            "9423:\tlearn: 7.7034616\ttotal: 56.1s\tremaining: 16.4s\n",
            "9424:\tlearn: 7.7034552\ttotal: 56.1s\tremaining: 16.4s\n",
            "9425:\tlearn: 7.7034417\ttotal: 56.1s\tremaining: 16.4s\n",
            "9426:\tlearn: 7.7034385\ttotal: 56.1s\tremaining: 16.4s\n",
            "9427:\tlearn: 7.7034220\ttotal: 56.1s\tremaining: 16.4s\n",
            "9428:\tlearn: 7.7034194\ttotal: 56.1s\tremaining: 16.4s\n",
            "9429:\tlearn: 7.7034108\ttotal: 56.1s\tremaining: 16.4s\n",
            "9430:\tlearn: 7.7033917\ttotal: 56.1s\tremaining: 16.4s\n",
            "9431:\tlearn: 7.7033837\ttotal: 56.1s\tremaining: 16.4s\n",
            "9432:\tlearn: 7.7033782\ttotal: 56.1s\tremaining: 16.4s\n",
            "9433:\tlearn: 7.7033661\ttotal: 56.1s\tremaining: 16.3s\n",
            "9434:\tlearn: 7.7033456\ttotal: 56.1s\tremaining: 16.3s\n",
            "9435:\tlearn: 7.7033358\ttotal: 56.1s\tremaining: 16.3s\n",
            "9436:\tlearn: 7.7033133\ttotal: 56.1s\tremaining: 16.3s\n",
            "9437:\tlearn: 7.7033020\ttotal: 56.2s\tremaining: 16.3s\n",
            "9438:\tlearn: 7.7032957\ttotal: 56.2s\tremaining: 16.3s\n",
            "9439:\tlearn: 7.7032891\ttotal: 56.2s\tremaining: 16.3s\n",
            "9440:\tlearn: 7.7032784\ttotal: 56.2s\tremaining: 16.3s\n",
            "9441:\tlearn: 7.7032458\ttotal: 56.2s\tremaining: 16.3s\n",
            "9442:\tlearn: 7.7032406\ttotal: 56.2s\tremaining: 16.3s\n",
            "9443:\tlearn: 7.7032253\ttotal: 56.2s\tremaining: 16.3s\n",
            "9444:\tlearn: 7.7032175\ttotal: 56.2s\tremaining: 16.3s\n",
            "9445:\tlearn: 7.7032051\ttotal: 56.2s\tremaining: 16.3s\n",
            "9446:\tlearn: 7.7031950\ttotal: 56.2s\tremaining: 16.3s\n",
            "9447:\tlearn: 7.7031794\ttotal: 56.2s\tremaining: 16.3s\n",
            "9448:\tlearn: 7.7031679\ttotal: 56.2s\tremaining: 16.3s\n",
            "9449:\tlearn: 7.7031561\ttotal: 56.2s\tremaining: 16.2s\n",
            "9450:\tlearn: 7.7031489\ttotal: 56.2s\tremaining: 16.2s\n",
            "9451:\tlearn: 7.7031287\ttotal: 56.2s\tremaining: 16.2s\n",
            "9452:\tlearn: 7.7031197\ttotal: 56.2s\tremaining: 16.2s\n",
            "9453:\tlearn: 7.7031079\ttotal: 56.2s\tremaining: 16.2s\n",
            "9454:\tlearn: 7.7031021\ttotal: 56.2s\tremaining: 16.2s\n",
            "9455:\tlearn: 7.7030733\ttotal: 56.3s\tremaining: 16.2s\n",
            "9456:\tlearn: 7.7030600\ttotal: 56.3s\tremaining: 16.2s\n",
            "9457:\tlearn: 7.7030542\ttotal: 56.3s\tremaining: 16.2s\n",
            "9458:\tlearn: 7.7030352\ttotal: 56.3s\tremaining: 16.2s\n",
            "9459:\tlearn: 7.7030283\ttotal: 56.3s\tremaining: 16.2s\n",
            "9460:\tlearn: 7.7030202\ttotal: 56.3s\tremaining: 16.2s\n",
            "9461:\tlearn: 7.7030078\ttotal: 56.3s\tremaining: 16.2s\n",
            "9462:\tlearn: 7.7029994\ttotal: 56.3s\tremaining: 16.2s\n",
            "9463:\tlearn: 7.7029714\ttotal: 56.3s\tremaining: 16.2s\n",
            "9464:\tlearn: 7.7029639\ttotal: 56.3s\tremaining: 16.2s\n",
            "9465:\tlearn: 7.7029501\ttotal: 56.3s\tremaining: 16.2s\n",
            "9466:\tlearn: 7.7029322\ttotal: 56.3s\tremaining: 16.1s\n",
            "9467:\tlearn: 7.7029132\ttotal: 56.3s\tremaining: 16.1s\n",
            "9468:\tlearn: 7.7029051\ttotal: 56.3s\tremaining: 16.1s\n",
            "9469:\tlearn: 7.7028907\ttotal: 56.3s\tremaining: 16.1s\n",
            "9470:\tlearn: 7.7028733\ttotal: 56.4s\tremaining: 16.1s\n",
            "9471:\tlearn: 7.7028647\ttotal: 56.4s\tremaining: 16.1s\n",
            "9472:\tlearn: 7.7028540\ttotal: 56.4s\tremaining: 16.1s\n",
            "9473:\tlearn: 7.7028393\ttotal: 56.4s\tremaining: 16.1s\n",
            "9474:\tlearn: 7.7028295\ttotal: 56.4s\tremaining: 16.1s\n",
            "9475:\tlearn: 7.7028142\ttotal: 56.4s\tremaining: 16.1s\n",
            "9476:\tlearn: 7.7027983\ttotal: 56.4s\tremaining: 16.1s\n",
            "9477:\tlearn: 7.7027848\ttotal: 56.4s\tremaining: 16.1s\n",
            "9478:\tlearn: 7.7027761\ttotal: 56.4s\tremaining: 16.1s\n",
            "9479:\tlearn: 7.7027663\ttotal: 56.4s\tremaining: 16.1s\n",
            "9480:\tlearn: 7.7027634\ttotal: 56.4s\tremaining: 16.1s\n",
            "9481:\tlearn: 7.7027487\ttotal: 56.4s\tremaining: 16.1s\n",
            "9482:\tlearn: 7.7027389\ttotal: 56.4s\tremaining: 16.1s\n",
            "9483:\tlearn: 7.7027297\ttotal: 56.4s\tremaining: 16s\n",
            "9484:\tlearn: 7.7027242\ttotal: 56.4s\tremaining: 16s\n",
            "9485:\tlearn: 7.7027178\ttotal: 56.4s\tremaining: 16s\n",
            "9486:\tlearn: 7.7027060\ttotal: 56.4s\tremaining: 16s\n",
            "9487:\tlearn: 7.7026953\ttotal: 56.4s\tremaining: 16s\n",
            "9488:\tlearn: 7.7026850\ttotal: 56.5s\tremaining: 16s\n",
            "9489:\tlearn: 7.7026777\ttotal: 56.5s\tremaining: 16s\n",
            "9490:\tlearn: 7.7026679\ttotal: 56.5s\tremaining: 16s\n",
            "9491:\tlearn: 7.7026526\ttotal: 56.5s\tremaining: 16s\n",
            "9492:\tlearn: 7.7026397\ttotal: 56.5s\tremaining: 16s\n",
            "9493:\tlearn: 7.7026284\ttotal: 56.5s\tremaining: 16s\n",
            "9494:\tlearn: 7.7026203\ttotal: 56.5s\tremaining: 16s\n",
            "9495:\tlearn: 7.7025984\ttotal: 56.5s\tremaining: 16s\n",
            "9496:\tlearn: 7.7025831\ttotal: 56.5s\tremaining: 16s\n",
            "9497:\tlearn: 7.7025690\ttotal: 56.5s\tremaining: 16s\n",
            "9498:\tlearn: 7.7025491\ttotal: 56.5s\tremaining: 16s\n",
            "9499:\tlearn: 7.7025450\ttotal: 56.5s\tremaining: 16s\n",
            "9500:\tlearn: 7.7025384\ttotal: 56.5s\tremaining: 15.9s\n",
            "9501:\tlearn: 7.7025315\ttotal: 56.5s\tremaining: 15.9s\n",
            "9502:\tlearn: 7.7025260\ttotal: 56.6s\tremaining: 15.9s\n",
            "9503:\tlearn: 7.7025191\ttotal: 56.6s\tremaining: 15.9s\n",
            "9504:\tlearn: 7.7025084\ttotal: 56.6s\tremaining: 15.9s\n",
            "9505:\tlearn: 7.7024966\ttotal: 56.6s\tremaining: 15.9s\n",
            "9506:\tlearn: 7.7024894\ttotal: 56.6s\tremaining: 15.9s\n",
            "9507:\tlearn: 7.7024767\ttotal: 56.6s\tremaining: 15.9s\n",
            "9508:\tlearn: 7.7024666\ttotal: 56.6s\tremaining: 15.9s\n",
            "9509:\tlearn: 7.7024582\ttotal: 56.6s\tremaining: 15.9s\n",
            "9510:\tlearn: 7.7024403\ttotal: 56.6s\tremaining: 15.9s\n",
            "9511:\tlearn: 7.7024253\ttotal: 56.6s\tremaining: 15.9s\n",
            "9512:\tlearn: 7.7024169\ttotal: 56.6s\tremaining: 15.9s\n",
            "9513:\tlearn: 7.7024071\ttotal: 56.6s\tremaining: 15.9s\n",
            "9514:\tlearn: 7.7023947\ttotal: 56.6s\tremaining: 15.9s\n",
            "9515:\tlearn: 7.7023731\ttotal: 56.6s\tremaining: 15.9s\n",
            "9516:\tlearn: 7.7023633\ttotal: 56.6s\tremaining: 15.9s\n",
            "9517:\tlearn: 7.7023575\ttotal: 56.6s\tremaining: 15.8s\n",
            "9518:\tlearn: 7.7023538\ttotal: 56.6s\tremaining: 15.8s\n",
            "9519:\tlearn: 7.7023428\ttotal: 56.6s\tremaining: 15.8s\n",
            "9520:\tlearn: 7.7023281\ttotal: 56.6s\tremaining: 15.8s\n",
            "9521:\tlearn: 7.7023157\ttotal: 56.7s\tremaining: 15.8s\n",
            "9522:\tlearn: 7.7023061\ttotal: 56.7s\tremaining: 15.8s\n",
            "9523:\tlearn: 7.7022958\ttotal: 56.7s\tremaining: 15.8s\n",
            "9524:\tlearn: 7.7022883\ttotal: 56.7s\tremaining: 15.8s\n",
            "9525:\tlearn: 7.7022802\ttotal: 56.7s\tremaining: 15.8s\n",
            "9526:\tlearn: 7.7022698\ttotal: 56.7s\tremaining: 15.8s\n",
            "9527:\tlearn: 7.7022392\ttotal: 56.7s\tremaining: 15.8s\n",
            "9528:\tlearn: 7.7022233\ttotal: 56.7s\tremaining: 15.8s\n",
            "9529:\tlearn: 7.7022092\ttotal: 56.7s\tremaining: 15.8s\n",
            "9530:\tlearn: 7.7021945\ttotal: 56.7s\tremaining: 15.8s\n",
            "9531:\tlearn: 7.7021792\ttotal: 56.7s\tremaining: 15.8s\n",
            "9532:\tlearn: 7.7021749\ttotal: 56.7s\tremaining: 15.8s\n",
            "9533:\tlearn: 7.7021636\ttotal: 56.7s\tremaining: 15.8s\n",
            "9534:\tlearn: 7.7021529\ttotal: 56.7s\tremaining: 15.7s\n",
            "9535:\tlearn: 7.7021495\ttotal: 56.7s\tremaining: 15.7s\n",
            "9536:\tlearn: 7.7021403\ttotal: 56.7s\tremaining: 15.7s\n",
            "9537:\tlearn: 7.7021339\ttotal: 56.8s\tremaining: 15.7s\n",
            "9538:\tlearn: 7.7021215\ttotal: 56.8s\tremaining: 15.7s\n",
            "9539:\tlearn: 7.7021071\ttotal: 56.8s\tremaining: 15.7s\n",
            "9540:\tlearn: 7.7020797\ttotal: 56.8s\tremaining: 15.7s\n",
            "9541:\tlearn: 7.7020707\ttotal: 56.8s\tremaining: 15.7s\n",
            "9542:\tlearn: 7.7020661\ttotal: 56.8s\tremaining: 15.7s\n",
            "9543:\tlearn: 7.7020514\ttotal: 56.8s\tremaining: 15.7s\n",
            "9544:\tlearn: 7.7020335\ttotal: 56.8s\tremaining: 15.7s\n",
            "9545:\tlearn: 7.7020211\ttotal: 56.8s\tremaining: 15.7s\n",
            "9546:\tlearn: 7.7020130\ttotal: 56.8s\tremaining: 15.7s\n",
            "9547:\tlearn: 7.7020000\ttotal: 56.8s\tremaining: 15.7s\n",
            "9548:\tlearn: 7.7019781\ttotal: 56.8s\tremaining: 15.7s\n",
            "9549:\tlearn: 7.7019694\ttotal: 56.8s\tremaining: 15.7s\n",
            "9550:\tlearn: 7.7019674\ttotal: 56.8s\tremaining: 15.6s\n",
            "9551:\tlearn: 7.7019579\ttotal: 56.8s\tremaining: 15.6s\n",
            "9552:\tlearn: 7.7019472\ttotal: 56.8s\tremaining: 15.6s\n",
            "9553:\tlearn: 7.7019415\ttotal: 56.8s\tremaining: 15.6s\n",
            "9554:\tlearn: 7.7019371\ttotal: 56.8s\tremaining: 15.6s\n",
            "9555:\tlearn: 7.7019328\ttotal: 56.8s\tremaining: 15.6s\n",
            "9556:\tlearn: 7.7019213\ttotal: 56.9s\tremaining: 15.6s\n",
            "9557:\tlearn: 7.7019100\ttotal: 56.9s\tremaining: 15.6s\n",
            "9558:\tlearn: 7.7018866\ttotal: 56.9s\tremaining: 15.6s\n",
            "9559:\tlearn: 7.7018774\ttotal: 56.9s\tremaining: 15.6s\n",
            "9560:\tlearn: 7.7018722\ttotal: 56.9s\tremaining: 15.6s\n",
            "9561:\tlearn: 7.7018558\ttotal: 56.9s\tremaining: 15.6s\n",
            "9562:\tlearn: 7.7018451\ttotal: 56.9s\tremaining: 15.6s\n",
            "9563:\tlearn: 7.7018292\ttotal: 56.9s\tremaining: 15.6s\n",
            "9564:\tlearn: 7.7018185\ttotal: 56.9s\tremaining: 15.6s\n",
            "9565:\tlearn: 7.7018084\ttotal: 56.9s\tremaining: 15.6s\n",
            "9566:\tlearn: 7.7017949\ttotal: 56.9s\tremaining: 15.6s\n",
            "9567:\tlearn: 7.7017885\ttotal: 56.9s\tremaining: 15.5s\n",
            "9568:\tlearn: 7.7017784\ttotal: 56.9s\tremaining: 15.5s\n",
            "9569:\tlearn: 7.7017672\ttotal: 56.9s\tremaining: 15.5s\n",
            "9570:\tlearn: 7.7017626\ttotal: 57s\tremaining: 15.5s\n",
            "9571:\tlearn: 7.7017539\ttotal: 57s\tremaining: 15.5s\n",
            "9572:\tlearn: 7.7017493\ttotal: 57s\tremaining: 15.5s\n",
            "9573:\tlearn: 7.7017441\ttotal: 57s\tremaining: 15.5s\n",
            "9574:\tlearn: 7.7017311\ttotal: 57s\tremaining: 15.5s\n",
            "9575:\tlearn: 7.7017222\ttotal: 57s\tremaining: 15.5s\n",
            "9576:\tlearn: 7.7017017\ttotal: 57s\tremaining: 15.5s\n",
            "9577:\tlearn: 7.7016962\ttotal: 57s\tremaining: 15.5s\n",
            "9578:\tlearn: 7.7016818\ttotal: 57s\tremaining: 15.5s\n",
            "9579:\tlearn: 7.7016711\ttotal: 57s\tremaining: 15.5s\n",
            "9580:\tlearn: 7.7016650\ttotal: 57s\tremaining: 15.5s\n",
            "9581:\tlearn: 7.7016570\ttotal: 57s\tremaining: 15.5s\n",
            "9582:\tlearn: 7.7016477\ttotal: 57s\tremaining: 15.5s\n",
            "9583:\tlearn: 7.7016434\ttotal: 57s\tremaining: 15.5s\n",
            "9584:\tlearn: 7.7016365\ttotal: 57s\tremaining: 15.4s\n",
            "9585:\tlearn: 7.7016235\ttotal: 57s\tremaining: 15.4s\n",
            "9586:\tlearn: 7.7016111\ttotal: 57s\tremaining: 15.4s\n",
            "9587:\tlearn: 7.7016042\ttotal: 57.1s\tremaining: 15.4s\n",
            "9588:\tlearn: 7.7015941\ttotal: 57.1s\tremaining: 15.4s\n",
            "9589:\tlearn: 7.7015707\ttotal: 57.1s\tremaining: 15.4s\n",
            "9590:\tlearn: 7.7015623\ttotal: 57.1s\tremaining: 15.4s\n",
            "9591:\tlearn: 7.7015525\ttotal: 57.1s\tremaining: 15.4s\n",
            "9592:\tlearn: 7.7015447\ttotal: 57.1s\tremaining: 15.4s\n",
            "9593:\tlearn: 7.7015375\ttotal: 57.1s\tremaining: 15.4s\n",
            "9594:\tlearn: 7.7015231\ttotal: 57.1s\tremaining: 15.4s\n",
            "9595:\tlearn: 7.7015153\ttotal: 57.1s\tremaining: 15.4s\n",
            "9596:\tlearn: 7.7015101\ttotal: 57.1s\tremaining: 15.4s\n",
            "9597:\tlearn: 7.7014960\ttotal: 57.1s\tremaining: 15.4s\n",
            "9598:\tlearn: 7.7014836\ttotal: 57.1s\tremaining: 15.4s\n",
            "9599:\tlearn: 7.7014711\ttotal: 57.1s\tremaining: 15.4s\n",
            "9600:\tlearn: 7.7014619\ttotal: 57.1s\tremaining: 15.4s\n",
            "9601:\tlearn: 7.7014489\ttotal: 57.1s\tremaining: 15.3s\n",
            "9602:\tlearn: 7.7014342\ttotal: 57.1s\tremaining: 15.3s\n",
            "9603:\tlearn: 7.7014192\ttotal: 57.2s\tremaining: 15.3s\n",
            "9604:\tlearn: 7.7014129\ttotal: 57.2s\tremaining: 15.3s\n",
            "9605:\tlearn: 7.7013993\ttotal: 57.2s\tremaining: 15.3s\n",
            "9606:\tlearn: 7.7013872\ttotal: 57.2s\tremaining: 15.3s\n",
            "9607:\tlearn: 7.7013730\ttotal: 57.2s\tremaining: 15.3s\n",
            "9608:\tlearn: 7.7013618\ttotal: 57.2s\tremaining: 15.3s\n",
            "9609:\tlearn: 7.7013514\ttotal: 57.2s\tremaining: 15.3s\n",
            "9610:\tlearn: 7.7013419\ttotal: 57.2s\tremaining: 15.3s\n",
            "9611:\tlearn: 7.7013202\ttotal: 57.2s\tremaining: 15.3s\n",
            "9612:\tlearn: 7.7013067\ttotal: 57.2s\tremaining: 15.3s\n",
            "9613:\tlearn: 7.7013038\ttotal: 57.2s\tremaining: 15.3s\n",
            "9614:\tlearn: 7.7012917\ttotal: 57.2s\tremaining: 15.3s\n",
            "9615:\tlearn: 7.7012778\ttotal: 57.2s\tremaining: 15.3s\n",
            "9616:\tlearn: 7.7012723\ttotal: 57.2s\tremaining: 15.3s\n",
            "9617:\tlearn: 7.7012576\ttotal: 57.2s\tremaining: 15.3s\n",
            "9618:\tlearn: 7.7012475\ttotal: 57.2s\tremaining: 15.2s\n",
            "9619:\tlearn: 7.7012420\ttotal: 57.2s\tremaining: 15.2s\n",
            "9620:\tlearn: 7.7012316\ttotal: 57.2s\tremaining: 15.2s\n",
            "9621:\tlearn: 7.7012256\ttotal: 57.3s\tremaining: 15.2s\n",
            "9622:\tlearn: 7.7012042\ttotal: 57.3s\tremaining: 15.2s\n",
            "9623:\tlearn: 7.7011884\ttotal: 57.3s\tremaining: 15.2s\n",
            "9624:\tlearn: 7.7011820\ttotal: 57.3s\tremaining: 15.2s\n",
            "9625:\tlearn: 7.7011708\ttotal: 57.3s\tremaining: 15.2s\n",
            "9626:\tlearn: 7.7011488\ttotal: 57.3s\tremaining: 15.2s\n",
            "9627:\tlearn: 7.7011376\ttotal: 57.3s\tremaining: 15.2s\n",
            "9628:\tlearn: 7.7011249\ttotal: 57.3s\tremaining: 15.2s\n",
            "9629:\tlearn: 7.7011139\ttotal: 57.3s\tremaining: 15.2s\n",
            "9630:\tlearn: 7.7011053\ttotal: 57.3s\tremaining: 15.2s\n",
            "9631:\tlearn: 7.7010931\ttotal: 57.3s\tremaining: 15.2s\n",
            "9632:\tlearn: 7.7010799\ttotal: 57.3s\tremaining: 15.2s\n",
            "9633:\tlearn: 7.7010657\ttotal: 57.3s\tremaining: 15.2s\n",
            "9634:\tlearn: 7.7010600\ttotal: 57.3s\tremaining: 15.1s\n",
            "9635:\tlearn: 7.7010421\ttotal: 57.3s\tremaining: 15.1s\n",
            "9636:\tlearn: 7.7010369\ttotal: 57.3s\tremaining: 15.1s\n",
            "9637:\tlearn: 7.7010305\ttotal: 57.3s\tremaining: 15.1s\n",
            "9638:\tlearn: 7.7010245\ttotal: 57.4s\tremaining: 15.1s\n",
            "9639:\tlearn: 7.7010100\ttotal: 57.4s\tremaining: 15.1s\n",
            "9640:\tlearn: 7.7010063\ttotal: 57.4s\tremaining: 15.1s\n",
            "9641:\tlearn: 7.7009916\ttotal: 57.4s\tremaining: 15.1s\n",
            "9642:\tlearn: 7.7009757\ttotal: 57.4s\tremaining: 15.1s\n",
            "9643:\tlearn: 7.7009561\ttotal: 57.4s\tremaining: 15.1s\n",
            "9644:\tlearn: 7.7009500\ttotal: 57.4s\tremaining: 15.1s\n",
            "9645:\tlearn: 7.7009292\ttotal: 57.4s\tremaining: 15.1s\n",
            "9646:\tlearn: 7.7009217\ttotal: 57.4s\tremaining: 15.1s\n",
            "9647:\tlearn: 7.7009168\ttotal: 57.4s\tremaining: 15.1s\n",
            "9648:\tlearn: 7.7009050\ttotal: 57.4s\tremaining: 15.1s\n",
            "9649:\tlearn: 7.7009027\ttotal: 57.4s\tremaining: 15.1s\n",
            "9650:\tlearn: 7.7008966\ttotal: 57.4s\tremaining: 15.1s\n",
            "9651:\tlearn: 7.7008851\ttotal: 57.4s\tremaining: 15s\n",
            "9652:\tlearn: 7.7008779\ttotal: 57.4s\tremaining: 15s\n",
            "9653:\tlearn: 7.7008672\ttotal: 57.4s\tremaining: 15s\n",
            "9654:\tlearn: 7.7008412\ttotal: 57.4s\tremaining: 15s\n",
            "9655:\tlearn: 7.7008291\ttotal: 57.5s\tremaining: 15s\n",
            "9656:\tlearn: 7.7008158\ttotal: 57.5s\tremaining: 15s\n",
            "9657:\tlearn: 7.7008040\ttotal: 57.5s\tremaining: 15s\n",
            "9658:\tlearn: 7.7007821\ttotal: 57.5s\tremaining: 15s\n",
            "9659:\tlearn: 7.7007812\ttotal: 57.5s\tremaining: 15s\n",
            "9660:\tlearn: 7.7007749\ttotal: 57.5s\tremaining: 15s\n",
            "9661:\tlearn: 7.7007694\ttotal: 57.5s\tremaining: 15s\n",
            "9662:\tlearn: 7.7007639\ttotal: 57.5s\tremaining: 15s\n",
            "9663:\tlearn: 7.7007547\ttotal: 57.5s\tremaining: 15s\n",
            "9664:\tlearn: 7.7007474\ttotal: 57.5s\tremaining: 15s\n",
            "9665:\tlearn: 7.7007385\ttotal: 57.5s\tremaining: 15s\n",
            "9666:\tlearn: 7.7007272\ttotal: 57.5s\tremaining: 15s\n",
            "9667:\tlearn: 7.7007183\ttotal: 57.5s\tremaining: 15s\n",
            "9668:\tlearn: 7.7007117\ttotal: 57.5s\tremaining: 14.9s\n",
            "9669:\tlearn: 7.7007065\ttotal: 57.6s\tremaining: 14.9s\n",
            "9670:\tlearn: 7.7006964\ttotal: 57.6s\tremaining: 14.9s\n",
            "9671:\tlearn: 7.7006805\ttotal: 57.6s\tremaining: 14.9s\n",
            "9672:\tlearn: 7.7006669\ttotal: 57.6s\tremaining: 14.9s\n",
            "9673:\tlearn: 7.7006531\ttotal: 57.6s\tremaining: 14.9s\n",
            "9674:\tlearn: 7.7006502\ttotal: 57.6s\tremaining: 14.9s\n",
            "9675:\tlearn: 7.7006441\ttotal: 57.6s\tremaining: 14.9s\n",
            "9676:\tlearn: 7.7006343\ttotal: 57.6s\tremaining: 14.9s\n",
            "9677:\tlearn: 7.7006213\ttotal: 57.6s\tremaining: 14.9s\n",
            "9678:\tlearn: 7.7006170\ttotal: 57.6s\tremaining: 14.9s\n",
            "9679:\tlearn: 7.7006008\ttotal: 57.6s\tremaining: 14.9s\n",
            "9680:\tlearn: 7.7005861\ttotal: 57.6s\tremaining: 14.9s\n",
            "9681:\tlearn: 7.7005659\ttotal: 57.6s\tremaining: 14.9s\n",
            "9682:\tlearn: 7.7005570\ttotal: 57.6s\tremaining: 14.9s\n",
            "9683:\tlearn: 7.7005437\ttotal: 57.6s\tremaining: 14.9s\n",
            "9684:\tlearn: 7.7005229\ttotal: 57.6s\tremaining: 14.9s\n",
            "9685:\tlearn: 7.7005137\ttotal: 57.6s\tremaining: 14.8s\n",
            "9686:\tlearn: 7.7005001\ttotal: 57.7s\tremaining: 14.8s\n",
            "9687:\tlearn: 7.7004900\ttotal: 57.7s\tremaining: 14.8s\n",
            "9688:\tlearn: 7.7004736\ttotal: 57.7s\tremaining: 14.8s\n",
            "9689:\tlearn: 7.7004589\ttotal: 57.7s\tremaining: 14.8s\n",
            "9690:\tlearn: 7.7004482\ttotal: 57.7s\tremaining: 14.8s\n",
            "9691:\tlearn: 7.7004303\ttotal: 57.7s\tremaining: 14.8s\n",
            "9692:\tlearn: 7.7004274\ttotal: 57.7s\tremaining: 14.8s\n",
            "9693:\tlearn: 7.7004202\ttotal: 57.7s\tremaining: 14.8s\n",
            "9694:\tlearn: 7.7004150\ttotal: 57.7s\tremaining: 14.8s\n",
            "9695:\tlearn: 7.7004043\ttotal: 57.7s\tremaining: 14.8s\n",
            "9696:\tlearn: 7.7003954\ttotal: 57.7s\tremaining: 14.8s\n",
            "9697:\tlearn: 7.7003879\ttotal: 57.7s\tremaining: 14.8s\n",
            "9698:\tlearn: 7.7003801\ttotal: 57.7s\tremaining: 14.8s\n",
            "9699:\tlearn: 7.7003628\ttotal: 57.7s\tremaining: 14.8s\n",
            "9700:\tlearn: 7.7003584\ttotal: 57.7s\tremaining: 14.8s\n",
            "9701:\tlearn: 7.7003446\ttotal: 57.7s\tremaining: 14.8s\n",
            "9702:\tlearn: 7.7003299\ttotal: 57.8s\tremaining: 14.7s\n",
            "9703:\tlearn: 7.7003180\ttotal: 57.8s\tremaining: 14.7s\n",
            "9704:\tlearn: 7.7003117\ttotal: 57.8s\tremaining: 14.7s\n",
            "9705:\tlearn: 7.7002993\ttotal: 57.8s\tremaining: 14.7s\n",
            "9706:\tlearn: 7.7002802\ttotal: 57.8s\tremaining: 14.7s\n",
            "9707:\tlearn: 7.7002644\ttotal: 57.8s\tremaining: 14.7s\n",
            "9708:\tlearn: 7.7002502\ttotal: 57.8s\tremaining: 14.7s\n",
            "9709:\tlearn: 7.7002260\ttotal: 57.8s\tremaining: 14.7s\n",
            "9710:\tlearn: 7.7002167\ttotal: 57.8s\tremaining: 14.7s\n",
            "9711:\tlearn: 7.7001919\ttotal: 57.8s\tremaining: 14.7s\n",
            "9712:\tlearn: 7.7001850\ttotal: 57.8s\tremaining: 14.7s\n",
            "9713:\tlearn: 7.7001726\ttotal: 57.8s\tremaining: 14.7s\n",
            "9714:\tlearn: 7.7001677\ttotal: 57.8s\tremaining: 14.7s\n",
            "9715:\tlearn: 7.7001515\ttotal: 57.8s\tremaining: 14.7s\n",
            "9716:\tlearn: 7.7001313\ttotal: 57.8s\tremaining: 14.7s\n",
            "9717:\tlearn: 7.7001258\ttotal: 57.8s\tremaining: 14.7s\n",
            "9718:\tlearn: 7.7001126\ttotal: 57.8s\tremaining: 14.7s\n",
            "9719:\tlearn: 7.7000961\ttotal: 57.9s\tremaining: 14.6s\n",
            "9720:\tlearn: 7.7000935\ttotal: 57.9s\tremaining: 14.6s\n",
            "9721:\tlearn: 7.7000756\ttotal: 57.9s\tremaining: 14.6s\n",
            "9722:\tlearn: 7.7000620\ttotal: 57.9s\tremaining: 14.6s\n",
            "9723:\tlearn: 7.7000511\ttotal: 57.9s\tremaining: 14.6s\n",
            "9724:\tlearn: 7.7000378\ttotal: 57.9s\tremaining: 14.6s\n",
            "9725:\tlearn: 7.7000309\ttotal: 57.9s\tremaining: 14.6s\n",
            "9726:\tlearn: 7.7000242\ttotal: 57.9s\tremaining: 14.6s\n",
            "9727:\tlearn: 7.7000136\ttotal: 57.9s\tremaining: 14.6s\n",
            "9728:\tlearn: 7.7000023\ttotal: 57.9s\tremaining: 14.6s\n",
            "9729:\tlearn: 7.6999968\ttotal: 57.9s\tremaining: 14.6s\n",
            "9730:\tlearn: 7.6999827\ttotal: 57.9s\tremaining: 14.6s\n",
            "9731:\tlearn: 7.6999763\ttotal: 57.9s\tremaining: 14.6s\n",
            "9732:\tlearn: 7.6999633\ttotal: 57.9s\tremaining: 14.6s\n",
            "9733:\tlearn: 7.6999573\ttotal: 57.9s\tremaining: 14.6s\n",
            "9734:\tlearn: 7.6999403\ttotal: 57.9s\tremaining: 14.6s\n",
            "9735:\tlearn: 7.6999316\ttotal: 58s\tremaining: 14.6s\n",
            "9736:\tlearn: 7.6999241\ttotal: 58s\tremaining: 14.5s\n",
            "9737:\tlearn: 7.6999195\ttotal: 58s\tremaining: 14.5s\n",
            "9738:\tlearn: 7.6999105\ttotal: 58s\tremaining: 14.5s\n",
            "9739:\tlearn: 7.6998999\ttotal: 58s\tremaining: 14.5s\n",
            "9740:\tlearn: 7.6998776\ttotal: 58s\tremaining: 14.5s\n",
            "9741:\tlearn: 7.6998626\ttotal: 58s\tremaining: 14.5s\n",
            "9742:\tlearn: 7.6998571\ttotal: 58s\tremaining: 14.5s\n",
            "9743:\tlearn: 7.6998375\ttotal: 58s\tremaining: 14.5s\n",
            "9744:\tlearn: 7.6998303\ttotal: 58s\tremaining: 14.5s\n",
            "9745:\tlearn: 7.6998156\ttotal: 58s\tremaining: 14.5s\n",
            "9746:\tlearn: 7.6998037\ttotal: 58s\tremaining: 14.5s\n",
            "9747:\tlearn: 7.6997916\ttotal: 58s\tremaining: 14.5s\n",
            "9748:\tlearn: 7.6997818\ttotal: 58s\tremaining: 14.5s\n",
            "9749:\tlearn: 7.6997708\ttotal: 58s\tremaining: 14.5s\n",
            "9750:\tlearn: 7.6997648\ttotal: 58s\tremaining: 14.5s\n",
            "9751:\tlearn: 7.6997509\ttotal: 58s\tremaining: 14.5s\n",
            "9752:\tlearn: 7.6997434\ttotal: 58.1s\tremaining: 14.5s\n",
            "9753:\tlearn: 7.6997304\ttotal: 58.1s\tremaining: 14.4s\n",
            "9754:\tlearn: 7.6997177\ttotal: 58.1s\tremaining: 14.4s\n",
            "9755:\tlearn: 7.6997068\ttotal: 58.1s\tremaining: 14.4s\n",
            "9756:\tlearn: 7.6996941\ttotal: 58.1s\tremaining: 14.4s\n",
            "9757:\tlearn: 7.6996872\ttotal: 58.1s\tremaining: 14.4s\n",
            "9758:\tlearn: 7.6996768\ttotal: 58.1s\tremaining: 14.4s\n",
            "9759:\tlearn: 7.6996620\ttotal: 58.1s\tremaining: 14.4s\n",
            "9760:\tlearn: 7.6996528\ttotal: 58.1s\tremaining: 14.4s\n",
            "9761:\tlearn: 7.6996424\ttotal: 58.1s\tremaining: 14.4s\n",
            "9762:\tlearn: 7.6996231\ttotal: 58.1s\tremaining: 14.4s\n",
            "9763:\tlearn: 7.6996133\ttotal: 58.1s\tremaining: 14.4s\n",
            "9764:\tlearn: 7.6995939\ttotal: 58.1s\tremaining: 14.4s\n",
            "9765:\tlearn: 7.6995815\ttotal: 58.1s\tremaining: 14.4s\n",
            "9766:\tlearn: 7.6995769\ttotal: 58.1s\tremaining: 14.4s\n",
            "9767:\tlearn: 7.6995674\ttotal: 58.1s\tremaining: 14.4s\n",
            "9768:\tlearn: 7.6995619\ttotal: 58.2s\tremaining: 14.4s\n",
            "9769:\tlearn: 7.6995555\ttotal: 58.2s\tremaining: 14.4s\n",
            "9770:\tlearn: 7.6995417\ttotal: 58.2s\tremaining: 14.3s\n",
            "9771:\tlearn: 7.6995296\ttotal: 58.2s\tremaining: 14.3s\n",
            "9772:\tlearn: 7.6995252\ttotal: 58.2s\tremaining: 14.3s\n",
            "9773:\tlearn: 7.6995140\ttotal: 58.2s\tremaining: 14.3s\n",
            "9774:\tlearn: 7.6995039\ttotal: 58.2s\tremaining: 14.3s\n",
            "9775:\tlearn: 7.6994975\ttotal: 58.2s\tremaining: 14.3s\n",
            "9776:\tlearn: 7.6994843\ttotal: 58.2s\tremaining: 14.3s\n",
            "9777:\tlearn: 7.6994710\ttotal: 58.2s\tremaining: 14.3s\n",
            "9778:\tlearn: 7.6994568\ttotal: 58.2s\tremaining: 14.3s\n",
            "9779:\tlearn: 7.6994528\ttotal: 58.2s\tremaining: 14.3s\n",
            "9780:\tlearn: 7.6994395\ttotal: 58.2s\tremaining: 14.3s\n",
            "9781:\tlearn: 7.6994335\ttotal: 58.2s\tremaining: 14.3s\n",
            "9782:\tlearn: 7.6994248\ttotal: 58.2s\tremaining: 14.3s\n",
            "9783:\tlearn: 7.6994167\ttotal: 58.2s\tremaining: 14.3s\n",
            "9784:\tlearn: 7.6993980\ttotal: 58.2s\tremaining: 14.3s\n",
            "9785:\tlearn: 7.6993855\ttotal: 58.2s\tremaining: 14.3s\n",
            "9786:\tlearn: 7.6993717\ttotal: 58.3s\tremaining: 14.2s\n",
            "9787:\tlearn: 7.6993584\ttotal: 58.3s\tremaining: 14.2s\n",
            "9788:\tlearn: 7.6993489\ttotal: 58.3s\tremaining: 14.2s\n",
            "9789:\tlearn: 7.6993440\ttotal: 58.3s\tremaining: 14.2s\n",
            "9790:\tlearn: 7.6993307\ttotal: 58.3s\tremaining: 14.2s\n",
            "9791:\tlearn: 7.6993278\ttotal: 58.3s\tremaining: 14.2s\n",
            "9792:\tlearn: 7.6993212\ttotal: 58.3s\tremaining: 14.2s\n",
            "9793:\tlearn: 7.6993114\ttotal: 58.3s\tremaining: 14.2s\n",
            "9794:\tlearn: 7.6993016\ttotal: 58.3s\tremaining: 14.2s\n",
            "9795:\tlearn: 7.6992831\ttotal: 58.3s\tremaining: 14.2s\n",
            "9796:\tlearn: 7.6992738\ttotal: 58.3s\tremaining: 14.2s\n",
            "9797:\tlearn: 7.6992548\ttotal: 58.3s\tremaining: 14.2s\n",
            "9798:\tlearn: 7.6992496\ttotal: 58.3s\tremaining: 14.2s\n",
            "9799:\tlearn: 7.6992435\ttotal: 58.3s\tremaining: 14.2s\n",
            "9800:\tlearn: 7.6992386\ttotal: 58.3s\tremaining: 14.2s\n",
            "9801:\tlearn: 7.6992288\ttotal: 58.3s\tremaining: 14.2s\n",
            "9802:\tlearn: 7.6992115\ttotal: 58.3s\tremaining: 14.2s\n",
            "9803:\tlearn: 7.6991847\ttotal: 58.4s\tremaining: 14.1s\n",
            "9804:\tlearn: 7.6991645\ttotal: 58.4s\tremaining: 14.1s\n",
            "9805:\tlearn: 7.6991552\ttotal: 58.4s\tremaining: 14.1s\n",
            "9806:\tlearn: 7.6991388\ttotal: 58.4s\tremaining: 14.1s\n",
            "9807:\tlearn: 7.6991157\ttotal: 58.4s\tremaining: 14.1s\n",
            "9808:\tlearn: 7.6990917\ttotal: 58.4s\tremaining: 14.1s\n",
            "9809:\tlearn: 7.6990747\ttotal: 58.4s\tremaining: 14.1s\n",
            "9810:\tlearn: 7.6990652\ttotal: 58.4s\tremaining: 14.1s\n",
            "9811:\tlearn: 7.6990455\ttotal: 58.4s\tremaining: 14.1s\n",
            "9812:\tlearn: 7.6990331\ttotal: 58.4s\tremaining: 14.1s\n",
            "9813:\tlearn: 7.6990207\ttotal: 58.4s\tremaining: 14.1s\n",
            "9814:\tlearn: 7.6990051\ttotal: 58.4s\tremaining: 14.1s\n",
            "9815:\tlearn: 7.6989945\ttotal: 58.4s\tremaining: 14.1s\n",
            "9816:\tlearn: 7.6989835\ttotal: 58.4s\tremaining: 14.1s\n",
            "9817:\tlearn: 7.6989780\ttotal: 58.4s\tremaining: 14.1s\n",
            "9818:\tlearn: 7.6989757\ttotal: 58.4s\tremaining: 14.1s\n",
            "9819:\tlearn: 7.6989699\ttotal: 58.4s\tremaining: 14.1s\n",
            "9820:\tlearn: 7.6989592\ttotal: 58.4s\tremaining: 14s\n",
            "9821:\tlearn: 7.6989422\ttotal: 58.5s\tremaining: 14s\n",
            "9822:\tlearn: 7.6989246\ttotal: 58.5s\tremaining: 14s\n",
            "9823:\tlearn: 7.6989145\ttotal: 58.5s\tremaining: 14s\n",
            "9824:\tlearn: 7.6988986\ttotal: 58.5s\tremaining: 14s\n",
            "9825:\tlearn: 7.6988879\ttotal: 58.5s\tremaining: 14s\n",
            "9826:\tlearn: 7.6988709\ttotal: 58.5s\tremaining: 14s\n",
            "9827:\tlearn: 7.6988623\ttotal: 58.5s\tremaining: 14s\n",
            "9828:\tlearn: 7.6988516\ttotal: 58.5s\tremaining: 14s\n",
            "9829:\tlearn: 7.6988302\ttotal: 58.5s\tremaining: 14s\n",
            "9830:\tlearn: 7.6988204\ttotal: 58.5s\tremaining: 14s\n",
            "9831:\tlearn: 7.6988175\ttotal: 58.5s\tremaining: 14s\n",
            "9832:\tlearn: 7.6988106\ttotal: 58.5s\tremaining: 14s\n",
            "9833:\tlearn: 7.6987973\ttotal: 58.5s\tremaining: 14s\n",
            "9834:\tlearn: 7.6987941\ttotal: 58.5s\tremaining: 14s\n",
            "9835:\tlearn: 7.6987751\ttotal: 58.5s\tremaining: 14s\n",
            "9836:\tlearn: 7.6987647\ttotal: 58.6s\tremaining: 14s\n",
            "9837:\tlearn: 7.6987529\ttotal: 58.6s\tremaining: 13.9s\n",
            "9838:\tlearn: 7.6987387\ttotal: 58.6s\tremaining: 13.9s\n",
            "9839:\tlearn: 7.6987283\ttotal: 58.6s\tremaining: 13.9s\n",
            "9840:\tlearn: 7.6987254\ttotal: 58.6s\tremaining: 13.9s\n",
            "9841:\tlearn: 7.6987153\ttotal: 58.6s\tremaining: 13.9s\n",
            "9842:\tlearn: 7.6986960\ttotal: 58.6s\tremaining: 13.9s\n",
            "9843:\tlearn: 7.6986833\ttotal: 58.6s\tremaining: 13.9s\n",
            "9844:\tlearn: 7.6986628\ttotal: 58.6s\tremaining: 13.9s\n",
            "9845:\tlearn: 7.6986489\ttotal: 58.6s\tremaining: 13.9s\n",
            "9846:\tlearn: 7.6986282\ttotal: 58.6s\tremaining: 13.9s\n",
            "9847:\tlearn: 7.6986157\ttotal: 58.6s\tremaining: 13.9s\n",
            "9848:\tlearn: 7.6985901\ttotal: 58.6s\tremaining: 13.9s\n",
            "9849:\tlearn: 7.6985687\ttotal: 58.6s\tremaining: 13.9s\n",
            "9850:\tlearn: 7.6985537\ttotal: 58.6s\tremaining: 13.9s\n",
            "9851:\tlearn: 7.6985286\ttotal: 58.6s\tremaining: 13.9s\n",
            "9852:\tlearn: 7.6985274\ttotal: 58.7s\tremaining: 13.9s\n",
            "9853:\tlearn: 7.6985150\ttotal: 58.7s\tremaining: 13.9s\n",
            "9854:\tlearn: 7.6985092\ttotal: 58.7s\tremaining: 13.8s\n",
            "9855:\tlearn: 7.6984971\ttotal: 58.7s\tremaining: 13.8s\n",
            "9856:\tlearn: 7.6984962\ttotal: 58.7s\tremaining: 13.8s\n",
            "9857:\tlearn: 7.6984861\ttotal: 58.7s\tremaining: 13.8s\n",
            "9858:\tlearn: 7.6984708\ttotal: 58.7s\tremaining: 13.8s\n",
            "9859:\tlearn: 7.6984636\ttotal: 58.7s\tremaining: 13.8s\n",
            "9860:\tlearn: 7.6984581\ttotal: 58.7s\tremaining: 13.8s\n",
            "9861:\tlearn: 7.6984498\ttotal: 58.7s\tremaining: 13.8s\n",
            "9862:\tlearn: 7.6984457\ttotal: 58.7s\tremaining: 13.8s\n",
            "9863:\tlearn: 7.6984388\ttotal: 58.7s\tremaining: 13.8s\n",
            "9864:\tlearn: 7.6984290\ttotal: 58.7s\tremaining: 13.8s\n",
            "9865:\tlearn: 7.6984198\ttotal: 58.7s\tremaining: 13.8s\n",
            "9866:\tlearn: 7.6984004\ttotal: 58.7s\tremaining: 13.8s\n",
            "9867:\tlearn: 7.6983897\ttotal: 58.7s\tremaining: 13.8s\n",
            "9868:\tlearn: 7.6983773\ttotal: 58.7s\tremaining: 13.8s\n",
            "9869:\tlearn: 7.6983635\ttotal: 58.7s\tremaining: 13.8s\n",
            "9870:\tlearn: 7.6983574\ttotal: 58.7s\tremaining: 13.7s\n",
            "9871:\tlearn: 7.6983317\ttotal: 58.8s\tremaining: 13.7s\n",
            "9872:\tlearn: 7.6983280\ttotal: 58.8s\tremaining: 13.7s\n",
            "9873:\tlearn: 7.6983135\ttotal: 58.8s\tremaining: 13.7s\n",
            "9874:\tlearn: 7.6983017\ttotal: 58.8s\tremaining: 13.7s\n",
            "9875:\tlearn: 7.6982927\ttotal: 58.8s\tremaining: 13.7s\n",
            "9876:\tlearn: 7.6982829\ttotal: 58.8s\tremaining: 13.7s\n",
            "9877:\tlearn: 7.6982619\ttotal: 58.8s\tremaining: 13.7s\n",
            "9878:\tlearn: 7.6982411\ttotal: 58.8s\tremaining: 13.7s\n",
            "9879:\tlearn: 7.6982347\ttotal: 58.8s\tremaining: 13.7s\n",
            "9880:\tlearn: 7.6982174\ttotal: 58.8s\tremaining: 13.7s\n",
            "9881:\tlearn: 7.6982131\ttotal: 58.8s\tremaining: 13.7s\n",
            "9882:\tlearn: 7.6982012\ttotal: 58.8s\tremaining: 13.7s\n",
            "9883:\tlearn: 7.6981914\ttotal: 58.8s\tremaining: 13.7s\n",
            "9884:\tlearn: 7.6981810\ttotal: 58.8s\tremaining: 13.7s\n",
            "9885:\tlearn: 7.6981779\ttotal: 58.8s\tremaining: 13.7s\n",
            "9886:\tlearn: 7.6981651\ttotal: 58.8s\tremaining: 13.7s\n",
            "9887:\tlearn: 7.6981527\ttotal: 58.9s\tremaining: 13.6s\n",
            "9888:\tlearn: 7.6981464\ttotal: 58.9s\tremaining: 13.6s\n",
            "9889:\tlearn: 7.6981389\ttotal: 58.9s\tremaining: 13.6s\n",
            "9890:\tlearn: 7.6981213\ttotal: 58.9s\tremaining: 13.6s\n",
            "9891:\tlearn: 7.6981054\ttotal: 58.9s\tremaining: 13.6s\n",
            "9892:\tlearn: 7.6980964\ttotal: 58.9s\tremaining: 13.6s\n",
            "9893:\tlearn: 7.6980904\ttotal: 58.9s\tremaining: 13.6s\n",
            "9894:\tlearn: 7.6980713\ttotal: 58.9s\tremaining: 13.6s\n",
            "9895:\tlearn: 7.6980641\ttotal: 58.9s\tremaining: 13.6s\n",
            "9896:\tlearn: 7.6980575\ttotal: 58.9s\tremaining: 13.6s\n",
            "9897:\tlearn: 7.6980425\ttotal: 58.9s\tremaining: 13.6s\n",
            "9898:\tlearn: 7.6980326\ttotal: 58.9s\tremaining: 13.6s\n",
            "9899:\tlearn: 7.6980251\ttotal: 58.9s\tremaining: 13.6s\n",
            "9900:\tlearn: 7.6979899\ttotal: 58.9s\tremaining: 13.6s\n",
            "9901:\tlearn: 7.6979842\ttotal: 58.9s\tremaining: 13.6s\n",
            "9902:\tlearn: 7.6979674\ttotal: 58.9s\tremaining: 13.6s\n",
            "9903:\tlearn: 7.6979512\ttotal: 58.9s\tremaining: 13.6s\n",
            "9904:\tlearn: 7.6979466\ttotal: 58.9s\tremaining: 13.5s\n",
            "9905:\tlearn: 7.6979388\ttotal: 59s\tremaining: 13.5s\n",
            "9906:\tlearn: 7.6979322\ttotal: 59s\tremaining: 13.5s\n",
            "9907:\tlearn: 7.6979201\ttotal: 59s\tremaining: 13.5s\n",
            "9908:\tlearn: 7.6979082\ttotal: 59s\tremaining: 13.5s\n",
            "9909:\tlearn: 7.6978970\ttotal: 59s\tremaining: 13.5s\n",
            "9910:\tlearn: 7.6978837\ttotal: 59s\tremaining: 13.5s\n",
            "9911:\tlearn: 7.6978753\ttotal: 59s\tremaining: 13.5s\n",
            "9912:\tlearn: 7.6978609\ttotal: 59s\tremaining: 13.5s\n",
            "9913:\tlearn: 7.6978421\ttotal: 59s\tremaining: 13.5s\n",
            "9914:\tlearn: 7.6978242\ttotal: 59s\tremaining: 13.5s\n",
            "9915:\tlearn: 7.6978112\ttotal: 59s\tremaining: 13.5s\n",
            "9916:\tlearn: 7.6978057\ttotal: 59s\tremaining: 13.5s\n",
            "9917:\tlearn: 7.6977861\ttotal: 59s\tremaining: 13.5s\n",
            "9918:\tlearn: 7.6977760\ttotal: 59s\tremaining: 13.5s\n",
            "9919:\tlearn: 7.6977619\ttotal: 59s\tremaining: 13.5s\n",
            "9920:\tlearn: 7.6977451\ttotal: 59s\tremaining: 13.5s\n",
            "9921:\tlearn: 7.6977356\ttotal: 59.1s\tremaining: 13.4s\n",
            "9922:\tlearn: 7.6977292\ttotal: 59.1s\tremaining: 13.4s\n",
            "9923:\tlearn: 7.6977090\ttotal: 59.1s\tremaining: 13.4s\n",
            "9924:\tlearn: 7.6976958\ttotal: 59.1s\tremaining: 13.4s\n",
            "9925:\tlearn: 7.6976909\ttotal: 59.1s\tremaining: 13.4s\n",
            "9926:\tlearn: 7.6976880\ttotal: 59.1s\tremaining: 13.4s\n",
            "9927:\tlearn: 7.6976756\ttotal: 59.1s\tremaining: 13.4s\n",
            "9928:\tlearn: 7.6976649\ttotal: 59.1s\tremaining: 13.4s\n",
            "9929:\tlearn: 7.6976536\ttotal: 59.1s\tremaining: 13.4s\n",
            "9930:\tlearn: 7.6976496\ttotal: 59.1s\tremaining: 13.4s\n",
            "9931:\tlearn: 7.6976406\ttotal: 59.1s\tremaining: 13.4s\n",
            "9932:\tlearn: 7.6976346\ttotal: 59.1s\tremaining: 13.4s\n",
            "9933:\tlearn: 7.6976296\ttotal: 59.1s\tremaining: 13.4s\n",
            "9934:\tlearn: 7.6976285\ttotal: 59.1s\tremaining: 13.4s\n",
            "9935:\tlearn: 7.6976210\ttotal: 59.1s\tremaining: 13.4s\n",
            "9936:\tlearn: 7.6976120\ttotal: 59.1s\tremaining: 13.4s\n",
            "9937:\tlearn: 7.6976011\ttotal: 59.1s\tremaining: 13.3s\n",
            "9938:\tlearn: 7.6975993\ttotal: 59.1s\tremaining: 13.3s\n",
            "9939:\tlearn: 7.6975973\ttotal: 59.2s\tremaining: 13.3s\n",
            "9940:\tlearn: 7.6975901\ttotal: 59.2s\tremaining: 13.3s\n",
            "9941:\tlearn: 7.6975788\ttotal: 59.2s\tremaining: 13.3s\n",
            "9942:\tlearn: 7.6975653\ttotal: 59.2s\tremaining: 13.3s\n",
            "9943:\tlearn: 7.6975517\ttotal: 59.2s\tremaining: 13.3s\n",
            "9944:\tlearn: 7.6975378\ttotal: 59.2s\tremaining: 13.3s\n",
            "9945:\tlearn: 7.6975225\ttotal: 59.2s\tremaining: 13.3s\n",
            "9946:\tlearn: 7.6975150\ttotal: 59.2s\tremaining: 13.3s\n",
            "9947:\tlearn: 7.6975041\ttotal: 59.2s\tremaining: 13.3s\n",
            "9948:\tlearn: 7.6974862\ttotal: 59.2s\tremaining: 13.3s\n",
            "9949:\tlearn: 7.6974781\ttotal: 59.2s\tremaining: 13.3s\n",
            "9950:\tlearn: 7.6974587\ttotal: 59.2s\tremaining: 13.3s\n",
            "9951:\tlearn: 7.6974443\ttotal: 59.2s\tremaining: 13.3s\n",
            "9952:\tlearn: 7.6974313\ttotal: 59.2s\tremaining: 13.3s\n",
            "9953:\tlearn: 7.6974201\ttotal: 59.2s\tremaining: 13.3s\n",
            "9954:\tlearn: 7.6974160\ttotal: 59.2s\tremaining: 13.2s\n",
            "9955:\tlearn: 7.6974045\ttotal: 59.2s\tremaining: 13.2s\n",
            "9956:\tlearn: 7.6973970\ttotal: 59.3s\tremaining: 13.2s\n",
            "9957:\tlearn: 7.6973805\ttotal: 59.3s\tremaining: 13.2s\n",
            "9958:\tlearn: 7.6973638\ttotal: 59.3s\tremaining: 13.2s\n",
            "9959:\tlearn: 7.6973522\ttotal: 59.3s\tremaining: 13.2s\n",
            "9960:\tlearn: 7.6973499\ttotal: 59.3s\tremaining: 13.2s\n",
            "9961:\tlearn: 7.6973323\ttotal: 59.3s\tremaining: 13.2s\n",
            "9962:\tlearn: 7.6973164\ttotal: 59.3s\tremaining: 13.2s\n",
            "9963:\tlearn: 7.6973028\ttotal: 59.3s\tremaining: 13.2s\n",
            "9964:\tlearn: 7.6972867\ttotal: 59.3s\tremaining: 13.2s\n",
            "9965:\tlearn: 7.6972711\ttotal: 59.3s\tremaining: 13.2s\n",
            "9966:\tlearn: 7.6972627\ttotal: 59.3s\tremaining: 13.2s\n",
            "9967:\tlearn: 7.6972448\ttotal: 59.3s\tremaining: 13.2s\n",
            "9968:\tlearn: 7.6972353\ttotal: 59.3s\tremaining: 13.2s\n",
            "9969:\tlearn: 7.6972292\ttotal: 59.3s\tremaining: 13.2s\n",
            "9970:\tlearn: 7.6972220\ttotal: 59.3s\tremaining: 13.2s\n",
            "9971:\tlearn: 7.6972102\ttotal: 59.3s\tremaining: 13.1s\n",
            "9972:\tlearn: 7.6972041\ttotal: 59.3s\tremaining: 13.1s\n",
            "9973:\tlearn: 7.6971980\ttotal: 59.4s\tremaining: 13.1s\n",
            "9974:\tlearn: 7.6971848\ttotal: 59.4s\tremaining: 13.1s\n",
            "9975:\tlearn: 7.6971793\ttotal: 59.4s\tremaining: 13.1s\n",
            "9976:\tlearn: 7.6971750\ttotal: 59.4s\tremaining: 13.1s\n",
            "9977:\tlearn: 7.6971712\ttotal: 59.4s\tremaining: 13.1s\n",
            "9978:\tlearn: 7.6971588\ttotal: 59.4s\tremaining: 13.1s\n",
            "9979:\tlearn: 7.6971426\ttotal: 59.4s\tremaining: 13.1s\n",
            "9980:\tlearn: 7.6971250\ttotal: 59.4s\tremaining: 13.1s\n",
            "9981:\tlearn: 7.6971132\ttotal: 59.4s\tremaining: 13.1s\n",
            "9982:\tlearn: 7.6970803\ttotal: 59.4s\tremaining: 13.1s\n",
            "9983:\tlearn: 7.6970742\ttotal: 59.4s\tremaining: 13.1s\n",
            "9984:\tlearn: 7.6970638\ttotal: 59.4s\tremaining: 13.1s\n",
            "9985:\tlearn: 7.6970592\ttotal: 59.5s\tremaining: 13.1s\n",
            "9986:\tlearn: 7.6970543\ttotal: 59.5s\tremaining: 13.1s\n",
            "9987:\tlearn: 7.6970499\ttotal: 59.5s\tremaining: 13.1s\n",
            "9988:\tlearn: 7.6970367\ttotal: 59.5s\tremaining: 13.1s\n",
            "9989:\tlearn: 7.6970136\ttotal: 59.5s\tremaining: 13s\n",
            "9990:\tlearn: 7.6970087\ttotal: 59.5s\tremaining: 13s\n",
            "9991:\tlearn: 7.6969957\ttotal: 59.5s\tremaining: 13s\n",
            "9992:\tlearn: 7.6969789\ttotal: 59.5s\tremaining: 13s\n",
            "9993:\tlearn: 7.6969737\ttotal: 59.5s\tremaining: 13s\n",
            "9994:\tlearn: 7.6969636\ttotal: 59.5s\tremaining: 13s\n",
            "9995:\tlearn: 7.6969503\ttotal: 59.5s\tremaining: 13s\n",
            "9996:\tlearn: 7.6969399\ttotal: 59.5s\tremaining: 13s\n",
            "9997:\tlearn: 7.6969290\ttotal: 59.5s\tremaining: 13s\n",
            "9998:\tlearn: 7.6969160\ttotal: 59.5s\tremaining: 13s\n",
            "9999:\tlearn: 7.6969145\ttotal: 59.5s\tremaining: 13s\n",
            "10000:\tlearn: 7.6969108\ttotal: 59.5s\tremaining: 13s\n",
            "10001:\tlearn: 7.6969007\ttotal: 59.6s\tremaining: 13s\n",
            "10002:\tlearn: 7.6968914\ttotal: 59.6s\tremaining: 13s\n",
            "10003:\tlearn: 7.6968796\ttotal: 59.6s\tremaining: 13s\n",
            "10004:\tlearn: 7.6968669\ttotal: 59.6s\tremaining: 13s\n",
            "10005:\tlearn: 7.6968536\ttotal: 59.6s\tremaining: 13s\n",
            "10006:\tlearn: 7.6968458\ttotal: 59.6s\tremaining: 12.9s\n",
            "10007:\tlearn: 7.6968187\ttotal: 59.6s\tremaining: 12.9s\n",
            "10008:\tlearn: 7.6968092\ttotal: 59.6s\tremaining: 12.9s\n",
            "10009:\tlearn: 7.6968045\ttotal: 59.6s\tremaining: 12.9s\n",
            "10010:\tlearn: 7.6967855\ttotal: 59.6s\tremaining: 12.9s\n",
            "10011:\tlearn: 7.6967696\ttotal: 59.6s\tremaining: 12.9s\n",
            "10012:\tlearn: 7.6967517\ttotal: 59.6s\tremaining: 12.9s\n",
            "10013:\tlearn: 7.6967375\ttotal: 59.6s\tremaining: 12.9s\n",
            "10014:\tlearn: 7.6967205\ttotal: 59.6s\tremaining: 12.9s\n",
            "10015:\tlearn: 7.6967139\ttotal: 59.7s\tremaining: 12.9s\n",
            "10016:\tlearn: 7.6967023\ttotal: 59.7s\tremaining: 12.9s\n",
            "10017:\tlearn: 7.6966905\ttotal: 59.7s\tremaining: 12.9s\n",
            "10018:\tlearn: 7.6966824\ttotal: 59.7s\tremaining: 12.9s\n",
            "10019:\tlearn: 7.6966795\ttotal: 59.7s\tremaining: 12.9s\n",
            "10020:\tlearn: 7.6966628\ttotal: 59.7s\tremaining: 12.9s\n",
            "10021:\tlearn: 7.6966478\ttotal: 59.7s\tremaining: 12.9s\n",
            "10022:\tlearn: 7.6966388\ttotal: 59.7s\tremaining: 12.9s\n",
            "10023:\tlearn: 7.6966212\ttotal: 59.7s\tremaining: 12.8s\n",
            "10024:\tlearn: 7.6966050\ttotal: 59.7s\tremaining: 12.8s\n",
            "10025:\tlearn: 7.6965955\ttotal: 59.7s\tremaining: 12.8s\n",
            "10026:\tlearn: 7.6965834\ttotal: 59.7s\tremaining: 12.8s\n",
            "10027:\tlearn: 7.6965620\ttotal: 59.7s\tremaining: 12.8s\n",
            "10028:\tlearn: 7.6965528\ttotal: 59.7s\tremaining: 12.8s\n",
            "10029:\tlearn: 7.6965493\ttotal: 59.7s\tremaining: 12.8s\n",
            "10030:\tlearn: 7.6965320\ttotal: 59.7s\tremaining: 12.8s\n",
            "10031:\tlearn: 7.6965048\ttotal: 59.7s\tremaining: 12.8s\n",
            "10032:\tlearn: 7.6964916\ttotal: 59.8s\tremaining: 12.8s\n",
            "10033:\tlearn: 7.6964708\ttotal: 59.8s\tremaining: 12.8s\n",
            "10034:\tlearn: 7.6964656\ttotal: 59.8s\tremaining: 12.8s\n",
            "10035:\tlearn: 7.6964500\ttotal: 59.8s\tremaining: 12.8s\n",
            "10036:\tlearn: 7.6964344\ttotal: 59.8s\tremaining: 12.8s\n",
            "10037:\tlearn: 7.6964165\ttotal: 59.8s\tremaining: 12.8s\n",
            "10038:\tlearn: 7.6964018\ttotal: 59.8s\tremaining: 12.8s\n",
            "10039:\tlearn: 7.6963882\ttotal: 59.8s\tremaining: 12.8s\n",
            "10040:\tlearn: 7.6963784\ttotal: 59.8s\tremaining: 12.7s\n",
            "10041:\tlearn: 7.6963723\ttotal: 59.8s\tremaining: 12.7s\n",
            "10042:\tlearn: 7.6963651\ttotal: 59.8s\tremaining: 12.7s\n",
            "10043:\tlearn: 7.6963414\ttotal: 59.8s\tremaining: 12.7s\n",
            "10044:\tlearn: 7.6963189\ttotal: 59.8s\tremaining: 12.7s\n",
            "10045:\tlearn: 7.6963114\ttotal: 59.8s\tremaining: 12.7s\n",
            "10046:\tlearn: 7.6962975\ttotal: 59.8s\tremaining: 12.7s\n",
            "10047:\tlearn: 7.6962912\ttotal: 59.9s\tremaining: 12.7s\n",
            "10048:\tlearn: 7.6962684\ttotal: 59.9s\tremaining: 12.7s\n",
            "10049:\tlearn: 7.6962525\ttotal: 59.9s\tremaining: 12.7s\n",
            "10050:\tlearn: 7.6962415\ttotal: 59.9s\tremaining: 12.7s\n",
            "10051:\tlearn: 7.6962320\ttotal: 59.9s\tremaining: 12.7s\n",
            "10052:\tlearn: 7.6962164\ttotal: 59.9s\tremaining: 12.7s\n",
            "10053:\tlearn: 7.6961979\ttotal: 59.9s\tremaining: 12.7s\n",
            "10054:\tlearn: 7.6961832\ttotal: 59.9s\tremaining: 12.7s\n",
            "10055:\tlearn: 7.6961786\ttotal: 59.9s\tremaining: 12.7s\n",
            "10056:\tlearn: 7.6961670\ttotal: 59.9s\tremaining: 12.7s\n",
            "10057:\tlearn: 7.6961503\ttotal: 59.9s\tremaining: 12.6s\n",
            "10058:\tlearn: 7.6961425\ttotal: 59.9s\tremaining: 12.6s\n",
            "10059:\tlearn: 7.6961275\ttotal: 59.9s\tremaining: 12.6s\n",
            "10060:\tlearn: 7.6961147\ttotal: 59.9s\tremaining: 12.6s\n",
            "10061:\tlearn: 7.6961093\ttotal: 59.9s\tremaining: 12.6s\n",
            "10062:\tlearn: 7.6960945\ttotal: 59.9s\tremaining: 12.6s\n",
            "10063:\tlearn: 7.6960815\ttotal: 60s\tremaining: 12.6s\n",
            "10064:\tlearn: 7.6960804\ttotal: 60s\tremaining: 12.6s\n",
            "10065:\tlearn: 7.6960743\ttotal: 60s\tremaining: 12.6s\n",
            "10066:\tlearn: 7.6960634\ttotal: 60s\tremaining: 12.6s\n",
            "10067:\tlearn: 7.6960501\ttotal: 60s\tremaining: 12.6s\n",
            "10068:\tlearn: 7.6960293\ttotal: 60s\tremaining: 12.6s\n",
            "10069:\tlearn: 7.6960186\ttotal: 1m\tremaining: 12.6s\n",
            "10070:\tlearn: 7.6960122\ttotal: 1m\tremaining: 12.6s\n",
            "10071:\tlearn: 7.6960004\ttotal: 1m\tremaining: 12.6s\n",
            "10072:\tlearn: 7.6959871\ttotal: 1m\tremaining: 12.6s\n",
            "10073:\tlearn: 7.6959811\ttotal: 1m\tremaining: 12.6s\n",
            "10074:\tlearn: 7.6959808\ttotal: 1m\tremaining: 12.5s\n",
            "10075:\tlearn: 7.6959761\ttotal: 1m\tremaining: 12.5s\n",
            "10076:\tlearn: 7.6959672\ttotal: 1m\tremaining: 12.5s\n",
            "10077:\tlearn: 7.6959533\ttotal: 1m\tremaining: 12.5s\n",
            "10078:\tlearn: 7.6959412\ttotal: 1m\tremaining: 12.5s\n",
            "10079:\tlearn: 7.6959294\ttotal: 1m\tremaining: 12.5s\n",
            "10080:\tlearn: 7.6959294\ttotal: 1m\tremaining: 12.5s\n",
            "10081:\tlearn: 7.6959161\ttotal: 1m\tremaining: 12.5s\n",
            "10082:\tlearn: 7.6959100\ttotal: 1m\tremaining: 12.5s\n",
            "10083:\tlearn: 7.6959014\ttotal: 1m\tremaining: 12.5s\n",
            "10084:\tlearn: 7.6958887\ttotal: 1m\tremaining: 12.5s\n",
            "10085:\tlearn: 7.6958716\ttotal: 1m\tremaining: 12.5s\n",
            "10086:\tlearn: 7.6958624\ttotal: 1m\tremaining: 12.5s\n",
            "10087:\tlearn: 7.6958503\ttotal: 1m\tremaining: 12.5s\n",
            "10088:\tlearn: 7.6958413\ttotal: 1m\tremaining: 12.5s\n",
            "10089:\tlearn: 7.6958338\ttotal: 1m\tremaining: 12.5s\n",
            "10090:\tlearn: 7.6958277\ttotal: 1m\tremaining: 12.5s\n",
            "10091:\tlearn: 7.6958266\ttotal: 1m\tremaining: 12.4s\n",
            "10092:\tlearn: 7.6958147\ttotal: 1m\tremaining: 12.4s\n",
            "10093:\tlearn: 7.6958098\ttotal: 1m\tremaining: 12.4s\n",
            "10094:\tlearn: 7.6957887\ttotal: 1m\tremaining: 12.4s\n",
            "10095:\tlearn: 7.6957775\ttotal: 1m\tremaining: 12.4s\n",
            "10096:\tlearn: 7.6957737\ttotal: 1m\tremaining: 12.4s\n",
            "10097:\tlearn: 7.6957613\ttotal: 1m\tremaining: 12.4s\n",
            "10098:\tlearn: 7.6957495\ttotal: 1m\tremaining: 12.4s\n",
            "10099:\tlearn: 7.6957423\ttotal: 1m\tremaining: 12.4s\n",
            "10100:\tlearn: 7.6957342\ttotal: 1m\tremaining: 12.4s\n",
            "10101:\tlearn: 7.6957200\ttotal: 1m\tremaining: 12.4s\n",
            "10102:\tlearn: 7.6956963\ttotal: 1m\tremaining: 12.4s\n",
            "10103:\tlearn: 7.6956819\ttotal: 1m\tremaining: 12.4s\n",
            "10104:\tlearn: 7.6956709\ttotal: 1m\tremaining: 12.4s\n",
            "10105:\tlearn: 7.6956623\ttotal: 1m\tremaining: 12.4s\n",
            "10106:\tlearn: 7.6956432\ttotal: 1m\tremaining: 12.4s\n",
            "10107:\tlearn: 7.6956233\ttotal: 1m\tremaining: 12.4s\n",
            "10108:\tlearn: 7.6956161\ttotal: 1m\tremaining: 12.3s\n",
            "10109:\tlearn: 7.6955999\ttotal: 1m\tremaining: 12.3s\n",
            "10110:\tlearn: 7.6955909\ttotal: 1m\tremaining: 12.3s\n",
            "10111:\tlearn: 7.6955780\ttotal: 1m\tremaining: 12.3s\n",
            "10112:\tlearn: 7.6955609\ttotal: 1m\tremaining: 12.3s\n",
            "10113:\tlearn: 7.6955488\ttotal: 1m\tremaining: 12.3s\n",
            "10114:\tlearn: 7.6955335\ttotal: 1m\tremaining: 12.3s\n",
            "10115:\tlearn: 7.6955312\ttotal: 1m\tremaining: 12.3s\n",
            "10116:\tlearn: 7.6955231\ttotal: 1m\tremaining: 12.3s\n",
            "10117:\tlearn: 7.6955058\ttotal: 1m\tremaining: 12.3s\n",
            "10118:\tlearn: 7.6954942\ttotal: 1m\tremaining: 12.3s\n",
            "10119:\tlearn: 7.6954844\ttotal: 1m\tremaining: 12.3s\n",
            "10120:\tlearn: 7.6954803\ttotal: 1m\tremaining: 12.3s\n",
            "10121:\tlearn: 7.6954659\ttotal: 1m\tremaining: 12.3s\n",
            "10122:\tlearn: 7.6954561\ttotal: 1m\tremaining: 12.3s\n",
            "10123:\tlearn: 7.6954532\ttotal: 1m\tremaining: 12.3s\n",
            "10124:\tlearn: 7.6954480\ttotal: 1m\tremaining: 12.3s\n",
            "10125:\tlearn: 7.6954422\ttotal: 1m\tremaining: 12.2s\n",
            "10126:\tlearn: 7.6954313\ttotal: 1m\tremaining: 12.2s\n",
            "10127:\tlearn: 7.6954162\ttotal: 1m\tremaining: 12.2s\n",
            "10128:\tlearn: 7.6954090\ttotal: 1m\tremaining: 12.2s\n",
            "10129:\tlearn: 7.6953931\ttotal: 1m\tremaining: 12.2s\n",
            "10130:\tlearn: 7.6953799\ttotal: 1m\tremaining: 12.2s\n",
            "10131:\tlearn: 7.6953628\ttotal: 1m\tremaining: 12.2s\n",
            "10132:\tlearn: 7.6953553\ttotal: 1m\tremaining: 12.2s\n",
            "10133:\tlearn: 7.6953383\ttotal: 1m\tremaining: 12.2s\n",
            "10134:\tlearn: 7.6953348\ttotal: 1m\tremaining: 12.2s\n",
            "10135:\tlearn: 7.6953241\ttotal: 1m\tremaining: 12.2s\n",
            "10136:\tlearn: 7.6953192\ttotal: 1m\tremaining: 12.2s\n",
            "10137:\tlearn: 7.6953048\ttotal: 1m\tremaining: 12.2s\n",
            "10138:\tlearn: 7.6952955\ttotal: 1m\tremaining: 12.2s\n",
            "10139:\tlearn: 7.6952898\ttotal: 1m\tremaining: 12.2s\n",
            "10140:\tlearn: 7.6952649\ttotal: 1m\tremaining: 12.2s\n",
            "10141:\tlearn: 7.6952539\ttotal: 1m\tremaining: 12.2s\n",
            "10142:\tlearn: 7.6952421\ttotal: 1m\tremaining: 12.1s\n",
            "10143:\tlearn: 7.6952369\ttotal: 1m\tremaining: 12.1s\n",
            "10144:\tlearn: 7.6952262\ttotal: 1m\tremaining: 12.1s\n",
            "10145:\tlearn: 7.6952170\ttotal: 1m\tremaining: 12.1s\n",
            "10146:\tlearn: 7.6952129\ttotal: 1m\tremaining: 12.1s\n",
            "10147:\tlearn: 7.6952069\ttotal: 1m\tremaining: 12.1s\n",
            "10148:\tlearn: 7.6951933\ttotal: 1m\tremaining: 12.1s\n",
            "10149:\tlearn: 7.6951875\ttotal: 1m\tremaining: 12.1s\n",
            "10150:\tlearn: 7.6951786\ttotal: 1m\tremaining: 12.1s\n",
            "10151:\tlearn: 7.6951722\ttotal: 1m\tremaining: 12.1s\n",
            "10152:\tlearn: 7.6951667\ttotal: 1m\tremaining: 12.1s\n",
            "10153:\tlearn: 7.6951572\ttotal: 1m\tremaining: 12.1s\n",
            "10154:\tlearn: 7.6951448\ttotal: 1m\tremaining: 12.1s\n",
            "10155:\tlearn: 7.6951298\ttotal: 1m\tremaining: 12.1s\n",
            "10156:\tlearn: 7.6951257\ttotal: 1m\tremaining: 12.1s\n",
            "10157:\tlearn: 7.6951052\ttotal: 1m\tremaining: 12.1s\n",
            "10158:\tlearn: 7.6950865\ttotal: 1m\tremaining: 12.1s\n",
            "10159:\tlearn: 7.6950801\ttotal: 1m\tremaining: 12s\n",
            "10160:\tlearn: 7.6950703\ttotal: 1m\tremaining: 12s\n",
            "10161:\tlearn: 7.6950518\ttotal: 1m\tremaining: 12s\n",
            "10162:\tlearn: 7.6950420\ttotal: 1m\tremaining: 12s\n",
            "10163:\tlearn: 7.6950275\ttotal: 1m\tremaining: 12s\n",
            "10164:\tlearn: 7.6950183\ttotal: 1m\tremaining: 12s\n",
            "10165:\tlearn: 7.6950056\ttotal: 1m\tremaining: 12s\n",
            "10166:\tlearn: 7.6949935\ttotal: 1m\tremaining: 12s\n",
            "10167:\tlearn: 7.6949891\ttotal: 1m\tremaining: 12s\n",
            "10168:\tlearn: 7.6949764\ttotal: 1m\tremaining: 12s\n",
            "10169:\tlearn: 7.6949608\ttotal: 1m\tremaining: 12s\n",
            "10170:\tlearn: 7.6949435\ttotal: 1m\tremaining: 12s\n",
            "10171:\tlearn: 7.6949294\ttotal: 1m\tremaining: 12s\n",
            "10172:\tlearn: 7.6949143\ttotal: 1m\tremaining: 12s\n",
            "10173:\tlearn: 7.6949086\ttotal: 1m\tremaining: 12s\n",
            "10174:\tlearn: 7.6948938\ttotal: 1m\tremaining: 12s\n",
            "10175:\tlearn: 7.6948780\ttotal: 1m\tremaining: 11.9s\n",
            "10176:\tlearn: 7.6948690\ttotal: 1m\tremaining: 11.9s\n",
            "10177:\tlearn: 7.6948626\ttotal: 1m\tremaining: 11.9s\n",
            "10178:\tlearn: 7.6948511\ttotal: 1m\tremaining: 11.9s\n",
            "10179:\tlearn: 7.6948393\ttotal: 1m\tremaining: 11.9s\n",
            "10180:\tlearn: 7.6948216\ttotal: 1m\tremaining: 11.9s\n",
            "10181:\tlearn: 7.6948153\ttotal: 1m\tremaining: 11.9s\n",
            "10182:\tlearn: 7.6947985\ttotal: 1m\tremaining: 11.9s\n",
            "10183:\tlearn: 7.6947835\ttotal: 1m\tremaining: 11.9s\n",
            "10184:\tlearn: 7.6947627\ttotal: 1m\tremaining: 11.9s\n",
            "10185:\tlearn: 7.6947595\ttotal: 1m\tremaining: 11.9s\n",
            "10186:\tlearn: 7.6947491\ttotal: 1m\tremaining: 11.9s\n",
            "10187:\tlearn: 7.6947362\ttotal: 1m\tremaining: 11.9s\n",
            "10188:\tlearn: 7.6947321\ttotal: 1m\tremaining: 11.9s\n",
            "10189:\tlearn: 7.6947243\ttotal: 1m\tremaining: 11.9s\n",
            "10190:\tlearn: 7.6947177\ttotal: 1m\tremaining: 11.9s\n",
            "10191:\tlearn: 7.6947070\ttotal: 1m\tremaining: 11.9s\n",
            "10192:\tlearn: 7.6946928\ttotal: 1m\tremaining: 11.8s\n",
            "10193:\tlearn: 7.6946920\ttotal: 1m\tremaining: 11.8s\n",
            "10194:\tlearn: 7.6946830\ttotal: 1m\tremaining: 11.8s\n",
            "10195:\tlearn: 7.6946717\ttotal: 1m\tremaining: 11.8s\n",
            "10196:\tlearn: 7.6946654\ttotal: 1m\tremaining: 11.8s\n",
            "10197:\tlearn: 7.6946564\ttotal: 1m\tremaining: 11.8s\n",
            "10198:\tlearn: 7.6946481\ttotal: 1m\tremaining: 11.8s\n",
            "10199:\tlearn: 7.6946279\ttotal: 1m\tremaining: 11.8s\n",
            "10200:\tlearn: 7.6946151\ttotal: 1m\tremaining: 11.8s\n",
            "10201:\tlearn: 7.6946068\ttotal: 1m\tremaining: 11.8s\n",
            "10202:\tlearn: 7.6945909\ttotal: 1m\tremaining: 11.8s\n",
            "10203:\tlearn: 7.6945868\ttotal: 1m\tremaining: 11.8s\n",
            "10204:\tlearn: 7.6945707\ttotal: 1m\tremaining: 11.8s\n",
            "10205:\tlearn: 7.6945655\ttotal: 1m\tremaining: 11.8s\n",
            "10206:\tlearn: 7.6945519\ttotal: 1m\tremaining: 11.8s\n",
            "10207:\tlearn: 7.6945438\ttotal: 1m\tremaining: 11.8s\n",
            "10208:\tlearn: 7.6945409\ttotal: 1m\tremaining: 11.8s\n",
            "10209:\tlearn: 7.6945201\ttotal: 1m\tremaining: 11.7s\n",
            "10210:\tlearn: 7.6945190\ttotal: 1m\tremaining: 11.7s\n",
            "10211:\tlearn: 7.6945120\ttotal: 1m\tremaining: 11.7s\n",
            "10212:\tlearn: 7.6944982\ttotal: 1m\tremaining: 11.7s\n",
            "10213:\tlearn: 7.6944898\ttotal: 1m\tremaining: 11.7s\n",
            "10214:\tlearn: 7.6944849\ttotal: 1m\tremaining: 11.7s\n",
            "10215:\tlearn: 7.6944733\ttotal: 1m\tremaining: 11.7s\n",
            "10216:\tlearn: 7.6944603\ttotal: 1m\tremaining: 11.7s\n",
            "10217:\tlearn: 7.6944549\ttotal: 1m\tremaining: 11.7s\n",
            "10218:\tlearn: 7.6944505\ttotal: 1m\tremaining: 11.7s\n",
            "10219:\tlearn: 7.6944473\ttotal: 1m\tremaining: 11.7s\n",
            "10220:\tlearn: 7.6944393\ttotal: 1m\tremaining: 11.7s\n",
            "10221:\tlearn: 7.6944341\ttotal: 1m\tremaining: 11.7s\n",
            "10222:\tlearn: 7.6944263\ttotal: 1m\tremaining: 11.7s\n",
            "10223:\tlearn: 7.6944069\ttotal: 1m\tremaining: 11.7s\n",
            "10224:\tlearn: 7.6943991\ttotal: 1m\tremaining: 11.7s\n",
            "10225:\tlearn: 7.6943884\ttotal: 1m\tremaining: 11.6s\n",
            "10226:\tlearn: 7.6943697\ttotal: 1m\tremaining: 11.6s\n",
            "10227:\tlearn: 7.6943598\ttotal: 1m\tremaining: 11.6s\n",
            "10228:\tlearn: 7.6943451\ttotal: 1m\tremaining: 11.6s\n",
            "10229:\tlearn: 7.6943356\ttotal: 1m\tremaining: 11.6s\n",
            "10230:\tlearn: 7.6943214\ttotal: 1m\tremaining: 11.6s\n",
            "10231:\tlearn: 7.6943110\ttotal: 1m\tremaining: 11.6s\n",
            "10232:\tlearn: 7.6942998\ttotal: 1m\tremaining: 11.6s\n",
            "10233:\tlearn: 7.6942946\ttotal: 1m\tremaining: 11.6s\n",
            "10234:\tlearn: 7.6942836\ttotal: 1m\tremaining: 11.6s\n",
            "10235:\tlearn: 7.6942677\ttotal: 1m\tremaining: 11.6s\n",
            "10236:\tlearn: 7.6942599\ttotal: 1m\tremaining: 11.6s\n",
            "10237:\tlearn: 7.6942437\ttotal: 1m\tremaining: 11.6s\n",
            "10238:\tlearn: 7.6942382\ttotal: 1m\tremaining: 11.6s\n",
            "10239:\tlearn: 7.6942336\ttotal: 1m\tremaining: 11.6s\n",
            "10240:\tlearn: 7.6942198\ttotal: 1m 1s\tremaining: 11.6s\n",
            "10241:\tlearn: 7.6942068\ttotal: 1m 1s\tremaining: 11.6s\n",
            "10242:\tlearn: 7.6942030\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10243:\tlearn: 7.6941955\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10244:\tlearn: 7.6941811\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10245:\tlearn: 7.6941692\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10246:\tlearn: 7.6941568\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10247:\tlearn: 7.6941447\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10248:\tlearn: 7.6941285\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10249:\tlearn: 7.6941129\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10250:\tlearn: 7.6940987\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10251:\tlearn: 7.6940930\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10252:\tlearn: 7.6940803\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10253:\tlearn: 7.6940699\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10254:\tlearn: 7.6940621\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10255:\tlearn: 7.6940470\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10256:\tlearn: 7.6940329\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10257:\tlearn: 7.6940170\ttotal: 1m 1s\tremaining: 11.5s\n",
            "10258:\tlearn: 7.6940101\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10259:\tlearn: 7.6940057\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10260:\tlearn: 7.6939962\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10261:\tlearn: 7.6939876\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10262:\tlearn: 7.6939803\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10263:\tlearn: 7.6939670\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10264:\tlearn: 7.6939621\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10265:\tlearn: 7.6939590\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10266:\tlearn: 7.6939529\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10267:\tlearn: 7.6939289\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10268:\tlearn: 7.6939188\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10269:\tlearn: 7.6939122\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10270:\tlearn: 7.6939116\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10271:\tlearn: 7.6939018\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10272:\tlearn: 7.6938908\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10273:\tlearn: 7.6938787\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10274:\tlearn: 7.6938758\ttotal: 1m 1s\tremaining: 11.4s\n",
            "10275:\tlearn: 7.6938743\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10276:\tlearn: 7.6938596\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10277:\tlearn: 7.6938376\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10278:\tlearn: 7.6938278\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10279:\tlearn: 7.6938140\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10280:\tlearn: 7.6938050\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10281:\tlearn: 7.6937937\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10282:\tlearn: 7.6937807\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10283:\tlearn: 7.6937724\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10284:\tlearn: 7.6937594\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10285:\tlearn: 7.6937507\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10286:\tlearn: 7.6937435\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10287:\tlearn: 7.6937293\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10288:\tlearn: 7.6937189\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10289:\tlearn: 7.6937106\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10290:\tlearn: 7.6937016\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10291:\tlearn: 7.6936912\ttotal: 1m 1s\tremaining: 11.3s\n",
            "10292:\tlearn: 7.6936880\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10293:\tlearn: 7.6936768\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10294:\tlearn: 7.6936574\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10295:\tlearn: 7.6936525\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10296:\tlearn: 7.6936433\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10297:\tlearn: 7.6936355\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10298:\tlearn: 7.6936204\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10299:\tlearn: 7.6936141\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10300:\tlearn: 7.6935996\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10301:\tlearn: 7.6935947\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10302:\tlearn: 7.6935864\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10303:\tlearn: 7.6935760\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10304:\tlearn: 7.6935650\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10305:\tlearn: 7.6935540\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10306:\tlearn: 7.6935297\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10307:\tlearn: 7.6935225\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10308:\tlearn: 7.6935029\ttotal: 1m 1s\tremaining: 11.2s\n",
            "10309:\tlearn: 7.6934957\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10310:\tlearn: 7.6934905\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10311:\tlearn: 7.6934830\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10312:\tlearn: 7.6934642\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10313:\tlearn: 7.6934489\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10314:\tlearn: 7.6934382\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10315:\tlearn: 7.6934252\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10316:\tlearn: 7.6934226\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10317:\tlearn: 7.6934113\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10318:\tlearn: 7.6933943\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10319:\tlearn: 7.6933842\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10320:\tlearn: 7.6933599\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10321:\tlearn: 7.6933408\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10322:\tlearn: 7.6933339\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10323:\tlearn: 7.6933226\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10324:\tlearn: 7.6933111\ttotal: 1m 1s\tremaining: 11.1s\n",
            "10325:\tlearn: 7.6932958\ttotal: 1m 1s\tremaining: 11s\n",
            "10326:\tlearn: 7.6932871\ttotal: 1m 1s\tremaining: 11s\n",
            "10327:\tlearn: 7.6932808\ttotal: 1m 1s\tremaining: 11s\n",
            "10328:\tlearn: 7.6932672\ttotal: 1m 1s\tremaining: 11s\n",
            "10329:\tlearn: 7.6932588\ttotal: 1m 1s\tremaining: 11s\n",
            "10330:\tlearn: 7.6932418\ttotal: 1m 1s\tremaining: 11s\n",
            "10331:\tlearn: 7.6932334\ttotal: 1m 1s\tremaining: 11s\n",
            "10332:\tlearn: 7.6932256\ttotal: 1m 1s\tremaining: 11s\n",
            "10333:\tlearn: 7.6932039\ttotal: 1m 1s\tremaining: 11s\n",
            "10334:\tlearn: 7.6932013\ttotal: 1m 1s\tremaining: 11s\n",
            "10335:\tlearn: 7.6931883\ttotal: 1m 1s\tremaining: 11s\n",
            "10336:\tlearn: 7.6931765\ttotal: 1m 1s\tremaining: 11s\n",
            "10337:\tlearn: 7.6931623\ttotal: 1m 1s\tremaining: 11s\n",
            "10338:\tlearn: 7.6931488\ttotal: 1m 1s\tremaining: 11s\n",
            "10339:\tlearn: 7.6931415\ttotal: 1m 1s\tremaining: 11s\n",
            "10340:\tlearn: 7.6931291\ttotal: 1m 1s\tremaining: 11s\n",
            "10341:\tlearn: 7.6931210\ttotal: 1m 1s\tremaining: 11s\n",
            "10342:\tlearn: 7.6931164\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10343:\tlearn: 7.6931086\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10344:\tlearn: 7.6930956\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10345:\tlearn: 7.6930809\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10346:\tlearn: 7.6930763\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10347:\tlearn: 7.6930656\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10348:\tlearn: 7.6930612\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10349:\tlearn: 7.6930529\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10350:\tlearn: 7.6930378\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10351:\tlearn: 7.6930271\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10352:\tlearn: 7.6930159\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10353:\tlearn: 7.6930040\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10354:\tlearn: 7.6929844\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10355:\tlearn: 7.6929717\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10356:\tlearn: 7.6929596\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10357:\tlearn: 7.6929321\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10358:\tlearn: 7.6929243\ttotal: 1m 1s\tremaining: 10.9s\n",
            "10359:\tlearn: 7.6929018\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10360:\tlearn: 7.6928899\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10361:\tlearn: 7.6928839\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10362:\tlearn: 7.6928645\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10363:\tlearn: 7.6928596\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10364:\tlearn: 7.6928521\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10365:\tlearn: 7.6928385\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10366:\tlearn: 7.6928287\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10367:\tlearn: 7.6928264\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10368:\tlearn: 7.6928093\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10369:\tlearn: 7.6928027\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10370:\tlearn: 7.6927799\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10371:\tlearn: 7.6927761\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10372:\tlearn: 7.6927718\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10373:\tlearn: 7.6927594\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10374:\tlearn: 7.6927495\ttotal: 1m 1s\tremaining: 10.8s\n",
            "10375:\tlearn: 7.6927374\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10376:\tlearn: 7.6927253\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10377:\tlearn: 7.6927117\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10378:\tlearn: 7.6927042\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10379:\tlearn: 7.6926929\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10380:\tlearn: 7.6926825\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10381:\tlearn: 7.6926767\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10382:\tlearn: 7.6926707\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10383:\tlearn: 7.6926551\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10384:\tlearn: 7.6926533\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10385:\tlearn: 7.6926375\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10386:\tlearn: 7.6926288\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10387:\tlearn: 7.6926170\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10388:\tlearn: 7.6926083\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10389:\tlearn: 7.6925947\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10390:\tlearn: 7.6925725\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10391:\tlearn: 7.6925598\ttotal: 1m 1s\tremaining: 10.7s\n",
            "10392:\tlearn: 7.6925416\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10393:\tlearn: 7.6925366\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10394:\tlearn: 7.6925343\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10395:\tlearn: 7.6925231\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10396:\tlearn: 7.6925092\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10397:\tlearn: 7.6924901\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10398:\tlearn: 7.6924650\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10399:\tlearn: 7.6924558\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10400:\tlearn: 7.6924491\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10401:\tlearn: 7.6924410\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10402:\tlearn: 7.6924277\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10403:\tlearn: 7.6924182\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10404:\tlearn: 7.6924069\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10405:\tlearn: 7.6923936\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10406:\tlearn: 7.6923700\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10407:\tlearn: 7.6923610\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10408:\tlearn: 7.6923492\ttotal: 1m 1s\tremaining: 10.6s\n",
            "10409:\tlearn: 7.6923373\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10410:\tlearn: 7.6923191\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10411:\tlearn: 7.6923122\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10412:\tlearn: 7.6923015\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10413:\tlearn: 7.6922891\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10414:\tlearn: 7.6922827\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10415:\tlearn: 7.6922694\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10416:\tlearn: 7.6922570\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10417:\tlearn: 7.6922460\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10418:\tlearn: 7.6922348\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10419:\tlearn: 7.6922154\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10420:\tlearn: 7.6921958\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10421:\tlearn: 7.6921859\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10422:\tlearn: 7.6921648\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10423:\tlearn: 7.6921464\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10424:\tlearn: 7.6921412\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10425:\tlearn: 7.6921319\ttotal: 1m 2s\tremaining: 10.5s\n",
            "10426:\tlearn: 7.6921183\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10427:\tlearn: 7.6921088\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10428:\tlearn: 7.6920889\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10429:\tlearn: 7.6920759\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10430:\tlearn: 7.6920646\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10431:\tlearn: 7.6920426\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10432:\tlearn: 7.6920363\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10433:\tlearn: 7.6920294\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10434:\tlearn: 7.6920239\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10435:\tlearn: 7.6920129\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10436:\tlearn: 7.6920010\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10437:\tlearn: 7.6919976\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10438:\tlearn: 7.6919880\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10439:\tlearn: 7.6919753\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10440:\tlearn: 7.6919632\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10441:\tlearn: 7.6919537\ttotal: 1m 2s\tremaining: 10.4s\n",
            "10442:\tlearn: 7.6919424\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10443:\tlearn: 7.6919369\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10444:\tlearn: 7.6919308\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10445:\tlearn: 7.6919207\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10446:\tlearn: 7.6918976\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10447:\tlearn: 7.6918861\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10448:\tlearn: 7.6918797\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10449:\tlearn: 7.6918739\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10450:\tlearn: 7.6918684\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10451:\tlearn: 7.6918601\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10452:\tlearn: 7.6918436\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10453:\tlearn: 7.6918346\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10454:\tlearn: 7.6918306\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10455:\tlearn: 7.6918161\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10456:\tlearn: 7.6918086\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10457:\tlearn: 7.6918026\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10458:\tlearn: 7.6917942\ttotal: 1m 2s\tremaining: 10.3s\n",
            "10459:\tlearn: 7.6917832\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10460:\tlearn: 7.6917708\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10461:\tlearn: 7.6917682\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10462:\tlearn: 7.6917641\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10463:\tlearn: 7.6917578\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10464:\tlearn: 7.6917514\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10465:\tlearn: 7.6917373\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10466:\tlearn: 7.6917225\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10467:\tlearn: 7.6917101\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10468:\tlearn: 7.6916890\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10469:\tlearn: 7.6916783\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10470:\tlearn: 7.6916656\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10471:\tlearn: 7.6916544\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10472:\tlearn: 7.6916393\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10473:\tlearn: 7.6916390\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10474:\tlearn: 7.6916312\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10475:\tlearn: 7.6916231\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10476:\tlearn: 7.6916130\ttotal: 1m 2s\tremaining: 10.2s\n",
            "10477:\tlearn: 7.6916015\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10478:\tlearn: 7.6915873\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10479:\tlearn: 7.6915711\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10480:\tlearn: 7.6915605\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10481:\tlearn: 7.6915457\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10482:\tlearn: 7.6915310\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10483:\tlearn: 7.6915180\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10484:\tlearn: 7.6915024\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10485:\tlearn: 7.6914954\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10486:\tlearn: 7.6914859\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10487:\tlearn: 7.6914798\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10488:\tlearn: 7.6914605\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10489:\tlearn: 7.6914403\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10490:\tlearn: 7.6914304\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10491:\tlearn: 7.6914218\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10492:\tlearn: 7.6914143\ttotal: 1m 2s\tremaining: 10.1s\n",
            "10493:\tlearn: 7.6914041\ttotal: 1m 2s\tremaining: 10s\n",
            "10494:\tlearn: 7.6913946\ttotal: 1m 2s\tremaining: 10s\n",
            "10495:\tlearn: 7.6913859\ttotal: 1m 2s\tremaining: 10s\n",
            "10496:\tlearn: 7.6913779\ttotal: 1m 2s\tremaining: 10s\n",
            "10497:\tlearn: 7.6913677\ttotal: 1m 2s\tremaining: 10s\n",
            "10498:\tlearn: 7.6913542\ttotal: 1m 2s\tremaining: 10s\n",
            "10499:\tlearn: 7.6913472\ttotal: 1m 2s\tremaining: 10s\n",
            "10500:\tlearn: 7.6913357\ttotal: 1m 2s\tremaining: 10s\n",
            "10501:\tlearn: 7.6913241\ttotal: 1m 2s\tremaining: 10s\n",
            "10502:\tlearn: 7.6913085\ttotal: 1m 2s\tremaining: 9.99s\n",
            "10503:\tlearn: 7.6913045\ttotal: 1m 2s\tremaining: 9.99s\n",
            "10504:\tlearn: 7.6912929\ttotal: 1m 2s\tremaining: 9.98s\n",
            "10505:\tlearn: 7.6912744\ttotal: 1m 2s\tremaining: 9.98s\n",
            "10506:\tlearn: 7.6912568\ttotal: 1m 2s\tremaining: 9.97s\n",
            "10507:\tlearn: 7.6912461\ttotal: 1m 2s\tremaining: 9.96s\n",
            "10508:\tlearn: 7.6912371\ttotal: 1m 2s\tremaining: 9.96s\n",
            "10509:\tlearn: 7.6912319\ttotal: 1m 2s\tremaining: 9.95s\n",
            "10510:\tlearn: 7.6912285\ttotal: 1m 2s\tremaining: 9.95s\n",
            "10511:\tlearn: 7.6912111\ttotal: 1m 2s\tremaining: 9.94s\n",
            "10512:\tlearn: 7.6911929\ttotal: 1m 2s\tremaining: 9.94s\n",
            "10513:\tlearn: 7.6911840\ttotal: 1m 2s\tremaining: 9.93s\n",
            "10514:\tlearn: 7.6911678\ttotal: 1m 2s\tremaining: 9.93s\n",
            "10515:\tlearn: 7.6911539\ttotal: 1m 2s\tremaining: 9.92s\n",
            "10516:\tlearn: 7.6911508\ttotal: 1m 2s\tremaining: 9.91s\n",
            "10517:\tlearn: 7.6911421\ttotal: 1m 2s\tremaining: 9.91s\n",
            "10518:\tlearn: 7.6911343\ttotal: 1m 2s\tremaining: 9.9s\n",
            "10519:\tlearn: 7.6911222\ttotal: 1m 2s\tremaining: 9.89s\n",
            "10520:\tlearn: 7.6911190\ttotal: 1m 2s\tremaining: 9.89s\n",
            "10521:\tlearn: 7.6911109\ttotal: 1m 2s\tremaining: 9.88s\n",
            "10522:\tlearn: 7.6911022\ttotal: 1m 2s\tremaining: 9.88s\n",
            "10523:\tlearn: 7.6910875\ttotal: 1m 2s\tremaining: 9.87s\n",
            "10524:\tlearn: 7.6910710\ttotal: 1m 2s\tremaining: 9.86s\n",
            "10525:\tlearn: 7.6910592\ttotal: 1m 2s\tremaining: 9.86s\n",
            "10526:\tlearn: 7.6910511\ttotal: 1m 2s\tremaining: 9.85s\n",
            "10527:\tlearn: 7.6910485\ttotal: 1m 2s\tremaining: 9.85s\n",
            "10528:\tlearn: 7.6910349\ttotal: 1m 2s\tremaining: 9.84s\n",
            "10529:\tlearn: 7.6910225\ttotal: 1m 2s\tremaining: 9.83s\n",
            "10530:\tlearn: 7.6910170\ttotal: 1m 2s\tremaining: 9.83s\n",
            "10531:\tlearn: 7.6909999\ttotal: 1m 2s\tremaining: 9.82s\n",
            "10532:\tlearn: 7.6909930\ttotal: 1m 2s\tremaining: 9.82s\n",
            "10533:\tlearn: 7.6909768\ttotal: 1m 2s\tremaining: 9.81s\n",
            "10534:\tlearn: 7.6909632\ttotal: 1m 2s\tremaining: 9.8s\n",
            "10535:\tlearn: 7.6909482\ttotal: 1m 2s\tremaining: 9.8s\n",
            "10536:\tlearn: 7.6909427\ttotal: 1m 2s\tremaining: 9.79s\n",
            "10537:\tlearn: 7.6909341\ttotal: 1m 2s\tremaining: 9.79s\n",
            "10538:\tlearn: 7.6909286\ttotal: 1m 2s\tremaining: 9.78s\n",
            "10539:\tlearn: 7.6909118\ttotal: 1m 2s\tremaining: 9.77s\n",
            "10540:\tlearn: 7.6909005\ttotal: 1m 2s\tremaining: 9.77s\n",
            "10541:\tlearn: 7.6908872\ttotal: 1m 2s\tremaining: 9.76s\n",
            "10542:\tlearn: 7.6908777\ttotal: 1m 2s\tremaining: 9.76s\n",
            "10543:\tlearn: 7.6908673\ttotal: 1m 2s\tremaining: 9.75s\n",
            "10544:\tlearn: 7.6908543\ttotal: 1m 2s\tremaining: 9.74s\n",
            "10545:\tlearn: 7.6908419\ttotal: 1m 2s\tremaining: 9.74s\n",
            "10546:\tlearn: 7.6908263\ttotal: 1m 2s\tremaining: 9.73s\n",
            "10547:\tlearn: 7.6908144\ttotal: 1m 2s\tremaining: 9.73s\n",
            "10548:\tlearn: 7.6908092\ttotal: 1m 2s\tremaining: 9.72s\n",
            "10549:\tlearn: 7.6907945\ttotal: 1m 2s\tremaining: 9.71s\n",
            "10550:\tlearn: 7.6907870\ttotal: 1m 2s\tremaining: 9.71s\n",
            "10551:\tlearn: 7.6907824\ttotal: 1m 2s\tremaining: 9.7s\n",
            "10552:\tlearn: 7.6907728\ttotal: 1m 2s\tremaining: 9.7s\n",
            "10553:\tlearn: 7.6907644\ttotal: 1m 2s\tremaining: 9.69s\n",
            "10554:\tlearn: 7.6907457\ttotal: 1m 2s\tremaining: 9.69s\n",
            "10555:\tlearn: 7.6907266\ttotal: 1m 2s\tremaining: 9.68s\n",
            "10556:\tlearn: 7.6907202\ttotal: 1m 2s\tremaining: 9.67s\n",
            "10557:\tlearn: 7.6907136\ttotal: 1m 2s\tremaining: 9.67s\n",
            "10558:\tlearn: 7.6906937\ttotal: 1m 2s\tremaining: 9.66s\n",
            "10559:\tlearn: 7.6906807\ttotal: 1m 2s\tremaining: 9.65s\n",
            "10560:\tlearn: 7.6906769\ttotal: 1m 2s\tremaining: 9.65s\n",
            "10561:\tlearn: 7.6906642\ttotal: 1m 2s\tremaining: 9.64s\n",
            "10562:\tlearn: 7.6906555\ttotal: 1m 2s\tremaining: 9.64s\n",
            "10563:\tlearn: 7.6906388\ttotal: 1m 2s\tremaining: 9.63s\n",
            "10564:\tlearn: 7.6906133\ttotal: 1m 2s\tremaining: 9.63s\n",
            "10565:\tlearn: 7.6905931\ttotal: 1m 2s\tremaining: 9.62s\n",
            "10566:\tlearn: 7.6905752\ttotal: 1m 2s\tremaining: 9.61s\n",
            "10567:\tlearn: 7.6905694\ttotal: 1m 2s\tremaining: 9.61s\n",
            "10568:\tlearn: 7.6905570\ttotal: 1m 2s\tremaining: 9.6s\n",
            "10569:\tlearn: 7.6905460\ttotal: 1m 2s\tremaining: 9.6s\n",
            "10570:\tlearn: 7.6905336\ttotal: 1m 2s\tremaining: 9.59s\n",
            "10571:\tlearn: 7.6905197\ttotal: 1m 2s\tremaining: 9.58s\n",
            "10572:\tlearn: 7.6905099\ttotal: 1m 2s\tremaining: 9.58s\n",
            "10573:\tlearn: 7.6904951\ttotal: 1m 2s\tremaining: 9.57s\n",
            "10574:\tlearn: 7.6904847\ttotal: 1m 2s\tremaining: 9.56s\n",
            "10575:\tlearn: 7.6904743\ttotal: 1m 2s\tremaining: 9.56s\n",
            "10576:\tlearn: 7.6904654\ttotal: 1m 2s\tremaining: 9.55s\n",
            "10577:\tlearn: 7.6904556\ttotal: 1m 3s\tremaining: 9.55s\n",
            "10578:\tlearn: 7.6904509\ttotal: 1m 3s\tremaining: 9.54s\n",
            "10579:\tlearn: 7.6904371\ttotal: 1m 3s\tremaining: 9.54s\n",
            "10580:\tlearn: 7.6904243\ttotal: 1m 3s\tremaining: 9.53s\n",
            "10581:\tlearn: 7.6904217\ttotal: 1m 3s\tremaining: 9.52s\n",
            "10582:\tlearn: 7.6904038\ttotal: 1m 3s\tremaining: 9.52s\n",
            "10583:\tlearn: 7.6903978\ttotal: 1m 3s\tremaining: 9.51s\n",
            "10584:\tlearn: 7.6903963\ttotal: 1m 3s\tremaining: 9.51s\n",
            "10585:\tlearn: 7.6903874\ttotal: 1m 3s\tremaining: 9.5s\n",
            "10586:\tlearn: 7.6903819\ttotal: 1m 3s\tremaining: 9.49s\n",
            "10587:\tlearn: 7.6903752\ttotal: 1m 3s\tremaining: 9.49s\n",
            "10588:\tlearn: 7.6903654\ttotal: 1m 3s\tremaining: 9.48s\n",
            "10589:\tlearn: 7.6903463\ttotal: 1m 3s\tremaining: 9.48s\n",
            "10590:\tlearn: 7.6903391\ttotal: 1m 3s\tremaining: 9.47s\n",
            "10591:\tlearn: 7.6903281\ttotal: 1m 3s\tremaining: 9.46s\n",
            "10592:\tlearn: 7.6903241\ttotal: 1m 3s\tremaining: 9.46s\n",
            "10593:\tlearn: 7.6903111\ttotal: 1m 3s\tremaining: 9.45s\n",
            "10594:\tlearn: 7.6902987\ttotal: 1m 3s\tremaining: 9.45s\n",
            "10595:\tlearn: 7.6902946\ttotal: 1m 3s\tremaining: 9.44s\n",
            "10596:\tlearn: 7.6902885\ttotal: 1m 3s\tremaining: 9.43s\n",
            "10597:\tlearn: 7.6902781\ttotal: 1m 3s\tremaining: 9.43s\n",
            "10598:\tlearn: 7.6902677\ttotal: 1m 3s\tremaining: 9.42s\n",
            "10599:\tlearn: 7.6902475\ttotal: 1m 3s\tremaining: 9.41s\n",
            "10600:\tlearn: 7.6902449\ttotal: 1m 3s\tremaining: 9.41s\n",
            "10601:\tlearn: 7.6902325\ttotal: 1m 3s\tremaining: 9.4s\n",
            "10602:\tlearn: 7.6902232\ttotal: 1m 3s\tremaining: 9.4s\n",
            "10603:\tlearn: 7.6902163\ttotal: 1m 3s\tremaining: 9.39s\n",
            "10604:\tlearn: 7.6901987\ttotal: 1m 3s\tremaining: 9.39s\n",
            "10605:\tlearn: 7.6901888\ttotal: 1m 3s\tremaining: 9.38s\n",
            "10606:\tlearn: 7.6901744\ttotal: 1m 3s\tremaining: 9.37s\n",
            "10607:\tlearn: 7.6901634\ttotal: 1m 3s\tremaining: 9.37s\n",
            "10608:\tlearn: 7.6901565\ttotal: 1m 3s\tremaining: 9.36s\n",
            "10609:\tlearn: 7.6901365\ttotal: 1m 3s\tremaining: 9.36s\n",
            "10610:\tlearn: 7.6901111\ttotal: 1m 3s\tremaining: 9.35s\n",
            "10611:\tlearn: 7.6900926\ttotal: 1m 3s\tremaining: 9.34s\n",
            "10612:\tlearn: 7.6900871\ttotal: 1m 3s\tremaining: 9.34s\n",
            "10613:\tlearn: 7.6900785\ttotal: 1m 3s\tremaining: 9.33s\n",
            "10614:\tlearn: 7.6900753\ttotal: 1m 3s\tremaining: 9.33s\n",
            "10615:\tlearn: 7.6900603\ttotal: 1m 3s\tremaining: 9.32s\n",
            "10616:\tlearn: 7.6900510\ttotal: 1m 3s\tremaining: 9.31s\n",
            "10617:\tlearn: 7.6900481\ttotal: 1m 3s\tremaining: 9.31s\n",
            "10618:\tlearn: 7.6900392\ttotal: 1m 3s\tremaining: 9.3s\n",
            "10619:\tlearn: 7.6900308\ttotal: 1m 3s\tremaining: 9.3s\n",
            "10620:\tlearn: 7.6900227\ttotal: 1m 3s\tremaining: 9.29s\n",
            "10621:\tlearn: 7.6900172\ttotal: 1m 3s\tremaining: 9.29s\n",
            "10622:\tlearn: 7.6900143\ttotal: 1m 3s\tremaining: 9.28s\n",
            "10623:\tlearn: 7.6900077\ttotal: 1m 3s\tremaining: 9.27s\n",
            "10624:\tlearn: 7.6900030\ttotal: 1m 3s\tremaining: 9.27s\n",
            "10625:\tlearn: 7.6899970\ttotal: 1m 3s\tremaining: 9.26s\n",
            "10626:\tlearn: 7.6899871\ttotal: 1m 3s\tremaining: 9.26s\n",
            "10627:\tlearn: 7.6899814\ttotal: 1m 3s\tremaining: 9.25s\n",
            "10628:\tlearn: 7.6899779\ttotal: 1m 3s\tremaining: 9.24s\n",
            "10629:\tlearn: 7.6899707\ttotal: 1m 3s\tremaining: 9.24s\n",
            "10630:\tlearn: 7.6899548\ttotal: 1m 3s\tremaining: 9.23s\n",
            "10631:\tlearn: 7.6899403\ttotal: 1m 3s\tremaining: 9.23s\n",
            "10632:\tlearn: 7.6899302\ttotal: 1m 3s\tremaining: 9.22s\n",
            "10633:\tlearn: 7.6899244\ttotal: 1m 3s\tremaining: 9.21s\n",
            "10634:\tlearn: 7.6899161\ttotal: 1m 3s\tremaining: 9.21s\n",
            "10635:\tlearn: 7.6899071\ttotal: 1m 3s\tremaining: 9.2s\n",
            "10636:\tlearn: 7.6898993\ttotal: 1m 3s\tremaining: 9.2s\n",
            "10637:\tlearn: 7.6898900\ttotal: 1m 3s\tremaining: 9.19s\n",
            "10638:\tlearn: 7.6898843\ttotal: 1m 3s\tremaining: 9.19s\n",
            "10639:\tlearn: 7.6898756\ttotal: 1m 3s\tremaining: 9.18s\n",
            "10640:\tlearn: 7.6898721\ttotal: 1m 3s\tremaining: 9.17s\n",
            "10641:\tlearn: 7.6898626\ttotal: 1m 3s\tremaining: 9.17s\n",
            "10642:\tlearn: 7.6898545\ttotal: 1m 3s\tremaining: 9.16s\n",
            "10643:\tlearn: 7.6898369\ttotal: 1m 3s\tremaining: 9.15s\n",
            "10644:\tlearn: 7.6898308\ttotal: 1m 3s\tremaining: 9.15s\n",
            "10645:\tlearn: 7.6898247\ttotal: 1m 3s\tremaining: 9.14s\n",
            "10646:\tlearn: 7.6898155\ttotal: 1m 3s\tremaining: 9.14s\n",
            "10647:\tlearn: 7.6898048\ttotal: 1m 3s\tremaining: 9.13s\n",
            "10648:\tlearn: 7.6898002\ttotal: 1m 3s\tremaining: 9.13s\n",
            "10649:\tlearn: 7.6897857\ttotal: 1m 3s\tremaining: 9.12s\n",
            "10650:\tlearn: 7.6897724\ttotal: 1m 3s\tremaining: 9.11s\n",
            "10651:\tlearn: 7.6897560\ttotal: 1m 3s\tremaining: 9.11s\n",
            "10652:\tlearn: 7.6897406\ttotal: 1m 3s\tremaining: 9.1s\n",
            "10653:\tlearn: 7.6897343\ttotal: 1m 3s\tremaining: 9.1s\n",
            "10654:\tlearn: 7.6897271\ttotal: 1m 3s\tremaining: 9.09s\n",
            "10655:\tlearn: 7.6897219\ttotal: 1m 3s\tremaining: 9.08s\n",
            "10656:\tlearn: 7.6897010\ttotal: 1m 3s\tremaining: 9.08s\n",
            "10657:\tlearn: 7.6896924\ttotal: 1m 3s\tremaining: 9.07s\n",
            "10658:\tlearn: 7.6896808\ttotal: 1m 3s\tremaining: 9.07s\n",
            "10659:\tlearn: 7.6896655\ttotal: 1m 3s\tremaining: 9.06s\n",
            "10660:\tlearn: 7.6896519\ttotal: 1m 3s\tremaining: 9.05s\n",
            "10661:\tlearn: 7.6896438\ttotal: 1m 3s\tremaining: 9.05s\n",
            "10662:\tlearn: 7.6896262\ttotal: 1m 3s\tremaining: 9.04s\n",
            "10663:\tlearn: 7.6896219\ttotal: 1m 3s\tremaining: 9.04s\n",
            "10664:\tlearn: 7.6896190\ttotal: 1m 3s\tremaining: 9.03s\n",
            "10665:\tlearn: 7.6896008\ttotal: 1m 3s\tremaining: 9.02s\n",
            "10666:\tlearn: 7.6895915\ttotal: 1m 3s\tremaining: 9.02s\n",
            "10667:\tlearn: 7.6895875\ttotal: 1m 3s\tremaining: 9.01s\n",
            "10668:\tlearn: 7.6895730\ttotal: 1m 3s\tremaining: 9.01s\n",
            "10669:\tlearn: 7.6895499\ttotal: 1m 3s\tremaining: 9s\n",
            "10670:\tlearn: 7.6895357\ttotal: 1m 3s\tremaining: 8.99s\n",
            "10671:\tlearn: 7.6895178\ttotal: 1m 3s\tremaining: 8.99s\n",
            "10672:\tlearn: 7.6894927\ttotal: 1m 3s\tremaining: 8.98s\n",
            "10673:\tlearn: 7.6894805\ttotal: 1m 3s\tremaining: 8.98s\n",
            "10674:\tlearn: 7.6894621\ttotal: 1m 3s\tremaining: 8.97s\n",
            "10675:\tlearn: 7.6894560\ttotal: 1m 3s\tremaining: 8.96s\n",
            "10676:\tlearn: 7.6894462\ttotal: 1m 3s\tremaining: 8.96s\n",
            "10677:\tlearn: 7.6894392\ttotal: 1m 3s\tremaining: 8.95s\n",
            "10678:\tlearn: 7.6894288\ttotal: 1m 3s\tremaining: 8.95s\n",
            "10679:\tlearn: 7.6894173\ttotal: 1m 3s\tremaining: 8.94s\n",
            "10680:\tlearn: 7.6894063\ttotal: 1m 3s\tremaining: 8.94s\n",
            "10681:\tlearn: 7.6893927\ttotal: 1m 3s\tremaining: 8.93s\n",
            "10682:\tlearn: 7.6893846\ttotal: 1m 3s\tremaining: 8.92s\n",
            "10683:\tlearn: 7.6893629\ttotal: 1m 3s\tremaining: 8.92s\n",
            "10684:\tlearn: 7.6893566\ttotal: 1m 3s\tremaining: 8.91s\n",
            "10685:\tlearn: 7.6893268\ttotal: 1m 3s\tremaining: 8.91s\n",
            "10686:\tlearn: 7.6893219\ttotal: 1m 3s\tremaining: 8.9s\n",
            "10687:\tlearn: 7.6893077\ttotal: 1m 3s\tremaining: 8.89s\n",
            "10688:\tlearn: 7.6892910\ttotal: 1m 3s\tremaining: 8.89s\n",
            "10689:\tlearn: 7.6892835\ttotal: 1m 3s\tremaining: 8.88s\n",
            "10690:\tlearn: 7.6892702\ttotal: 1m 3s\tremaining: 8.88s\n",
            "10691:\tlearn: 7.6892476\ttotal: 1m 3s\tremaining: 8.87s\n",
            "10692:\tlearn: 7.6892363\ttotal: 1m 3s\tremaining: 8.87s\n",
            "10693:\tlearn: 7.6892193\ttotal: 1m 3s\tremaining: 8.86s\n",
            "10694:\tlearn: 7.6892086\ttotal: 1m 3s\tremaining: 8.85s\n",
            "10695:\tlearn: 7.6891988\ttotal: 1m 3s\tremaining: 8.85s\n",
            "10696:\tlearn: 7.6891907\ttotal: 1m 3s\tremaining: 8.84s\n",
            "10697:\tlearn: 7.6891861\ttotal: 1m 3s\tremaining: 8.83s\n",
            "10698:\tlearn: 7.6891739\ttotal: 1m 3s\tremaining: 8.83s\n",
            "10699:\tlearn: 7.6891583\ttotal: 1m 3s\tremaining: 8.82s\n",
            "10700:\tlearn: 7.6891569\ttotal: 1m 3s\tremaining: 8.82s\n",
            "10701:\tlearn: 7.6891470\ttotal: 1m 3s\tremaining: 8.81s\n",
            "10702:\tlearn: 7.6891343\ttotal: 1m 3s\tremaining: 8.8s\n",
            "10703:\tlearn: 7.6891225\ttotal: 1m 3s\tremaining: 8.8s\n",
            "10704:\tlearn: 7.6891155\ttotal: 1m 3s\tremaining: 8.79s\n",
            "10705:\tlearn: 7.6891017\ttotal: 1m 3s\tremaining: 8.79s\n",
            "10706:\tlearn: 7.6890852\ttotal: 1m 3s\tremaining: 8.78s\n",
            "10707:\tlearn: 7.6890794\ttotal: 1m 3s\tremaining: 8.77s\n",
            "10708:\tlearn: 7.6890731\ttotal: 1m 3s\tremaining: 8.77s\n",
            "10709:\tlearn: 7.6890551\ttotal: 1m 3s\tremaining: 8.76s\n",
            "10710:\tlearn: 7.6890430\ttotal: 1m 3s\tremaining: 8.76s\n",
            "10711:\tlearn: 7.6890364\ttotal: 1m 3s\tremaining: 8.75s\n",
            "10712:\tlearn: 7.6890251\ttotal: 1m 3s\tremaining: 8.74s\n",
            "10713:\tlearn: 7.6890150\ttotal: 1m 3s\tremaining: 8.74s\n",
            "10714:\tlearn: 7.6890069\ttotal: 1m 3s\tremaining: 8.73s\n",
            "10715:\tlearn: 7.6889985\ttotal: 1m 3s\tremaining: 8.73s\n",
            "10716:\tlearn: 7.6889892\ttotal: 1m 3s\tremaining: 8.72s\n",
            "10717:\tlearn: 7.6889673\ttotal: 1m 3s\tremaining: 8.71s\n",
            "10718:\tlearn: 7.6889577\ttotal: 1m 3s\tremaining: 8.71s\n",
            "10719:\tlearn: 7.6889479\ttotal: 1m 3s\tremaining: 8.7s\n",
            "10720:\tlearn: 7.6889358\ttotal: 1m 3s\tremaining: 8.7s\n",
            "10721:\tlearn: 7.6889164\ttotal: 1m 3s\tremaining: 8.69s\n",
            "10722:\tlearn: 7.6889077\ttotal: 1m 3s\tremaining: 8.69s\n",
            "10723:\tlearn: 7.6888985\ttotal: 1m 3s\tremaining: 8.68s\n",
            "10724:\tlearn: 7.6888823\ttotal: 1m 3s\tremaining: 8.67s\n",
            "10725:\tlearn: 7.6888780\ttotal: 1m 3s\tremaining: 8.67s\n",
            "10726:\tlearn: 7.6888681\ttotal: 1m 3s\tremaining: 8.66s\n",
            "10727:\tlearn: 7.6888583\ttotal: 1m 3s\tremaining: 8.65s\n",
            "10728:\tlearn: 7.6888502\ttotal: 1m 3s\tremaining: 8.65s\n",
            "10729:\tlearn: 7.6888407\ttotal: 1m 3s\tremaining: 8.64s\n",
            "10730:\tlearn: 7.6888271\ttotal: 1m 3s\tremaining: 8.64s\n",
            "10731:\tlearn: 7.6888228\ttotal: 1m 3s\tremaining: 8.63s\n",
            "10732:\tlearn: 7.6888098\ttotal: 1m 3s\tremaining: 8.63s\n",
            "10733:\tlearn: 7.6888063\ttotal: 1m 3s\tremaining: 8.62s\n",
            "10734:\tlearn: 7.6887884\ttotal: 1m 3s\tremaining: 8.61s\n",
            "10735:\tlearn: 7.6887543\ttotal: 1m 3s\tremaining: 8.61s\n",
            "10736:\tlearn: 7.6887470\ttotal: 1m 3s\tremaining: 8.6s\n",
            "10737:\tlearn: 7.6887369\ttotal: 1m 3s\tremaining: 8.6s\n",
            "10738:\tlearn: 7.6887219\ttotal: 1m 3s\tremaining: 8.59s\n",
            "10739:\tlearn: 7.6887187\ttotal: 1m 3s\tremaining: 8.58s\n",
            "10740:\tlearn: 7.6886982\ttotal: 1m 3s\tremaining: 8.58s\n",
            "10741:\tlearn: 7.6886907\ttotal: 1m 3s\tremaining: 8.57s\n",
            "10742:\tlearn: 7.6886814\ttotal: 1m 3s\tremaining: 8.56s\n",
            "10743:\tlearn: 7.6886733\ttotal: 1m 3s\tremaining: 8.56s\n",
            "10744:\tlearn: 7.6886586\ttotal: 1m 4s\tremaining: 8.55s\n",
            "10745:\tlearn: 7.6886372\ttotal: 1m 4s\tremaining: 8.55s\n",
            "10746:\tlearn: 7.6886222\ttotal: 1m 4s\tremaining: 8.54s\n",
            "10747:\tlearn: 7.6886060\ttotal: 1m 4s\tremaining: 8.54s\n",
            "10748:\tlearn: 7.6885939\ttotal: 1m 4s\tremaining: 8.53s\n",
            "10749:\tlearn: 7.6885835\ttotal: 1m 4s\tremaining: 8.52s\n",
            "10750:\tlearn: 7.6885757\ttotal: 1m 4s\tremaining: 8.52s\n",
            "10751:\tlearn: 7.6885600\ttotal: 1m 4s\tremaining: 8.51s\n",
            "10752:\tlearn: 7.6885476\ttotal: 1m 4s\tremaining: 8.51s\n",
            "10753:\tlearn: 7.6885294\ttotal: 1m 4s\tremaining: 8.5s\n",
            "10754:\tlearn: 7.6885167\ttotal: 1m 4s\tremaining: 8.49s\n",
            "10755:\tlearn: 7.6885083\ttotal: 1m 4s\tremaining: 8.49s\n",
            "10756:\tlearn: 7.6884835\ttotal: 1m 4s\tremaining: 8.48s\n",
            "10757:\tlearn: 7.6884710\ttotal: 1m 4s\tremaining: 8.48s\n",
            "10758:\tlearn: 7.6884664\ttotal: 1m 4s\tremaining: 8.47s\n",
            "10759:\tlearn: 7.6884644\ttotal: 1m 4s\tremaining: 8.46s\n",
            "10760:\tlearn: 7.6884557\ttotal: 1m 4s\tremaining: 8.46s\n",
            "10761:\tlearn: 7.6884531\ttotal: 1m 4s\tremaining: 8.45s\n",
            "10762:\tlearn: 7.6884418\ttotal: 1m 4s\tremaining: 8.45s\n",
            "10763:\tlearn: 7.6884317\ttotal: 1m 4s\tremaining: 8.44s\n",
            "10764:\tlearn: 7.6884303\ttotal: 1m 4s\tremaining: 8.43s\n",
            "10765:\tlearn: 7.6884230\ttotal: 1m 4s\tremaining: 8.43s\n",
            "10766:\tlearn: 7.6884071\ttotal: 1m 4s\tremaining: 8.42s\n",
            "10767:\tlearn: 7.6884017\ttotal: 1m 4s\tremaining: 8.42s\n",
            "10768:\tlearn: 7.6883855\ttotal: 1m 4s\tremaining: 8.41s\n",
            "10769:\tlearn: 7.6883754\ttotal: 1m 4s\tremaining: 8.4s\n",
            "10770:\tlearn: 7.6883531\ttotal: 1m 4s\tremaining: 8.4s\n",
            "10771:\tlearn: 7.6883493\ttotal: 1m 4s\tremaining: 8.39s\n",
            "10772:\tlearn: 7.6883441\ttotal: 1m 4s\tremaining: 8.39s\n",
            "10773:\tlearn: 7.6883285\ttotal: 1m 4s\tremaining: 8.38s\n",
            "10774:\tlearn: 7.6883245\ttotal: 1m 4s\tremaining: 8.37s\n",
            "10775:\tlearn: 7.6883074\ttotal: 1m 4s\tremaining: 8.37s\n",
            "10776:\tlearn: 7.6882947\ttotal: 1m 4s\tremaining: 8.36s\n",
            "10777:\tlearn: 7.6882748\ttotal: 1m 4s\tremaining: 8.36s\n",
            "10778:\tlearn: 7.6882690\ttotal: 1m 4s\tremaining: 8.35s\n",
            "10779:\tlearn: 7.6882545\ttotal: 1m 4s\tremaining: 8.35s\n",
            "10780:\tlearn: 7.6882485\ttotal: 1m 4s\tremaining: 8.34s\n",
            "10781:\tlearn: 7.6882447\ttotal: 1m 4s\tremaining: 8.33s\n",
            "10782:\tlearn: 7.6882288\ttotal: 1m 4s\tremaining: 8.33s\n",
            "10783:\tlearn: 7.6882170\ttotal: 1m 4s\tremaining: 8.32s\n",
            "10784:\tlearn: 7.6881953\ttotal: 1m 4s\tremaining: 8.32s\n",
            "10785:\tlearn: 7.6881805\ttotal: 1m 4s\tremaining: 8.31s\n",
            "10786:\tlearn: 7.6881693\ttotal: 1m 4s\tremaining: 8.31s\n",
            "10787:\tlearn: 7.6881586\ttotal: 1m 4s\tremaining: 8.3s\n",
            "10788:\tlearn: 7.6881363\ttotal: 1m 4s\tremaining: 8.29s\n",
            "10789:\tlearn: 7.6881279\ttotal: 1m 4s\tremaining: 8.29s\n",
            "10790:\tlearn: 7.6881149\ttotal: 1m 4s\tremaining: 8.28s\n",
            "10791:\tlearn: 7.6881126\ttotal: 1m 4s\tremaining: 8.28s\n",
            "10792:\tlearn: 7.6880886\ttotal: 1m 4s\tremaining: 8.27s\n",
            "10793:\tlearn: 7.6880794\ttotal: 1m 4s\tremaining: 8.26s\n",
            "10794:\tlearn: 7.6880589\ttotal: 1m 4s\tremaining: 8.26s\n",
            "10795:\tlearn: 7.6880519\ttotal: 1m 4s\tremaining: 8.25s\n",
            "10796:\tlearn: 7.6880343\ttotal: 1m 4s\tremaining: 8.25s\n",
            "10797:\tlearn: 7.6880213\ttotal: 1m 4s\tremaining: 8.24s\n",
            "10798:\tlearn: 7.6880158\ttotal: 1m 4s\tremaining: 8.23s\n",
            "10799:\tlearn: 7.6880086\ttotal: 1m 4s\tremaining: 8.23s\n",
            "10800:\tlearn: 7.6879993\ttotal: 1m 4s\tremaining: 8.22s\n",
            "10801:\tlearn: 7.6879889\ttotal: 1m 4s\tremaining: 8.22s\n",
            "10802:\tlearn: 7.6879788\ttotal: 1m 4s\tremaining: 8.21s\n",
            "10803:\tlearn: 7.6879545\ttotal: 1m 4s\tremaining: 8.2s\n",
            "10804:\tlearn: 7.6879513\ttotal: 1m 4s\tremaining: 8.2s\n",
            "10805:\tlearn: 7.6879435\ttotal: 1m 4s\tremaining: 8.19s\n",
            "10806:\tlearn: 7.6879351\ttotal: 1m 4s\tremaining: 8.19s\n",
            "10807:\tlearn: 7.6879224\ttotal: 1m 4s\tremaining: 8.18s\n",
            "10808:\tlearn: 7.6879091\ttotal: 1m 4s\tremaining: 8.17s\n",
            "10809:\tlearn: 7.6878967\ttotal: 1m 4s\tremaining: 8.17s\n",
            "10810:\tlearn: 7.6878799\ttotal: 1m 4s\tremaining: 8.16s\n",
            "10811:\tlearn: 7.6878533\ttotal: 1m 4s\tremaining: 8.16s\n",
            "10812:\tlearn: 7.6878435\ttotal: 1m 4s\tremaining: 8.15s\n",
            "10813:\tlearn: 7.6878331\ttotal: 1m 4s\tremaining: 8.14s\n",
            "10814:\tlearn: 7.6878296\ttotal: 1m 4s\tremaining: 8.14s\n",
            "10815:\tlearn: 7.6878262\ttotal: 1m 4s\tremaining: 8.13s\n",
            "10816:\tlearn: 7.6878210\ttotal: 1m 4s\tremaining: 8.13s\n",
            "10817:\tlearn: 7.6878103\ttotal: 1m 4s\tremaining: 8.12s\n",
            "10818:\tlearn: 7.6878042\ttotal: 1m 4s\tremaining: 8.12s\n",
            "10819:\tlearn: 7.6877941\ttotal: 1m 4s\tremaining: 8.11s\n",
            "10820:\tlearn: 7.6877802\ttotal: 1m 4s\tremaining: 8.1s\n",
            "10821:\tlearn: 7.6877475\ttotal: 1m 4s\tremaining: 8.1s\n",
            "10822:\tlearn: 7.6877394\ttotal: 1m 4s\tremaining: 8.09s\n",
            "10823:\tlearn: 7.6877311\ttotal: 1m 4s\tremaining: 8.09s\n",
            "10824:\tlearn: 7.6877224\ttotal: 1m 4s\tremaining: 8.08s\n",
            "10825:\tlearn: 7.6877068\ttotal: 1m 4s\tremaining: 8.07s\n",
            "10826:\tlearn: 7.6877033\ttotal: 1m 4s\tremaining: 8.07s\n",
            "10827:\tlearn: 7.6876955\ttotal: 1m 4s\tremaining: 8.06s\n",
            "10828:\tlearn: 7.6876819\ttotal: 1m 4s\tremaining: 8.06s\n",
            "10829:\tlearn: 7.6876756\ttotal: 1m 4s\tremaining: 8.05s\n",
            "10830:\tlearn: 7.6876692\ttotal: 1m 4s\tremaining: 8.04s\n",
            "10831:\tlearn: 7.6876548\ttotal: 1m 4s\tremaining: 8.04s\n",
            "10832:\tlearn: 7.6876397\ttotal: 1m 4s\tremaining: 8.03s\n",
            "10833:\tlearn: 7.6876267\ttotal: 1m 4s\tremaining: 8.03s\n",
            "10834:\tlearn: 7.6876183\ttotal: 1m 4s\tremaining: 8.02s\n",
            "10835:\tlearn: 7.6876094\ttotal: 1m 4s\tremaining: 8.01s\n",
            "10836:\tlearn: 7.6876019\ttotal: 1m 4s\tremaining: 8.01s\n",
            "10837:\tlearn: 7.6875920\ttotal: 1m 4s\tremaining: 8s\n",
            "10838:\tlearn: 7.6875741\ttotal: 1m 4s\tremaining: 8s\n",
            "10839:\tlearn: 7.6875709\ttotal: 1m 4s\tremaining: 7.99s\n",
            "10840:\tlearn: 7.6875628\ttotal: 1m 4s\tremaining: 7.98s\n",
            "10841:\tlearn: 7.6875469\ttotal: 1m 4s\tremaining: 7.98s\n",
            "10842:\tlearn: 7.6875331\ttotal: 1m 4s\tremaining: 7.97s\n",
            "10843:\tlearn: 7.6875250\ttotal: 1m 4s\tremaining: 7.97s\n",
            "10844:\tlearn: 7.6875117\ttotal: 1m 4s\tremaining: 7.96s\n",
            "10845:\tlearn: 7.6874989\ttotal: 1m 4s\tremaining: 7.95s\n",
            "10846:\tlearn: 7.6874908\ttotal: 1m 4s\tremaining: 7.95s\n",
            "10847:\tlearn: 7.6874787\ttotal: 1m 4s\tremaining: 7.94s\n",
            "10848:\tlearn: 7.6874744\ttotal: 1m 4s\tremaining: 7.94s\n",
            "10849:\tlearn: 7.6874692\ttotal: 1m 4s\tremaining: 7.93s\n",
            "10850:\tlearn: 7.6874562\ttotal: 1m 4s\tremaining: 7.93s\n",
            "10851:\tlearn: 7.6874411\ttotal: 1m 4s\tremaining: 7.92s\n",
            "10852:\tlearn: 7.6874299\ttotal: 1m 4s\tremaining: 7.91s\n",
            "10853:\tlearn: 7.6874177\ttotal: 1m 4s\tremaining: 7.91s\n",
            "10854:\tlearn: 7.6874093\ttotal: 1m 4s\tremaining: 7.9s\n",
            "10855:\tlearn: 7.6873981\ttotal: 1m 4s\tremaining: 7.89s\n",
            "10856:\tlearn: 7.6873839\ttotal: 1m 4s\tremaining: 7.89s\n",
            "10857:\tlearn: 7.6873758\ttotal: 1m 4s\tremaining: 7.88s\n",
            "10858:\tlearn: 7.6873547\ttotal: 1m 4s\tremaining: 7.88s\n",
            "10859:\tlearn: 7.6873463\ttotal: 1m 4s\tremaining: 7.87s\n",
            "10860:\tlearn: 7.6873391\ttotal: 1m 4s\tremaining: 7.87s\n",
            "10861:\tlearn: 7.6873183\ttotal: 1m 4s\tremaining: 7.86s\n",
            "10862:\tlearn: 7.6873018\ttotal: 1m 4s\tremaining: 7.85s\n",
            "10863:\tlearn: 7.6872923\ttotal: 1m 4s\tremaining: 7.85s\n",
            "10864:\tlearn: 7.6872853\ttotal: 1m 4s\tremaining: 7.84s\n",
            "10865:\tlearn: 7.6872723\ttotal: 1m 4s\tremaining: 7.83s\n",
            "10866:\tlearn: 7.6872610\ttotal: 1m 4s\tremaining: 7.83s\n",
            "10867:\tlearn: 7.6872532\ttotal: 1m 4s\tremaining: 7.82s\n",
            "10868:\tlearn: 7.6872492\ttotal: 1m 4s\tremaining: 7.82s\n",
            "10869:\tlearn: 7.6872443\ttotal: 1m 4s\tremaining: 7.81s\n",
            "10870:\tlearn: 7.6872284\ttotal: 1m 4s\tremaining: 7.8s\n",
            "10871:\tlearn: 7.6872096\ttotal: 1m 4s\tremaining: 7.8s\n",
            "10872:\tlearn: 7.6871948\ttotal: 1m 4s\tremaining: 7.79s\n",
            "10873:\tlearn: 7.6871726\ttotal: 1m 4s\tremaining: 7.79s\n",
            "10874:\tlearn: 7.6871653\ttotal: 1m 4s\tremaining: 7.78s\n",
            "10875:\tlearn: 7.6871489\ttotal: 1m 4s\tremaining: 7.78s\n",
            "10876:\tlearn: 7.6871269\ttotal: 1m 4s\tremaining: 7.77s\n",
            "10877:\tlearn: 7.6871171\ttotal: 1m 4s\tremaining: 7.76s\n",
            "10878:\tlearn: 7.6871107\ttotal: 1m 4s\tremaining: 7.76s\n",
            "10879:\tlearn: 7.6870986\ttotal: 1m 4s\tremaining: 7.75s\n",
            "10880:\tlearn: 7.6870928\ttotal: 1m 4s\tremaining: 7.74s\n",
            "10881:\tlearn: 7.6870830\ttotal: 1m 4s\tremaining: 7.74s\n",
            "10882:\tlearn: 7.6870792\ttotal: 1m 4s\tremaining: 7.73s\n",
            "10883:\tlearn: 7.6870743\ttotal: 1m 4s\tremaining: 7.73s\n",
            "10884:\tlearn: 7.6870552\ttotal: 1m 4s\tremaining: 7.72s\n",
            "10885:\tlearn: 7.6870434\ttotal: 1m 4s\tremaining: 7.72s\n",
            "10886:\tlearn: 7.6870286\ttotal: 1m 4s\tremaining: 7.71s\n",
            "10887:\tlearn: 7.6870240\ttotal: 1m 4s\tremaining: 7.7s\n",
            "10888:\tlearn: 7.6870003\ttotal: 1m 4s\tremaining: 7.7s\n",
            "10889:\tlearn: 7.6869905\ttotal: 1m 4s\tremaining: 7.69s\n",
            "10890:\tlearn: 7.6869852\ttotal: 1m 4s\tremaining: 7.69s\n",
            "10891:\tlearn: 7.6869789\ttotal: 1m 4s\tremaining: 7.68s\n",
            "10892:\tlearn: 7.6869731\ttotal: 1m 4s\tremaining: 7.67s\n",
            "10893:\tlearn: 7.6869639\ttotal: 1m 4s\tremaining: 7.67s\n",
            "10894:\tlearn: 7.6869514\ttotal: 1m 4s\tremaining: 7.66s\n",
            "10895:\tlearn: 7.6869338\ttotal: 1m 4s\tremaining: 7.66s\n",
            "10896:\tlearn: 7.6869280\ttotal: 1m 4s\tremaining: 7.65s\n",
            "10897:\tlearn: 7.6869136\ttotal: 1m 4s\tremaining: 7.64s\n",
            "10898:\tlearn: 7.6869026\ttotal: 1m 4s\tremaining: 7.64s\n",
            "10899:\tlearn: 7.6868832\ttotal: 1m 4s\tremaining: 7.63s\n",
            "10900:\tlearn: 7.6868786\ttotal: 1m 4s\tremaining: 7.63s\n",
            "10901:\tlearn: 7.6868661\ttotal: 1m 4s\tremaining: 7.62s\n",
            "10902:\tlearn: 7.6868534\ttotal: 1m 4s\tremaining: 7.61s\n",
            "10903:\tlearn: 7.6868485\ttotal: 1m 4s\tremaining: 7.61s\n",
            "10904:\tlearn: 7.6868361\ttotal: 1m 4s\tremaining: 7.6s\n",
            "10905:\tlearn: 7.6868289\ttotal: 1m 4s\tremaining: 7.6s\n",
            "10906:\tlearn: 7.6868225\ttotal: 1m 4s\tremaining: 7.59s\n",
            "10907:\tlearn: 7.6868103\ttotal: 1m 4s\tremaining: 7.58s\n",
            "10908:\tlearn: 7.6867924\ttotal: 1m 4s\tremaining: 7.58s\n",
            "10909:\tlearn: 7.6867785\ttotal: 1m 4s\tremaining: 7.57s\n",
            "10910:\tlearn: 7.6867612\ttotal: 1m 5s\tremaining: 7.57s\n",
            "10911:\tlearn: 7.6867493\ttotal: 1m 5s\tremaining: 7.56s\n",
            "10912:\tlearn: 7.6867418\ttotal: 1m 5s\tremaining: 7.55s\n",
            "10913:\tlearn: 7.6867317\ttotal: 1m 5s\tremaining: 7.55s\n",
            "10914:\tlearn: 7.6867225\ttotal: 1m 5s\tremaining: 7.54s\n",
            "10915:\tlearn: 7.6867135\ttotal: 1m 5s\tremaining: 7.54s\n",
            "10916:\tlearn: 7.6867060\ttotal: 1m 5s\tremaining: 7.53s\n",
            "10917:\tlearn: 7.6866840\ttotal: 1m 5s\tremaining: 7.52s\n",
            "10918:\tlearn: 7.6866736\ttotal: 1m 5s\tremaining: 7.52s\n",
            "10919:\tlearn: 7.6866574\ttotal: 1m 5s\tremaining: 7.51s\n",
            "10920:\tlearn: 7.6866513\ttotal: 1m 5s\tremaining: 7.51s\n",
            "10921:\tlearn: 7.6866444\ttotal: 1m 5s\tremaining: 7.5s\n",
            "10922:\tlearn: 7.6866372\ttotal: 1m 5s\tremaining: 7.5s\n",
            "10923:\tlearn: 7.6866328\ttotal: 1m 5s\tremaining: 7.49s\n",
            "10924:\tlearn: 7.6866233\ttotal: 1m 5s\tremaining: 7.48s\n",
            "10925:\tlearn: 7.6866123\ttotal: 1m 5s\tremaining: 7.48s\n",
            "10926:\tlearn: 7.6865929\ttotal: 1m 5s\tremaining: 7.47s\n",
            "10927:\tlearn: 7.6865828\ttotal: 1m 5s\tremaining: 7.46s\n",
            "10928:\tlearn: 7.6865687\ttotal: 1m 5s\tremaining: 7.46s\n",
            "10929:\tlearn: 7.6865614\ttotal: 1m 5s\tremaining: 7.45s\n",
            "10930:\tlearn: 7.6865481\ttotal: 1m 5s\tremaining: 7.45s\n",
            "10931:\tlearn: 7.6865369\ttotal: 1m 5s\tremaining: 7.44s\n",
            "10932:\tlearn: 7.6865230\ttotal: 1m 5s\tremaining: 7.43s\n",
            "10933:\tlearn: 7.6865184\ttotal: 1m 5s\tremaining: 7.43s\n",
            "10934:\tlearn: 7.6865027\ttotal: 1m 5s\tremaining: 7.42s\n",
            "10935:\tlearn: 7.6864799\ttotal: 1m 5s\tremaining: 7.42s\n",
            "10936:\tlearn: 7.6864735\ttotal: 1m 5s\tremaining: 7.41s\n",
            "10937:\tlearn: 7.6864602\ttotal: 1m 5s\tremaining: 7.41s\n",
            "10938:\tlearn: 7.6864533\ttotal: 1m 5s\tremaining: 7.4s\n",
            "10939:\tlearn: 7.6864357\ttotal: 1m 5s\tremaining: 7.39s\n",
            "10940:\tlearn: 7.6864241\ttotal: 1m 5s\tremaining: 7.39s\n",
            "10941:\tlearn: 7.6864076\ttotal: 1m 5s\tremaining: 7.38s\n",
            "10942:\tlearn: 7.6863848\ttotal: 1m 5s\tremaining: 7.38s\n",
            "10943:\tlearn: 7.6863724\ttotal: 1m 5s\tremaining: 7.37s\n",
            "10944:\tlearn: 7.6863544\ttotal: 1m 5s\tremaining: 7.36s\n",
            "10945:\tlearn: 7.6863504\ttotal: 1m 5s\tremaining: 7.36s\n",
            "10946:\tlearn: 7.6863394\ttotal: 1m 5s\tremaining: 7.35s\n",
            "10947:\tlearn: 7.6863226\ttotal: 1m 5s\tremaining: 7.34s\n",
            "10948:\tlearn: 7.6863148\ttotal: 1m 5s\tremaining: 7.34s\n",
            "10949:\tlearn: 7.6863059\ttotal: 1m 5s\tremaining: 7.33s\n",
            "10950:\tlearn: 7.6862989\ttotal: 1m 5s\tremaining: 7.33s\n",
            "10951:\tlearn: 7.6862943\ttotal: 1m 5s\tremaining: 7.32s\n",
            "10952:\tlearn: 7.6862816\ttotal: 1m 5s\tremaining: 7.32s\n",
            "10953:\tlearn: 7.6862729\ttotal: 1m 5s\tremaining: 7.31s\n",
            "10954:\tlearn: 7.6862495\ttotal: 1m 5s\tremaining: 7.3s\n",
            "10955:\tlearn: 7.6862431\ttotal: 1m 5s\tremaining: 7.3s\n",
            "10956:\tlearn: 7.6862333\ttotal: 1m 5s\tremaining: 7.29s\n",
            "10957:\tlearn: 7.6862211\ttotal: 1m 5s\tremaining: 7.29s\n",
            "10958:\tlearn: 7.6862145\ttotal: 1m 5s\tremaining: 7.28s\n",
            "10959:\tlearn: 7.6861908\ttotal: 1m 5s\tremaining: 7.28s\n",
            "10960:\tlearn: 7.6861769\ttotal: 1m 5s\tremaining: 7.27s\n",
            "10961:\tlearn: 7.6861688\ttotal: 1m 5s\tremaining: 7.26s\n",
            "10962:\tlearn: 7.6861642\ttotal: 1m 5s\tremaining: 7.26s\n",
            "10963:\tlearn: 7.6861509\ttotal: 1m 5s\tremaining: 7.25s\n",
            "10964:\tlearn: 7.6861419\ttotal: 1m 5s\tremaining: 7.25s\n",
            "10965:\tlearn: 7.6861292\ttotal: 1m 5s\tremaining: 7.24s\n",
            "10966:\tlearn: 7.6861214\ttotal: 1m 5s\tremaining: 7.23s\n",
            "10967:\tlearn: 7.6861049\ttotal: 1m 5s\tremaining: 7.23s\n",
            "10968:\tlearn: 7.6861009\ttotal: 1m 5s\tremaining: 7.22s\n",
            "10969:\tlearn: 7.6860879\ttotal: 1m 5s\tremaining: 7.22s\n",
            "10970:\tlearn: 7.6860821\ttotal: 1m 5s\tremaining: 7.21s\n",
            "10971:\tlearn: 7.6860749\ttotal: 1m 5s\tremaining: 7.2s\n",
            "10972:\tlearn: 7.6860694\ttotal: 1m 5s\tremaining: 7.2s\n",
            "10973:\tlearn: 7.6860535\ttotal: 1m 5s\tremaining: 7.19s\n",
            "10974:\tlearn: 7.6860448\ttotal: 1m 5s\tremaining: 7.18s\n",
            "10975:\tlearn: 7.6860378\ttotal: 1m 5s\tremaining: 7.18s\n",
            "10976:\tlearn: 7.6860257\ttotal: 1m 5s\tremaining: 7.17s\n",
            "10977:\tlearn: 7.6860153\ttotal: 1m 5s\tremaining: 7.17s\n",
            "10978:\tlearn: 7.6860060\ttotal: 1m 5s\tremaining: 7.16s\n",
            "10979:\tlearn: 7.6859982\ttotal: 1m 5s\tremaining: 7.16s\n",
            "10980:\tlearn: 7.6859922\ttotal: 1m 5s\tremaining: 7.15s\n",
            "10981:\tlearn: 7.6859820\ttotal: 1m 5s\tremaining: 7.14s\n",
            "10982:\tlearn: 7.6859763\ttotal: 1m 5s\tremaining: 7.14s\n",
            "10983:\tlearn: 7.6859618\ttotal: 1m 5s\tremaining: 7.13s\n",
            "10984:\tlearn: 7.6859468\ttotal: 1m 5s\tremaining: 7.13s\n",
            "10985:\tlearn: 7.6859242\ttotal: 1m 5s\tremaining: 7.12s\n",
            "10986:\tlearn: 7.6859205\ttotal: 1m 5s\tremaining: 7.11s\n",
            "10987:\tlearn: 7.6859127\ttotal: 1m 5s\tremaining: 7.11s\n",
            "10988:\tlearn: 7.6859051\ttotal: 1m 5s\tremaining: 7.1s\n",
            "10989:\tlearn: 7.6858942\ttotal: 1m 5s\tremaining: 7.1s\n",
            "10990:\tlearn: 7.6858806\ttotal: 1m 5s\tremaining: 7.09s\n",
            "10991:\tlearn: 7.6858707\ttotal: 1m 5s\tremaining: 7.08s\n",
            "10992:\tlearn: 7.6858626\ttotal: 1m 5s\tremaining: 7.08s\n",
            "10993:\tlearn: 7.6858528\ttotal: 1m 5s\tremaining: 7.07s\n",
            "10994:\tlearn: 7.6858282\ttotal: 1m 5s\tremaining: 7.07s\n",
            "10995:\tlearn: 7.6858164\ttotal: 1m 5s\tremaining: 7.06s\n",
            "10996:\tlearn: 7.6858132\ttotal: 1m 5s\tremaining: 7.05s\n",
            "10997:\tlearn: 7.6858025\ttotal: 1m 5s\tremaining: 7.05s\n",
            "10998:\tlearn: 7.6857872\ttotal: 1m 5s\tremaining: 7.04s\n",
            "10999:\tlearn: 7.6857846\ttotal: 1m 5s\tremaining: 7.04s\n",
            "11000:\tlearn: 7.6857692\ttotal: 1m 5s\tremaining: 7.03s\n",
            "11001:\tlearn: 7.6857620\ttotal: 1m 5s\tremaining: 7.03s\n",
            "11002:\tlearn: 7.6857395\ttotal: 1m 5s\tremaining: 7.02s\n",
            "11003:\tlearn: 7.6857181\ttotal: 1m 5s\tremaining: 7.01s\n",
            "11004:\tlearn: 7.6857120\ttotal: 1m 5s\tremaining: 7.01s\n",
            "11005:\tlearn: 7.6857068\ttotal: 1m 5s\tremaining: 7s\n",
            "11006:\tlearn: 7.6857004\ttotal: 1m 5s\tremaining: 7s\n",
            "11007:\tlearn: 7.6856897\ttotal: 1m 5s\tremaining: 6.99s\n",
            "11008:\tlearn: 7.6856860\ttotal: 1m 5s\tremaining: 6.98s\n",
            "11009:\tlearn: 7.6856773\ttotal: 1m 5s\tremaining: 6.98s\n",
            "11010:\tlearn: 7.6856617\ttotal: 1m 5s\tremaining: 6.97s\n",
            "11011:\tlearn: 7.6856524\ttotal: 1m 5s\tremaining: 6.96s\n",
            "11012:\tlearn: 7.6856348\ttotal: 1m 5s\tremaining: 6.96s\n",
            "11013:\tlearn: 7.6856215\ttotal: 1m 5s\tremaining: 6.95s\n",
            "11014:\tlearn: 7.6856108\ttotal: 1m 5s\tremaining: 6.95s\n",
            "11015:\tlearn: 7.6856024\ttotal: 1m 5s\tremaining: 6.94s\n",
            "11016:\tlearn: 7.6855839\ttotal: 1m 5s\tremaining: 6.93s\n",
            "11017:\tlearn: 7.6855738\ttotal: 1m 5s\tremaining: 6.93s\n",
            "11018:\tlearn: 7.6855538\ttotal: 1m 5s\tremaining: 6.92s\n",
            "11019:\tlearn: 7.6855428\ttotal: 1m 5s\tremaining: 6.92s\n",
            "11020:\tlearn: 7.6855313\ttotal: 1m 5s\tremaining: 6.91s\n",
            "11021:\tlearn: 7.6855275\ttotal: 1m 5s\tremaining: 6.91s\n",
            "11022:\tlearn: 7.6855174\ttotal: 1m 5s\tremaining: 6.9s\n",
            "11023:\tlearn: 7.6855136\ttotal: 1m 5s\tremaining: 6.89s\n",
            "11024:\tlearn: 7.6855021\ttotal: 1m 5s\tremaining: 6.89s\n",
            "11025:\tlearn: 7.6854879\ttotal: 1m 5s\tremaining: 6.88s\n",
            "11026:\tlearn: 7.6854755\ttotal: 1m 5s\tremaining: 6.88s\n",
            "11027:\tlearn: 7.6854607\ttotal: 1m 5s\tremaining: 6.87s\n",
            "11028:\tlearn: 7.6854526\ttotal: 1m 5s\tremaining: 6.86s\n",
            "11029:\tlearn: 7.6854469\ttotal: 1m 5s\tremaining: 6.86s\n",
            "11030:\tlearn: 7.6854451\ttotal: 1m 5s\tremaining: 6.85s\n",
            "11031:\tlearn: 7.6854283\ttotal: 1m 5s\tremaining: 6.85s\n",
            "11032:\tlearn: 7.6854223\ttotal: 1m 5s\tremaining: 6.84s\n",
            "11033:\tlearn: 7.6854133\ttotal: 1m 5s\tremaining: 6.83s\n",
            "11034:\tlearn: 7.6854067\ttotal: 1m 5s\tremaining: 6.83s\n",
            "11035:\tlearn: 7.6853957\ttotal: 1m 5s\tremaining: 6.82s\n",
            "11036:\tlearn: 7.6853806\ttotal: 1m 5s\tremaining: 6.82s\n",
            "11037:\tlearn: 7.6853685\ttotal: 1m 5s\tremaining: 6.81s\n",
            "11038:\tlearn: 7.6853639\ttotal: 1m 5s\tremaining: 6.8s\n",
            "11039:\tlearn: 7.6853517\ttotal: 1m 5s\tremaining: 6.8s\n",
            "11040:\tlearn: 7.6853477\ttotal: 1m 5s\tremaining: 6.79s\n",
            "11041:\tlearn: 7.6853399\ttotal: 1m 5s\tremaining: 6.79s\n",
            "11042:\tlearn: 7.6853251\ttotal: 1m 5s\tremaining: 6.78s\n",
            "11043:\tlearn: 7.6853084\ttotal: 1m 5s\tremaining: 6.77s\n",
            "11044:\tlearn: 7.6852924\ttotal: 1m 5s\tremaining: 6.77s\n",
            "11045:\tlearn: 7.6852849\ttotal: 1m 5s\tremaining: 6.76s\n",
            "11046:\tlearn: 7.6852774\ttotal: 1m 5s\tremaining: 6.76s\n",
            "11047:\tlearn: 7.6852693\ttotal: 1m 5s\tremaining: 6.75s\n",
            "11048:\tlearn: 7.6852601\ttotal: 1m 5s\tremaining: 6.74s\n",
            "11049:\tlearn: 7.6852476\ttotal: 1m 5s\tremaining: 6.74s\n",
            "11050:\tlearn: 7.6852259\ttotal: 1m 5s\tremaining: 6.73s\n",
            "11051:\tlearn: 7.6852071\ttotal: 1m 5s\tremaining: 6.73s\n",
            "11052:\tlearn: 7.6851901\ttotal: 1m 5s\tremaining: 6.72s\n",
            "11053:\tlearn: 7.6851805\ttotal: 1m 5s\tremaining: 6.71s\n",
            "11054:\tlearn: 7.6851704\ttotal: 1m 5s\tremaining: 6.71s\n",
            "11055:\tlearn: 7.6851620\ttotal: 1m 5s\tremaining: 6.7s\n",
            "11056:\tlearn: 7.6851473\ttotal: 1m 5s\tremaining: 6.7s\n",
            "11057:\tlearn: 7.6851317\ttotal: 1m 5s\tremaining: 6.69s\n",
            "11058:\tlearn: 7.6851190\ttotal: 1m 5s\tremaining: 6.68s\n",
            "11059:\tlearn: 7.6851088\ttotal: 1m 5s\tremaining: 6.68s\n",
            "11060:\tlearn: 7.6851019\ttotal: 1m 5s\tremaining: 6.67s\n",
            "11061:\tlearn: 7.6850869\ttotal: 1m 5s\tremaining: 6.67s\n",
            "11062:\tlearn: 7.6850805\ttotal: 1m 5s\tremaining: 6.66s\n",
            "11063:\tlearn: 7.6850556\ttotal: 1m 5s\tremaining: 6.66s\n",
            "11064:\tlearn: 7.6850429\ttotal: 1m 5s\tremaining: 6.65s\n",
            "11065:\tlearn: 7.6850085\ttotal: 1m 5s\tremaining: 6.64s\n",
            "11066:\tlearn: 7.6850062\ttotal: 1m 5s\tremaining: 6.64s\n",
            "11067:\tlearn: 7.6850013\ttotal: 1m 5s\tremaining: 6.63s\n",
            "11068:\tlearn: 7.6849984\ttotal: 1m 5s\tremaining: 6.63s\n",
            "11069:\tlearn: 7.6849848\ttotal: 1m 5s\tremaining: 6.62s\n",
            "11070:\tlearn: 7.6849735\ttotal: 1m 5s\tremaining: 6.61s\n",
            "11071:\tlearn: 7.6849579\ttotal: 1m 5s\tremaining: 6.61s\n",
            "11072:\tlearn: 7.6849455\ttotal: 1m 5s\tremaining: 6.6s\n",
            "11073:\tlearn: 7.6849319\ttotal: 1m 5s\tremaining: 6.6s\n",
            "11074:\tlearn: 7.6849148\ttotal: 1m 5s\tremaining: 6.59s\n",
            "11075:\tlearn: 7.6849099\ttotal: 1m 5s\tremaining: 6.58s\n",
            "11076:\tlearn: 7.6848960\ttotal: 1m 6s\tremaining: 6.58s\n",
            "11077:\tlearn: 7.6848749\ttotal: 1m 6s\tremaining: 6.57s\n",
            "11078:\tlearn: 7.6848639\ttotal: 1m 6s\tremaining: 6.57s\n",
            "11079:\tlearn: 7.6848607\ttotal: 1m 6s\tremaining: 6.56s\n",
            "11080:\tlearn: 7.6848532\ttotal: 1m 6s\tremaining: 6.55s\n",
            "11081:\tlearn: 7.6848359\ttotal: 1m 6s\tremaining: 6.55s\n",
            "11082:\tlearn: 7.6848252\ttotal: 1m 6s\tremaining: 6.54s\n",
            "11083:\tlearn: 7.6848136\ttotal: 1m 6s\tremaining: 6.54s\n",
            "11084:\tlearn: 7.6848038\ttotal: 1m 6s\tremaining: 6.53s\n",
            "11085:\tlearn: 7.6847893\ttotal: 1m 6s\tremaining: 6.52s\n",
            "11086:\tlearn: 7.6847751\ttotal: 1m 6s\tremaining: 6.52s\n",
            "11087:\tlearn: 7.6847667\ttotal: 1m 6s\tremaining: 6.51s\n",
            "11088:\tlearn: 7.6847633\ttotal: 1m 6s\tremaining: 6.5s\n",
            "11089:\tlearn: 7.6847506\ttotal: 1m 6s\tremaining: 6.5s\n",
            "11090:\tlearn: 7.6847456\ttotal: 1m 6s\tremaining: 6.49s\n",
            "11091:\tlearn: 7.6847401\ttotal: 1m 6s\tremaining: 6.49s\n",
            "11092:\tlearn: 7.6847237\ttotal: 1m 6s\tremaining: 6.48s\n",
            "11093:\tlearn: 7.6846997\ttotal: 1m 6s\tremaining: 6.48s\n",
            "11094:\tlearn: 7.6846950\ttotal: 1m 6s\tremaining: 6.47s\n",
            "11095:\tlearn: 7.6846823\ttotal: 1m 6s\tremaining: 6.46s\n",
            "11096:\tlearn: 7.6846658\ttotal: 1m 6s\tremaining: 6.46s\n",
            "11097:\tlearn: 7.6846543\ttotal: 1m 6s\tremaining: 6.45s\n",
            "11098:\tlearn: 7.6846508\ttotal: 1m 6s\tremaining: 6.45s\n",
            "11099:\tlearn: 7.6846421\ttotal: 1m 6s\tremaining: 6.44s\n",
            "11100:\tlearn: 7.6846314\ttotal: 1m 6s\tremaining: 6.43s\n",
            "11101:\tlearn: 7.6846193\ttotal: 1m 6s\tremaining: 6.43s\n",
            "11102:\tlearn: 7.6846071\ttotal: 1m 6s\tremaining: 6.42s\n",
            "11103:\tlearn: 7.6845932\ttotal: 1m 6s\tremaining: 6.42s\n",
            "11104:\tlearn: 7.6845904\ttotal: 1m 6s\tremaining: 6.41s\n",
            "11105:\tlearn: 7.6845727\ttotal: 1m 6s\tremaining: 6.4s\n",
            "11106:\tlearn: 7.6845591\ttotal: 1m 6s\tremaining: 6.4s\n",
            "11107:\tlearn: 7.6845502\ttotal: 1m 6s\tremaining: 6.39s\n",
            "11108:\tlearn: 7.6845409\ttotal: 1m 6s\tremaining: 6.39s\n",
            "11109:\tlearn: 7.6845288\ttotal: 1m 6s\tremaining: 6.38s\n",
            "11110:\tlearn: 7.6845166\ttotal: 1m 6s\tremaining: 6.38s\n",
            "11111:\tlearn: 7.6845169\ttotal: 1m 6s\tremaining: 6.37s\n",
            "11112:\tlearn: 7.6845074\ttotal: 1m 6s\tremaining: 6.36s\n",
            "11113:\tlearn: 7.6844943\ttotal: 1m 6s\tremaining: 6.36s\n",
            "11114:\tlearn: 7.6844790\ttotal: 1m 6s\tremaining: 6.35s\n",
            "11115:\tlearn: 7.6844599\ttotal: 1m 6s\tremaining: 6.35s\n",
            "11116:\tlearn: 7.6844498\ttotal: 1m 6s\tremaining: 6.34s\n",
            "11117:\tlearn: 7.6844241\ttotal: 1m 6s\tremaining: 6.33s\n",
            "11118:\tlearn: 7.6844085\ttotal: 1m 6s\tremaining: 6.33s\n",
            "11119:\tlearn: 7.6843992\ttotal: 1m 6s\tremaining: 6.32s\n",
            "11120:\tlearn: 7.6843879\ttotal: 1m 6s\tremaining: 6.32s\n",
            "11121:\tlearn: 7.6843810\ttotal: 1m 6s\tremaining: 6.31s\n",
            "11122:\tlearn: 7.6843697\ttotal: 1m 6s\tremaining: 6.3s\n",
            "11123:\tlearn: 7.6843616\ttotal: 1m 6s\tremaining: 6.3s\n",
            "11124:\tlearn: 7.6843541\ttotal: 1m 6s\tremaining: 6.29s\n",
            "11125:\tlearn: 7.6843431\ttotal: 1m 6s\tremaining: 6.29s\n",
            "11126:\tlearn: 7.6843289\ttotal: 1m 6s\tremaining: 6.28s\n",
            "11127:\tlearn: 7.6843179\ttotal: 1m 6s\tremaining: 6.28s\n",
            "11128:\tlearn: 7.6843055\ttotal: 1m 6s\tremaining: 6.27s\n",
            "11129:\tlearn: 7.6843035\ttotal: 1m 6s\tremaining: 6.26s\n",
            "11130:\tlearn: 7.6842948\ttotal: 1m 6s\tremaining: 6.26s\n",
            "11131:\tlearn: 7.6842824\ttotal: 1m 6s\tremaining: 6.25s\n",
            "11132:\tlearn: 7.6842754\ttotal: 1m 6s\tremaining: 6.25s\n",
            "11133:\tlearn: 7.6842592\ttotal: 1m 6s\tremaining: 6.24s\n",
            "11134:\tlearn: 7.6842422\ttotal: 1m 6s\tremaining: 6.23s\n",
            "11135:\tlearn: 7.6842352\ttotal: 1m 6s\tremaining: 6.23s\n",
            "11136:\tlearn: 7.6842303\ttotal: 1m 6s\tremaining: 6.22s\n",
            "11137:\tlearn: 7.6842179\ttotal: 1m 6s\tremaining: 6.21s\n",
            "11138:\tlearn: 7.6842043\ttotal: 1m 6s\tremaining: 6.21s\n",
            "11139:\tlearn: 7.6841878\ttotal: 1m 6s\tremaining: 6.2s\n",
            "11140:\tlearn: 7.6841667\ttotal: 1m 6s\tremaining: 6.2s\n",
            "11141:\tlearn: 7.6841624\ttotal: 1m 6s\tremaining: 6.19s\n",
            "11142:\tlearn: 7.6841496\ttotal: 1m 6s\tremaining: 6.18s\n",
            "11143:\tlearn: 7.6841314\ttotal: 1m 6s\tremaining: 6.18s\n",
            "11144:\tlearn: 7.6841250\ttotal: 1m 6s\tremaining: 6.17s\n",
            "11145:\tlearn: 7.6841210\ttotal: 1m 6s\tremaining: 6.17s\n",
            "11146:\tlearn: 7.6841123\ttotal: 1m 6s\tremaining: 6.16s\n",
            "11147:\tlearn: 7.6840915\ttotal: 1m 6s\tremaining: 6.16s\n",
            "11148:\tlearn: 7.6840817\ttotal: 1m 6s\tremaining: 6.15s\n",
            "11149:\tlearn: 7.6840744\ttotal: 1m 6s\tremaining: 6.14s\n",
            "11150:\tlearn: 7.6840597\ttotal: 1m 6s\tremaining: 6.14s\n",
            "11151:\tlearn: 7.6840545\ttotal: 1m 6s\tremaining: 6.13s\n",
            "11152:\tlearn: 7.6840386\ttotal: 1m 6s\tremaining: 6.13s\n",
            "11153:\tlearn: 7.6840282\ttotal: 1m 6s\tremaining: 6.12s\n",
            "11154:\tlearn: 7.6840206\ttotal: 1m 6s\tremaining: 6.11s\n",
            "11155:\tlearn: 7.6840099\ttotal: 1m 6s\tremaining: 6.11s\n",
            "11156:\tlearn: 7.6840059\ttotal: 1m 6s\tremaining: 6.1s\n",
            "11157:\tlearn: 7.6839943\ttotal: 1m 6s\tremaining: 6.1s\n",
            "11158:\tlearn: 7.6839703\ttotal: 1m 6s\tremaining: 6.09s\n",
            "11159:\tlearn: 7.6839657\ttotal: 1m 6s\tremaining: 6.08s\n",
            "11160:\tlearn: 7.6839515\ttotal: 1m 6s\tremaining: 6.08s\n",
            "11161:\tlearn: 7.6839345\ttotal: 1m 6s\tremaining: 6.07s\n",
            "11162:\tlearn: 7.6839249\ttotal: 1m 6s\tremaining: 6.07s\n",
            "11163:\tlearn: 7.6839122\ttotal: 1m 6s\tremaining: 6.06s\n",
            "11164:\tlearn: 7.6838948\ttotal: 1m 6s\tremaining: 6.05s\n",
            "11165:\tlearn: 7.6838844\ttotal: 1m 6s\tremaining: 6.05s\n",
            "11166:\tlearn: 7.6838746\ttotal: 1m 6s\tremaining: 6.04s\n",
            "11167:\tlearn: 7.6838717\ttotal: 1m 6s\tremaining: 6.04s\n",
            "11168:\tlearn: 7.6838570\ttotal: 1m 6s\tremaining: 6.03s\n",
            "11169:\tlearn: 7.6838439\ttotal: 1m 6s\tremaining: 6.03s\n",
            "11170:\tlearn: 7.6838330\ttotal: 1m 6s\tremaining: 6.02s\n",
            "11171:\tlearn: 7.6838257\ttotal: 1m 6s\tremaining: 6.01s\n",
            "11172:\tlearn: 7.6838197\ttotal: 1m 6s\tremaining: 6.01s\n",
            "11173:\tlearn: 7.6838144\ttotal: 1m 6s\tremaining: 6s\n",
            "11174:\tlearn: 7.6837997\ttotal: 1m 6s\tremaining: 6s\n",
            "11175:\tlearn: 7.6837945\ttotal: 1m 6s\tremaining: 5.99s\n",
            "11176:\tlearn: 7.6837841\ttotal: 1m 6s\tremaining: 5.98s\n",
            "11177:\tlearn: 7.6837745\ttotal: 1m 6s\tremaining: 5.98s\n",
            "11178:\tlearn: 7.6837604\ttotal: 1m 6s\tremaining: 5.97s\n",
            "11179:\tlearn: 7.6837511\ttotal: 1m 6s\tremaining: 5.97s\n",
            "11180:\tlearn: 7.6837366\ttotal: 1m 6s\tremaining: 5.96s\n",
            "11181:\tlearn: 7.6837228\ttotal: 1m 6s\tremaining: 5.95s\n",
            "11182:\tlearn: 7.6836979\ttotal: 1m 6s\tremaining: 5.95s\n",
            "11183:\tlearn: 7.6836840\ttotal: 1m 6s\tremaining: 5.94s\n",
            "11184:\tlearn: 7.6836722\ttotal: 1m 6s\tremaining: 5.94s\n",
            "11185:\tlearn: 7.6836641\ttotal: 1m 6s\tremaining: 5.93s\n",
            "11186:\tlearn: 7.6836580\ttotal: 1m 6s\tremaining: 5.92s\n",
            "11187:\tlearn: 7.6836447\ttotal: 1m 6s\tremaining: 5.92s\n",
            "11188:\tlearn: 7.6836198\ttotal: 1m 6s\tremaining: 5.91s\n",
            "11189:\tlearn: 7.6836140\ttotal: 1m 6s\tremaining: 5.91s\n",
            "11190:\tlearn: 7.6836030\ttotal: 1m 6s\tremaining: 5.9s\n",
            "11191:\tlearn: 7.6835877\ttotal: 1m 6s\tremaining: 5.89s\n",
            "11192:\tlearn: 7.6835782\ttotal: 1m 6s\tremaining: 5.89s\n",
            "11193:\tlearn: 7.6835576\ttotal: 1m 6s\tremaining: 5.88s\n",
            "11194:\tlearn: 7.6835406\ttotal: 1m 6s\tremaining: 5.88s\n",
            "11195:\tlearn: 7.6835264\ttotal: 1m 6s\tremaining: 5.87s\n",
            "11196:\tlearn: 7.6835073\ttotal: 1m 6s\tremaining: 5.87s\n",
            "11197:\tlearn: 7.6834975\ttotal: 1m 6s\tremaining: 5.86s\n",
            "11198:\tlearn: 7.6834833\ttotal: 1m 6s\tremaining: 5.85s\n",
            "11199:\tlearn: 7.6834668\ttotal: 1m 6s\tremaining: 5.85s\n",
            "11200:\tlearn: 7.6834564\ttotal: 1m 6s\tremaining: 5.84s\n",
            "11201:\tlearn: 7.6834440\ttotal: 1m 6s\tremaining: 5.83s\n",
            "11202:\tlearn: 7.6834324\ttotal: 1m 6s\tremaining: 5.83s\n",
            "11203:\tlearn: 7.6834292\ttotal: 1m 6s\tremaining: 5.82s\n",
            "11204:\tlearn: 7.6834237\ttotal: 1m 6s\tremaining: 5.82s\n",
            "11205:\tlearn: 7.6834136\ttotal: 1m 6s\tremaining: 5.81s\n",
            "11206:\tlearn: 7.6834040\ttotal: 1m 6s\tremaining: 5.81s\n",
            "11207:\tlearn: 7.6833936\ttotal: 1m 6s\tremaining: 5.8s\n",
            "11208:\tlearn: 7.6833766\ttotal: 1m 6s\tremaining: 5.79s\n",
            "11209:\tlearn: 7.6833627\ttotal: 1m 6s\tremaining: 5.79s\n",
            "11210:\tlearn: 7.6833505\ttotal: 1m 6s\tremaining: 5.78s\n",
            "11211:\tlearn: 7.6833474\ttotal: 1m 6s\tremaining: 5.78s\n",
            "11212:\tlearn: 7.6833289\ttotal: 1m 6s\tremaining: 5.77s\n",
            "11213:\tlearn: 7.6833155\ttotal: 1m 6s\tremaining: 5.76s\n",
            "11214:\tlearn: 7.6833109\ttotal: 1m 6s\tremaining: 5.76s\n",
            "11215:\tlearn: 7.6833034\ttotal: 1m 6s\tremaining: 5.75s\n",
            "11216:\tlearn: 7.6832840\ttotal: 1m 6s\tremaining: 5.75s\n",
            "11217:\tlearn: 7.6832791\ttotal: 1m 6s\tremaining: 5.74s\n",
            "11218:\tlearn: 7.6832652\ttotal: 1m 6s\tremaining: 5.73s\n",
            "11219:\tlearn: 7.6832542\ttotal: 1m 6s\tremaining: 5.73s\n",
            "11220:\tlearn: 7.6832409\ttotal: 1m 6s\tremaining: 5.72s\n",
            "11221:\tlearn: 7.6832320\ttotal: 1m 6s\tremaining: 5.72s\n",
            "11222:\tlearn: 7.6832166\ttotal: 1m 6s\tremaining: 5.71s\n",
            "11223:\tlearn: 7.6832120\ttotal: 1m 6s\tremaining: 5.71s\n",
            "11224:\tlearn: 7.6831975\ttotal: 1m 6s\tremaining: 5.7s\n",
            "11225:\tlearn: 7.6831889\ttotal: 1m 6s\tremaining: 5.69s\n",
            "11226:\tlearn: 7.6831761\ttotal: 1m 6s\tremaining: 5.69s\n",
            "11227:\tlearn: 7.6831628\ttotal: 1m 6s\tremaining: 5.68s\n",
            "11228:\tlearn: 7.6831487\ttotal: 1m 6s\tremaining: 5.68s\n",
            "11229:\tlearn: 7.6831400\ttotal: 1m 6s\tremaining: 5.67s\n",
            "11230:\tlearn: 7.6831241\ttotal: 1m 6s\tremaining: 5.66s\n",
            "11231:\tlearn: 7.6830998\ttotal: 1m 6s\tremaining: 5.66s\n",
            "11232:\tlearn: 7.6830740\ttotal: 1m 6s\tremaining: 5.65s\n",
            "11233:\tlearn: 7.6830526\ttotal: 1m 6s\tremaining: 5.65s\n",
            "11234:\tlearn: 7.6830393\ttotal: 1m 6s\tremaining: 5.64s\n",
            "11235:\tlearn: 7.6830278\ttotal: 1m 6s\tremaining: 5.63s\n",
            "11236:\tlearn: 7.6830202\ttotal: 1m 6s\tremaining: 5.63s\n",
            "11237:\tlearn: 7.6830150\ttotal: 1m 7s\tremaining: 5.62s\n",
            "11238:\tlearn: 7.6829957\ttotal: 1m 7s\tremaining: 5.62s\n",
            "11239:\tlearn: 7.6829899\ttotal: 1m 7s\tremaining: 5.61s\n",
            "11240:\tlearn: 7.6829751\ttotal: 1m 7s\tremaining: 5.6s\n",
            "11241:\tlearn: 7.6829638\ttotal: 1m 7s\tremaining: 5.6s\n",
            "11242:\tlearn: 7.6829442\ttotal: 1m 7s\tremaining: 5.59s\n",
            "11243:\tlearn: 7.6829335\ttotal: 1m 7s\tremaining: 5.59s\n",
            "11244:\tlearn: 7.6829291\ttotal: 1m 7s\tremaining: 5.58s\n",
            "11245:\tlearn: 7.6829129\ttotal: 1m 7s\tremaining: 5.58s\n",
            "11246:\tlearn: 7.6829028\ttotal: 1m 7s\tremaining: 5.57s\n",
            "11247:\tlearn: 7.6828959\ttotal: 1m 7s\tremaining: 5.56s\n",
            "11248:\tlearn: 7.6828820\ttotal: 1m 7s\tremaining: 5.56s\n",
            "11249:\tlearn: 7.6828701\ttotal: 1m 7s\tremaining: 5.55s\n",
            "11250:\tlearn: 7.6828568\ttotal: 1m 7s\tremaining: 5.55s\n",
            "11251:\tlearn: 7.6828499\ttotal: 1m 7s\tremaining: 5.54s\n",
            "11252:\tlearn: 7.6828398\ttotal: 1m 7s\tremaining: 5.53s\n",
            "11253:\tlearn: 7.6828331\ttotal: 1m 7s\tremaining: 5.53s\n",
            "11254:\tlearn: 7.6828293\ttotal: 1m 7s\tremaining: 5.52s\n",
            "11255:\tlearn: 7.6828186\ttotal: 1m 7s\tremaining: 5.52s\n",
            "11256:\tlearn: 7.6827998\ttotal: 1m 7s\tremaining: 5.51s\n",
            "11257:\tlearn: 7.6827920\ttotal: 1m 7s\tremaining: 5.5s\n",
            "11258:\tlearn: 7.6827831\ttotal: 1m 7s\tremaining: 5.5s\n",
            "11259:\tlearn: 7.6827758\ttotal: 1m 7s\tremaining: 5.49s\n",
            "11260:\tlearn: 7.6827625\ttotal: 1m 7s\tremaining: 5.49s\n",
            "11261:\tlearn: 7.6827567\ttotal: 1m 7s\tremaining: 5.48s\n",
            "11262:\tlearn: 7.6827452\ttotal: 1m 7s\tremaining: 5.48s\n",
            "11263:\tlearn: 7.6827400\ttotal: 1m 7s\tremaining: 5.47s\n",
            "11264:\tlearn: 7.6827278\ttotal: 1m 7s\tremaining: 5.46s\n",
            "11265:\tlearn: 7.6827188\ttotal: 1m 7s\tremaining: 5.46s\n",
            "11266:\tlearn: 7.6827122\ttotal: 1m 7s\tremaining: 5.45s\n",
            "11267:\tlearn: 7.6827029\ttotal: 1m 7s\tremaining: 5.45s\n",
            "11268:\tlearn: 7.6826977\ttotal: 1m 7s\tremaining: 5.44s\n",
            "11269:\tlearn: 7.6826867\ttotal: 1m 7s\tremaining: 5.43s\n",
            "11270:\tlearn: 7.6826763\ttotal: 1m 7s\tremaining: 5.43s\n",
            "11271:\tlearn: 7.6826679\ttotal: 1m 7s\tremaining: 5.42s\n",
            "11272:\tlearn: 7.6826373\ttotal: 1m 7s\tremaining: 5.42s\n",
            "11273:\tlearn: 7.6826309\ttotal: 1m 7s\tremaining: 5.41s\n",
            "11274:\tlearn: 7.6826283\ttotal: 1m 7s\tremaining: 5.4s\n",
            "11275:\tlearn: 7.6826008\ttotal: 1m 7s\tremaining: 5.4s\n",
            "11276:\tlearn: 7.6825901\ttotal: 1m 7s\tremaining: 5.39s\n",
            "11277:\tlearn: 7.6825774\ttotal: 1m 7s\tremaining: 5.39s\n",
            "11278:\tlearn: 7.6825655\ttotal: 1m 7s\tremaining: 5.38s\n",
            "11279:\tlearn: 7.6825450\ttotal: 1m 7s\tremaining: 5.38s\n",
            "11280:\tlearn: 7.6825340\ttotal: 1m 7s\tremaining: 5.37s\n",
            "11281:\tlearn: 7.6825230\ttotal: 1m 7s\tremaining: 5.36s\n",
            "11282:\tlearn: 7.6825057\ttotal: 1m 7s\tremaining: 5.36s\n",
            "11283:\tlearn: 7.6825025\ttotal: 1m 7s\tremaining: 5.35s\n",
            "11284:\tlearn: 7.6824866\ttotal: 1m 7s\tremaining: 5.34s\n",
            "11285:\tlearn: 7.6824710\ttotal: 1m 7s\tremaining: 5.34s\n",
            "11286:\tlearn: 7.6824631\ttotal: 1m 7s\tremaining: 5.33s\n",
            "11287:\tlearn: 7.6824406\ttotal: 1m 7s\tremaining: 5.33s\n",
            "11288:\tlearn: 7.6824284\ttotal: 1m 7s\tremaining: 5.32s\n",
            "11289:\tlearn: 7.6824047\ttotal: 1m 7s\tremaining: 5.32s\n",
            "11290:\tlearn: 7.6823929\ttotal: 1m 7s\tremaining: 5.31s\n",
            "11291:\tlearn: 7.6823804\ttotal: 1m 7s\tremaining: 5.3s\n",
            "11292:\tlearn: 7.6823706\ttotal: 1m 7s\tremaining: 5.3s\n",
            "11293:\tlearn: 7.6823576\ttotal: 1m 7s\tremaining: 5.29s\n",
            "11294:\tlearn: 7.6823532\ttotal: 1m 7s\tremaining: 5.29s\n",
            "11295:\tlearn: 7.6823437\ttotal: 1m 7s\tremaining: 5.28s\n",
            "11296:\tlearn: 7.6823405\ttotal: 1m 7s\tremaining: 5.27s\n",
            "11297:\tlearn: 7.6823266\ttotal: 1m 7s\tremaining: 5.27s\n",
            "11298:\tlearn: 7.6823119\ttotal: 1m 7s\tremaining: 5.26s\n",
            "11299:\tlearn: 7.6822928\ttotal: 1m 7s\tremaining: 5.26s\n",
            "11300:\tlearn: 7.6822826\ttotal: 1m 7s\tremaining: 5.25s\n",
            "11301:\tlearn: 7.6822737\ttotal: 1m 7s\tremaining: 5.24s\n",
            "11302:\tlearn: 7.6822641\ttotal: 1m 7s\tremaining: 5.24s\n",
            "11303:\tlearn: 7.6822566\ttotal: 1m 7s\tremaining: 5.23s\n",
            "11304:\tlearn: 7.6822427\ttotal: 1m 7s\tremaining: 5.23s\n",
            "11305:\tlearn: 7.6822286\ttotal: 1m 7s\tremaining: 5.22s\n",
            "11306:\tlearn: 7.6822196\ttotal: 1m 7s\tremaining: 5.21s\n",
            "11307:\tlearn: 7.6822069\ttotal: 1m 7s\tremaining: 5.21s\n",
            "11308:\tlearn: 7.6821950\ttotal: 1m 7s\tremaining: 5.2s\n",
            "11309:\tlearn: 7.6821924\ttotal: 1m 7s\tremaining: 5.2s\n",
            "11310:\tlearn: 7.6821750\ttotal: 1m 7s\tremaining: 5.19s\n",
            "11311:\tlearn: 7.6821721\ttotal: 1m 7s\tremaining: 5.18s\n",
            "11312:\tlearn: 7.6821559\ttotal: 1m 7s\tremaining: 5.18s\n",
            "11313:\tlearn: 7.6821481\ttotal: 1m 7s\tremaining: 5.17s\n",
            "11314:\tlearn: 7.6821377\ttotal: 1m 7s\tremaining: 5.17s\n",
            "11315:\tlearn: 7.6821305\ttotal: 1m 7s\tremaining: 5.16s\n",
            "11316:\tlearn: 7.6821227\ttotal: 1m 7s\tremaining: 5.16s\n",
            "11317:\tlearn: 7.6821160\ttotal: 1m 7s\tremaining: 5.15s\n",
            "11318:\tlearn: 7.6820993\ttotal: 1m 7s\tremaining: 5.14s\n",
            "11319:\tlearn: 7.6820874\ttotal: 1m 7s\tremaining: 5.14s\n",
            "11320:\tlearn: 7.6820813\ttotal: 1m 7s\tremaining: 5.13s\n",
            "11321:\tlearn: 7.6820767\ttotal: 1m 7s\tremaining: 5.13s\n",
            "11322:\tlearn: 7.6820582\ttotal: 1m 7s\tremaining: 5.12s\n",
            "11323:\tlearn: 7.6820431\ttotal: 1m 7s\tremaining: 5.11s\n",
            "11324:\tlearn: 7.6820359\ttotal: 1m 7s\tremaining: 5.11s\n",
            "11325:\tlearn: 7.6820292\ttotal: 1m 7s\tremaining: 5.1s\n",
            "11326:\tlearn: 7.6820217\ttotal: 1m 7s\tremaining: 5.09s\n",
            "11327:\tlearn: 7.6820128\ttotal: 1m 7s\tremaining: 5.09s\n",
            "11328:\tlearn: 7.6819966\ttotal: 1m 7s\tremaining: 5.08s\n",
            "11329:\tlearn: 7.6819844\ttotal: 1m 7s\tremaining: 5.08s\n",
            "11330:\tlearn: 7.6819775\ttotal: 1m 7s\tremaining: 5.07s\n",
            "11331:\tlearn: 7.6819644\ttotal: 1m 7s\tremaining: 5.07s\n",
            "11332:\tlearn: 7.6819601\ttotal: 1m 7s\tremaining: 5.06s\n",
            "11333:\tlearn: 7.6819436\ttotal: 1m 7s\tremaining: 5.05s\n",
            "11334:\tlearn: 7.6819286\ttotal: 1m 7s\tremaining: 5.05s\n",
            "11335:\tlearn: 7.6819158\ttotal: 1m 7s\tremaining: 5.04s\n",
            "11336:\tlearn: 7.6818999\ttotal: 1m 7s\tremaining: 5.04s\n",
            "11337:\tlearn: 7.6818927\ttotal: 1m 7s\tremaining: 5.03s\n",
            "11338:\tlearn: 7.6818861\ttotal: 1m 7s\tremaining: 5.02s\n",
            "11339:\tlearn: 7.6818681\ttotal: 1m 7s\tremaining: 5.02s\n",
            "11340:\tlearn: 7.6818539\ttotal: 1m 7s\tremaining: 5.01s\n",
            "11341:\tlearn: 7.6818403\ttotal: 1m 7s\tremaining: 5s\n",
            "11342:\tlearn: 7.6818380\ttotal: 1m 7s\tremaining: 5s\n",
            "11343:\tlearn: 7.6818296\ttotal: 1m 7s\tremaining: 4.99s\n",
            "11344:\tlearn: 7.6818192\ttotal: 1m 7s\tremaining: 4.99s\n",
            "11345:\tlearn: 7.6818126\ttotal: 1m 7s\tremaining: 4.98s\n",
            "11346:\tlearn: 7.6818123\ttotal: 1m 7s\tremaining: 4.97s\n",
            "11347:\tlearn: 7.6817926\ttotal: 1m 7s\tremaining: 4.97s\n",
            "11348:\tlearn: 7.6817741\ttotal: 1m 7s\tremaining: 4.96s\n",
            "11349:\tlearn: 7.6817631\ttotal: 1m 7s\tremaining: 4.96s\n",
            "11350:\tlearn: 7.6817489\ttotal: 1m 7s\tremaining: 4.95s\n",
            "11351:\tlearn: 7.6817426\ttotal: 1m 7s\tremaining: 4.95s\n",
            "11352:\tlearn: 7.6817362\ttotal: 1m 7s\tremaining: 4.94s\n",
            "11353:\tlearn: 7.6817298\ttotal: 1m 7s\tremaining: 4.93s\n",
            "11354:\tlearn: 7.6817226\ttotal: 1m 7s\tremaining: 4.93s\n",
            "11355:\tlearn: 7.6817160\ttotal: 1m 7s\tremaining: 4.92s\n",
            "11356:\tlearn: 7.6816972\ttotal: 1m 7s\tremaining: 4.92s\n",
            "11357:\tlearn: 7.6816925\ttotal: 1m 7s\tremaining: 4.91s\n",
            "11358:\tlearn: 7.6816830\ttotal: 1m 7s\tremaining: 4.91s\n",
            "11359:\tlearn: 7.6816781\ttotal: 1m 7s\tremaining: 4.9s\n",
            "11360:\tlearn: 7.6816662\ttotal: 1m 7s\tremaining: 4.89s\n",
            "11361:\tlearn: 7.6816558\ttotal: 1m 7s\tremaining: 4.89s\n",
            "11362:\tlearn: 7.6816404\ttotal: 1m 7s\tremaining: 4.88s\n",
            "11363:\tlearn: 7.6816373\ttotal: 1m 7s\tremaining: 4.88s\n",
            "11364:\tlearn: 7.6816289\ttotal: 1m 7s\tremaining: 4.87s\n",
            "11365:\tlearn: 7.6816292\ttotal: 1m 7s\tremaining: 4.86s\n",
            "11366:\tlearn: 7.6816179\ttotal: 1m 7s\tremaining: 4.86s\n",
            "11367:\tlearn: 7.6816083\ttotal: 1m 7s\tremaining: 4.85s\n",
            "11368:\tlearn: 7.6815947\ttotal: 1m 7s\tremaining: 4.84s\n",
            "11369:\tlearn: 7.6815780\ttotal: 1m 7s\tremaining: 4.84s\n",
            "11370:\tlearn: 7.6815739\ttotal: 1m 7s\tremaining: 4.83s\n",
            "11371:\tlearn: 7.6815621\ttotal: 1m 7s\tremaining: 4.83s\n",
            "11372:\tlearn: 7.6815554\ttotal: 1m 7s\tremaining: 4.82s\n",
            "11373:\tlearn: 7.6815421\ttotal: 1m 7s\tremaining: 4.82s\n",
            "11374:\tlearn: 7.6815285\ttotal: 1m 7s\tremaining: 4.81s\n",
            "11375:\tlearn: 7.6815230\ttotal: 1m 7s\tremaining: 4.8s\n",
            "11376:\tlearn: 7.6814993\ttotal: 1m 7s\tremaining: 4.8s\n",
            "11377:\tlearn: 7.6814938\ttotal: 1m 7s\tremaining: 4.79s\n",
            "11378:\tlearn: 7.6814767\ttotal: 1m 7s\tremaining: 4.79s\n",
            "11379:\tlearn: 7.6814585\ttotal: 1m 7s\tremaining: 4.78s\n",
            "11380:\tlearn: 7.6814495\ttotal: 1m 7s\tremaining: 4.77s\n",
            "11381:\tlearn: 7.6814469\ttotal: 1m 7s\tremaining: 4.77s\n",
            "11382:\tlearn: 7.6814351\ttotal: 1m 7s\tremaining: 4.76s\n",
            "11383:\tlearn: 7.6814324\ttotal: 1m 7s\tremaining: 4.76s\n",
            "11384:\tlearn: 7.6814249\ttotal: 1m 7s\tremaining: 4.75s\n",
            "11385:\tlearn: 7.6814012\ttotal: 1m 7s\tremaining: 4.74s\n",
            "11386:\tlearn: 7.6813963\ttotal: 1m 7s\tremaining: 4.74s\n",
            "11387:\tlearn: 7.6813864\ttotal: 1m 7s\tremaining: 4.73s\n",
            "11388:\tlearn: 7.6813746\ttotal: 1m 7s\tremaining: 4.73s\n",
            "11389:\tlearn: 7.6813633\ttotal: 1m 7s\tremaining: 4.72s\n",
            "11390:\tlearn: 7.6813584\ttotal: 1m 7s\tremaining: 4.71s\n",
            "11391:\tlearn: 7.6813538\ttotal: 1m 7s\tremaining: 4.71s\n",
            "11392:\tlearn: 7.6813338\ttotal: 1m 7s\tremaining: 4.7s\n",
            "11393:\tlearn: 7.6813214\ttotal: 1m 8s\tremaining: 4.7s\n",
            "11394:\tlearn: 7.6813054\ttotal: 1m 8s\tremaining: 4.69s\n",
            "11395:\tlearn: 7.6812942\ttotal: 1m 8s\tremaining: 4.68s\n",
            "11396:\tlearn: 7.6812837\ttotal: 1m 8s\tremaining: 4.68s\n",
            "11397:\tlearn: 7.6812794\ttotal: 1m 8s\tremaining: 4.67s\n",
            "11398:\tlearn: 7.6812647\ttotal: 1m 8s\tremaining: 4.67s\n",
            "11399:\tlearn: 7.6812522\ttotal: 1m 8s\tremaining: 4.66s\n",
            "11400:\tlearn: 7.6812317\ttotal: 1m 8s\tremaining: 4.66s\n",
            "11401:\tlearn: 7.6812201\ttotal: 1m 8s\tremaining: 4.65s\n",
            "11402:\tlearn: 7.6812077\ttotal: 1m 8s\tremaining: 4.64s\n",
            "11403:\tlearn: 7.6812001\ttotal: 1m 8s\tremaining: 4.64s\n",
            "11404:\tlearn: 7.6811906\ttotal: 1m 8s\tremaining: 4.63s\n",
            "11405:\tlearn: 7.6811808\ttotal: 1m 8s\tremaining: 4.63s\n",
            "11406:\tlearn: 7.6811747\ttotal: 1m 8s\tremaining: 4.62s\n",
            "11407:\tlearn: 7.6811605\ttotal: 1m 8s\tremaining: 4.61s\n",
            "11408:\tlearn: 7.6811536\ttotal: 1m 8s\tremaining: 4.61s\n",
            "11409:\tlearn: 7.6811495\ttotal: 1m 8s\tremaining: 4.6s\n",
            "11410:\tlearn: 7.6811405\ttotal: 1m 8s\tremaining: 4.59s\n",
            "11411:\tlearn: 7.6811324\ttotal: 1m 8s\tremaining: 4.59s\n",
            "11412:\tlearn: 7.6811310\ttotal: 1m 8s\tremaining: 4.58s\n",
            "11413:\tlearn: 7.6811261\ttotal: 1m 8s\tremaining: 4.58s\n",
            "11414:\tlearn: 7.6811107\ttotal: 1m 8s\tremaining: 4.57s\n",
            "11415:\tlearn: 7.6811076\ttotal: 1m 8s\tremaining: 4.57s\n",
            "11416:\tlearn: 7.6810989\ttotal: 1m 8s\tremaining: 4.56s\n",
            "11417:\tlearn: 7.6810888\ttotal: 1m 8s\tremaining: 4.55s\n",
            "11418:\tlearn: 7.6810786\ttotal: 1m 8s\tremaining: 4.55s\n",
            "11419:\tlearn: 7.6810656\ttotal: 1m 8s\tremaining: 4.54s\n",
            "11420:\tlearn: 7.6810549\ttotal: 1m 8s\tremaining: 4.54s\n",
            "11421:\tlearn: 7.6810483\ttotal: 1m 8s\tremaining: 4.53s\n",
            "11422:\tlearn: 7.6810318\ttotal: 1m 8s\tremaining: 4.52s\n",
            "11423:\tlearn: 7.6810066\ttotal: 1m 8s\tremaining: 4.52s\n",
            "11424:\tlearn: 7.6809962\ttotal: 1m 8s\tremaining: 4.51s\n",
            "11425:\tlearn: 7.6809858\ttotal: 1m 8s\tremaining: 4.51s\n",
            "11426:\tlearn: 7.6809661\ttotal: 1m 8s\tremaining: 4.5s\n",
            "11427:\tlearn: 7.6809574\ttotal: 1m 8s\tremaining: 4.5s\n",
            "11428:\tlearn: 7.6809510\ttotal: 1m 8s\tremaining: 4.49s\n",
            "11429:\tlearn: 7.6809476\ttotal: 1m 8s\tremaining: 4.48s\n",
            "11430:\tlearn: 7.6809360\ttotal: 1m 8s\tremaining: 4.48s\n",
            "11431:\tlearn: 7.6809244\ttotal: 1m 8s\tremaining: 4.47s\n",
            "11432:\tlearn: 7.6809091\ttotal: 1m 8s\tremaining: 4.46s\n",
            "11433:\tlearn: 7.6808975\ttotal: 1m 8s\tremaining: 4.46s\n",
            "11434:\tlearn: 7.6808897\ttotal: 1m 8s\tremaining: 4.45s\n",
            "11435:\tlearn: 7.6808825\ttotal: 1m 8s\tremaining: 4.45s\n",
            "11436:\tlearn: 7.6808631\ttotal: 1m 8s\tremaining: 4.44s\n",
            "11437:\tlearn: 7.6808550\ttotal: 1m 8s\tremaining: 4.43s\n",
            "11438:\tlearn: 7.6808486\ttotal: 1m 8s\tremaining: 4.43s\n",
            "11439:\tlearn: 7.6808397\ttotal: 1m 8s\tremaining: 4.42s\n",
            "11440:\tlearn: 7.6808255\ttotal: 1m 8s\tremaining: 4.42s\n",
            "11441:\tlearn: 7.6808200\ttotal: 1m 8s\tremaining: 4.41s\n",
            "11442:\tlearn: 7.6808127\ttotal: 1m 8s\tremaining: 4.41s\n",
            "11443:\tlearn: 7.6807991\ttotal: 1m 8s\tremaining: 4.4s\n",
            "11444:\tlearn: 7.6807876\ttotal: 1m 8s\tremaining: 4.39s\n",
            "11445:\tlearn: 7.6807734\ttotal: 1m 8s\tremaining: 4.39s\n",
            "11446:\tlearn: 7.6807586\ttotal: 1m 8s\tremaining: 4.38s\n",
            "11447:\tlearn: 7.6807459\ttotal: 1m 8s\tremaining: 4.38s\n",
            "11448:\tlearn: 7.6807416\ttotal: 1m 8s\tremaining: 4.37s\n",
            "11449:\tlearn: 7.6807314\ttotal: 1m 8s\tremaining: 4.36s\n",
            "11450:\tlearn: 7.6807239\ttotal: 1m 8s\tremaining: 4.36s\n",
            "11451:\tlearn: 7.6807115\ttotal: 1m 8s\tremaining: 4.35s\n",
            "11452:\tlearn: 7.6807019\ttotal: 1m 8s\tremaining: 4.34s\n",
            "11453:\tlearn: 7.6806967\ttotal: 1m 8s\tremaining: 4.34s\n",
            "11454:\tlearn: 7.6806788\ttotal: 1m 8s\tremaining: 4.33s\n",
            "11455:\tlearn: 7.6806663\ttotal: 1m 8s\tremaining: 4.33s\n",
            "11456:\tlearn: 7.6806620\ttotal: 1m 8s\tremaining: 4.32s\n",
            "11457:\tlearn: 7.6806562\ttotal: 1m 8s\tremaining: 4.32s\n",
            "11458:\tlearn: 7.6806406\ttotal: 1m 8s\tremaining: 4.31s\n",
            "11459:\tlearn: 7.6806360\ttotal: 1m 8s\tremaining: 4.3s\n",
            "11460:\tlearn: 7.6806229\ttotal: 1m 8s\tremaining: 4.3s\n",
            "11461:\tlearn: 7.6806180\ttotal: 1m 8s\tremaining: 4.29s\n",
            "11462:\tlearn: 7.6806169\ttotal: 1m 8s\tremaining: 4.29s\n",
            "11463:\tlearn: 7.6806062\ttotal: 1m 8s\tremaining: 4.28s\n",
            "11464:\tlearn: 7.6805917\ttotal: 1m 8s\tremaining: 4.27s\n",
            "11465:\tlearn: 7.6805752\ttotal: 1m 8s\tremaining: 4.27s\n",
            "11466:\tlearn: 7.6805749\ttotal: 1m 8s\tremaining: 4.26s\n",
            "11467:\tlearn: 7.6805642\ttotal: 1m 8s\tremaining: 4.26s\n",
            "11468:\tlearn: 7.6805515\ttotal: 1m 8s\tremaining: 4.25s\n",
            "11469:\tlearn: 7.6805445\ttotal: 1m 8s\tremaining: 4.24s\n",
            "11470:\tlearn: 7.6805321\ttotal: 1m 8s\tremaining: 4.24s\n",
            "11471:\tlearn: 7.6805173\ttotal: 1m 8s\tremaining: 4.23s\n",
            "11472:\tlearn: 7.6805133\ttotal: 1m 8s\tremaining: 4.23s\n",
            "11473:\tlearn: 7.6805058\ttotal: 1m 8s\tremaining: 4.22s\n",
            "11474:\tlearn: 7.6804951\ttotal: 1m 8s\tremaining: 4.21s\n",
            "11475:\tlearn: 7.6804812\ttotal: 1m 8s\tremaining: 4.21s\n",
            "11476:\tlearn: 7.6804774\ttotal: 1m 8s\tremaining: 4.2s\n",
            "11477:\tlearn: 7.6804673\ttotal: 1m 8s\tremaining: 4.2s\n",
            "11478:\tlearn: 7.6804595\ttotal: 1m 8s\tremaining: 4.19s\n",
            "11479:\tlearn: 7.6804534\ttotal: 1m 8s\tremaining: 4.18s\n",
            "11480:\tlearn: 7.6804375\ttotal: 1m 8s\tremaining: 4.18s\n",
            "11481:\tlearn: 7.6804294\ttotal: 1m 8s\tremaining: 4.17s\n",
            "11482:\tlearn: 7.6804227\ttotal: 1m 8s\tremaining: 4.17s\n",
            "11483:\tlearn: 7.6804062\ttotal: 1m 8s\tremaining: 4.16s\n",
            "11484:\tlearn: 7.6803996\ttotal: 1m 8s\tremaining: 4.16s\n",
            "11485:\tlearn: 7.6803938\ttotal: 1m 8s\tremaining: 4.15s\n",
            "11486:\tlearn: 7.6803799\ttotal: 1m 8s\tremaining: 4.14s\n",
            "11487:\tlearn: 7.6803643\ttotal: 1m 8s\tremaining: 4.14s\n",
            "11488:\tlearn: 7.6803562\ttotal: 1m 8s\tremaining: 4.13s\n",
            "11489:\tlearn: 7.6803487\ttotal: 1m 8s\tremaining: 4.13s\n",
            "11490:\tlearn: 7.6803359\ttotal: 1m 8s\tremaining: 4.12s\n",
            "11491:\tlearn: 7.6803255\ttotal: 1m 8s\tremaining: 4.11s\n",
            "11492:\tlearn: 7.6803110\ttotal: 1m 8s\tremaining: 4.11s\n",
            "11493:\tlearn: 7.6803058\ttotal: 1m 8s\tremaining: 4.1s\n",
            "11494:\tlearn: 7.6802931\ttotal: 1m 8s\tremaining: 4.09s\n",
            "11495:\tlearn: 7.6802656\ttotal: 1m 8s\tremaining: 4.09s\n",
            "11496:\tlearn: 7.6802656\ttotal: 1m 8s\tremaining: 4.08s\n",
            "11497:\tlearn: 7.6802517\ttotal: 1m 8s\tremaining: 4.08s\n",
            "11498:\tlearn: 7.6802425\ttotal: 1m 8s\tremaining: 4.07s\n",
            "11499:\tlearn: 7.6802234\ttotal: 1m 8s\tremaining: 4.07s\n",
            "11500:\tlearn: 7.6802023\ttotal: 1m 8s\tremaining: 4.06s\n",
            "11501:\tlearn: 7.6801973\ttotal: 1m 8s\tremaining: 4.05s\n",
            "11502:\tlearn: 7.6801768\ttotal: 1m 8s\tremaining: 4.05s\n",
            "11503:\tlearn: 7.6801713\ttotal: 1m 8s\tremaining: 4.04s\n",
            "11504:\tlearn: 7.6801580\ttotal: 1m 8s\tremaining: 4.04s\n",
            "11505:\tlearn: 7.6801438\ttotal: 1m 8s\tremaining: 4.03s\n",
            "11506:\tlearn: 7.6801398\ttotal: 1m 8s\tremaining: 4.02s\n",
            "11507:\tlearn: 7.6801343\ttotal: 1m 8s\tremaining: 4.02s\n",
            "11508:\tlearn: 7.6801276\ttotal: 1m 8s\tremaining: 4.01s\n",
            "11509:\tlearn: 7.6801221\ttotal: 1m 8s\tremaining: 4s\n",
            "11510:\tlearn: 7.6801207\ttotal: 1m 8s\tremaining: 4s\n",
            "11511:\tlearn: 7.6800926\ttotal: 1m 8s\tremaining: 3.99s\n",
            "11512:\tlearn: 7.6800825\ttotal: 1m 8s\tremaining: 3.99s\n",
            "11513:\tlearn: 7.6800660\ttotal: 1m 8s\tremaining: 3.98s\n",
            "11514:\tlearn: 7.6800414\ttotal: 1m 8s\tremaining: 3.98s\n",
            "11515:\tlearn: 7.6800370\ttotal: 1m 8s\tremaining: 3.97s\n",
            "11516:\tlearn: 7.6800260\ttotal: 1m 8s\tremaining: 3.96s\n",
            "11517:\tlearn: 7.6800220\ttotal: 1m 8s\tremaining: 3.96s\n",
            "11518:\tlearn: 7.6800119\ttotal: 1m 8s\tremaining: 3.95s\n",
            "11519:\tlearn: 7.6799925\ttotal: 1m 8s\tremaining: 3.95s\n",
            "11520:\tlearn: 7.6799884\ttotal: 1m 8s\tremaining: 3.94s\n",
            "11521:\tlearn: 7.6799760\ttotal: 1m 8s\tremaining: 3.93s\n",
            "11522:\tlearn: 7.6799659\ttotal: 1m 8s\tremaining: 3.93s\n",
            "11523:\tlearn: 7.6799575\ttotal: 1m 8s\tremaining: 3.92s\n",
            "11524:\tlearn: 7.6799404\ttotal: 1m 8s\tremaining: 3.92s\n",
            "11525:\tlearn: 7.6799389\ttotal: 1m 8s\tremaining: 3.91s\n",
            "11526:\tlearn: 7.6799361\ttotal: 1m 8s\tremaining: 3.9s\n",
            "11527:\tlearn: 7.6799300\ttotal: 1m 8s\tremaining: 3.9s\n",
            "11528:\tlearn: 7.6799204\ttotal: 1m 8s\tremaining: 3.89s\n",
            "11529:\tlearn: 7.6799065\ttotal: 1m 8s\tremaining: 3.89s\n",
            "11530:\tlearn: 7.6798967\ttotal: 1m 8s\tremaining: 3.88s\n",
            "11531:\tlearn: 7.6798941\ttotal: 1m 8s\tremaining: 3.87s\n",
            "11532:\tlearn: 7.6798918\ttotal: 1m 8s\tremaining: 3.87s\n",
            "11533:\tlearn: 7.6798620\ttotal: 1m 8s\tremaining: 3.86s\n",
            "11534:\tlearn: 7.6798495\ttotal: 1m 8s\tremaining: 3.86s\n",
            "11535:\tlearn: 7.6798449\ttotal: 1m 8s\tremaining: 3.85s\n",
            "11536:\tlearn: 7.6798301\ttotal: 1m 8s\tremaining: 3.84s\n",
            "11537:\tlearn: 7.6798050\ttotal: 1m 8s\tremaining: 3.84s\n",
            "11538:\tlearn: 7.6797896\ttotal: 1m 8s\tremaining: 3.83s\n",
            "11539:\tlearn: 7.6797766\ttotal: 1m 8s\tremaining: 3.83s\n",
            "11540:\tlearn: 7.6797653\ttotal: 1m 8s\tremaining: 3.82s\n",
            "11541:\tlearn: 7.6797445\ttotal: 1m 8s\tremaining: 3.81s\n",
            "11542:\tlearn: 7.6797355\ttotal: 1m 8s\tremaining: 3.81s\n",
            "11543:\tlearn: 7.6797318\ttotal: 1m 8s\tremaining: 3.8s\n",
            "11544:\tlearn: 7.6797205\ttotal: 1m 8s\tremaining: 3.8s\n",
            "11545:\tlearn: 7.6797063\ttotal: 1m 8s\tremaining: 3.79s\n",
            "11546:\tlearn: 7.6796962\ttotal: 1m 8s\tremaining: 3.78s\n",
            "11547:\tlearn: 7.6796918\ttotal: 1m 8s\tremaining: 3.78s\n",
            "11548:\tlearn: 7.6796814\ttotal: 1m 8s\tremaining: 3.77s\n",
            "11549:\tlearn: 7.6796696\ttotal: 1m 8s\tremaining: 3.77s\n",
            "11550:\tlearn: 7.6796620\ttotal: 1m 8s\tremaining: 3.76s\n",
            "11551:\tlearn: 7.6796429\ttotal: 1m 8s\tremaining: 3.75s\n",
            "11552:\tlearn: 7.6796366\ttotal: 1m 8s\tremaining: 3.75s\n",
            "11553:\tlearn: 7.6796154\ttotal: 1m 8s\tremaining: 3.74s\n",
            "11554:\tlearn: 7.6796082\ttotal: 1m 8s\tremaining: 3.74s\n",
            "11555:\tlearn: 7.6796039\ttotal: 1m 8s\tremaining: 3.73s\n",
            "11556:\tlearn: 7.6796021\ttotal: 1m 8s\tremaining: 3.73s\n",
            "11557:\tlearn: 7.6795992\ttotal: 1m 9s\tremaining: 3.72s\n",
            "11558:\tlearn: 7.6795877\ttotal: 1m 9s\tremaining: 3.71s\n",
            "11559:\tlearn: 7.6795691\ttotal: 1m 9s\tremaining: 3.71s\n",
            "11560:\tlearn: 7.6795561\ttotal: 1m 9s\tremaining: 3.7s\n",
            "11561:\tlearn: 7.6795353\ttotal: 1m 9s\tremaining: 3.69s\n",
            "11562:\tlearn: 7.6795214\ttotal: 1m 9s\tremaining: 3.69s\n",
            "11563:\tlearn: 7.6795142\ttotal: 1m 9s\tremaining: 3.68s\n",
            "11564:\tlearn: 7.6795049\ttotal: 1m 9s\tremaining: 3.68s\n",
            "11565:\tlearn: 7.6794965\ttotal: 1m 9s\tremaining: 3.67s\n",
            "11566:\tlearn: 7.6794826\ttotal: 1m 9s\tremaining: 3.67s\n",
            "11567:\tlearn: 7.6794818\ttotal: 1m 9s\tremaining: 3.66s\n",
            "11568:\tlearn: 7.6794713\ttotal: 1m 9s\tremaining: 3.65s\n",
            "11569:\tlearn: 7.6794627\ttotal: 1m 9s\tremaining: 3.65s\n",
            "11570:\tlearn: 7.6794470\ttotal: 1m 9s\tremaining: 3.64s\n",
            "11571:\tlearn: 7.6794415\ttotal: 1m 9s\tremaining: 3.63s\n",
            "11572:\tlearn: 7.6794308\ttotal: 1m 9s\tremaining: 3.63s\n",
            "11573:\tlearn: 7.6794207\ttotal: 1m 9s\tremaining: 3.62s\n",
            "11574:\tlearn: 7.6794126\ttotal: 1m 9s\tremaining: 3.62s\n",
            "11575:\tlearn: 7.6794025\ttotal: 1m 9s\tremaining: 3.61s\n",
            "11576:\tlearn: 7.6793897\ttotal: 1m 9s\tremaining: 3.6s\n",
            "11577:\tlearn: 7.6793808\ttotal: 1m 9s\tremaining: 3.6s\n",
            "11578:\tlearn: 7.6793608\ttotal: 1m 9s\tremaining: 3.59s\n",
            "11579:\tlearn: 7.6793429\ttotal: 1m 9s\tremaining: 3.59s\n",
            "11580:\tlearn: 7.6793356\ttotal: 1m 9s\tremaining: 3.58s\n",
            "11581:\tlearn: 7.6793235\ttotal: 1m 9s\tremaining: 3.58s\n",
            "11582:\tlearn: 7.6793157\ttotal: 1m 9s\tremaining: 3.57s\n",
            "11583:\tlearn: 7.6793081\ttotal: 1m 9s\tremaining: 3.56s\n",
            "11584:\tlearn: 7.6793015\ttotal: 1m 9s\tremaining: 3.56s\n",
            "11585:\tlearn: 7.6792934\ttotal: 1m 9s\tremaining: 3.55s\n",
            "11586:\tlearn: 7.6792853\ttotal: 1m 9s\tremaining: 3.55s\n",
            "11587:\tlearn: 7.6792760\ttotal: 1m 9s\tremaining: 3.54s\n",
            "11588:\tlearn: 7.6792711\ttotal: 1m 9s\tremaining: 3.53s\n",
            "11589:\tlearn: 7.6792589\ttotal: 1m 9s\tremaining: 3.53s\n",
            "11590:\tlearn: 7.6792445\ttotal: 1m 9s\tremaining: 3.52s\n",
            "11591:\tlearn: 7.6792343\ttotal: 1m 9s\tremaining: 3.52s\n",
            "11592:\tlearn: 7.6792216\ttotal: 1m 9s\tremaining: 3.51s\n",
            "11593:\tlearn: 7.6792158\ttotal: 1m 9s\tremaining: 3.5s\n",
            "11594:\tlearn: 7.6792068\ttotal: 1m 9s\tremaining: 3.5s\n",
            "11595:\tlearn: 7.6791849\ttotal: 1m 9s\tremaining: 3.49s\n",
            "11596:\tlearn: 7.6791689\ttotal: 1m 9s\tremaining: 3.49s\n",
            "11597:\tlearn: 7.6791643\ttotal: 1m 9s\tremaining: 3.48s\n",
            "11598:\tlearn: 7.6791542\ttotal: 1m 9s\tremaining: 3.47s\n",
            "11599:\tlearn: 7.6791458\ttotal: 1m 9s\tremaining: 3.47s\n",
            "11600:\tlearn: 7.6791417\ttotal: 1m 9s\tremaining: 3.46s\n",
            "11601:\tlearn: 7.6791226\ttotal: 1m 9s\tremaining: 3.46s\n",
            "11602:\tlearn: 7.6791128\ttotal: 1m 9s\tremaining: 3.45s\n",
            "11603:\tlearn: 7.6791059\ttotal: 1m 9s\tremaining: 3.44s\n",
            "11604:\tlearn: 7.6790894\ttotal: 1m 9s\tremaining: 3.44s\n",
            "11605:\tlearn: 7.6790778\ttotal: 1m 9s\tremaining: 3.43s\n",
            "11606:\tlearn: 7.6790711\ttotal: 1m 9s\tremaining: 3.43s\n",
            "11607:\tlearn: 7.6790650\ttotal: 1m 9s\tremaining: 3.42s\n",
            "11608:\tlearn: 7.6790477\ttotal: 1m 9s\tremaining: 3.41s\n",
            "11609:\tlearn: 7.6790393\ttotal: 1m 9s\tremaining: 3.41s\n",
            "11610:\tlearn: 7.6790297\ttotal: 1m 9s\tremaining: 3.4s\n",
            "11611:\tlearn: 7.6790112\ttotal: 1m 9s\tremaining: 3.4s\n",
            "11612:\tlearn: 7.6789968\ttotal: 1m 9s\tremaining: 3.39s\n",
            "11613:\tlearn: 7.6789892\ttotal: 1m 9s\tremaining: 3.38s\n",
            "11614:\tlearn: 7.6789724\ttotal: 1m 9s\tremaining: 3.38s\n",
            "11615:\tlearn: 7.6789678\ttotal: 1m 9s\tremaining: 3.37s\n",
            "11616:\tlearn: 7.6789423\ttotal: 1m 9s\tremaining: 3.37s\n",
            "11617:\tlearn: 7.6789264\ttotal: 1m 9s\tremaining: 3.36s\n",
            "11618:\tlearn: 7.6789183\ttotal: 1m 9s\tremaining: 3.35s\n",
            "11619:\tlearn: 7.6789018\ttotal: 1m 9s\tremaining: 3.35s\n",
            "11620:\tlearn: 7.6788929\ttotal: 1m 9s\tremaining: 3.34s\n",
            "11621:\tlearn: 7.6788882\ttotal: 1m 9s\tremaining: 3.34s\n",
            "11622:\tlearn: 7.6788856\ttotal: 1m 9s\tremaining: 3.33s\n",
            "11623:\tlearn: 7.6788842\ttotal: 1m 9s\tremaining: 3.33s\n",
            "11624:\tlearn: 7.6788801\ttotal: 1m 9s\tremaining: 3.32s\n",
            "11625:\tlearn: 7.6788677\ttotal: 1m 9s\tremaining: 3.31s\n",
            "11626:\tlearn: 7.6788628\ttotal: 1m 9s\tremaining: 3.31s\n",
            "11627:\tlearn: 7.6788512\ttotal: 1m 9s\tremaining: 3.3s\n",
            "11628:\tlearn: 7.6788431\ttotal: 1m 9s\tremaining: 3.3s\n",
            "11629:\tlearn: 7.6788330\ttotal: 1m 9s\tremaining: 3.29s\n",
            "11630:\tlearn: 7.6788222\ttotal: 1m 9s\tremaining: 3.28s\n",
            "11631:\tlearn: 7.6788141\ttotal: 1m 9s\tremaining: 3.28s\n",
            "11632:\tlearn: 7.6788078\ttotal: 1m 9s\tremaining: 3.27s\n",
            "11633:\tlearn: 7.6788031\ttotal: 1m 9s\tremaining: 3.27s\n",
            "11634:\tlearn: 7.6787890\ttotal: 1m 9s\tremaining: 3.26s\n",
            "11635:\tlearn: 7.6787754\ttotal: 1m 9s\tremaining: 3.25s\n",
            "11636:\tlearn: 7.6787592\ttotal: 1m 9s\tremaining: 3.25s\n",
            "11637:\tlearn: 7.6787499\ttotal: 1m 9s\tremaining: 3.24s\n",
            "11638:\tlearn: 7.6787401\ttotal: 1m 9s\tremaining: 3.24s\n",
            "11639:\tlearn: 7.6787305\ttotal: 1m 9s\tremaining: 3.23s\n",
            "11640:\tlearn: 7.6787244\ttotal: 1m 9s\tremaining: 3.22s\n",
            "11641:\tlearn: 7.6787178\ttotal: 1m 9s\tremaining: 3.22s\n",
            "11642:\tlearn: 7.6787123\ttotal: 1m 9s\tremaining: 3.21s\n",
            "11643:\tlearn: 7.6787033\ttotal: 1m 9s\tremaining: 3.21s\n",
            "11644:\tlearn: 7.6786874\ttotal: 1m 9s\tremaining: 3.2s\n",
            "11645:\tlearn: 7.6786816\ttotal: 1m 9s\tremaining: 3.19s\n",
            "11646:\tlearn: 7.6786639\ttotal: 1m 9s\tremaining: 3.19s\n",
            "11647:\tlearn: 7.6786547\ttotal: 1m 9s\tremaining: 3.18s\n",
            "11648:\tlearn: 7.6786475\ttotal: 1m 9s\tremaining: 3.18s\n",
            "11649:\tlearn: 7.6786448\ttotal: 1m 9s\tremaining: 3.17s\n",
            "11650:\tlearn: 7.6786289\ttotal: 1m 9s\tremaining: 3.16s\n",
            "11651:\tlearn: 7.6786147\ttotal: 1m 9s\tremaining: 3.16s\n",
            "11652:\tlearn: 7.6785988\ttotal: 1m 9s\tremaining: 3.15s\n",
            "11653:\tlearn: 7.6785838\ttotal: 1m 9s\tremaining: 3.15s\n",
            "11654:\tlearn: 7.6785800\ttotal: 1m 9s\tremaining: 3.14s\n",
            "11655:\tlearn: 7.6785632\ttotal: 1m 9s\tremaining: 3.13s\n",
            "11656:\tlearn: 7.6785580\ttotal: 1m 9s\tremaining: 3.13s\n",
            "11657:\tlearn: 7.6785517\ttotal: 1m 9s\tremaining: 3.12s\n",
            "11658:\tlearn: 7.6785479\ttotal: 1m 9s\tremaining: 3.12s\n",
            "11659:\tlearn: 7.6785389\ttotal: 1m 9s\tremaining: 3.11s\n",
            "11660:\tlearn: 7.6785308\ttotal: 1m 9s\tremaining: 3.1s\n",
            "11661:\tlearn: 7.6785239\ttotal: 1m 9s\tremaining: 3.1s\n",
            "11662:\tlearn: 7.6785163\ttotal: 1m 9s\tremaining: 3.09s\n",
            "11663:\tlearn: 7.6785001\ttotal: 1m 9s\tremaining: 3.09s\n",
            "11664:\tlearn: 7.6784880\ttotal: 1m 9s\tremaining: 3.08s\n",
            "11665:\tlearn: 7.6784764\ttotal: 1m 9s\tremaining: 3.08s\n",
            "11666:\tlearn: 7.6784599\ttotal: 1m 9s\tremaining: 3.07s\n",
            "11667:\tlearn: 7.6784509\ttotal: 1m 9s\tremaining: 3.06s\n",
            "11668:\tlearn: 7.6784475\ttotal: 1m 9s\tremaining: 3.06s\n",
            "11669:\tlearn: 7.6784336\ttotal: 1m 9s\tremaining: 3.05s\n",
            "11670:\tlearn: 7.6784298\ttotal: 1m 9s\tremaining: 3.04s\n",
            "11671:\tlearn: 7.6784214\ttotal: 1m 9s\tremaining: 3.04s\n",
            "11672:\tlearn: 7.6784113\ttotal: 1m 9s\tremaining: 3.03s\n",
            "11673:\tlearn: 7.6783974\ttotal: 1m 9s\tremaining: 3.03s\n",
            "11674:\tlearn: 7.6783824\ttotal: 1m 9s\tremaining: 3.02s\n",
            "11675:\tlearn: 7.6783696\ttotal: 1m 9s\tremaining: 3.02s\n",
            "11676:\tlearn: 7.6783604\ttotal: 1m 9s\tremaining: 3.01s\n",
            "11677:\tlearn: 7.6783523\ttotal: 1m 9s\tremaining: 3s\n",
            "11678:\tlearn: 7.6783360\ttotal: 1m 9s\tremaining: 3s\n",
            "11679:\tlearn: 7.6783230\ttotal: 1m 9s\tremaining: 2.99s\n",
            "11680:\tlearn: 7.6783106\ttotal: 1m 9s\tremaining: 2.98s\n",
            "11681:\tlearn: 7.6783062\ttotal: 1m 9s\tremaining: 2.98s\n",
            "11682:\tlearn: 7.6782860\ttotal: 1m 9s\tremaining: 2.97s\n",
            "11683:\tlearn: 7.6782764\ttotal: 1m 9s\tremaining: 2.97s\n",
            "11684:\tlearn: 7.6782622\ttotal: 1m 9s\tremaining: 2.96s\n",
            "11685:\tlearn: 7.6782484\ttotal: 1m 9s\tremaining: 2.96s\n",
            "11686:\tlearn: 7.6782261\ttotal: 1m 9s\tremaining: 2.95s\n",
            "11687:\tlearn: 7.6782107\ttotal: 1m 9s\tremaining: 2.94s\n",
            "11688:\tlearn: 7.6781934\ttotal: 1m 9s\tremaining: 2.94s\n",
            "11689:\tlearn: 7.6781746\ttotal: 1m 9s\tremaining: 2.93s\n",
            "11690:\tlearn: 7.6781688\ttotal: 1m 9s\tremaining: 2.93s\n",
            "11691:\tlearn: 7.6781604\ttotal: 1m 9s\tremaining: 2.92s\n",
            "11692:\tlearn: 7.6781505\ttotal: 1m 9s\tremaining: 2.91s\n",
            "11693:\tlearn: 7.6781479\ttotal: 1m 9s\tremaining: 2.91s\n",
            "11694:\tlearn: 7.6781233\ttotal: 1m 9s\tremaining: 2.9s\n",
            "11695:\tlearn: 7.6781065\ttotal: 1m 9s\tremaining: 2.9s\n",
            "11696:\tlearn: 7.6781045\ttotal: 1m 9s\tremaining: 2.89s\n",
            "11697:\tlearn: 7.6780909\ttotal: 1m 9s\tremaining: 2.88s\n",
            "11698:\tlearn: 7.6780848\ttotal: 1m 9s\tremaining: 2.88s\n",
            "11699:\tlearn: 7.6780799\ttotal: 1m 9s\tremaining: 2.87s\n",
            "11700:\tlearn: 7.6780704\ttotal: 1m 9s\tremaining: 2.87s\n",
            "11701:\tlearn: 7.6780640\ttotal: 1m 9s\tremaining: 2.86s\n",
            "11702:\tlearn: 7.6780542\ttotal: 1m 9s\tremaining: 2.85s\n",
            "11703:\tlearn: 7.6780382\ttotal: 1m 9s\tremaining: 2.85s\n",
            "11704:\tlearn: 7.6780304\ttotal: 1m 9s\tremaining: 2.84s\n",
            "11705:\tlearn: 7.6780122\ttotal: 1m 9s\tremaining: 2.84s\n",
            "11706:\tlearn: 7.6780055\ttotal: 1m 9s\tremaining: 2.83s\n",
            "11707:\tlearn: 7.6779902\ttotal: 1m 9s\tremaining: 2.82s\n",
            "11708:\tlearn: 7.6779809\ttotal: 1m 9s\tremaining: 2.82s\n",
            "11709:\tlearn: 7.6779702\ttotal: 1m 9s\tremaining: 2.81s\n",
            "11710:\tlearn: 7.6779653\ttotal: 1m 9s\tremaining: 2.81s\n",
            "11711:\tlearn: 7.6779560\ttotal: 1m 9s\tremaining: 2.8s\n",
            "11712:\tlearn: 7.6779404\ttotal: 1m 9s\tremaining: 2.79s\n",
            "11713:\tlearn: 7.6779236\ttotal: 1m 9s\tremaining: 2.79s\n",
            "11714:\tlearn: 7.6779118\ttotal: 1m 9s\tremaining: 2.78s\n",
            "11715:\tlearn: 7.6779051\ttotal: 1m 9s\tremaining: 2.78s\n",
            "11716:\tlearn: 7.6779008\ttotal: 1m 9s\tremaining: 2.77s\n",
            "11717:\tlearn: 7.6778938\ttotal: 1m 9s\tremaining: 2.77s\n",
            "11718:\tlearn: 7.6778799\ttotal: 1m 9s\tremaining: 2.76s\n",
            "11719:\tlearn: 7.6778704\ttotal: 1m 9s\tremaining: 2.75s\n",
            "11720:\tlearn: 7.6778562\ttotal: 1m 10s\tremaining: 2.75s\n",
            "11721:\tlearn: 7.6778533\ttotal: 1m 10s\tremaining: 2.74s\n",
            "11722:\tlearn: 7.6778429\ttotal: 1m 10s\tremaining: 2.73s\n",
            "11723:\tlearn: 7.6778324\ttotal: 1m 10s\tremaining: 2.73s\n",
            "11724:\tlearn: 7.6778220\ttotal: 1m 10s\tremaining: 2.72s\n",
            "11725:\tlearn: 7.6778139\ttotal: 1m 10s\tremaining: 2.72s\n",
            "11726:\tlearn: 7.6778021\ttotal: 1m 10s\tremaining: 2.71s\n",
            "11727:\tlearn: 7.6777908\ttotal: 1m 10s\tremaining: 2.71s\n",
            "11728:\tlearn: 7.6777743\ttotal: 1m 10s\tremaining: 2.7s\n",
            "11729:\tlearn: 7.6777679\ttotal: 1m 10s\tremaining: 2.69s\n",
            "11730:\tlearn: 7.6777673\ttotal: 1m 10s\tremaining: 2.69s\n",
            "11731:\tlearn: 7.6777476\ttotal: 1m 10s\tremaining: 2.68s\n",
            "11732:\tlearn: 7.6777427\ttotal: 1m 10s\tremaining: 2.67s\n",
            "11733:\tlearn: 7.6777207\ttotal: 1m 10s\tremaining: 2.67s\n",
            "11734:\tlearn: 7.6777022\ttotal: 1m 10s\tremaining: 2.66s\n",
            "11735:\tlearn: 7.6776822\ttotal: 1m 10s\tremaining: 2.66s\n",
            "11736:\tlearn: 7.6776704\ttotal: 1m 10s\tremaining: 2.65s\n",
            "11737:\tlearn: 7.6776663\ttotal: 1m 10s\tremaining: 2.65s\n",
            "11738:\tlearn: 7.6776588\ttotal: 1m 10s\tremaining: 2.64s\n",
            "11739:\tlearn: 7.6776466\ttotal: 1m 10s\tremaining: 2.63s\n",
            "11740:\tlearn: 7.6776293\ttotal: 1m 10s\tremaining: 2.63s\n",
            "11741:\tlearn: 7.6776188\ttotal: 1m 10s\tremaining: 2.62s\n",
            "11742:\tlearn: 7.6776006\ttotal: 1m 10s\tremaining: 2.62s\n",
            "11743:\tlearn: 7.6775913\ttotal: 1m 10s\tremaining: 2.61s\n",
            "11744:\tlearn: 7.6775856\ttotal: 1m 10s\tremaining: 2.6s\n",
            "11745:\tlearn: 7.6775751\ttotal: 1m 10s\tremaining: 2.6s\n",
            "11746:\tlearn: 7.6775494\ttotal: 1m 10s\tremaining: 2.59s\n",
            "11747:\tlearn: 7.6775404\ttotal: 1m 10s\tremaining: 2.58s\n",
            "11748:\tlearn: 7.6775227\ttotal: 1m 10s\tremaining: 2.58s\n",
            "11749:\tlearn: 7.6775129\ttotal: 1m 10s\tremaining: 2.57s\n",
            "11750:\tlearn: 7.6775039\ttotal: 1m 10s\tremaining: 2.57s\n",
            "11751:\tlearn: 7.6774955\ttotal: 1m 10s\tremaining: 2.56s\n",
            "11752:\tlearn: 7.6774883\ttotal: 1m 10s\tremaining: 2.56s\n",
            "11753:\tlearn: 7.6774733\ttotal: 1m 10s\tremaining: 2.55s\n",
            "11754:\tlearn: 7.6774669\ttotal: 1m 10s\tremaining: 2.54s\n",
            "11755:\tlearn: 7.6774510\ttotal: 1m 10s\tremaining: 2.54s\n",
            "11756:\tlearn: 7.6774350\ttotal: 1m 10s\tremaining: 2.53s\n",
            "11757:\tlearn: 7.6774264\ttotal: 1m 10s\tremaining: 2.53s\n",
            "11758:\tlearn: 7.6774023\ttotal: 1m 10s\tremaining: 2.52s\n",
            "11759:\tlearn: 7.6773963\ttotal: 1m 10s\tremaining: 2.51s\n",
            "11760:\tlearn: 7.6773934\ttotal: 1m 10s\tremaining: 2.51s\n",
            "11761:\tlearn: 7.6773827\ttotal: 1m 10s\tremaining: 2.5s\n",
            "11762:\tlearn: 7.6773644\ttotal: 1m 10s\tremaining: 2.5s\n",
            "11763:\tlearn: 7.6773491\ttotal: 1m 10s\tremaining: 2.49s\n",
            "11764:\tlearn: 7.6773277\ttotal: 1m 10s\tremaining: 2.48s\n",
            "11765:\tlearn: 7.6773277\ttotal: 1m 10s\tremaining: 2.48s\n",
            "11766:\tlearn: 7.6773106\ttotal: 1m 10s\tremaining: 2.47s\n",
            "11767:\tlearn: 7.6773033\ttotal: 1m 10s\tremaining: 2.47s\n",
            "11768:\tlearn: 7.6772944\ttotal: 1m 10s\tremaining: 2.46s\n",
            "11769:\tlearn: 7.6772828\ttotal: 1m 10s\tremaining: 2.45s\n",
            "11770:\tlearn: 7.6772628\ttotal: 1m 10s\tremaining: 2.45s\n",
            "11771:\tlearn: 7.6772483\ttotal: 1m 10s\tremaining: 2.44s\n",
            "11772:\tlearn: 7.6772345\ttotal: 1m 10s\tremaining: 2.44s\n",
            "11773:\tlearn: 7.6772249\ttotal: 1m 10s\tremaining: 2.43s\n",
            "11774:\tlearn: 7.6772130\ttotal: 1m 10s\tremaining: 2.42s\n",
            "11775:\tlearn: 7.6772081\ttotal: 1m 10s\tremaining: 2.42s\n",
            "11776:\tlearn: 7.6772020\ttotal: 1m 10s\tremaining: 2.41s\n",
            "11777:\tlearn: 7.6771751\ttotal: 1m 10s\tremaining: 2.41s\n",
            "11778:\tlearn: 7.6771667\ttotal: 1m 10s\tremaining: 2.4s\n",
            "11779:\tlearn: 7.6771459\ttotal: 1m 10s\tremaining: 2.39s\n",
            "11780:\tlearn: 7.6771297\ttotal: 1m 10s\tremaining: 2.39s\n",
            "11781:\tlearn: 7.6771285\ttotal: 1m 10s\tremaining: 2.38s\n",
            "11782:\tlearn: 7.6771242\ttotal: 1m 10s\tremaining: 2.38s\n",
            "11783:\tlearn: 7.6771077\ttotal: 1m 10s\tremaining: 2.37s\n",
            "11784:\tlearn: 7.6770975\ttotal: 1m 10s\tremaining: 2.36s\n",
            "11785:\tlearn: 7.6770819\ttotal: 1m 10s\tremaining: 2.36s\n",
            "11786:\tlearn: 7.6770619\ttotal: 1m 10s\tremaining: 2.35s\n",
            "11787:\tlearn: 7.6770469\ttotal: 1m 10s\tremaining: 2.35s\n",
            "11788:\tlearn: 7.6770373\ttotal: 1m 10s\tremaining: 2.34s\n",
            "11789:\tlearn: 7.6770217\ttotal: 1m 10s\tremaining: 2.33s\n",
            "11790:\tlearn: 7.6770162\ttotal: 1m 10s\tremaining: 2.33s\n",
            "11791:\tlearn: 7.6770038\ttotal: 1m 10s\tremaining: 2.32s\n",
            "11792:\tlearn: 7.6769919\ttotal: 1m 10s\tremaining: 2.32s\n",
            "11793:\tlearn: 7.6769771\ttotal: 1m 10s\tremaining: 2.31s\n",
            "11794:\tlearn: 7.6769493\ttotal: 1m 10s\tremaining: 2.3s\n",
            "11795:\tlearn: 7.6769334\ttotal: 1m 10s\tremaining: 2.3s\n",
            "11796:\tlearn: 7.6769204\ttotal: 1m 10s\tremaining: 2.29s\n",
            "11797:\tlearn: 7.6769143\ttotal: 1m 10s\tremaining: 2.29s\n",
            "11798:\tlearn: 7.6768888\ttotal: 1m 10s\tremaining: 2.28s\n",
            "11799:\tlearn: 7.6768738\ttotal: 1m 10s\tremaining: 2.27s\n",
            "11800:\tlearn: 7.6768697\ttotal: 1m 10s\tremaining: 2.27s\n",
            "11801:\tlearn: 7.6768469\ttotal: 1m 10s\tremaining: 2.26s\n",
            "11802:\tlearn: 7.6768396\ttotal: 1m 10s\tremaining: 2.26s\n",
            "11803:\tlearn: 7.6768341\ttotal: 1m 10s\tremaining: 2.25s\n",
            "11804:\tlearn: 7.6768249\ttotal: 1m 10s\tremaining: 2.25s\n",
            "11805:\tlearn: 7.6768197\ttotal: 1m 10s\tremaining: 2.24s\n",
            "11806:\tlearn: 7.6768191\ttotal: 1m 10s\tremaining: 2.23s\n",
            "11807:\tlearn: 7.6768066\ttotal: 1m 10s\tremaining: 2.23s\n",
            "11808:\tlearn: 7.6768011\ttotal: 1m 10s\tremaining: 2.22s\n",
            "11809:\tlearn: 7.6767829\ttotal: 1m 10s\tremaining: 2.21s\n",
            "11810:\tlearn: 7.6767652\ttotal: 1m 10s\tremaining: 2.21s\n",
            "11811:\tlearn: 7.6767606\ttotal: 1m 10s\tremaining: 2.2s\n",
            "11812:\tlearn: 7.6767516\ttotal: 1m 10s\tremaining: 2.2s\n",
            "11813:\tlearn: 7.6767400\ttotal: 1m 10s\tremaining: 2.19s\n",
            "11814:\tlearn: 7.6767302\ttotal: 1m 10s\tremaining: 2.19s\n",
            "11815:\tlearn: 7.6767007\ttotal: 1m 10s\tremaining: 2.18s\n",
            "11816:\tlearn: 7.6766966\ttotal: 1m 10s\tremaining: 2.17s\n",
            "11817:\tlearn: 7.6766917\ttotal: 1m 10s\tremaining: 2.17s\n",
            "11818:\tlearn: 7.6766827\ttotal: 1m 10s\tremaining: 2.16s\n",
            "11819:\tlearn: 7.6766758\ttotal: 1m 10s\tremaining: 2.15s\n",
            "11820:\tlearn: 7.6766628\ttotal: 1m 10s\tremaining: 2.15s\n",
            "11821:\tlearn: 7.6766544\ttotal: 1m 10s\tremaining: 2.14s\n",
            "11822:\tlearn: 7.6766439\ttotal: 1m 10s\tremaining: 2.14s\n",
            "11823:\tlearn: 7.6766329\ttotal: 1m 10s\tremaining: 2.13s\n",
            "11824:\tlearn: 7.6766205\ttotal: 1m 10s\tremaining: 2.13s\n",
            "11825:\tlearn: 7.6766150\ttotal: 1m 10s\tremaining: 2.12s\n",
            "11826:\tlearn: 7.6766080\ttotal: 1m 10s\tremaining: 2.11s\n",
            "11827:\tlearn: 7.6765944\ttotal: 1m 10s\tremaining: 2.11s\n",
            "11828:\tlearn: 7.6765913\ttotal: 1m 10s\tremaining: 2.1s\n",
            "11829:\tlearn: 7.6765852\ttotal: 1m 10s\tremaining: 2.1s\n",
            "11830:\tlearn: 7.6765736\ttotal: 1m 10s\tremaining: 2.09s\n",
            "11831:\tlearn: 7.6765510\ttotal: 1m 10s\tremaining: 2.08s\n",
            "11832:\tlearn: 7.6765426\ttotal: 1m 10s\tremaining: 2.08s\n",
            "11833:\tlearn: 7.6765397\ttotal: 1m 10s\tremaining: 2.07s\n",
            "11834:\tlearn: 7.6765354\ttotal: 1m 10s\tremaining: 2.06s\n",
            "11835:\tlearn: 7.6765154\ttotal: 1m 10s\tremaining: 2.06s\n",
            "11836:\tlearn: 7.6764983\ttotal: 1m 10s\tremaining: 2.05s\n",
            "11837:\tlearn: 7.6764850\ttotal: 1m 10s\tremaining: 2.05s\n",
            "11838:\tlearn: 7.6764758\ttotal: 1m 10s\tremaining: 2.04s\n",
            "11839:\tlearn: 7.6764749\ttotal: 1m 10s\tremaining: 2.04s\n",
            "11840:\tlearn: 7.6764572\ttotal: 1m 10s\tremaining: 2.03s\n",
            "11841:\tlearn: 7.6764451\ttotal: 1m 10s\tremaining: 2.02s\n",
            "11842:\tlearn: 7.6764364\ttotal: 1m 10s\tremaining: 2.02s\n",
            "11843:\tlearn: 7.6764216\ttotal: 1m 10s\tremaining: 2.01s\n",
            "11844:\tlearn: 7.6764086\ttotal: 1m 10s\tremaining: 2s\n",
            "11845:\tlearn: 7.6763982\ttotal: 1m 10s\tremaining: 2s\n",
            "11846:\tlearn: 7.6763901\ttotal: 1m 10s\tremaining: 1.99s\n",
            "11847:\tlearn: 7.6763834\ttotal: 1m 10s\tremaining: 1.99s\n",
            "11848:\tlearn: 7.6763776\ttotal: 1m 10s\tremaining: 1.98s\n",
            "11849:\tlearn: 7.6763611\ttotal: 1m 10s\tremaining: 1.98s\n",
            "11850:\tlearn: 7.6763466\ttotal: 1m 10s\tremaining: 1.97s\n",
            "11851:\tlearn: 7.6763284\ttotal: 1m 10s\tremaining: 1.96s\n",
            "11852:\tlearn: 7.6763134\ttotal: 1m 10s\tremaining: 1.96s\n",
            "11853:\tlearn: 7.6763044\ttotal: 1m 10s\tremaining: 1.95s\n",
            "11854:\tlearn: 7.6762951\ttotal: 1m 10s\tremaining: 1.95s\n",
            "11855:\tlearn: 7.6762908\ttotal: 1m 10s\tremaining: 1.94s\n",
            "11856:\tlearn: 7.6762775\ttotal: 1m 10s\tremaining: 1.93s\n",
            "11857:\tlearn: 7.6762720\ttotal: 1m 10s\tremaining: 1.93s\n",
            "11858:\tlearn: 7.6762586\ttotal: 1m 10s\tremaining: 1.92s\n",
            "11859:\tlearn: 7.6762482\ttotal: 1m 10s\tremaining: 1.92s\n",
            "11860:\tlearn: 7.6762427\ttotal: 1m 10s\tremaining: 1.91s\n",
            "11861:\tlearn: 7.6762259\ttotal: 1m 10s\tremaining: 1.9s\n",
            "11862:\tlearn: 7.6762086\ttotal: 1m 10s\tremaining: 1.9s\n",
            "11863:\tlearn: 7.6762057\ttotal: 1m 10s\tremaining: 1.89s\n",
            "11864:\tlearn: 7.6761955\ttotal: 1m 10s\tremaining: 1.89s\n",
            "11865:\tlearn: 7.6761866\ttotal: 1m 10s\tremaining: 1.88s\n",
            "11866:\tlearn: 7.6761793\ttotal: 1m 10s\tremaining: 1.87s\n",
            "11867:\tlearn: 7.6761718\ttotal: 1m 10s\tremaining: 1.87s\n",
            "11868:\tlearn: 7.6761622\ttotal: 1m 10s\tremaining: 1.86s\n",
            "11869:\tlearn: 7.6761564\ttotal: 1m 10s\tremaining: 1.86s\n",
            "11870:\tlearn: 7.6761518\ttotal: 1m 10s\tremaining: 1.85s\n",
            "11871:\tlearn: 7.6761489\ttotal: 1m 10s\tremaining: 1.84s\n",
            "11872:\tlearn: 7.6761284\ttotal: 1m 10s\tremaining: 1.84s\n",
            "11873:\tlearn: 7.6761203\ttotal: 1m 10s\tremaining: 1.83s\n",
            "11874:\tlearn: 7.6761171\ttotal: 1m 10s\tremaining: 1.83s\n",
            "11875:\tlearn: 7.6761020\ttotal: 1m 10s\tremaining: 1.82s\n",
            "11876:\tlearn: 7.6760852\ttotal: 1m 10s\tremaining: 1.81s\n",
            "11877:\tlearn: 7.6760722\ttotal: 1m 10s\tremaining: 1.81s\n",
            "11878:\tlearn: 7.6760696\ttotal: 1m 10s\tremaining: 1.8s\n",
            "11879:\tlearn: 7.6760415\ttotal: 1m 10s\tremaining: 1.8s\n",
            "11880:\tlearn: 7.6760328\ttotal: 1m 10s\tremaining: 1.79s\n",
            "11881:\tlearn: 7.6760302\ttotal: 1m 10s\tremaining: 1.78s\n",
            "11882:\tlearn: 7.6760218\ttotal: 1m 10s\tremaining: 1.78s\n",
            "11883:\tlearn: 7.6760091\ttotal: 1m 10s\tremaining: 1.77s\n",
            "11884:\tlearn: 7.6759998\ttotal: 1m 10s\tremaining: 1.77s\n",
            "11885:\tlearn: 7.6759992\ttotal: 1m 10s\tremaining: 1.76s\n",
            "11886:\tlearn: 7.6759897\ttotal: 1m 10s\tremaining: 1.75s\n",
            "11887:\tlearn: 7.6759839\ttotal: 1m 10s\tremaining: 1.75s\n",
            "11888:\tlearn: 7.6759715\ttotal: 1m 10s\tremaining: 1.74s\n",
            "11889:\tlearn: 7.6759584\ttotal: 1m 10s\tremaining: 1.74s\n",
            "11890:\tlearn: 7.6759474\ttotal: 1m 10s\tremaining: 1.73s\n",
            "11891:\tlearn: 7.6759332\ttotal: 1m 11s\tremaining: 1.73s\n",
            "11892:\tlearn: 7.6759205\ttotal: 1m 11s\tremaining: 1.72s\n",
            "11893:\tlearn: 7.6759127\ttotal: 1m 11s\tremaining: 1.71s\n",
            "11894:\tlearn: 7.6759054\ttotal: 1m 11s\tremaining: 1.71s\n",
            "11895:\tlearn: 7.6758907\ttotal: 1m 11s\tremaining: 1.7s\n",
            "11896:\tlearn: 7.6758756\ttotal: 1m 11s\tremaining: 1.7s\n",
            "11897:\tlearn: 7.6758612\ttotal: 1m 11s\tremaining: 1.69s\n",
            "11898:\tlearn: 7.6758475\ttotal: 1m 11s\tremaining: 1.68s\n",
            "11899:\tlearn: 7.6758363\ttotal: 1m 11s\tremaining: 1.68s\n",
            "11900:\tlearn: 7.6758270\ttotal: 1m 11s\tremaining: 1.67s\n",
            "11901:\tlearn: 7.6758203\ttotal: 1m 11s\tremaining: 1.67s\n",
            "11902:\tlearn: 7.6758111\ttotal: 1m 11s\tremaining: 1.66s\n",
            "11903:\tlearn: 7.6758004\ttotal: 1m 11s\tremaining: 1.65s\n",
            "11904:\tlearn: 7.6757873\ttotal: 1m 11s\tremaining: 1.65s\n",
            "11905:\tlearn: 7.6757746\ttotal: 1m 11s\tremaining: 1.64s\n",
            "11906:\tlearn: 7.6757595\ttotal: 1m 11s\tremaining: 1.64s\n",
            "11907:\tlearn: 7.6757448\ttotal: 1m 11s\tremaining: 1.63s\n",
            "11908:\tlearn: 7.6757367\ttotal: 1m 11s\tremaining: 1.62s\n",
            "11909:\tlearn: 7.6757294\ttotal: 1m 11s\tremaining: 1.62s\n",
            "11910:\tlearn: 7.6757245\ttotal: 1m 11s\tremaining: 1.61s\n",
            "11911:\tlearn: 7.6757135\ttotal: 1m 11s\tremaining: 1.61s\n",
            "11912:\tlearn: 7.6757077\ttotal: 1m 11s\tremaining: 1.6s\n",
            "11913:\tlearn: 7.6756982\ttotal: 1m 11s\tremaining: 1.59s\n",
            "11914:\tlearn: 7.6756892\ttotal: 1m 11s\tremaining: 1.59s\n",
            "11915:\tlearn: 7.6756785\ttotal: 1m 11s\tremaining: 1.58s\n",
            "11916:\tlearn: 7.6756707\ttotal: 1m 11s\tremaining: 1.58s\n",
            "11917:\tlearn: 7.6756657\ttotal: 1m 11s\tremaining: 1.57s\n",
            "11918:\tlearn: 7.6756605\ttotal: 1m 11s\tremaining: 1.56s\n",
            "11919:\tlearn: 7.6756437\ttotal: 1m 11s\tremaining: 1.56s\n",
            "11920:\tlearn: 7.6756333\ttotal: 1m 11s\tremaining: 1.55s\n",
            "11921:\tlearn: 7.6756191\ttotal: 1m 11s\tremaining: 1.55s\n",
            "11922:\tlearn: 7.6756136\ttotal: 1m 11s\tremaining: 1.54s\n",
            "11923:\tlearn: 7.6756049\ttotal: 1m 11s\tremaining: 1.53s\n",
            "11924:\tlearn: 7.6755907\ttotal: 1m 11s\tremaining: 1.53s\n",
            "11925:\tlearn: 7.6755835\ttotal: 1m 11s\tremaining: 1.52s\n",
            "11926:\tlearn: 7.6755745\ttotal: 1m 11s\tremaining: 1.52s\n",
            "11927:\tlearn: 7.6755647\ttotal: 1m 11s\tremaining: 1.51s\n",
            "11928:\tlearn: 7.6755569\ttotal: 1m 11s\tremaining: 1.5s\n",
            "11929:\tlearn: 7.6755482\ttotal: 1m 11s\tremaining: 1.5s\n",
            "11930:\tlearn: 7.6755352\ttotal: 1m 11s\tremaining: 1.49s\n",
            "11931:\tlearn: 7.6755250\ttotal: 1m 11s\tremaining: 1.49s\n",
            "11932:\tlearn: 7.6755169\ttotal: 1m 11s\tremaining: 1.48s\n",
            "11933:\tlearn: 7.6755001\ttotal: 1m 11s\tremaining: 1.48s\n",
            "11934:\tlearn: 7.6754917\ttotal: 1m 11s\tremaining: 1.47s\n",
            "11935:\tlearn: 7.6754732\ttotal: 1m 11s\tremaining: 1.46s\n",
            "11936:\tlearn: 7.6754567\ttotal: 1m 11s\tremaining: 1.46s\n",
            "11937:\tlearn: 7.6754492\ttotal: 1m 11s\tremaining: 1.45s\n",
            "11938:\tlearn: 7.6754306\ttotal: 1m 11s\tremaining: 1.45s\n",
            "11939:\tlearn: 7.6754217\ttotal: 1m 11s\tremaining: 1.44s\n",
            "11940:\tlearn: 7.6754182\ttotal: 1m 11s\tremaining: 1.43s\n",
            "11941:\tlearn: 7.6754046\ttotal: 1m 11s\tremaining: 1.43s\n",
            "11942:\tlearn: 7.6753939\ttotal: 1m 11s\tremaining: 1.42s\n",
            "11943:\tlearn: 7.6753869\ttotal: 1m 11s\tremaining: 1.42s\n",
            "11944:\tlearn: 7.6753727\ttotal: 1m 11s\tremaining: 1.41s\n",
            "11945:\tlearn: 7.6753597\ttotal: 1m 11s\tremaining: 1.4s\n",
            "11946:\tlearn: 7.6753554\ttotal: 1m 11s\tremaining: 1.4s\n",
            "11947:\tlearn: 7.6753374\ttotal: 1m 11s\tremaining: 1.39s\n",
            "11948:\tlearn: 7.6753313\ttotal: 1m 11s\tremaining: 1.39s\n",
            "11949:\tlearn: 7.6753189\ttotal: 1m 11s\tremaining: 1.38s\n",
            "11950:\tlearn: 7.6753093\ttotal: 1m 11s\tremaining: 1.37s\n",
            "11951:\tlearn: 7.6752980\ttotal: 1m 11s\tremaining: 1.37s\n",
            "11952:\tlearn: 7.6752905\ttotal: 1m 11s\tremaining: 1.36s\n",
            "11953:\tlearn: 7.6752760\ttotal: 1m 11s\tremaining: 1.35s\n",
            "11954:\tlearn: 7.6752604\ttotal: 1m 11s\tremaining: 1.35s\n",
            "11955:\tlearn: 7.6752491\ttotal: 1m 11s\tremaining: 1.34s\n",
            "11956:\tlearn: 7.6752416\ttotal: 1m 11s\tremaining: 1.34s\n",
            "11957:\tlearn: 7.6752309\ttotal: 1m 11s\tremaining: 1.33s\n",
            "11958:\tlearn: 7.6752184\ttotal: 1m 11s\tremaining: 1.32s\n",
            "11959:\tlearn: 7.6752152\ttotal: 1m 11s\tremaining: 1.32s\n",
            "11960:\tlearn: 7.6752065\ttotal: 1m 11s\tremaining: 1.31s\n",
            "11961:\tlearn: 7.6751941\ttotal: 1m 11s\tremaining: 1.31s\n",
            "11962:\tlearn: 7.6751869\ttotal: 1m 11s\tremaining: 1.3s\n",
            "11963:\tlearn: 7.6751730\ttotal: 1m 11s\tremaining: 1.29s\n",
            "11964:\tlearn: 7.6751660\ttotal: 1m 11s\tremaining: 1.29s\n",
            "11965:\tlearn: 7.6751559\ttotal: 1m 11s\tremaining: 1.28s\n",
            "11966:\tlearn: 7.6751463\ttotal: 1m 11s\tremaining: 1.28s\n",
            "11967:\tlearn: 7.6751327\ttotal: 1m 11s\tremaining: 1.27s\n",
            "11968:\tlearn: 7.6751180\ttotal: 1m 11s\tremaining: 1.27s\n",
            "11969:\tlearn: 7.6751084\ttotal: 1m 11s\tremaining: 1.26s\n",
            "11970:\tlearn: 7.6750980\ttotal: 1m 11s\tremaining: 1.25s\n",
            "11971:\tlearn: 7.6750745\ttotal: 1m 11s\tremaining: 1.25s\n",
            "11972:\tlearn: 7.6750670\ttotal: 1m 11s\tremaining: 1.24s\n",
            "11973:\tlearn: 7.6750592\ttotal: 1m 11s\tremaining: 1.24s\n",
            "11974:\tlearn: 7.6750415\ttotal: 1m 11s\tremaining: 1.23s\n",
            "11975:\tlearn: 7.6750349\ttotal: 1m 11s\tremaining: 1.22s\n",
            "11976:\tlearn: 7.6750224\ttotal: 1m 11s\tremaining: 1.22s\n",
            "11977:\tlearn: 7.6750091\ttotal: 1m 11s\tremaining: 1.21s\n",
            "11978:\tlearn: 7.6749998\ttotal: 1m 11s\tremaining: 1.21s\n",
            "11979:\tlearn: 7.6749894\ttotal: 1m 11s\tremaining: 1.2s\n",
            "11980:\tlearn: 7.6749836\ttotal: 1m 11s\tremaining: 1.19s\n",
            "11981:\tlearn: 7.6749697\ttotal: 1m 11s\tremaining: 1.19s\n",
            "11982:\tlearn: 7.6749590\ttotal: 1m 11s\tremaining: 1.18s\n",
            "11983:\tlearn: 7.6749471\ttotal: 1m 11s\tremaining: 1.18s\n",
            "11984:\tlearn: 7.6749384\ttotal: 1m 11s\tremaining: 1.17s\n",
            "11985:\tlearn: 7.6749260\ttotal: 1m 11s\tremaining: 1.16s\n",
            "11986:\tlearn: 7.6749072\ttotal: 1m 11s\tremaining: 1.16s\n",
            "11987:\tlearn: 7.6748941\ttotal: 1m 11s\tremaining: 1.15s\n",
            "11988:\tlearn: 7.6748791\ttotal: 1m 11s\tremaining: 1.15s\n",
            "11989:\tlearn: 7.6748704\ttotal: 1m 11s\tremaining: 1.14s\n",
            "11990:\tlearn: 7.6748579\ttotal: 1m 11s\tremaining: 1.13s\n",
            "11991:\tlearn: 7.6748461\ttotal: 1m 11s\tremaining: 1.13s\n",
            "11992:\tlearn: 7.6748426\ttotal: 1m 11s\tremaining: 1.12s\n",
            "11993:\tlearn: 7.6748319\ttotal: 1m 11s\tremaining: 1.12s\n",
            "11994:\tlearn: 7.6748267\ttotal: 1m 11s\tremaining: 1.11s\n",
            "11995:\tlearn: 7.6748197\ttotal: 1m 11s\tremaining: 1.1s\n",
            "11996:\tlearn: 7.6748067\ttotal: 1m 11s\tremaining: 1.1s\n",
            "11997:\tlearn: 7.6747890\ttotal: 1m 11s\tremaining: 1.09s\n",
            "11998:\tlearn: 7.6747688\ttotal: 1m 11s\tremaining: 1.09s\n",
            "11999:\tlearn: 7.6747563\ttotal: 1m 11s\tremaining: 1.08s\n",
            "12000:\tlearn: 7.6747444\ttotal: 1m 11s\tremaining: 1.07s\n",
            "12001:\tlearn: 7.6747386\ttotal: 1m 11s\tremaining: 1.07s\n",
            "12002:\tlearn: 7.6747320\ttotal: 1m 11s\tremaining: 1.06s\n",
            "12003:\tlearn: 7.6747149\ttotal: 1m 11s\tremaining: 1.06s\n",
            "12004:\tlearn: 7.6747129\ttotal: 1m 11s\tremaining: 1.05s\n",
            "12005:\tlearn: 7.6747013\ttotal: 1m 11s\tremaining: 1.04s\n",
            "12006:\tlearn: 7.6746990\ttotal: 1m 11s\tremaining: 1.04s\n",
            "12007:\tlearn: 7.6746836\ttotal: 1m 11s\tremaining: 1.03s\n",
            "12008:\tlearn: 7.6746738\ttotal: 1m 11s\tremaining: 1.03s\n",
            "12009:\tlearn: 7.6746599\ttotal: 1m 11s\tremaining: 1.02s\n",
            "12010:\tlearn: 7.6746593\ttotal: 1m 11s\tremaining: 1.01s\n",
            "12011:\tlearn: 7.6746544\ttotal: 1m 11s\tremaining: 1.01s\n",
            "12012:\tlearn: 7.6746399\ttotal: 1m 11s\tremaining: 1s\n",
            "12013:\tlearn: 7.6746335\ttotal: 1m 11s\tremaining: 997ms\n",
            "12014:\tlearn: 7.6746222\ttotal: 1m 11s\tremaining: 991ms\n",
            "12015:\tlearn: 7.6746162\ttotal: 1m 11s\tremaining: 985ms\n",
            "12016:\tlearn: 7.6746089\ttotal: 1m 11s\tremaining: 979ms\n",
            "12017:\tlearn: 7.6746034\ttotal: 1m 11s\tremaining: 973ms\n",
            "12018:\tlearn: 7.6745878\ttotal: 1m 11s\tremaining: 967ms\n",
            "12019:\tlearn: 7.6745649\ttotal: 1m 11s\tremaining: 961ms\n",
            "12020:\tlearn: 7.6745446\ttotal: 1m 11s\tremaining: 955ms\n",
            "12021:\tlearn: 7.6745250\ttotal: 1m 11s\tremaining: 950ms\n",
            "12022:\tlearn: 7.6745142\ttotal: 1m 11s\tremaining: 944ms\n",
            "12023:\tlearn: 7.6745058\ttotal: 1m 11s\tremaining: 938ms\n",
            "12024:\tlearn: 7.6744917\ttotal: 1m 11s\tremaining: 932ms\n",
            "12025:\tlearn: 7.6744862\ttotal: 1m 11s\tremaining: 926ms\n",
            "12026:\tlearn: 7.6744656\ttotal: 1m 11s\tremaining: 920ms\n",
            "12027:\tlearn: 7.6744549\ttotal: 1m 11s\tremaining: 914ms\n",
            "12028:\tlearn: 7.6744384\ttotal: 1m 11s\tremaining: 908ms\n",
            "12029:\tlearn: 7.6744280\ttotal: 1m 11s\tremaining: 902ms\n",
            "12030:\tlearn: 7.6744184\ttotal: 1m 11s\tremaining: 896ms\n",
            "12031:\tlearn: 7.6743993\ttotal: 1m 11s\tremaining: 890ms\n",
            "12032:\tlearn: 7.6743834\ttotal: 1m 11s\tremaining: 884ms\n",
            "12033:\tlearn: 7.6743611\ttotal: 1m 11s\tremaining: 878ms\n",
            "12034:\tlearn: 7.6743446\ttotal: 1m 11s\tremaining: 872ms\n",
            "12035:\tlearn: 7.6743388\ttotal: 1m 11s\tremaining: 866ms\n",
            "12036:\tlearn: 7.6743228\ttotal: 1m 11s\tremaining: 860ms\n",
            "12037:\tlearn: 7.6743144\ttotal: 1m 11s\tremaining: 854ms\n",
            "12038:\tlearn: 7.6743014\ttotal: 1m 11s\tremaining: 848ms\n",
            "12039:\tlearn: 7.6742901\ttotal: 1m 11s\tremaining: 842ms\n",
            "12040:\tlearn: 7.6742811\ttotal: 1m 11s\tremaining: 836ms\n",
            "12041:\tlearn: 7.6742777\ttotal: 1m 11s\tremaining: 830ms\n",
            "12042:\tlearn: 7.6742658\ttotal: 1m 11s\tremaining: 824ms\n",
            "12043:\tlearn: 7.6742638\ttotal: 1m 11s\tremaining: 818ms\n",
            "12044:\tlearn: 7.6742574\ttotal: 1m 11s\tremaining: 812ms\n",
            "12045:\tlearn: 7.6742476\ttotal: 1m 11s\tremaining: 806ms\n",
            "12046:\tlearn: 7.6742368\ttotal: 1m 11s\tremaining: 800ms\n",
            "12047:\tlearn: 7.6742339\ttotal: 1m 11s\tremaining: 794ms\n",
            "12048:\tlearn: 7.6742209\ttotal: 1m 11s\tremaining: 788ms\n",
            "12049:\tlearn: 7.6742151\ttotal: 1m 11s\tremaining: 782ms\n",
            "12050:\tlearn: 7.6742073\ttotal: 1m 11s\tremaining: 776ms\n",
            "12051:\tlearn: 7.6741980\ttotal: 1m 11s\tremaining: 770ms\n",
            "12052:\tlearn: 7.6741859\ttotal: 1m 11s\tremaining: 764ms\n",
            "12053:\tlearn: 7.6741772\ttotal: 1m 11s\tremaining: 758ms\n",
            "12054:\tlearn: 7.6741644\ttotal: 1m 11s\tremaining: 752ms\n",
            "12055:\tlearn: 7.6741610\ttotal: 1m 11s\tremaining: 746ms\n",
            "12056:\tlearn: 7.6741520\ttotal: 1m 12s\tremaining: 741ms\n",
            "12057:\tlearn: 7.6741416\ttotal: 1m 12s\tremaining: 735ms\n",
            "12058:\tlearn: 7.6741369\ttotal: 1m 12s\tremaining: 729ms\n",
            "12059:\tlearn: 7.6741228\ttotal: 1m 12s\tremaining: 723ms\n",
            "12060:\tlearn: 7.6741138\ttotal: 1m 12s\tremaining: 717ms\n",
            "12061:\tlearn: 7.6740923\ttotal: 1m 12s\tremaining: 711ms\n",
            "12062:\tlearn: 7.6740895\ttotal: 1m 12s\tremaining: 705ms\n",
            "12063:\tlearn: 7.6740761\ttotal: 1m 12s\tremaining: 699ms\n",
            "12064:\tlearn: 7.6740695\ttotal: 1m 12s\tremaining: 693ms\n",
            "12065:\tlearn: 7.6740672\ttotal: 1m 12s\tremaining: 687ms\n",
            "12066:\tlearn: 7.6740449\ttotal: 1m 12s\tremaining: 681ms\n",
            "12067:\tlearn: 7.6740365\ttotal: 1m 12s\tremaining: 675ms\n",
            "12068:\tlearn: 7.6740231\ttotal: 1m 12s\tremaining: 669ms\n",
            "12069:\tlearn: 7.6740194\ttotal: 1m 12s\tremaining: 663ms\n",
            "12070:\tlearn: 7.6740092\ttotal: 1m 12s\tremaining: 657ms\n",
            "12071:\tlearn: 7.6739959\ttotal: 1m 12s\tremaining: 651ms\n",
            "12072:\tlearn: 7.6739927\ttotal: 1m 12s\tremaining: 645ms\n",
            "12073:\tlearn: 7.6739878\ttotal: 1m 12s\tremaining: 639ms\n",
            "12074:\tlearn: 7.6739811\ttotal: 1m 12s\tremaining: 633ms\n",
            "12075:\tlearn: 7.6739751\ttotal: 1m 12s\tremaining: 627ms\n",
            "12076:\tlearn: 7.6739672\ttotal: 1m 12s\tremaining: 621ms\n",
            "12077:\tlearn: 7.6739533\ttotal: 1m 12s\tremaining: 615ms\n",
            "12078:\tlearn: 7.6739418\ttotal: 1m 12s\tremaining: 609ms\n",
            "12079:\tlearn: 7.6739267\ttotal: 1m 12s\tremaining: 603ms\n",
            "12080:\tlearn: 7.6739157\ttotal: 1m 12s\tremaining: 597ms\n",
            "12081:\tlearn: 7.6739053\ttotal: 1m 12s\tremaining: 591ms\n",
            "12082:\tlearn: 7.6738943\ttotal: 1m 12s\tremaining: 585ms\n",
            "12083:\tlearn: 7.6738697\ttotal: 1m 12s\tremaining: 579ms\n",
            "12084:\tlearn: 7.6738529\ttotal: 1m 12s\tremaining: 573ms\n",
            "12085:\tlearn: 7.6738401\ttotal: 1m 12s\tremaining: 567ms\n",
            "12086:\tlearn: 7.6738346\ttotal: 1m 12s\tremaining: 561ms\n",
            "12087:\tlearn: 7.6738256\ttotal: 1m 12s\tremaining: 555ms\n",
            "12088:\tlearn: 7.6738225\ttotal: 1m 12s\tremaining: 549ms\n",
            "12089:\tlearn: 7.6738196\ttotal: 1m 12s\tremaining: 544ms\n",
            "12090:\tlearn: 7.6738126\ttotal: 1m 12s\tremaining: 538ms\n",
            "12091:\tlearn: 7.6738019\ttotal: 1m 12s\tremaining: 532ms\n",
            "12092:\tlearn: 7.6737805\ttotal: 1m 12s\tremaining: 526ms\n",
            "12093:\tlearn: 7.6737787\ttotal: 1m 12s\tremaining: 520ms\n",
            "12094:\tlearn: 7.6737582\ttotal: 1m 12s\tremaining: 514ms\n",
            "12095:\tlearn: 7.6737509\ttotal: 1m 12s\tremaining: 508ms\n",
            "12096:\tlearn: 7.6737304\ttotal: 1m 12s\tremaining: 502ms\n",
            "12097:\tlearn: 7.6737170\ttotal: 1m 12s\tremaining: 496ms\n",
            "12098:\tlearn: 7.6737008\ttotal: 1m 12s\tremaining: 490ms\n",
            "12099:\tlearn: 7.6736979\ttotal: 1m 12s\tremaining: 484ms\n",
            "12100:\tlearn: 7.6736632\ttotal: 1m 12s\tremaining: 478ms\n",
            "12101:\tlearn: 7.6736525\ttotal: 1m 12s\tremaining: 472ms\n",
            "12102:\tlearn: 7.6736426\ttotal: 1m 12s\tremaining: 466ms\n",
            "12103:\tlearn: 7.6736322\ttotal: 1m 12s\tremaining: 460ms\n",
            "12104:\tlearn: 7.6736218\ttotal: 1m 12s\tremaining: 454ms\n",
            "12105:\tlearn: 7.6736154\ttotal: 1m 12s\tremaining: 448ms\n",
            "12106:\tlearn: 7.6736006\ttotal: 1m 12s\tremaining: 442ms\n",
            "12107:\tlearn: 7.6735890\ttotal: 1m 12s\tremaining: 436ms\n",
            "12108:\tlearn: 7.6735786\ttotal: 1m 12s\tremaining: 430ms\n",
            "12109:\tlearn: 7.6735653\ttotal: 1m 12s\tremaining: 424ms\n",
            "12110:\tlearn: 7.6735641\ttotal: 1m 12s\tremaining: 418ms\n",
            "12111:\tlearn: 7.6735537\ttotal: 1m 12s\tremaining: 412ms\n",
            "12112:\tlearn: 7.6735349\ttotal: 1m 12s\tremaining: 406ms\n",
            "12113:\tlearn: 7.6735308\ttotal: 1m 12s\tremaining: 400ms\n",
            "12114:\tlearn: 7.6735262\ttotal: 1m 12s\tremaining: 394ms\n",
            "12115:\tlearn: 7.6735146\ttotal: 1m 12s\tremaining: 388ms\n",
            "12116:\tlearn: 7.6734972\ttotal: 1m 12s\tremaining: 382ms\n",
            "12117:\tlearn: 7.6734917\ttotal: 1m 12s\tremaining: 376ms\n",
            "12118:\tlearn: 7.6734799\ttotal: 1m 12s\tremaining: 370ms\n",
            "12119:\tlearn: 7.6734706\ttotal: 1m 12s\tremaining: 364ms\n",
            "12120:\tlearn: 7.6734509\ttotal: 1m 12s\tremaining: 358ms\n",
            "12121:\tlearn: 7.6734364\ttotal: 1m 12s\tremaining: 352ms\n",
            "12122:\tlearn: 7.6734237\ttotal: 1m 12s\tremaining: 346ms\n",
            "12123:\tlearn: 7.6734170\ttotal: 1m 12s\tremaining: 340ms\n",
            "12124:\tlearn: 7.6734037\ttotal: 1m 12s\tremaining: 334ms\n",
            "12125:\tlearn: 7.6733930\ttotal: 1m 12s\tremaining: 329ms\n",
            "12126:\tlearn: 7.6733930\ttotal: 1m 12s\tremaining: 323ms\n",
            "12127:\tlearn: 7.6733843\ttotal: 1m 12s\tremaining: 317ms\n",
            "12128:\tlearn: 7.6733756\ttotal: 1m 12s\tremaining: 311ms\n",
            "12129:\tlearn: 7.6733730\ttotal: 1m 12s\tremaining: 305ms\n",
            "12130:\tlearn: 7.6733635\ttotal: 1m 12s\tremaining: 299ms\n",
            "12131:\tlearn: 7.6733475\ttotal: 1m 12s\tremaining: 293ms\n",
            "12132:\tlearn: 7.6733377\ttotal: 1m 12s\tremaining: 287ms\n",
            "12133:\tlearn: 7.6733328\ttotal: 1m 12s\tremaining: 281ms\n",
            "12134:\tlearn: 7.6733197\ttotal: 1m 12s\tremaining: 275ms\n",
            "12135:\tlearn: 7.6733023\ttotal: 1m 12s\tremaining: 269ms\n",
            "12136:\tlearn: 7.6732934\ttotal: 1m 12s\tremaining: 263ms\n",
            "12137:\tlearn: 7.6732818\ttotal: 1m 12s\tremaining: 257ms\n",
            "12138:\tlearn: 7.6732754\ttotal: 1m 12s\tremaining: 251ms\n",
            "12139:\tlearn: 7.6732635\ttotal: 1m 12s\tremaining: 245ms\n",
            "12140:\tlearn: 7.6732557\ttotal: 1m 12s\tremaining: 239ms\n",
            "12141:\tlearn: 7.6732386\ttotal: 1m 12s\tremaining: 233ms\n",
            "12142:\tlearn: 7.6732294\ttotal: 1m 12s\tremaining: 227ms\n",
            "12143:\tlearn: 7.6732198\ttotal: 1m 12s\tremaining: 221ms\n",
            "12144:\tlearn: 7.6731937\ttotal: 1m 12s\tremaining: 215ms\n",
            "12145:\tlearn: 7.6731871\ttotal: 1m 12s\tremaining: 209ms\n",
            "12146:\tlearn: 7.6731688\ttotal: 1m 12s\tremaining: 203ms\n",
            "12147:\tlearn: 7.6731596\ttotal: 1m 12s\tremaining: 197ms\n",
            "12148:\tlearn: 7.6731503\ttotal: 1m 12s\tremaining: 191ms\n",
            "12149:\tlearn: 7.6731329\ttotal: 1m 12s\tremaining: 185ms\n",
            "12150:\tlearn: 7.6731237\ttotal: 1m 12s\tremaining: 179ms\n",
            "12151:\tlearn: 7.6731190\ttotal: 1m 12s\tremaining: 173ms\n",
            "12152:\tlearn: 7.6731098\ttotal: 1m 12s\tremaining: 167ms\n",
            "12153:\tlearn: 7.6731057\ttotal: 1m 12s\tremaining: 161ms\n",
            "12154:\tlearn: 7.6731011\ttotal: 1m 12s\tremaining: 155ms\n",
            "12155:\tlearn: 7.6730872\ttotal: 1m 12s\tremaining: 149ms\n",
            "12156:\tlearn: 7.6730831\ttotal: 1m 12s\tremaining: 143ms\n",
            "12157:\tlearn: 7.6730692\ttotal: 1m 12s\tremaining: 137ms\n",
            "12158:\tlearn: 7.6730623\ttotal: 1m 12s\tremaining: 131ms\n",
            "12159:\tlearn: 7.6730481\ttotal: 1m 12s\tremaining: 125ms\n",
            "12160:\tlearn: 7.6730313\ttotal: 1m 12s\tremaining: 119ms\n",
            "12161:\tlearn: 7.6730249\ttotal: 1m 12s\tremaining: 113ms\n",
            "12162:\tlearn: 7.6730194\ttotal: 1m 12s\tremaining: 108ms\n",
            "12163:\tlearn: 7.6730075\ttotal: 1m 12s\tremaining: 102ms\n",
            "12164:\tlearn: 7.6729974\ttotal: 1m 12s\tremaining: 95.6ms\n",
            "12165:\tlearn: 7.6729809\ttotal: 1m 12s\tremaining: 89.6ms\n",
            "12166:\tlearn: 7.6729684\ttotal: 1m 12s\tremaining: 83.6ms\n",
            "12167:\tlearn: 7.6729537\ttotal: 1m 12s\tremaining: 77.6ms\n",
            "12168:\tlearn: 7.6729505\ttotal: 1m 12s\tremaining: 71.7ms\n",
            "12169:\tlearn: 7.6729374\ttotal: 1m 12s\tremaining: 65.7ms\n",
            "12170:\tlearn: 7.6729360\ttotal: 1m 12s\tremaining: 59.7ms\n",
            "12171:\tlearn: 7.6729186\ttotal: 1m 12s\tremaining: 53.8ms\n",
            "12172:\tlearn: 7.6729041\ttotal: 1m 12s\tremaining: 47.8ms\n",
            "12173:\tlearn: 7.6728923\ttotal: 1m 12s\tremaining: 41.8ms\n",
            "12174:\tlearn: 7.6728833\ttotal: 1m 12s\tremaining: 35.8ms\n",
            "12175:\tlearn: 7.6728711\ttotal: 1m 12s\tremaining: 29.9ms\n",
            "12176:\tlearn: 7.6728505\ttotal: 1m 12s\tremaining: 23.9ms\n",
            "12177:\tlearn: 7.6728427\ttotal: 1m 12s\tremaining: 17.9ms\n",
            "12178:\tlearn: 7.6728271\ttotal: 1m 12s\tremaining: 11.9ms\n",
            "12179:\tlearn: 7.6728146\ttotal: 1m 12s\tremaining: 5.97ms\n",
            "12180:\tlearn: 7.6728068\ttotal: 1m 12s\tremaining: 0us\n",
            " mean_squared_error: 7.794436216479928\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foHbYDoT1ut6"
      },
      "source": [
        "# Stacking Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBwqa0Mz2UKw"
      },
      "source": [
        "cat = catboost.CatBoostRegressor(**params_cat)\n",
        "lgb = lightgbm.LGBMRegressor(**best_lgb_params)\n",
        "xgb = xgboost.XGBRegressor(**params_xgb)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "pIm4Kale1uTR",
        "outputId": "6f714752-46a1-4c3e-d46a-d3e3692fe333"
      },
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import Lasso, ElasticNet, LinearRegression\n",
        "\n",
        "folds = KFold(n_splits = 10, random_state = 2021, shuffle = True)\n",
        "\n",
        "predictions = np.zeros((len(x_test),))\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(folds.split(x_train)):\n",
        "    print(f\"Fold: {fold}\")\n",
        "    X_train, X_val = x_train.values[trn_idx], x_train.values[val_idx]\n",
        "    Y_train, Y_val = y_train.values[trn_idx], y_train.values[val_idx]\n",
        "\n",
        "    model = StackingRegressor(\n",
        "            estimators = [\n",
        "                ('xgb', xgb),\n",
        "                ('cat', cat),\n",
        "                ('lgb', lgb)\n",
        "            ],\n",
        "            final_estimator=LinearRegression()\n",
        "        )\n",
        "   \n",
        "    model.fit(X_train, Y_train)\n",
        "    pred = model.predict(X_val)\n",
        "    error = mean_squared_error(Y_val, pred,squared = False)\n",
        "    print(f\" mean_squared_error: {error}\")\n",
        "    print(\"-\"*50)\n",
        "    \n",
        "    predictions += model.predict(x_test) / folds.n_splits "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
            "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00018079588095795137, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00018079588095795137\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06439204656539935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06439204656539935\n",
            "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3375c843bcea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msquared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \"\"\"\n\u001b[1;32m    687\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    182\u001b[0m                                        \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                        verbose=self.verbose)\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'drop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    880\u001b[0m     predictions = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    881\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 882\u001b[0;31m         for train, test in splits)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0minv_test_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    851\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                     categorical_feature=categorical_feature, callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    715\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                               callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    276\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2948\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   2949\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2950\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   2951\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "r7sikefec5Gq",
        "outputId": "817e84a0-6cbf-4ba7-a9ba-964ae5d84e5e"
      },
      "source": [
        "submit = pd.read_csv('/content/drive/MyDrive/dataset/kaggle/tabular-playground-series/2021-aug/tabular-playground-series-aug-2021_sample_submission.csv')\n",
        "submit['loss'] = predictions\n",
        "submit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>250000</td>\n",
              "      <td>8.465962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>250001</td>\n",
              "      <td>4.385302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>250002</td>\n",
              "      <td>8.648569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>250003</td>\n",
              "      <td>7.194910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>250004</td>\n",
              "      <td>6.851920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149995</th>\n",
              "      <td>399995</td>\n",
              "      <td>8.057907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149996</th>\n",
              "      <td>399996</td>\n",
              "      <td>7.580662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149997</th>\n",
              "      <td>399997</td>\n",
              "      <td>5.886419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149998</th>\n",
              "      <td>399998</td>\n",
              "      <td>5.054294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149999</th>\n",
              "      <td>399999</td>\n",
              "      <td>6.659585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id      loss\n",
              "0       250000  8.465962\n",
              "1       250001  4.385302\n",
              "2       250002  8.648569\n",
              "3       250003  7.194910\n",
              "4       250004  6.851920\n",
              "...        ...       ...\n",
              "149995  399995  8.057907\n",
              "149996  399996  7.580662\n",
              "149997  399997  5.886419\n",
              "149998  399998  5.054294\n",
              "149999  399999  6.659585\n",
              "\n",
              "[150000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ZoCWm2dGS5"
      },
      "source": [
        "submit.to_csv('/content/drive/MyDrive/dataset/kaggle/tabular-playground-series/2021-aug/submit12.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PksB08kUWKL6"
      },
      "source": [
        "# To Do\n",
        "* optuna integration 사용 해보기\n",
        "* 다른 모델 사용(Rasso, Ridge, ElasticNet)"
      ]
    }
  ]
}