{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "파이토치 CNN 연습.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNQfRxFlY8Mm6WBrqQNZydI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/O-Kpy/Kaggle/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_CNN_%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEJBGCEdf3Dv"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tf  # 학습할때 필요한 토치들을 여러형태로 바꿔줄수있다. \n",
        "from torch.utils.data import DataLoader, Dataset  # 데이터 배치사이즈 조정\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dml7Q2GVk9rV"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tf\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC7eUHOQxXyM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7b05e56-8ab4-47b7-e9b0-22f6733d7a36"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ob7msy9IlNEU",
        "outputId": "dfee6352-abf4-49a4-bb48-e173e17148e8"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goaXGtnilT5l"
      },
      "source": [
        "# transforms\n",
        "train_transf = tf.Compose([\n",
        "                           tf.RandomCrop(32),\n",
        "                           tf.RandomAffine(degrees=3),\n",
        "                           tf.ToTensor(),\n",
        "                           tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_transf = tf.Compose([\n",
        "                          tf.ToTensor(),\n",
        "                          tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2DwUuAwlwyL"
      },
      "source": [
        "train_transf = tf.Compose([\n",
        "                     tf.RandomAffine(degrees=3),\n",
        "                     tf.ToTensor(),\n",
        "                     tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "test_transf = tf.Compose([\n",
        "                          tf.ToTensor(),\n",
        "                          tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNPy5dIygrK0"
      },
      "source": [
        "transf = tf.Compose([\n",
        "                     tf.ToTensor(),\n",
        "                     tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC8zX4-Vlq7X",
        "outputId": "d0977114-7054-4bd6-a55d-2befe5527571"
      },
      "source": [
        "# 데이터 불러오기 \n",
        "# 다른곳에서 데이터를 불러올때는 따로 Class 만들어서 불러오기\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transf)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EC7hQVNmtPj",
        "outputId": "a664384e-fedb-49fc-f862-de34fb2e0458"
      },
      "source": [
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transf)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPKZttPigVkj",
        "outputId": "2d9171a3-9b44-4410-8e98-b4332d9a0f1a"
      },
      "source": [
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjQHWS64mF5O",
        "outputId": "98bea626-c1b6-4eaa-ae19-5014036c4d98"
      },
      "source": [
        "train_set[0][0]  # image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5373, -0.6627, -0.6078,  ...,  0.2392,  0.1922,  0.1608],\n",
              "         [-0.8745, -1.0000, -0.8588,  ..., -0.0353, -0.0667, -0.0431],\n",
              "         [-0.8039, -0.8745, -0.6157,  ..., -0.0745, -0.0588, -0.1451],\n",
              "         ...,\n",
              "         [ 0.6314,  0.5765,  0.5529,  ...,  0.2549, -0.5608, -0.5843],\n",
              "         [ 0.4118,  0.3569,  0.4588,  ...,  0.4431, -0.2392, -0.3490],\n",
              "         [ 0.3882,  0.3176,  0.4039,  ...,  0.6941,  0.1843, -0.0353]],\n",
              "\n",
              "        [[-0.5137, -0.6392, -0.6235,  ...,  0.0353, -0.0196, -0.0275],\n",
              "         [-0.8431, -1.0000, -0.9373,  ..., -0.3098, -0.3490, -0.3176],\n",
              "         [-0.8118, -0.9451, -0.7882,  ..., -0.3412, -0.3412, -0.4275],\n",
              "         ...,\n",
              "         [ 0.3333,  0.2000,  0.2627,  ...,  0.0431, -0.7569, -0.7333],\n",
              "         [ 0.0902, -0.0353,  0.1294,  ...,  0.1608, -0.5137, -0.5843],\n",
              "         [ 0.1294,  0.0118,  0.1137,  ...,  0.4431, -0.0745, -0.2784]],\n",
              "\n",
              "        [[-0.5059, -0.6471, -0.6627,  ..., -0.1529, -0.2000, -0.1922],\n",
              "         [-0.8431, -1.0000, -1.0000,  ..., -0.5686, -0.6078, -0.5529],\n",
              "         [-0.8353, -1.0000, -0.9373,  ..., -0.6078, -0.6078, -0.6706],\n",
              "         ...,\n",
              "         [-0.2471, -0.7333, -0.7961,  ..., -0.4510, -0.9451, -0.8431],\n",
              "         [-0.2471, -0.6706, -0.7647,  ..., -0.2627, -0.7333, -0.7333],\n",
              "         [-0.0902, -0.2627, -0.3176,  ...,  0.0980, -0.3412, -0.4353]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLNy5JztmYIm",
        "outputId": "95d244e7-1676-4555-c183-aac44028876a"
      },
      "source": [
        "train_set[0][1]  # lable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl4qBlkmhPEC",
        "outputId": "84f6f9c5-3915-4d09-99f2-22d8f0972297"
      },
      "source": [
        "train_set[0][0].shape  # 채널 3개 8*8사이즈"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "NCUYnn9BmiZH",
        "outputId": "4d187c5d-bf93-4705-b17f-bb3f1a6bca3c"
      },
      "source": [
        "img = train_set[2][0].numpy()\n",
        "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S84hnCidnGA1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "bGa5vshVoqPZ",
        "outputId": "27edcd7a-7ce8-4535-afb7-e993ce08b204"
      },
      "source": [
        "def custom_imshow(img):\n",
        "    img = img.numpy()\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  # 이미지크기 -> 채널 순으로 바꾸기\n",
        "    plt.show()\n",
        "\n",
        " \n",
        "\n",
        "def process():\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_dl):\n",
        "        custom_imshow(inputs[0])\n",
        "        break\n",
        "\n",
        "process()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuaQSk7VpX52",
        "outputId": "06f2efde-d7b4-4f5e-f993-aafac6921ee8"
      },
      "source": [
        "# 모델 만들기(Custom)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "    self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)  # ==> flatten()\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "  # 원래는 이 자리에 transforms집어넣어야함 \n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(2, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-z4LN1ZvXHc",
        "outputId": "fd1a1f10-e0c3-4113-e884-3dd59019c25a"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=16*5*5, out_features = 120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "    self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex3zu-5vshAL",
        "outputId": "57c20f47-a5a1-4269-9d55-1b411dd314e2"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)  \n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)  ## classes가 10개이기때문\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n",
        "net.to(device)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b__oIBu-qoIN"
      },
      "source": [
        "# DataLoader 사용 모델 돌리기 전에 데이터 셋 준비\n",
        "train_dl = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=2)\n",
        "test_dl = DataLoader(test_set, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPRzt3T8hV_r"
      },
      "source": [
        "train_dl = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=2)\n",
        "test_dl = DataLoader(test_set, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bhOf0QXhtM9",
        "outputId": "c12bc58a-6e9d-4c97-d046-1371c52d0234"
      },
      "source": [
        "for x,y in train_dl:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break \n",
        "# 배치사이즈 8, 채널 3개, 32*32크기의 이미지"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 32, 32])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC3a87RGt8F0"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)  # momentum ==> 속도(?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vvZt2SyrDq2",
        "outputId": "3d72a665-e75b-49e2-d433-f58162bc096b"
      },
      "source": [
        "for epoch in range(5):\n",
        "  running_loss = 0.0\n",
        "  net.train()\n",
        "  for i, data in enumerate(train_dl, 0):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = net(inputs)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss = loss.item()\n",
        "\n",
        "    if i % 2000 == 1999:\n",
        "      print(f'epoch{epoch+1}, loss:{running_loss}')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    correct, total=0, 0\n",
        "    for images, labels in test_dl:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  print(f'{epoch+1}epoch Val Accuracy:{100*correct/total}%')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch1, loss:1.8523128032684326\n",
            "epoch1, loss:1.1082526445388794\n",
            "epoch1, loss:0.9003583788871765\n",
            "1epoch Val Accuracy:52.13%\n",
            "epoch2, loss:1.4025157690048218\n",
            "epoch2, loss:1.3520389795303345\n",
            "epoch2, loss:0.6463478207588196\n",
            "2epoch Val Accuracy:54.79%\n",
            "epoch3, loss:1.6448726654052734\n",
            "epoch3, loss:0.7909791469573975\n",
            "epoch3, loss:1.2029054164886475\n",
            "3epoch Val Accuracy:59.13%\n",
            "epoch4, loss:0.8945367336273193\n",
            "epoch4, loss:0.9018144607543945\n",
            "epoch4, loss:1.7237244844436646\n",
            "4epoch Val Accuracy:60.37%\n",
            "epoch5, loss:1.6356837749481201\n",
            "epoch5, loss:0.5191423296928406\n",
            "epoch5, loss:0.24466899037361145\n",
            "5epoch Val Accuracy:60.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "32EL4MZ-uc51",
        "outputId": "8ab450e1-7884-409f-c096-390f801bba09"
      },
      "source": [
        "for epoch in range(5):\n",
        "  running_loss = 0.0\n",
        "  net.train()\n",
        "  for i, data in enumerate(train_dl, 0):\n",
        "    input, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(input)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print('[epoch:%d, %5d] loss:%.3f' %(epoch+1, i+1, running_loss / 2000))\n",
        "      running_loss=0.0\n",
        "  with torch.no_grad():\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in test_dl:\n",
        "      images, labels = data\n",
        "      outputs = net(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)  # == argmax() 가장 큰 자리값을 구하겠다.\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  print('%d% Epochs Val Accuracy:%d%%' %(epoch+1, 100*correct/total))\n",
        "print('Finisihed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch:1,  2000] loss:2.304\n",
            "[epoch:1,  4000] loss:2.305\n",
            "[epoch:1,  6000] loss:2.304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-de6462fce247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d% Epochs Val Accuracy:%d%%'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finisihed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not enough arguments for format string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6-1Ghau68AR",
        "outputId": "d15929e7-dbec-4f7c-9a86-acce44427e2e"
      },
      "source": [
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for data in test_dl:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  # == argmax() 가장 큰 자리값을 구하겠다.\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Val Accuracy:%d%%' %(100*correct/total))\n",
        "print('Finisihed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Accuracy:62%\n",
            "Finisihed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5mJyG9C0suP"
      },
      "source": [
        "# 저장\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "# 불러오기\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIinZNph04_X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYojfeE1lNEI"
      },
      "source": [
        "class MyDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, transforms=None):\n",
        "        self.X = images\n",
        "        self.y = labels\n",
        "        self.transforms = transforms\n",
        "        self.len = len(labels)\n",
        "                    \n",
        "    def __len__(self):\n",
        "        return len\n",
        "    \n",
        "    def __getitem__(self, index):  # 데이터를 튜플형태로 내보낸다(getitem)\n",
        "        data = self.X[index], self.y[index] # gets the row\n",
        "        # reshape the row into the image size \n",
        "        # (numpy arrays have the color channels dim last)\n",
        "        data = np.array(data).astype(np.uint8).reshape(28, 28, 1) \n",
        "        \n",
        "        # perform transforms if there are any\n",
        "        if self.transforms:\n",
        "            data = self.transforms(data)\n",
        "        \n",
        "        # if !test_set return the label as well, otherwise don't\n",
        "        if self.y is not None: # train/val\n",
        "            return (data, self.y[i])\n",
        "        else: # test\n",
        "            return data\n",
        "\n",
        "class ToTensor:  ## data 받기\n",
        "  def __call__(self, data):\n",
        "    x_data, y_data = data\n",
        "    x_data = torch.FloatTensor(x_data)  # x_data 변환\n",
        "    x_data = x.data.permute(2,0,1)  # x_data 채널수와 이미지 사이즈 순서 변환\n",
        "    return x_data, torch.LongTensor(y_data)  # y_data LongTensor로 변환"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}