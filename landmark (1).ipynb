{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T05:45:11.138168Z","iopub.execute_input":"2021-11-01T05:45:11.138536Z","iopub.status.idle":"2021-11-01T05:45:20.327398Z","shell.execute_reply.started":"2021-11-01T05:45:11.138454Z","shell.execute_reply":"2021-11-01T05:45:20.326604Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport random\nimport time\nimport copy\nfrom PIL import Image\n\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport torchvision.transforms as T\n\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n\nimport timm\n\nfrom colorama import Fore, Back, Style\ng_ = Fore.GREEN\nc_ = Fore.CYAN\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-11-01T05:55:55.425719Z","iopub.execute_input":"2021-11-01T05:55:55.426319Z","iopub.status.idle":"2021-11-01T05:55:59.661835Z","shell.execute_reply.started":"2021-11-01T05:55:55.426280Z","shell.execute_reply":"2021-11-01T05:55:59.661023Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret('wandb_api')\n    wandb.login(key=api_key)\n    anony=None\nexcept:\n    anony = 'must'","metadata":{"execution":{"iopub.status.busy":"2021-11-01T05:57:45.929988Z","iopub.execute_input":"2021-11-01T05:57:45.930613Z","iopub.status.idle":"2021-11-01T05:57:46.071519Z","shell.execute_reply.started":"2021-11-01T05:57:45.930574Z","shell.execute_reply":"2021-11-01T05:57:46.070839Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/landmark-retrieval-2021'\nTRAIN_DIR = '../input/landmark-retrieval-2021/train'\nTEST_DIR = '../input/landmark-retrieval-2021/test'","metadata":{"execution":{"iopub.status.busy":"2021-11-01T05:58:19.961143Z","iopub.execute_input":"2021-11-01T05:58:19.961897Z","iopub.status.idle":"2021-11-01T05:58:19.965607Z","shell.execute_reply.started":"2021-11-01T05:58:19.961862Z","shell.execute_reply":"2021-11-01T05:58:19.964683Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    seed = 42,\n    model_name = 'tf_mobilenetv3_small_100',\n    train_batch_size = 256,\n    valid_batch_size = 512,\n    img_size = 256,\n    epochs = 6,\n    learning_rate = 5e-4,\n    min_lr = 1e-6,\n    T_max = 100,\n    T_0 = 25,\n    weight_decay=1e-6,\n    n_accumulate = 1,\n    num_classes = 81313,\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n    competition = 'Google',\n    wandb_kernel = 'deb',\n    n_fold = 5\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:01:54.823937Z","iopub.execute_input":"2021-11-01T06:01:54.824592Z","iopub.status.idle":"2021-11-01T06:01:54.875652Z","shell.execute_reply.started":"2021-11-01T06:01:54.824551Z","shell.execute_reply":"2021-11-01T06:01:54.874669Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    os.environ['PYTHONHASHSEED'] = str(seed)  # set a fixed value for the 'hash' seed\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:03:27.447315Z","iopub.execute_input":"2021-11-01T06:03:27.447571Z","iopub.status.idle":"2021-11-01T06:03:27.453812Z","shell.execute_reply.started":"2021-11-01T06:03:27.447543Z","shell.execute_reply":"2021-11-01T06:03:27.453039Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Read the Data","metadata":{}},{"cell_type":"code","source":"def get_train_file_path(id):\n    return f'{TRAIN_DIR}/{id[0]}/{id[1]}/{id[2]}/{id}.jpg'","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:04:14.671502Z","iopub.execute_input":"2021-11-01T06:04:14.672119Z","iopub.status.idle":"2021-11-01T06:04:14.676350Z","shell.execute_reply.started":"2021-11-01T06:04:14.672079Z","shell.execute_reply":"2021-11-01T06:04:14.675229Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n\nle = LabelEncoder()\ndf['landmark_id'] = le.fit_transform(df['landmark_id'])\n\ndf['file_path'] = df['id'].apply(get_train_file_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:05:42.389336Z","iopub.execute_input":"2021-11-01T06:05:42.390184Z","iopub.status.idle":"2021-11-01T06:05:44.710231Z","shell.execute_reply.started":"2021-11-01T06:05:42.390135Z","shell.execute_reply":"2021-11-01T06:05:44.709369Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Image","metadata":{}},{"cell_type":"code","source":"run = wandb.init(project='GLRet2021',\n                 config=CONFIG,\n                 job_type='Visualizaion',\n                 anonymous='must')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T12:36:37.924085Z","iopub.execute_input":"2021-10-27T12:36:37.92469Z","iopub.status.idle":"2021-10-27T12:36:44.565545Z","shell.execute_reply.started":"2021-10-27T12:36:37.924648Z","shell.execute_reply":"2021-10-27T12:36:44.564735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preview_table = wandb.Table(columns=['Id', 'Image', 'Landmark'])\ntmp_df = df.sample(3000, random_state=CONFIG['seHorizontalFlipndex(drop=True)\nfor i in tqdm(range(len(tmp_df))):\n    row = tmp_df.loc[i]\n    img = Image.open(row['file_path'])\n    preview_table.add_data(row['id'], wandb.Image(img), row['landmark_id'])\n    \nwandb.log({'Visualization':preview_table})\nrun.finish()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T11:35:55.854359Z","iopub.execute_input":"2021-10-27T11:35:55.854729Z","iopub.status.idle":"2021-10-27T11:46:40.383388Z","shell.execute_reply.started":"2021-10-27T11:35:55.854695Z","shell.execute_reply":"2021-10-27T11:46:40.382676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_valid = train_test_split(df, test_size=0.3, stratify=df['landmark_id'], shuffle=True, random_state=CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T13:07:31.825222Z","iopub.execute_input":"2021-10-27T13:07:31.825478Z","iopub.status.idle":"2021-10-27T13:07:34.732086Z","shell.execute_reply.started":"2021-10-27T13:07:31.825448Z","shell.execute_reply":"2021-10-27T13:07:34.731319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = train_test_split(df, test_size=0.4, stratify=df['landmark_id'],\n                                     shuffle=True, random_state=CONFIG['seed'])  # Train셋, Test셋 나누기\ndf_valid, df_test = train_test_split(df_test, test_size=0.5, shuffle=True,\n                                     random_state=CONFIG['seed'])  # Valid셋과 Test셋 나누기","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:12:25.608896Z","iopub.execute_input":"2021-11-01T06:12:25.609460Z","iopub.status.idle":"2021-11-01T06:12:28.322994Z","shell.execute_reply.started":"2021-11-01T06:12:25.609424Z","shell.execute_reply":"2021-11-01T06:12:28.322189Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class LandmarkDataset(Dataset):\n    def __init__(self, root_dir, df, transforms=True):\n        self.root_dir = root_dir\n        self.df = df\n        self.file_name = df['file_path'].values\n        self.labels = df['landmark_id'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_name[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        labels = self.labels[index]\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        return img, labels","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:20:49.574743Z","iopub.execute_input":"2021-11-01T06:20:49.575341Z","iopub.status.idle":"2021-11-01T06:20:49.581913Z","shell.execute_reply.started":"2021-11-01T06:20:49.575304Z","shell.execute_reply":"2021-11-01T06:20:49.581215Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentations","metadata":{}},{"cell_type":"code","source":"MEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\n\ndata_transforms = {\n    'train' : A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(),\n        A.CoarseDropout(),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0, p=1.0),\n        ToTensorV2()\n    ], p=1.0),\n    \n    'valid' : A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0, p=1.0),\n        ToTensorV2()\n    ], p=1.0)\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:23:27.433541Z","iopub.execute_input":"2021-11-01T06:23:27.433907Z","iopub.status.idle":"2021-11-01T06:23:27.441842Z","shell.execute_reply.started":"2021-11-01T06:23:27.433870Z","shell.execute_reply":"2021-11-01T06:23:27.439865Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class LandmarkModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super(LandmarkModel, self).__init__()\n        self.model = timm.create_model(model_name=model_name, pretrained=pretrained)\n        self.in_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.in_features, CONFIG['num_classes'])\n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self, images):\n        features = self.model(images)\n        features = self.dropout(features)\n        output = self.fc(features)\n        return output\n    \nmodel = LandmarkModel(CONFIG['model_name'])\nmodel.to(CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:40:44.848708Z","iopub.execute_input":"2021-11-01T06:40:44.849081Z","iopub.status.idle":"2021-11-01T06:40:50.722443Z","shell.execute_reply.started":"2021-11-01T06:40:44.849042Z","shell.execute_reply":"2021-11-01T06:40:50.721768Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class LandmarkModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super(LandmarkModel, self).__init__()\n        self.model = timm.create_model(model_name=model_name, pretrained=pretrained)\n        self.in_features = self.model.classifier.in_features\n        self.model.reset_classifier(0)\n        self.fc = nn.Linear(self.in_features, CONFIG['num_classes'])\n        # self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self, x):\n        features = self.model(x)\n        # features = self.dropout(features)\n        output = self.fc(features)\n        return output\n    \n    def extract_features(self, x):\n        features = self.model(x)\n        # features = self.dropout(features)\n        return features\n    \nmodel = LandmarkModel(CONFIG['model_name'])\nmodel.to(CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T13:07:37.814425Z","iopub.execute_input":"2021-10-27T13:07:37.814889Z","iopub.status.idle":"2021-10-27T13:07:43.686802Z","shell.execute_reply.started":"2021-10-27T13:07:37.81485Z","shell.execute_reply":"2021-10-27T13:07:43.686095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss Function\n\ndef criterion(outputs, targets):\n    return nn.CrossEntropyLoss()(outputs, targets)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T06:43:07.947891Z","iopub.execute_input":"2021-11-01T06:43:07.948157Z","iopub.status.idle":"2021-11-01T06:43:07.954360Z","shell.execute_reply.started":"2021-11-01T06:43:07.948129Z","shell.execute_reply":"2021-11-01T06:43:07.953519Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training ","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, labels) in bar:\n        images = images.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n        \n        with amp.autocast(enabled=True):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss = loss / CONFIG['n_accumulate']\n            \n        scaler.scale(loss).backward()\n        \n        if (step+1) % CONFIG['n_accumulate'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            \n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n        \n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:22:45.445654Z","iopub.execute_input":"2021-11-01T07:22:45.446219Z","iopub.status.idle":"2021-11-01T07:22:45.460992Z","shell.execute_reply.started":"2021-11-01T07:22:45.446182Z","shell.execute_reply":"2021-11-01T07:22:45.460232Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, labels) in bar:         \n        images = images.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n        \n        with amp.autocast(enabled=True):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss = loss / CONFIG['n_accumulate']\n            \n        scaler.scale(loss).backward()\n    \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n\n            # zero the parameter gradients\n            # optimizer.zero_grad()\n            for p in model.parameters():\n                p.grad = None\n\n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss/dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2021-10-27T13:07:48.67893Z","iopub.execute_input":"2021-10-27T13:07:48.67949Z","iopub.status.idle":"2021-10-27T13:07:48.690115Z","shell.execute_reply.started":"2021-10-27T13:07:48.67945Z","shell.execute_reply":"2021-10-27T13:07:48.689429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, model_name, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, labels) in bar:\n        images = images.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images)\n        _, preds = torch.max(outputs, 1)\n        loss = criterion(outputs, labels)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        PREDS.append(preds.view(-1).cpu().detach().numpy())\n        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n    \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_acc = accuracy_score(TARGETS, PREDS)\n    gc.collect()\n    \n    return epoch_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:03:51.231735Z","iopub.execute_input":"2021-11-01T07:03:51.232349Z","iopub.status.idle":"2021-11-01T07:03:51.243854Z","shell.execute_reply.started":"2021-11-01T07:03:51.232311Z","shell.execute_reply":"2021-11-01T07:03:51.242106Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, labels) in bar:        \n        images = images.to(device, dtype=torch.float)\n        labels = labels.to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images)\n        _, preds = torch.max(outputs,1)\n        loss = criterion(outputs, labels)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss/dataset_size\n        \n        PREDS.append(preds.view(-1).cpu().detach().numpy())\n        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_acc = accuracy_score(TARGETS, PREDS)\n    gc.collect()\n    \n    return epoch_loss, val_acc","metadata":{"execution":{"iopub.status.busy":"2021-10-27T13:07:50.482896Z","iopub.execute_input":"2021-10-27T13:07:50.483357Z","iopub.status.idle":"2021-10-27T13:07:50.492887Z","shell.execute_reply.started":"2021-10-27T13:07:50.483321Z","shell.execute_reply":"2021-10-27T13:07:50.492115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run Training","metadata":{}},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    wandb.watch(model, log_freq=100)\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_acc = 0\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler,\n                                           dataloader=train_loader, device=CONFIG['device'], epoch=epoch)\n        val_epoch_loss, val_epoch_acc = valid_one_epoch(model, dataloader=valid_loader, \n                                                        device=CONFIG['device'], epoch=epoch)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Valid Acc'].append(val_epoch_acc)\n        \n        wandb.log({'Train Loss' : train_epoch_loss})\n        wandb.log({'Valid Loss' : val_epoch_loss})\n        wandb.log({'Valid Acc' : val_epoch_acc})\n        \n        print(f'Valid Accuracy : {val_epoch_acc}')\n        \n        if val_epoch_acc >= best_epoch_acc:\n            print(f'{c_}Validation Acc Improved({best_epoch_acc} --> {val_epoch_acc})')\n            best_epoch_acc = val_epoch_acc\n            run.summary['Best Accuracy'] = best_epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f'Epoch{epoch}.bin'\n            torch.save(model.state_dict(), PATH)\n            wandb.save(PATH)\n            print(f'Model Saved{sr_}')\n            \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best ACC: {:.4f}\".format(best_epoch_acc))\n    \n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:16:14.933551Z","iopub.execute_input":"2021-11-01T07:16:14.933836Z","iopub.status.idle":"2021-11-01T07:16:14.946064Z","shell.execute_reply.started":"2021-11-01T07:16:14.933784Z","shell.execute_reply":"2021-11-01T07:16:14.945200Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# DataLoader\ndef prepare_loader():\n    train_dataset = LandmarkDataset(TRAIN_DIR, df_train, transforms=data_transforms['train'])\n    valid_dataset = LandmarkDataset(TRAIN_DIR, df_valid, transforms=data_transforms['valid'])\n    \n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], shuffle=True, pin_memory=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader\n\ntrain_loader, valid_loader = prepare_loader()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:19:55.354553Z","iopub.execute_input":"2021-11-01T07:19:55.355030Z","iopub.status.idle":"2021-11-01T07:19:55.360389Z","shell.execute_reply.started":"2021-11-01T07:19:55.354994Z","shell.execute_reply":"2021-11-01T07:19:55.359741Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr'])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:21:11.724680Z","iopub.execute_input":"2021-11-01T07:21:11.725272Z","iopub.status.idle":"2021-11-01T07:21:11.731431Z","shell.execute_reply.started":"2021-11-01T07:21:11.725233Z","shell.execute_reply":"2021-11-01T07:21:11.730533Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"run = wandb.init(project='GLRet2021', \n                 config=CONFIG,\n                 job_type='Train',\n                 anonymous='must')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:21:16.061370Z","iopub.execute_input":"2021-11-01T07:21:16.062112Z","iopub.status.idle":"2021-11-01T07:21:23.700914Z","shell.execute_reply.started":"2021-11-01T07:21:16.062072Z","shell.execute_reply":"2021-11-01T07:21:23.700133Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"mode, history = run_training(model, optimizer, scheduler,\n                            device=CONFIG['device'], num_epochs=CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T07:22:50.012116Z","iopub.execute_input":"2021-11-01T07:22:50.012382Z","iopub.status.idle":"2021-11-01T09:07:15.195428Z","shell.execute_reply.started":"2021-11-01T07:22:50.012354Z","shell.execute_reply":"2021-11-01T09:07:15.194096Z"},"trusted":true},"execution_count":32,"outputs":[]}]}